id,description,insecure_code,secure_code,severity,explanation_of_fix,Link,Confidence
Sol-001,"The vulnerability arises from missing a signer check for an account, which could allow unauthorized actions.","rust
authority: AccountInfo<'info>,","rust
authority: Signer<'info>,",High,"The secure code uses `Signer<'info>` instead of `AccountInfo<'info>`, ensuring the account is a transaction signer. This prevents unauthorized calls by requiring cryptographic proof of intent, a critical Solana security requirement.",,Medium
Sol-002,"The insecure code fails to properly check that the caller is the owner of the token before proceeding with operations, leading to a potential vulnerability where unauthorized users could interact with the contract as if they were the owner.","rust
if authority.key != token.owner { 
    return Err(ProgramError::InvalidAccountData); 
}","rust
#[account(constraint = authority.key == &token.owner)]",High,"The secure code uses Anchor’s `#[account(constraint)]` to enforce that the authority’s key matches the token’s owner at the account validation stage, preventing unauthorized operations by embedding the check in the framework’s runtime.",,Medium
Sol-003,"The vulnerability arises from the use of incorrect `seeds` for generating a Program Derived Address (PDA), thereby potentially allowing unauthorized token withdrawal or interaction with the wrong PDA.","rust
let seeds = &[
    ctx.accounts.pool.mint.as_ref(),
    &[ctx.accounts.pool.bump]
];","rust
let seeds = &[
    ctx.accounts.pool.withdraw_destination.as_ref(), 
    &[ctx.accounts.pool.bump]
];",Critical,"The secure code corrects the PDA seeds to use `withdraw_destination` instead of `mint`, ensuring the PDA aligns with the intended account. This prevents attackers from withdrawing tokens from an unintended PDA, a severe exploit vector.",,Medium
Sol-004,"The vulnerability involves incorrect seed canonicalization when creating a program address. Insecure code uses a provided `bump` seed that might not match the bump seed calculated by the Solana runtime, leading to potential bypass of security checks or other unintended behaviors.","rust
if address != ctx.accounts.data.key() {
    return Err(ProgramError::InvalidArgument);
}","rust
let (_, expected_bump) = Pubkey::find_program_address(&[key.to_le_bytes().as_ref()], ctx.program_id);

if expected_bump != bump {
    return Err(ProgramError::InvalidArgument);
}",High,"The secure code calculates the canonical `bump` using `Pubkey::find_program_address` and compares it to the provided `bump`, ensuring the PDA is valid and matches runtime expectations. This prevents spoofing or bypassing PDA-based security checks.",,Medium
Sol-005,"The ""TypeCosplay"" vulnerability involves the absence of a check to ensure an account's data matches the expected account type or discriminant, allowing an attacker to pass an account of an incorrect type.","rust
if ctx.accounts.user.owner != ctx.program_id { 
    return Err(ProgramError::IllegalOwner); 
}","rust
if ctx.accounts.user.owner != ctx.program_id { 
    return Err(ProgramError::IllegalOwner); 
} 

if user.discriminant != AccountDiscriminant::User { 
    return Err(ProgramError::InvalidAccountData); 
}",Medium,"The secure code adds a `discriminant` check to verify the account’s type matches `AccountDiscriminant::User`, preventing attackers from passing a different account type (e.g., a token account as a user account), which could disrupt contract logic.",,Medium
Sol-006,DuplicateMutableAccounts,"rust
let user_a = &mut ctx.accounts.user_a; 
let user_b = &mut ctx.accounts.user_b;","rust
if ctx.accounts.user_a.key() == ctx.accounts.user_b.key() {
    return Err(ProgramError::InvalidArgument)
}

let user_a = &mut ctx.accounts.user_a;
let user_b = &mut ctx.accounts.user_b;",Medium,"The secure code checks if `user_a` and `user_b` have the same key, rejecting duplicates. Solana disallows duplicate mutable accounts to prevent data races, and this fix ensures runtime compliance and prevents unintended state changes.",,Medium
Sol-007,"The vulnerability arises from not verifying if an account provided as 'authority' in a Solana smart contract function has actually signed the transaction, potentially allowing unauthorized actions.","rust
msg!(""GM {}"", authority.key().to_string());","if !authority.is_signer {
    return Err(ProgramError::MissingRequiredSignature);
}
msg!(""GM {}"", authority.key().to_string());",High,"The secure code adds an `is_signer` check, ensuring the `authority` account signed the transaction. This prevents unauthorized execution by requiring explicit signer validation, a fundamental Solana security measure.",,Medium
Sol-008,Not verifying if an account provided to a smart contract is the expected system account could lead to malicious actors exploiting the contract by providing incorrect accounts. This issue is particularly critical when dealing with system accounts like the Rent sysvar in Solana.,"rust
msg!(""Rent Key -> {}"", rent.key().to_string());","rust
require_eq!(rent.key(), sysvar::rent::ID);
msg!(""Rent Key -> {}"", rent.key().to_string());",Medium,"The secure code uses `require_eq!` to verify the `rent` account matches the Rent sysvar’s ID (`sysvar::rent::ID`). This ensures the contract uses the correct system account, preventing attackers from substituting fake sysvars.",,Medium
Sol-009,"The vulnerability arises from not properly validating the ownership of a token account in smart contracts, which could allow unauthorized access to sensitive actions or information by failing to ensure the account is a valid SPL token account owned by the SPL Token Program and controlled by the expected authority.","rust
if authority.key != &token.owner {
    return Err(ProgramError::InvalidAccountData);
}","rust
if *token.owner != *authority.key {
    return Err(ProgramError::InvalidAccountData);
} 
if token.account_type != spl_token::state::AccountType::Account {
    return Err(ProgramError::InvalidAccountData);
} 
if *token.program != spl_token::id() {
    return Err(ProgramError::InvalidAccountData);
}",High,"The secure code checks that the token’s owner matches the authority, the account is an SPL token account (`AccountType::Account`), and it’s owned by the SPL Token Program (`spl_token::id()`). This ensures only valid, authority-controlled token accounts are used, preventing unauthorized access.",,Medium
Sol-010,"The vulnerability arises from not checking if the called program in a Cross-Program Invocation (CPI) is the intended one, allowing potential arbitrary executions by malicious actors.","rust
fn cpi(
    token_program: AccountInfo, 
    source: AccountInfo, 
    destination: AccountInfo, 
    authority: AccountInfo, 
    amount: u64
) 
{
    invoke(
        &transfer(
            token_program.key, 
            source.key, 
            destination.key, 
            authority.key, 
            &[],
            amount
        ), 
        &[source, destination, authority]
    );
}","rust
fn cpi_secure(
    token_program: AccountInfo, 
    source: AccountInfo, 
    destination: AccountInfo, 
    authority: AccountInfo, 
    amount: u64
) {
    if &TOKEN_PROGRAM_ID != token_program.key {
        panic!(""Incorrect program ID"");
    } 
    invoke(
        &transfer(
            token_program.key, 
            source.key, 
            destination.key, 
            authority.key, 
            &[],
            amount
        ),
        &[source, destination, authority]
    );
}",Critical,"The secure code verifies the `token_program` matches `TOKEN_PROGRAM_ID` before the CPI, preventing calls to malicious programs. This stops arbitrary execution, a severe risk in Solana’s CPI model.",,Medium
Sol-011,"The vulnerability revolves around a smart contract's improper account closure process. The insecure code fails to properly zero out the data of a closed account, leaving residual data that could be potentially exploited or lead to inconsistent state representations. Ensuring the data of an account is cleared and marked with a discriminator indicating closure is crucial for security and data integrity.","rust
let dest_starting_lamports = destination.lamports(); 
*destination.lamports.borrow_mut() = dest_starting_lamports.checked_add(account.lamports()).unwrap(); 
*account.lamports.borrow_mut() = 0;","rust
let dest_starting_lamports = destination.lamports();
*destination.lamports.borrow_mut() = dest_starting_lamports
    .checked_add(account.lamports())
    .unwrap();
*account.lamports.borrow_mut() = 0;

let mut data = account.try_borrow_mut_data()?;

for byte in data.iter_mut() {
    *byte = 0;
}

let mut cursor = Cursor::new(&mut data);
cursor.write_all(&CLOSED_ACCOUNT_DISCRIMINATOR).unwrap();",Medium,"The secure code zeroes out the account data and writes a `CLOSED_ACCOUNT_DISCRIMINATOR`, ensuring no residual data remains and the account’s closure is explicitly marked. This prevents reuse or misinterpretation of closed accounts.",,Medium
Sol-012,"The vulnerability is related to the improper initialization of smart contracts, allowing for the possibility of reinitialization attacks, where an attacker might reinitialize already initialized accounts, or create and not properly initialize accounts, potentially compromising the contract's security.","rust
let mut user = User::try_from_slice(&data).unwrap(); 
user.authority = authority; 
user.serialize(&mut data).unwrap();","rust
let mut user = User::try_from_slice(&data).unwrap(); 

if user.discriminator {
    return Err(ProgramError::InvalidAccountData); 
}

user.authority = authority; 
user.discriminator = true; 
user.serialize(&mut data).unwrap();",High,"The secure code checks the `discriminator` to prevent reinitialization, then sets it after initializing the account. This ensures accounts are initialized only once, blocking attackers from overwriting state.",,Medium
Sol-013,"The vulnerability arises from not verifying if The caller (authority) is The actual owner of The token account prior to executing actions or revealing sensitive information, which can lead to unauthorized access or information disclosure.","rust
let token = SplTokenAccount::unpack(&token.data.borrow())?;
msg!(""Your account balance is: {}"", token.amount);","rust
let token = SplTokenAccount::unpack(&token.data.borrow())?;

if authority.key != &token.owner {
    return Err(ProgramError::InvalidAccountData);
} 

msg!(""Your account balance is: {}"", token.amount);",Medium,The secure code adds a check to ensure the `authority` matches the `token.owner` before revealing sensitive data (balance). This prevents unauthorized users from accessing token account information.,,Medium
Sol-014,"The vulnerability arises from unchecked arithmetic operations in smart contracts, which can lead to overflows or underflows in Rust's release mode, allowing attackers to manipulate balances or other critical values.","rust
let new_balance = account.balance + amount;
account.balance = new_balance;","rust
let new_balance = account.balance
    .checked_add(amount)
    .ok_or(ProgramError::ArithmeticOverflow)?;

account.balance = new_balance;",Critical,"The secure code uses `checked_add` to detect overflows, returning an error if the operation exceeds `u64` limits. This prevents balance manipulation, a severe exploit seen in Solana hacks like Mango Markets.",,Medium
Sol-015,"The vulnerability occurs when a smart contract assumes an account’s data is initialized without checking, potentially allowing attackers to exploit uninitialized or garbage data to bypass logic.","rust
let user_data = User::try_deserialize(&mut account.data.borrow())?;
if user_data.authority == authority.key() {
    process_action();
}","rust
if account.data.borrow().is_empty() {
    User::init(&mut account.data.borrow_mut(), authority.key())?;
} else {
    let user_data = User::try_deserialize(&mut account.data.borrow())?;
    if user_data.authority != authority.key() {
        return Err(ProgramError::InvalidAccountData);
    }
}

process_action();",High,"The secure code checks if the account data is empty and initializes it if so, otherwise validating the deserialized `authority`. This prevents logic bypass via uninitialized or attacker-controlled data.",,Medium
Sol-016,"The vulnerability arises from not re-verifying signer status in a Cross-Program Invocation (CPI), allowing attackers to spoof a signer’s authority by manipulating the calling context.","rust
invoke(
    &transfer_instruction,
    &[source.clone(), destination.clone(), authority.clone()],
)?;","rust
let signer_seeds = &[authority.key.as_ref(), &[bump]];
invoke_signed(
    &transfer_instruction, 
    &[source.clone(), destination.clone(), authority.clone()],
    &[&signer_seeds],
)?;",Critical,"The secure code uses `invoke_signed` with PDA seeds, ensuring the CPI call carries signer authority cryptographically. This prevents spoofing, a severe risk in Solana’s CPI model (e.g., Wormhole exploit).",,Medium
Sol-017,"The vulnerability stems from not validating state changes before and after external calls, such as flash loans, allowing attackers to temporarily manipulate balances or other contract states.","rust
let initial_balance = account.balance; 
external_call(&mut account)?; 
account.balance += reward;","rust
let initial_balance = account.balance;

external_call(&mut account)?;

if account.balance != initial_balance {
    return Err(ProgramError::InvalidState);
}

account.balance = initial_balance
     .checked_add(reward)
     .ok_or(ProgramError::ArithmeticOverflow)?;",High,"The secure code checks the balance before and after the external call, rejecting changes, and uses `checked_add` for the reward. This prevents flash loan manipulations and ensures state integrity.",,Medium
Sol-018,"The vulnerability occurs when a smart contract does not prevent the replay of transaction instructions, potentially allowing attackers to reuse valid instructions for unauthorized actions like double-spending.","rust
process_transfer(&mut account, amount);","rust
if account.last_txn == ctx.instruction_context.transaction_context.transaction_id {
    return Err(ProgramError::InvalidArgument);
} 

process_transfer(&mut account, amount);

account.last_txn = ctx.instruction_context.transaction_context.transaction_id;",High,"The secure code tracks the last transaction ID, rejecting replays if it matches the current one, and updates it post-transfer. This prevents attackers from reusing signed instructions, ensuring transaction uniqueness.",,Medium
Sol-019,"The vulnerability arises from unchecked arithmetic operations in smart contracts, which can lead to overflows or underflows in Rust's release mode, allowing attackers to manipulate balances or other critical values.","fn main() {
    let mut balance: u64 = 10;
    balance -= 20;
    println!(""Balance: {}"", balance);
}","rust
fn main() {
    let balance: u64 = 10;
    let new_balance = balance
        .checked_sub(20)
        .expect(""Subtraction overflowed!"");

    println!(""New Balance: {}"", new_balance);
}",Critical,Use Rust’s checked_* or saturating_* methods to safely handle overflows and underflows:,,Medium
Sol-020,"The vulnerability occurs when an external contract calls back into the vulnerable contract before the original function call is completed, potentially allowing the external contract to alter the state unexpectedly (such as withdrawing funds multiple times). ","rust
pub fn withdraw(&mut self, amount: u128) {
    assert!(
        self.balances[self.caller()] >= amount, 
        ""Insufficient funds""
    );
    self.transfer(self.caller(), amount);
    self.balances[self.caller()] -= amount;  // Reentrancy vulnerability
}","rust
pub fn withdraw(&mut self, amount: u128) {
    assert!(self.balances[self.caller()] >= amount, ""Insufficient funds"");
    self.balances[self.caller()] -= amount;
    self.transfer(self.caller(), amount);
}",Critical,"Use the checks-effects-interactions pattern, updating the state before making external calls",,Medium
Sol-021,The vulnerability occurs due to a missing ownership check,"rust
fn withdraw_token_restricted(program_id: &Pubkey, accounts: &[AccountInfo], amount: u64) -> ProgramResult {
    let account_iter = &mut accounts.iter();
    let vault = next_account_info(account_iter)?;
    let admin = next_account_info(account_iter)?;
    let config = ConfigAccount::unpack(next_account_info(account_iter)?)?;
    let vault_authority = next_account_info(account_iter)?;

    if config.admin != admin.pubkey() {
        return Err(ProgramError::InvalidAdminAccount);
    }

    Ok(())
}","rust
fn withdraw_token_restricted(program_id: &Pubkey, accounts: &[AccountInfo], amount: u64) -> ProgramResult {
    let account_iter = &mut accounts.iter();
    let vault = next_account_info(account_iter)?;
    let admin = next_account_info(account_iter)?;
    let config = ConfigAccount::unpack(next_account_info(account_iter)?)?;
    let vault_authority = next_account_info(account_iter)?;
    
    if config.owner != program_id {
        return Err(ProgramError::InvalidConfigAccount);
    }
    
    if config.admin != admin.pubkey() {
        return Err(ProgramError::InvalidAdminAccount);
    }

    Ok(())
}",Critical,Add the missing ownership check to prevent unauthorized access,,Medium
Sol-022,The vulnerability occurs when the contract doesn't verify that the respective entity has signed the corresponding transaction,"rust
fn update_admin(program_id: &Pubkey, accounts: &[AccountInfo]) -> ProgramResult {
    let account_iter = &mut accounts.iter();
    let config = ConfigAccount::unpack(next_account_info(account_iter)?)?;
    let admin = next_account_info(account_iter)?;
    let new_admin = next_account_info(account_iter)?;

    // Validate the config account...
    if admin.pubkey() != config.admin {
        return Err(ProgramError::InvalidAdminAccount);
    }
    
    config.admin = new_admin.pubkey();

    Ok(())
}","rust
fn update_admin(program_id: &Pubkey, accounts: &[AccountInfo]) -> ProgramResult {
    let account_iter = &mut accounts.iter();
    let config = ConfigAccount::unpack(next_account_info(account_iter)?)?;
    let admin = next_account_info(account_iter)?;
    let new_admin = next_account_info(account_iter)?;
    
    // ...
    // Validate the config account...
    // ...
    
    if admin.pubkey() != config.admin {
        return Err(ProgramError::InvalidAdminAccount);
    }
  
    // check that the current admin has signed this operation
    if !admin.is_signer {
        return Err(ProgramError::MissingSigner);
    }
    
    config.admin = new_admin.pubkey();
    Ok(())
}",Critical,Insert the missing check to ensure valid checks are executed,,Medium
Sol-023,"The vulnerability occurrs due to integer overflow, causing the program to panic","rust
let FEE: u32 = 1000; 

fn withdraw_token(program_id: &Pubkey, accounts: &[AccountInfo], amount: u32) -> ProgramResult { 
    // ... 
    // deserialize & validate user and vault accounts 
    // ... 
    
    if amount + FEE > vault.user_balance[user_id] { 
        return Err(ProgramError::AttemptToWithdrawTooMuch); 
    } 
    
    // ... 
    // Transfer `amount` many tokens from vault to user-controlled account 
    // ... 
    
    Ok(()) 
}","rust
let FEE: u32 = 1000;

fn withdraw_token(program_id: &Pubkey, accounts: &[AccountInfo], amount: u32) -> ProgramResult {
    // ...
    // deserialize & validate user and vault accounts
    // ...

    if amount.checked_add(FEE).ok_or(ProgramError::InvalidArgument)? > vault.user_balance[user_id] {
        return Err(ProgramError::AttemptToWithdrawTooMuch);
    }

    // ...
    // Transfer `amount` many tokens from vault to user-controlled account
    // ...

    Ok(())
}",Critical,Replace the + with checked_add to mitigate this issue,,Medium
Sol-024,The vulnerability occurs when an attacker uses a foreign program account to call an unexpected function ,"rust
pub fn process_withdraw(
    program_id: &Pubkey, 
    accounts: &[AccountInfo], 
    amount: u64
) -> ProgramResult { 
    let account_info_iter = &mut accounts.iter(); 

    let vault = next_account_info(account_info_iter)?; 
    let vault_authority = next_account_info(account_info_iter)?; 
    let destination = next_account_info(account_info_iter)?; 
    let token_program = next_account_info(account_info_iter)?;

    // ...
    // get signer seeds, validate account owners and signers,
    // and verify that the user can withdraw the supplied amount 
    // ...

    // invoke unverified token_program 
    invoke_signed(
        &spl_token::instruction::transfer(
            &token_program.key, 
            &vault.key, 
            &destination.key, 
            &vault_authority.key, 
            &[&vault_authority.key], 
            amount,
        )?,
        &[ 
            vault.clone(), 
            destination.clone(), 
            vault_owner_info.clone(), 
            token_program.clone(), 
        ],
        &[&seeds],
    )?;

    Ok(())
}","rust
pub fn process_withdraw(program_id: &Pubkey, accounts: &[AccountInfo], amount: u64) -> ProgramResult {
    let account_info_iter = &mut accounts.iter();
    let vault = next_account_info(account_info_iter)?;
    let vault_authority = next_account_info(account_info_iter)?;
    let destination = next_account_info(account_info_iter)?;
    let token_program = next_account_info(account_info_iter)?;

    // ...
    // get signer seeds, validate account owners and signers,
    // and verify that the user can withdraw the supplied amount
    // ...

    // verify that token_program is in fact the official spl token program
    if token_program.key != &spl_token::id() {
        return Err(ProgramError::InvalidTokenProgram);
    }

    invoke_signed(
        &spl_token::instruction::transfer(
            &token_program.key,
            &vault.key,
            &destination.key,
            &vault_authority.key,
            &[&vault_authority.key],
            amount,
        )?,
        &[
            vault.clone(),
            destination.clone(),
            vault_owner_info.clone(),
            token_program.clone(),
        ],
        &[&seeds],
    )?;

    Ok(())
}",Critical,"Make sure we check that the program we are invoking is, in fact, the one we want",,Medium
Sol-025,The vulnerability arises when an account type is not the one expected by the program,"// ------- Account Types --------
pub struct Config {
    pub admin: Pubkey,
    pub fee: u32,
    pub user_count: u32,
}

pub struct User {
    pub user_authority: Pubkey,
    pub balance: u64,
}

// ------- Helper functions --------
fn unpack_config(account: &AccountInfo) -> Result<Config, ProgramError> {
    let config: Config = deserialize(&mut account.data.borrow())?;
    Ok(config)
}

// ------- Contract Instructions ---------
fn create_user(program_id: &Pubkey, accounts: &[AccountInfo]) -> ProgramResult {
    let account_iter = &mut accounts.iter();
    let user = next_account_info(account_iter)?;
    // ...
    // Initialize a User struct, set user_authority
    // to user and set balance to 0
    // ...
    Ok(())
}

fn withdraw_tokens(
    program_id: &Pubkey,
    accounts: &[AccountInfo],
    amount: u64,
) -> ProgramResult {
    let account_iter = &mut accounts.iter();
    let vault = next_account_info(account_iter)?;
    let admin = next_account_info(account_iter)?;
    let config = unpack_config(next_account_info(account_iter)?)?;
    let vault_authority = next_account_info(account_iter)?;

    if config.owner != *program_id {
        return Err(ProgramError::InvalidConfigAccount);
    }
    if config.admin != *admin.key {
        return Err(ProgramError::InvalidAdminAccount);
    }
    // ...
    // Transfer funds from vault to admin using vault_authority
    // ...
    Ok(())
}","rust
// ------- Account Types -------- 
pub struct Config { 
    pub TYPE: u8, // <-- should contain a unique identifier for this account type 
    pub admin: Pubkey, 
    pub fee: u32, 
    pub user_count: u32, 
} 

pub struct User { 
    pub TYPE: u8, // <-- should contain a unique identifier for this account type 
    pub user_authority: Pubkey, 
    pub balance: u64, 
} 

 // ------- Helper functions -------- 
 fn unpack_config(account: &AccountInfo) -> Result<Config, ProgramError> { 
     let mut config: Config = deserialize(&mut account.data.borrow())?;
     if config.TYPE != Types::ConfigType { 
         return Err(ProgramError::InvalidAccountType); 
     } 
     return config; 
}

 // ------- Contract Instructions --------- 

fn create_user(program_id: &Pubkey, accounts: &[AccountInfo]) -> ProgramResult { 
    let account_iter = &mut accounts.iter(); 
    let user = next_account_info(account_iter)?; 
    // ... 
    // Initialize a User struct, set user_authority 
    // to user and set balance to 0 
    // ... 
    Ok(()) 
} 

fn withdraw_tokens(program_id: &Pubkey, accounts: &[AccountInfo], amount: u64) -> ProgramResult { 
    let account_iter = &mut accounts.iter(); 
    let vault = next_account_info(account_iter)?;
    let admin = next_account_info(account_iter)?;
    let config = unpack_config(next_account_info(account_iter)?)?; 
    let vault_authority = next_account_info(account_iter)?;
    if config.owner != program_id { 
        return Err(ProgramError::InvalidConfigAccount); 
    } 
    if config.admin != admin.pubkey() { 
        return Err(ProgramError::InvalidAdminAccount); 
    } 
    // ... 
    // Transfer funds from vault to admin using vault_authority 
    // ... 
    Ok(()) 
}",High,"When we create a new account, we set the TYPE field to a value that is unique to accounts of that type. Our deserialization function will also have to validate the TYPE and error out if the account does not have the type we’re expecting.",,Medium
Sol-026,signer-authorization,"use anchor_lang::prelude::*;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod signer_authorization_insecure 
{
    use super::*;

    pub fn log_message(ctx: Context<LogMessage>) -> ProgramResult 
    {
        msg!(""GM {}"", ctx.accounts.authority.key().to_string());

        Ok(())
    }
}

#[derive(Accounts)]
pub struct LogMessage<'info> 
{
    authority: AccountInfo<'info>,
}","rust
use anchor_lang::prelude::*;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod signer_authorization_secure {
    use super::*;

    pub fn log_message(ctx: Context<LogMessage>) -> ProgramResult { 
        if !ctx.accounts.authority.is_signer {
            return Err(ProgramError::MissingRequiredSignature);
        } 
        msg!(""GM {}"", ctx.accounts.authority.key().to_string());
        
        Ok(()) 
    } 
}

#[derive(Accounts)]
pub struct LogMessage<'info> {
    authority: AccountInfo<'info>,
}",Critical,We should always add signer checks when making system calls that require authorization,https://github.com/coral-xyz/sealevel-attacks/tree/master/programs/0-signer-authorization/insecure/src/lib.rs,High
Sol-027,signer-authorization,"rust
use anchor_lang::prelude::*;
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod signer_authorization_recommended {
    use super::*;

    pub fn log_message(ctx: Context<LogMessage>) -> ProgramResult {
        msg!(""GM {}"", ctx.accounts.authority.key().to_string());
        Ok(())
    }
}

#[derive(Accounts)]
pub struct LogMessage<'info> {
    authority: Signer<'info>,
}","rust
use anchor_lang::prelude::*;
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod signer_authorization_secure {
    use super::*;

    pub fn log_message(ctx: Context<LogMessage>) -> ProgramResult {
        if !ctx.accounts.authority.is_signer {
            return Err(ProgramError::MissingRequiredSignature);
        }
        msg!(""GM {}"", ctx.accounts.authority.key().to_string());
        Ok(())
    }
}

#[derive(Accounts)]
pub struct LogMessage<'info> {
    authority: AccountInfo<'info>,
}",Informational,"Change from Signer<'info> to AccountInfo<'info>: The LogMessage struct was updated to use AccountInfo<'info> instead of Signer<'info>. This allows more flexibility because AccountInfo provides access to raw account data and metadata (such as whether the account is a signer). Added explicit check ensures that the authority account is indeed a signer. If the account is not signed, it returns an error ProgramError::MissingRequiredSignature. This check is crucial because even if Signer<'info> was used in the previous code (indicating that the account should be a signer), the runtime still needed to confirm the actual signer status before proceeding with any logic.",https://github.com/coral-xyz/sealevel-attacks/tree/master/programs/0-signer-authorization/recommended/src/lib.rs,High
Sol-028,account-data-matching,"use anchor_lang::prelude::*;
use anchor_lang::solana_program::program_pack::Pack;
use spl_token::state::Account as SplTokenAccount;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod account_data_matching_insecure {
    use super::*;

    pub fn log_message(ctx: Context<LogMessage>) -> ProgramResult {
        let token = SplTokenAccount::unpack(&ctx.accounts.token.data.borrow())?;
        msg!(""Your account balance is: {}"", token.amount);
        Ok(())
    }
}

#[derive(Accounts)]
pub struct LogMessage<'info> {
    token: AccountInfo<'info>,
    authority: Signer<'info>,
}","rust
use anchor_lang::prelude::*;
use anchor_lang::solana_program::program_pack::Pack;
use spl_token::state::Account as SplTokenAccount;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod account_data_matching_secure {
    use super::*;

    pub fn log_message(ctx: Context<LogMessage>) -> ProgramResult {
        let token = SplTokenAccount::unpack(&ctx.accounts.token.data.borrow())?;
        
        if ctx.accounts.authority.key != &token.owner {
            return Err(ProgramError::InvalidAccountData);
        }
        
        msg!(""Your account balance is: {}"", token.amount);
        Ok(())
    }
}

#[derive(Accounts)]
pub struct LogMessage<'info> {
    token: AccountInfo<'info>,
    authority: Signer<'info>,
}",Critical,Make sure to add the proper authority checks before making calls to token functions,https://github.com/coral-xyz/sealevel-attacks/tree/master/programs/1-account-data-matching/insecure/src/lib.rs,High
Sol-029,account-data-matching,"rust
use anchor_lang::prelude::*;
use anchor_spl::token::TokenAccount;
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod account_data_matching_recommended {
    use super::*;
	
    pub fn log_message(ctx: Context<LogMessage>) -> ProgramResult {
        msg!(""Your account balance is: {}"", ctx.accounts.token.amount);
        Ok(())
    }
}

#[derive(Accounts)]
pub struct LogMessage<'info> {
    #[account(constraint = authority.key == &token.owner)]
    token: Account<'info, TokenAccount>,
    authority: Signer<'info>,
}","rust
use anchor_lang::prelude::*;
use anchor_lang::solana_program::program_pack::Pack;
use spl_token::state::Account as SplTokenAccount;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod account_data_matching_secure {
    use super::*;

    pub fn log_message(ctx: Context<LogMessage>) -> ProgramResult {
        let token = SplTokenAccount::unpack(&ctx.accounts.token.data.borrow())?;

        if ctx.accounts.authority.key != &token.owner {
            return Err(ProgramError::InvalidAccountData);
        }

        msg!(""Your account balance is: {}"", token.amount);
        
        Ok(())
    }
}

#[derive(Accounts)]
pub struct LogMessage<'info> {
    token: AccountInfo<'info>,
    authority: Signer<'info>
}",Informational,"The vulnerability was fixed by manually unpacking the token account using the SplTokenAccount::unpack method, which allows the program to directly access and validate the token account's owner and other data. The program now performs a more explicit check on the token account's owner and ensures that the provided authority matches the owner of the token account. This is a more reliable and transparent method of verifying the ownership compared to relying solely on Anchor constraints.",https://github.com/coral-xyz/sealevel-attacks/tree/master/programs/1-account-data-matching/recommended/src/lib.rs,High
Sol-030,owner-checks,"rust
use anchor_lang::prelude::*;
use anchor_lang::solana_program::program_error::ProgramError;
use anchor_lang::solana_program::program_pack::Pack;
use spl_token::state::Account as SplTokenAccount;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod owner_checks_insecure {
    use super::*;

    pub fn log_message(ctx: Context<LogMessage>) -> ProgramResult {
        let token = SplTokenAccount::unpack(&ctx.accounts.token.data.borrow())?;

        if ctx.accounts.authority.key != &token.owner {
            return Err(ProgramError::InvalidAccountData);
        }

        msg!(""Your account balance is: {}"", token.amount);
        Ok(())
    }
}

#[derive(Accounts)]
pub struct LogMessage<'info> {
    token: AccountInfo<'info>,
    authority: Signer<'info>,
}","rust
use anchor_lang::prelude::*;
use anchor_lang::solana_program::program_error::ProgramError;
use anchor_lang::solana_program::program_pack::Pack;
use spl_token::state::Account as SplTokenAccount;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod owner_checks_secure {
    use super::*;

    pub fn log_message(ctx: Context<LogMessage>) -> ProgramResult {
        let token = SplTokenAccount::unpack(&ctx.accounts.token.data.borrow())?;
        
        if ctx.accounts.token.owner != &spl_token::ID {
            return Err(ProgramError::InvalidAccountData);
        }
        
        if ctx.accounts.authority.key != &token.owner {
            return Err(ProgramError::InvalidAccountData);
        }
        
        msg!(""Your account balance is: {}"", token.amount);
        Ok(())
    }
}

#[derive(Accounts)]
pub struct LogMessage<'info> {
    token: AccountInfo<'info>,
    authority: Signer<'info>,
}",Critical,"Check Token Program Ownership: The fix introduces a new validation check: if ctx.accounts.token.owner != &spl_token::ID. This ensures that the token account is actually owned by the SPL Token program (spl_token::ID), which is a crucial security step to avoid validating non-SPL token accounts. Retained Authority Ownership Check: The original check for whether the authority.key matches the token account's owner is retained: if ctx.accounts.authority.key != &token.owner. This ensures that the authority is indeed the owner of the token account.",https://github.com/coral-xyz/sealevel-attacks/tree/master/programs/2-owner-checks/insecure/src/lib.rs,High
Sol-031,owner-checks,"rust
use anchor_lang::prelude::*;
use anchor_spl::token::TokenAccount;
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod owner_checks_recommended {
    use super::*;

    pub fn log_message(ctx: Context<LogMessage>) -> ProgramResult {
        msg!(""Your account balance is: {}"", ctx.accounts.token.amount);
        Ok(())
    }
}

#[derive(Accounts)]
pub struct LogMessage<'info> {
    #[account(constraint = authority.key == &token.owner)]
    token: Account<'info, TokenAccount>,
    authority: Signer<'info>,
}","rust
use anchor_lang::prelude::*;
use anchor_lang::solana_program::program_error::ProgramError;
use anchor_lang::solana_program::program_pack::Pack;
use spl_token::state::Account as SplTokenAccount;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod owner_checks_secure {
    use super::*;

    pub fn log_message(ctx: Context<LogMessage>) -> ProgramResult {
        let token = SplTokenAccount::unpack(&ctx.accounts.token.data.borrow())?;
        
        if ctx.accounts.token.owner != &spl_token::ID {
            return Err(ProgramError::InvalidAccountData);
        } 

        if ctx.accounts.authority.key != &token.owner {
            return Err(ProgramError::InvalidAccountData);
        } 

        msg!(""Your account balance is: {}"", token.amount);
        
        Ok(())
    } 
}

#[derive(Accounts)]
pub struct LogMessage<'info> {
    token: AccountInfo<'info>,
    authority: Signer<'info>,
}",Informational," The original code checks whether the authority's key matches the token.owner, but does not verify that the token account belongs to the correct SPL token program (spl_token::ID). Without this check, the program could allow non-token accounts (i.e., accounts that aren't controlled by the SPL token program) to pass through. The fix ensures that the token account is indeed owned by the SPL token program. In the original code, the check on the token.owner is done using a simpler constraint (#[account(constraint = authority.key == &token.owner)]), which, while useful, doesn't explicitly handle cases where the token account might not be owned by the correct program. The fix refines the validation logic to be more explicit by loading the token account data, unpacking it, and ensuring that the account is associated with the SPL token program.",https://github.com/coral-xyz/sealevel-attacks/tree/master/programs/2-owner-checks/recommended/src/lib.rs,High
Sol-032,type-cosplay,"rust
use anchor_lang::prelude::*;
use borsh::{BorshDeserialize, BorshSerialize};

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod type_cosplay_insecure {
    use super::*;

    pub fn update_user(ctx: Context<UpdateUser>) -> ProgramResult {
        let user = User::try_from_slice(&ctx.accounts.user.data.borrow()).unwrap();
        if ctx.accounts.user.owner != ctx.program_id {
            return Err(ProgramError::IllegalOwner);
        }
        if user.authority != ctx.accounts.authority.key() {
            return Err(ProgramError::InvalidAccountData);
        }

        msg!(""GM {}"", user.authority);
        
        Ok(())
    }
}

#[derive(Accounts)]
pub struct UpdateUser<'info> {
    user: AccountInfo<'info>,
    authority: Signer<'info>,
}

#[derive(BorshSerialize, BorshDeserialize)]
pub struct User {
    authority: Pubkey,
}

#[derive(BorshSerialize, BorshDeserialize)]
pub struct Metadata {
    account: Pubkey,
}","rust
use anchor_lang::prelude::*;
use borsh::{BorshDeserialize, BorshSerialize};

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod type_cosplay_secure {
    use super::*;

    pub fn update_user(ctx: Context<UpdateUser>) -> ProgramResult {
        let user = User::try_from_slice(&ctx.accounts.user.data.borrow()).unwrap();

        if ctx.accounts.user.owner != ctx.program_id {
            return Err(ProgramError::IllegalOwner);
        }

        if user.authority != ctx.accounts.authority.key() {
            return Err(ProgramError::InvalidAccountData);
        }

        if user.discriminant != AccountDiscriminant::User {
            return Err(ProgramError::InvalidAccountData);
        }

        msg!(""GM {}"", user.authority);
        Ok(())
    }
}

#[derive(Accounts)]
pub struct UpdateUser<'info> {
    user: AccountInfo<'info>,
    authority: Signer<'info>,
}

#[derive(BorshSerialize, BorshDeserialize)]
pub struct User {
    discriminant: AccountDiscriminant,
    authority: Pubkey,
}

#[derive(BorshSerialize, BorshDeserialize)]
pub struct Metadata {
    discriminant: AccountDiscriminant,
    account: Pubkey,
}

#[derive(BorshSerialize, BorshDeserialize, PartialEq)]
pub enum AccountDiscriminant {
    User,
    Metadata,
}",Critical,"Discriminant Field Added: The most significant change is the addition of the discriminant field in the User struct. This field is used as a marker to explicitly identify the account type, ensuring that only accounts with the correct data structure are processed. The discriminant is checked in the code (if user.discriminant != AccountDiscriminant::User) to ensure that the account being accessed is of the expected type, preventing issues where an account of a different type could be misinterpreted as a User account. AccountDiscriminant::User is a constant that uniquely identifies the type of account being processed. If the discriminant doesn't match, an error is returned, preventing further processing of potentially malformed or malicious data. Improved Account Validation: By introducing the discriminant, the program ensures that it doesn't mistakenly operate on data that has the same structure but isn't intended for this use case. The discriminant ensures that the account data is consistent with the expected layout, offering an additional layer of protection against unexpected data types or malicious attempts to manipulate account data. Better Error Handling: The introduction of a discriminator allows for more precise error handling. If the account data doesn't match the expected structure, the program immediately returns an error, ensuring the program doesn't continue executing with invalid data. In summary, the fix improves the security of the program by ensuring that only accounts with the correct structure are processed, reducing the risk of accidental or malicious use of malformed data.",https://github.com/coral-xyz/sealevel-attacks/tree/master/programs/3-type-cosplay/insecure/src/lib.rs,High
Sol-033,type-cosplay,"rust
use anchor_lang::prelude::*;
use borsh::{BorshDeserialize, BorshSerialize};

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod type_cosplay_recommended {
    use super::*;
    
    pub fn update_user(ctx: Context<UpdateUser>) -> ProgramResult {
        msg!(""GM {}"", ctx.accounts.user.authority);
        Ok(())
    } 
}

#[derive(Accounts)]
pub struct UpdateUser<'info> {
    #[account(has_one = authority)]
    user: Account<'info, User>,
    authority: Signer<'info>,
}

#[account]
pub struct User {
    authority: Pubkey,
}

#[account]
pub struct Metadata {
    account: Pubkey,
}","rust
use anchor_lang::prelude::*;
use borsh::{BorshDeserialize, BorshSerialize};

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod type_cosplay_secure {
    use super::*;

    pub fn update_user(ctx: Context<UpdateUser>) -> ProgramResult {
        let user = User::try_from_slice(&ctx.accounts.user.data.borrow()).unwrap();
        
        if ctx.accounts.user.owner != ctx.program_id {
            return Err(ProgramError::IllegalOwner);
        } 
        
        if user.authority != ctx.accounts.authority.key() {
            return Err(ProgramError::InvalidAccountData);
        } 
        
        if user.discriminant != AccountDiscriminant::User {
            return Err(ProgramError::InvalidAccountData);
        }

        msg!(""GM {}"", user.authority);
        
        Ok(())
    }
}

#[derive(Accounts)]
pub struct UpdateUser<'info> {
    user: AccountInfo<'info>,
    authority: Signer<'info>,
}

#[derive(BorshSerialize, BorshDeserialize)]
pub struct User {
    discriminant: AccountDiscriminant,
    authority: Pubkey,
}

#[derive(BorshSerialize, BorshDeserialize)]
pub struct Metadata {
    discriminant: AccountDiscriminant,
    account: Pubkey,
}

#[derive(BorshSerialize, BorshDeserialize, PartialEq)]
pub enum AccountDiscriminant {
    User,
    Metadata,
}",Informational,"Discriminant Added to Account Structures: A new AccountDiscriminant enum is introduced, which serves as a marker for the type of account. This prevents unauthorized types of accounts from being processed as a User account. The User and Metadata structures now both have a discriminant field, ensuring that the program can correctly identify whether the account's data is valid. Discriminant Check in the Logic: Before processing the account, the code checks if the discriminant matches AccountDiscriminant::User. This guarantees that the account data conforms to the expected type, reducing the risk of processing arbitrary accounts or manipulated data. Stronger Account Validation: In addition to checking if the user.owner matches the program's ID and if the authority matches, the fix also validates that the account is of the correct type by checking the discriminant. This makes it much harder for an attacker to craft a malformed account with the correct layout but incorrect semantics. Benefits of the Fix: Type Safety: By introducing a discriminant, the program ensures that it operates only on accounts that are correctly structured, preventing issues where an account with similar data might be treated as a User. Prevention of Account Manipulation: The fix prevents attackers from exploiting the system by submitting arbitrary accounts that only happen to have a matching structure but are not actually of the expected type. Better Data Integrity: The discriminant provides a robust mechanism for ensuring that the account data conforms to the expected format, improving the overall reliability and security of the program.",https://github.com/coral-xyz/sealevel-attacks/tree/master/programs/3-type-cosplay/recommended/src/lib.rs,High
Sol-034,initialization,"rust
use anchor_lang::prelude::*;
use borsh::{BorshDeserialize, BorshSerialize};
use std::ops::DerefMut;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod initialization_insecure {
    use super::*;

    pub fn initialize(ctx: Context<Initialize>) -> ProgramResult {
        let mut user = User::try_from_slice(&ctx.accounts.user.data.borrow()).unwrap();
        user.authority = ctx.accounts.authority.key();

        let mut storage = ctx.accounts.user.try_borrow_mut_data()?;

        user.serialize(storage.deref_mut()).unwrap();

        Ok(())
    }
}

/*
- reinitialize
- create and dont initialize
- passing previously initialzed accounts from other programs (e.g. token program => need to check delegate and authority)
*/

#[derive(Accounts)]
pub struct Initialize<'info> {
    user: AccountInfo<'info>,
    authority: Signer<'info>,
}

#[derive(BorshSerialize, BorshDeserialize)]
pub struct User {
    authority: Pubkey,
}","rust
use anchor_lang::prelude::*;
use borsh::{BorshDeserialize, BorshSerialize};
use std::ops::DerefMut;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS""); 

#[program]
pub mod reinitialization_secure_recommended {
    use super::*;

    pub fn initialize(ctx: Context<Initialize>) -> ProgramResult {
        let mut user = User::try_from_slice(&ctx.accounts.user.data.borrow()).unwrap();

        if !user.discriminator {
            return Err(ProgramError::InvalidAccountData);
        }
        
        user.authority = ctx.accounts.authority.key();
        user.discriminator = true;
        
        let mut storage = ctx.accounts.user.try_borrow_mut_data()?;
        user.serialize(storage.deref_mut()).unwrap();
        
        msg!(""GM"");
        
        Ok(())
    } 
}

#[derive(Accounts)]
pub struct Initialize<'info> {
    user: AccountInfo<'info>,
    authority: Signer<'info>,
}

#[derive(BorshSerialize, BorshDeserialize)]
pub struct User {
    discriminator: bool,
    authority: Pubkey,
}",Critical,"Discriminator Field Added: A discriminator field is added to the User struct. This field is used to track whether the account has been initialized. It ensures that an account is only initialized once and prevents re-initialization. Check for Discriminator: Before modifying the User account, the program checks whether the discriminator field is set (i.e., true). If not, it means the account has not been initialized, and the program returns an error (ProgramError::InvalidAccountData). Set Discriminator After Initialization: Once the account is successfully initialized, the discriminator field is set to true, indicating that the account has been properly initialized. Prevents Re-Initialization: This fix ensures that the program does not accidentally overwrite an already initialized account, addressing the issue of re-initialization that exists in the vulnerable code.",https://github.com/coral-xyz/sealevel-attacks/tree/master/programs/4-initialization/insecure/src/lib.rs,High
Sol-035,initialization,"rust
use anchor_lang::prelude::*;
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod reinitialization_4 {
    use super::*;
    
    pub fn init(_ctx: Context<Init>) -> ProgramResult {
        msg!(""GM"");
        Ok(())
    }
}

#[derive(Accounts)]
pub struct Init<'info> {
    #[account(init, payer = authority, space = 8+32)]
    user: Account<'info, User>,
    
    #[account(mut)]
    authority: Signer<'info>,
    
    system_program: Program<'info, System>,
}

#[account]
pub struct User {
    authority: Pubkey,
}","rust
use anchor_lang::prelude::*;
use borsh::{BorshDeserialize, BorshSerialize};
use std::ops::DerefMut;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod reinitialization_secure_recommended {
    use super::*;

    pub fn initialize(ctx: Context<Initialize>) -> ProgramResult {
        let mut user = User::try_from_slice(&ctx.accounts.user.data.borrow()).unwrap();

        if !user.discriminator {
            return Err(ProgramError::InvalidAccountData);
        }

        user.authority = ctx.accounts.authority.key();
        user.discriminator = true;

        let mut storage = ctx.accounts.user.try_borrow_mut_data()?;
        user.serialize(storage.deref_mut()).unwrap();

        msg!(""GM"");

        Ok(())
    }
}

#[derive(Accounts)]
pub struct Initialize<'info> {
    user: AccountInfo<'info>,
    authority: Signer<'info>,
}

#[derive(BorshSerialize, BorshDeserialize)]
pub struct User {
    discriminator: bool,
    authority: Pubkey,
}",Informational,"Discriminator Field: The User struct now includes a discriminator: bool field to track whether the account has been initialized. This ensures that the account has been properly initialized before any modifications are made, preventing reinitialization or overwriting. If the account is not properly initialized (i.e., discriminator is false), the program returns an error (InvalidAccountData). Initialization Check: The initialize function checks if the discriminator is true (indicating that the account has been initialized). If not, it prevents further modifications and returns an error. This check ensures that the account is in the expected state before updating it. Data Integrity: The updated User struct is serialized back into the account’s data space after the discriminator is set, ensuring that the account is marked as initialized.",https://github.com/coral-xyz/sealevel-attacks/tree/master/programs/4-initialization/recommended/src/lib.rs,High
Sol-036,"arbitrary-cpi. In the original arbitrary_cpi_insecure code, there is no validation of the token_program before invoking the CPI. This means that an attacker could potentially manipulate the token_program account to point to a malicious program, allowing them to invoke any program (not just the spl_token program) and perform unintended actions. This is dangerous because it opens the door to unauthorized operations on other programs.","rust
use anchor_lang::prelude::*;
use anchor_lang::solana_program;
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod arbitrary_cpi_insecure {
    use super::*;

    pub fn cpi(ctx: Context<Cpi>, amount: u64) -> ProgramResult {
        solana_program::program::invoke(
            &spl_token::instruction::transfer(
                ctx.accounts.token_program.key,
                ctx.accounts.source.key,
                ctx.accounts.destination.key,
                ctx.accounts.authority.key,
                &[],
                amount,
            )?,
            &[
                ctx.accounts.source.clone(),
                ctx.accounts.destination.clone(),
                ctx.accounts.authority.clone(),
            ],
        )
    }
}

#[derive(Accounts)]
pub struct Cpi<'info> {
    source: AccountInfo<'info>,
    destination: AccountInfo<'info>,
    authority: AccountInfo<'info>,
    token_program: AccountInfo<'info>,
}","rust
use anchor_lang::prelude::*;
use anchor_lang::solana_program;


declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod arbitrary_cpi_secure {
    use super::*;

    pub fn cpi_secure(ctx: Context<Cpi>, amount: u64) -> ProgramResult {
        if &spl_token::ID != ctx.accounts.token_program.key {
            return Err(ProgramError::IncorrectProgramId);
        }

        solana_program::program::invoke(
            &spl_token::instruction::transfer(
                ctx.accounts.token_program.key,
                ctx.accounts.source.key,
                ctx.accounts.destination.key,
                ctx.accounts.authority.key,
                &[],
                amount,
            )?,
            &[
                ctx.accounts.source.clone(),
                ctx.accounts.destination.clone(),
                ctx.accounts.authority.clone(),
            ],
        )
    }
}

#[derive(Accounts)]
pub struct Cpi<'info> {
    source: AccountInfo<'info>,
    destination: AccountInfo<'info>,
    authority: AccountInfo<'info>,
    token_program: AccountInfo<'info>,
}",Critical,"Program ID Validation: The fix introduces a validation step to ensure that the token_program account is the expected spl_token program. The check if &spl_token::ID != ctx.accounts.token_program.key ensures that the provided token_program matches the expected spl_token program's ID. If the validation fails, the program returns ProgramError::IncorrectProgramId, preventing the call to a potentially malicious program. Secure Cross-Program Invocation (CPI): With this validation in place, the program can securely invoke the spl_token::transfer instruction, knowing that it is calling the correct program. This prevents attackers from invoking arbitrary programs that could alter the transfer logic or lead to fund theft.",https://github.com/coral-xyz/sealevel-attacks/tree/master/programs/5-arbitrary-cpi/insecure/src/lib.rs,High
Sol-037,arbitrary-cpi,"rust
use anchor_lang::prelude::*;
use anchor_spl::token::{self, Token, TokenAccount};

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod arbitrary_cpi_recommended {
    use super::*;

    pub fn cpi(ctx: Context<Cpi>, amount: u64) -> ProgramResult {
        token::transfer(ctx.accounts.transfer_ctx(), amount)
    }
}

#[derive(Accounts)]
pub struct Cpi<'info> {
    source: Account<'info, TokenAccount>,
    destination: Account<'info, TokenAccount>,
    authority: Signer<'info>,
    token_program: Program<'info, Token>,
}

impl<'info> Cpi<'info> {
    pub fn transfer_ctx(&self) -> CpiContext<'_, '_, '_, 'info, token::Transfer<'info>> {
        let program = self.token_program.to_account_info();
        let accounts = token::Transfer {
            from: self.source.to_account_info(),
            to: self.destination.to_account_info(),
            authority: self.authority.to_account_info(),
        };

        CpiContext::new(program, accounts)
    }
}","rust
use anchor_lang::prelude::*;
use anchor_lang::solana_program;
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod arbitrary_cpi_secure {
    use super::*;
    
    pub fn cpi_secure(ctx: Context<Cpi>, amount: u64) -> ProgramResult {
        if &spl_token::ID != ctx.accounts.token_program.key {
            return Err(ProgramError::IncorrectProgramId);
        }
        solana_program::program::invoke(
            &spl_token::instruction::transfer(
                ctx.accounts.token_program.key,
                ctx.accounts.source.key,
                ctx.accounts.destination.key,
                ctx.accounts.authority.key,
                &[],
                amount,
            )?,
            &[
                ctx.accounts.source.clone(),
                ctx.accounts.destination.clone(),
                ctx.accounts.authority.clone(),
            ],
        )
    }
}

#[derive(Accounts)]
pub struct Cpi<'info> {
    source: AccountInfo<'info>,
    destination: AccountInfo<'info>,
    authority: AccountInfo<'info>,
    token_program: AccountInfo<'info>,
}",Informational,"Simplified CPI Call with token::transfer: The recommended fix uses the token::transfer function from the anchor_spl crate. This function abstracts away much of the complexity involved in constructing and sending the transfer instruction, making the code simpler and less error-prone. Use of CpiContext for Proper Account Handling: The CpiContext is used in the transfer_ctx function to manage and validate the accounts involved in the CPI. This ensures that the source, destination, and authority accounts are properly passed and handled by Anchor's CPI mechanism. CpiContext::new automatically ensures that the accounts are aligned with the expected instruction for token transfers. Anchor's Built-in Validation: Anchor automatically performs checks on the accounts, ensuring they are of the correct type (TokenAccount for the source and destination accounts). The program doesn’t need to manually validate the accounts as in the insecure version, reducing the likelihood of errors. Reduced Risk of Incorrect Program Calls: By using Anchor’s abstractions, this code reduces the chance of invoking an incorrect program. It simplifies the interaction with the spl_token program, ensuring that the accounts provided match the expectations of the token::transfer function.",https://github.com/coral-xyz/sealevel-attacks/tree/master/programs/5-arbitrary-cpi/recommended/src/lib.rs,High
Sol-038,duplicate-mutable-accounts,"use anchor_lang::prelude::*;
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod duplicate_mutable_accounts_insecure {
    use super::*;

    pub fn update(ctx: Context<Update>, a: u64, b: u64) -> ProgramResult {
        let user_a = &mut ctx.accounts.user_a;
        let user_b = &mut ctx.accounts.user_b;
        user_a.data = a;
        user_b.data = b;
        Ok(())
    }
}

#[derive(Accounts)]
pub struct Update<'info> {
    user_a: Account<'info, User>,
    user_b: Account<'info, User>,
}

#[account]
pub struct User {
    data: u64,
}","rust
use anchor_lang::prelude::*;
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod duplicate_mutable_accounts_secure {
    use super::*;

    pub fn update(ctx: Context<Update>, a: u64, b: u64) -> ProgramResult {
        if ctx.accounts.user_a.key() == ctx.accounts.user_b.key() {
                return Err(ProgramError::InvalidArgument)
        }
        
        let user_a = &mut ctx.accounts.user_a;
        let user_b = &mut ctx.accounts.user_b;
        
        user_a.data = a;
        user_b.data = b;
        
        Ok(())
    }
}

#[derive(Accounts)]
pub struct Update<'info> {
    user_a: Account<'info, User>,
    user_b: Account<'info, User>,
}

#[account]
pub struct User {
    data: u64,
}",Critical,"Validation: The line if ctx.accounts.user_a.key() == ctx.accounts.user_b.key() checks whether user_a and user_b refer to the same account. If they do, the function returns an error (ProgramError::InvalidArgument), preventing the mutable borrow conflict. Security: This prevents potential issues caused by two mutable borrows of the same account. Rust enforces strict rules around mutable borrowing, so ensuring the accounts are distinct helps maintain program integrity.",https://github.com/coral-xyz/sealevel-attacks/blob/master/programs/6-duplicate-mutable-accounts/insecure/src/lib.rs,High
Sol-039,duplicate-mutable-accounts,"rust
use anchor_lang::prelude::*;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod duplicate_mutable_accounts_recommended {
    use super::*;

    pub fn update(ctx: Context<Update>, a: u64, b: u64) -> ProgramResult {
        let user_a = &mut ctx.accounts.user_a;
        let user_b = &mut ctx.accounts.user_b;
        user_a.data = a;
        user_b.data = b;
        Ok(())
    }
}

#[derive(Accounts)]
pub struct Update<'info> {
    #[account(constraint = user_a.key() != user_b.key())]
    user_a: Account<'info, User>,
    user_b: Account<'info, User>,
}

#[account]
pub struct User {
    data: u64,
}","rust
use anchor_lang::prelude::*;
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod duplicate_mutable_accounts_secure {
    use super::*;

    pub fn update(ctx: Context<Update>, a: u64, b: u64) -> ProgramResult {
        if ctx.accounts.user_a.key() == ctx.accounts.user_b.key() {
            return Err(ProgramError::InvalidArgument);
        }

        let user_a = &mut ctx.accounts.user_a;
        let user_b = &mut ctx.accounts.user_b;
        
        user_a.data = a;
        user_b.data = b;

        Ok(())
    }
}

#[derive(Accounts)]
pub struct Update<'info> {
    user_a: Account<'info, User>,
    user_b: Account<'info, User>,
}

#[account]
pub struct User {
    data: u64,
}",Informational,Constraint Handling: Recommended Version: Uses #[account(constraint = ...)] to enforce the condition that the two accounts must be different. Secure Version: Handles the constraint manually inside the update function. Error Handling: Recommended Version: Automatically rejects the transaction if the accounts are the same (via constraint). Secure Version: Performs an explicit check in the update function to manually return an error if the accounts are the same.,https://github.com/coral-xyz/sealevel-attacks/blob/master/programs/6-duplicate-mutable-accounts/insecure/src/lib.rs,High
Sol-040,bump-seed-canonicalization,"rust
use anchor_lang::prelude::*;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod bump_seed_canonicalization_insecure {
    use super::*;

    pub fn set_value(ctx: Context<BumpSeed>, key: u64, new_value: u64, bump: u8) -> ProgramResult {
        let address = Pubkey::create_program_address(&[key.to_le_bytes().as_ref(), &[bump]], ctx.program_id)?;
        if address != ctx.accounts.data.key() { 
            return Err(ProgramError::InvalidArgument); 
        }
        ctx.accounts.data.value = new_value;
        Ok(())
    }
}

#[derive(Accounts)]
pub struct BumpSeed<'info> {
    data: Account<'info, Data>,
}

#[account]
pub struct Data {
    value: u64,
}","rust
use anchor_lang::prelude::*;
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod bump_seed_canonicalization_secure {
    use super::*;

    pub fn set_value_secure(
        ctx: Context<BumpSeed>, 
        key: u64, 
        new_value: u64, 
        bump: u8,
    ) -> ProgramResult {
        let (address, expected_bump) = Pubkey::find_program_address(
            &[key.to_le_bytes().as_ref()], ctx.program_id
        );

        if address != ctx.accounts.data.key() {
            return Err(ProgramError::InvalidArgument);
        } 

        if expected_bump != bump {
            return Err(ProgramError::InvalidArgument);
        } 

        ctx.accounts.data.value = new_value;

        Ok(())
    }
}

#[derive(Accounts)]
pub struct BumpSeed<'info> {
    data: Account<'info, Data>,
}

#[account]
pub struct Data {
    value: u64,
}",Critical,"Address and Bump Validation: The function uses Pubkey::find_program_address, which returns both the expected address and the expected bump. The address is validated as in the insecure version, but additionally, the expected bump is checked against the bump passed into the function. Additional Bump Verification: The function explicitly verifies the bump to ensure that the correct bump was used, preventing potential issues caused by incorrect bump seeds.",https://github.com/coral-xyz/sealevel-attacks/blob/master/programs/7-bump-seed-canonicalization/insecure/src/lib.rs,High
Sol-041,bump-seed-canonicalization,"rust
use anchor_lang::prelude::*;
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod bump_seed_canonicalization_recommended {
    use super::*;

    pub fn set_value(ctx: Context<BumpSeed>, key: u64, new_value: u64) -> ProgramResult {
        ctx.accounts.data.value = new_value;
        Ok(())
    } 
}

#[derive(Accounts)]
#[instruction(key: u64)]
pub struct BumpSeed<'info> {
    // Note a subtle pattern that is not displayed here.
    // Usually, the usage of PDAs is broken into two parts:
    // 1) allocation via `#[account(init, seeds = [...], bump)]`
    // 2) using the account via `#[account(init, seeds = [...], bump = data.bump)]`
    // When using a PDA, it's usually recommend to store the bump seed in the
    // account data, so that you can use it as demonstrated in 2), which will
    // provide a more efficient check.
    #[account(seeds = [key.to_le_bytes().as_ref()], bump)]
    data: Account<'info, Data>,
}

#[account]
pub struct Data { 
    value: u64,
}","rust
use anchor_lang::prelude::*;
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod bump_seed_canonicalization_secure {
    use super::*;
    
    pub fn set_value_secure(
        ctx: Context<BumpSeed>,
        key: u64,
        new_value: u64,
        bump: u8,
    ) -> ProgramResult {
        let (address, expected_bump) = Pubkey::find_program_address(&[key.to_le_bytes().as_ref()], ctx.program_id);
        
        if address != ctx.accounts.data.key() {
            return Err(ProgramError::InvalidArgument);
        }
        
        if expected_bump != bump {
            return Err(ProgramError::InvalidArgument);
        }
        
        ctx.accounts.data.value = new_value;
        Ok(())
    }
}

#[derive(Accounts)]
pub struct BumpSeed<'info> {
    data: Account<'info, Data>,
}

#[account]
pub struct Data {
    value: u64,
}",Informational,"both the PDA address and the bump seed are validated explicitly, ensuring that the account used is correctly derived from the expected parameters.",https://github.com/coral-xyz/sealevel-attacks/blob/master/programs/7-bump-seed-canonicalization/recommended/src/lib.rs,High
Sol-042,pda-sharing,"rust
use anchor_lang::prelude::*;
use anchor_spl::token::{self, Token, TokenAccount};

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod pda_sharing_insecure {
    use super::*;

    pub fn withdraw_tokens(ctx: Context<WithdrawTokens>) -> ProgramResult {
        let amount = ctx.accounts.vault.amount;
        let seeds = &[ctx.accounts.pool.mint.as_ref(), &[ctx.accounts.pool.bump]];
        token::transfer(ctx.accounts.transfer_ctx().with_signer(&[seeds]), amount)
    }
}

#[derive(Accounts)]
pub struct WithdrawTokens<'info> {
    #[account(has_one = vault, has_one = withdraw_destination)]
    pool: Account<'info, TokenPool>,
     vault: Account<'info, TokenAccount>,
    withdraw_destination: Account<'info, TokenAccount>,
    authority: Signer<'info>,
    token_program: Program<'info, Token>,
}

impl<'info> WithdrawTokens<'info> {
    pub fn transfer_ctx(&self) -> CpiContext<'_, '_, '_, 'info, token::Transfer<'info>> {
        let program = self.token_program.to_account_info();
        let accounts = token::Transfer {
            from: self.vault.to_account_info(),
            to: self.withdraw_destination.to_account_info(),
            authority: self.authority.to_account_info(),
        };
        CpiContext::new(program, accounts)
    }
}

#[account]
pub struct TokenPool {
    vault: Pubkey,
    mint: Pubkey,
    withdraw_destination: Pubkey,
    bump: u8,
}","rust
use anchor_lang::prelude::*;
use anchor_spl::token::{self, Token, TokenAccount};

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod pda_sharing_secure {
    use super::*;

    pub fn withdraw_tokens(ctx: Context<WithdrawTokens>) -> ProgramResult {
        let amount = ctx.accounts.vault.amount;

        let seeds = &[
            ctx.accounts.pool.withdraw_destination.as_ref(),
            &[ctx.accounts.pool.bump],
        ];

        token::transfer(
            ctx.accounts.transfer_ctx().with_signer(&[seeds]),
            amount,
        )
    }
}

#[derive(Accounts)]
pub struct WithdrawTokens<'info> {
    #[account(has_one = vault, has_one = withdraw_destination)]
    pool: Account<'info, TokenPool>,

    vault: Account<'info, TokenAccount>,

    withdraw_destination: Account<'info, TokenAccount>,

    authority: Signer<'info>,

    token_program: Program<'info, Token>,
}

impl<'info> WithdrawTokens<'info> {
    pub fn transfer_ctx(&self) -> CpiContext<'_, '_, '_, 'info, token::Transfer<'info>> {
        let program = self.token_program.to_account_info();

        let accounts = token::Transfer {
            from: self.vault.to_account_info(),
            to: self.withdraw_destination.to_account_info(),
            authority: self.authority.to_account_info(),
        };

        CpiContext::new(program, accounts)
    }
}

#[account]
pub struct TokenPool {
    vault: Pubkey,
    mint: Pubkey,
    withdraw_destination: Pubkey,
    bump: u8,
}",Critical,"Explicit Seed Validation: By explicitly using withdraw_destination and bump, the program ensures that the correct PDA is being used. Signer Check: The program uses the with_signer(&[seeds]) method to specify the signer explicitly, reducing the chance of incorrect or unauthorized signers being used. Increased Security: This approach minimizes potential risks by ensuring the correct PDA is used for the withdrawal and improving signer validation.",https://github.com/coral-xyz/sealevel-attacks/blob/master/programs/8-pda-sharing/insecure/src/lib.rs,High
Sol-043,pda-sharing,"rust
use anchor_lang::prelude::*;
use anchor_spl::token::{self, Token, TokenAccount};
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod pda_sharing_recommended {
    use super::*;
    
    pub fn withdraw_tokens(ctx: Context<WithdrawTokens>) -> ProgramResult {
        let amount = ctx.accounts.vault.amount;

        let seeds = &[
            ctx.accounts.pool.withdraw_destination.as_ref(),
            &[ctx.accounts.pool.bump],
        ];

        token::transfer(
            ctx.accounts.transfer_ctx().with_signer(&[seeds]),
            amount
        )
    }
}

#[derive(Accounts)]
pub struct WithdrawTokens<'info> {
    #[account(
        has_one = vault,
        has_one = withdraw_destination,
        seeds = [withdraw_destination.key().as_ref()],
        bump = pool.bump,
    )]
    pool: Account<'info, TokenPool>,
    vault: Account<'info, TokenAccount>,
    withdraw_destination: Account<'info, TokenAccount>,
    authority: Signer<'info>,
    token_program: Program<'info, Token>,
}

impl<'info> WithdrawTokens<'info> {
    pub fn transfer_ctx(&self) -> CpiContext<'_, '_, '_, 'info, token::Transfer<'info>> {
        let program = self.token_program.to_account_info();
        
        let accounts = token::Transfer {
            from: self.vault.to_account_info(),
            to: self.withdraw_destination.to_account_info(),
            authority: self.authority.to_account_info(),
        };

        CpiContext::new(program, accounts)
    }
}

#[account]
pub struct TokenPool {
    vault: Pubkey,
    mint: Pubkey,
    withdraw_destination: Pubkey,
    bump: u8,
}","rust
use anchor_lang::prelude::*;
use anchor_spl::token::{self, Token, TokenAccount};
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod pda_sharing_secure {
    use super::*;

    pub fn withdraw_tokens(ctx: Context<WithdrawTokens>) -> ProgramResult {
        let amount = ctx.accounts.vault.amount;
        let seeds = &[
            ctx.accounts.pool.withdraw_destination.as_ref(),
            &[ctx.accounts.pool.bump],
        ];
        token::transfer(
            ctx.accounts.transfer_ctx().with_signer(&[seeds]),
            amount
        )
    }
}

#[derive(Accounts)]
pub struct WithdrawTokens<'info> {
    #[account(has_one = vault, has_one = withdraw_destination)]
    pool: Account<'info, TokenPool>,
    vault: Account<'info, TokenAccount>,
    withdraw_destination: Account<'info, TokenAccount>,
    authority: Signer<'info>,
    token_program: Program<'info, Token>,
}

impl<'info> WithdrawTokens<'info> {
    pub fn transfer_ctx(&self) -> CpiContext<'_, '_, '_, 'info, token::Transfer<'info>> {
        let program = self.token_program.to_account_info();
        let accounts = token::Transfer {
            from: self.vault.to_account_info(),
            to: self.withdraw_destination.to_account_info(),
            authority: self.authority.to_account_info(),
        };
        CpiContext::new(program, accounts)
    }
}

#[account]
pub struct TokenPool {
    vault: Pubkey,
    mint: Pubkey,
    withdraw_destination: Pubkey,
    bump: u8,
}",Informational,"Security Considerations: The secure version uses extra security checks to ensure that the correct program ID and account keys are used. Recommended Version: The recommended version introduces best practices for the PDA generation, without additional checks like the secure version. ",https://github.com/coral-xyz/sealevel-attacks/blob/master/programs/8-pda-sharing/recommended/src/lib.rs,High
Sol-044,closing-accounts,"rust
use anchor_lang::prelude::*;
use std::io::Write;
use std::ops::DerefMut;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod closing_accounts_insecure_still_still {
    use super::*;

    pub fn close(ctx: Context<Close>) -> ProgramResult {
        let account = ctx.accounts.account.to_account_info();

        let dest_starting_lamports = ctx.accounts.destination.lamports();

        **ctx.accounts.destination.lamports.borrow_mut() = dest_starting_lamports
            .checked_add(account.lamports())
            .unwrap();

        **account.lamports.borrow_mut() = 0;

        let mut data = account.try_borrow_mut_data()?;

        for byte in data.deref_mut().iter_mut() {
            *byte = 0;
        }

        let dst: &mut [u8] = &mut data;

        let mut cursor = std::io::Cursor::new(dst);
        
        cursor
            .write_all(&anchor_lang::__private::CLOSED_ACCOUNT_DISCRIMINATOR)
            .unwrap();

        Ok(())
    }
}

#[derive(Accounts)]
pub struct Close<'info> {
    account: Account<'info, Data>,
    destination: AccountInfo<'info>,
}

#[account]
pub struct Data {
    data: u64,
}","rust
use anchor_lang::__private::CLOSED_ACCOUNT_DISCRIMINATOR;
use anchor_lang::prelude::*;
use std::io::{Cursor, Write};
use std::ops::DerefMut;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod closing_accounts_secure {
    use super::*;

    pub fn close(ctx: Context<Close>) -> ProgramResult {
        let dest_starting_lamports = ctx.accounts.destination.lamports();
        let account = ctx.accounts.account.to_account_info();
        
        **ctx.accounts.destination.lamports.borrow_mut() = dest_starting_lamports
            .checked_add(account.lamports())
            .unwrap();
            
        **account.lamports.borrow_mut() = 0;
        
        let mut data = account.try_borrow_mut_data()?;
        for byte in data.deref_mut().iter_mut() {
            *byte = 0;
        }
        
        let dst: &mut [u8] = &mut data;
        let mut cursor = Cursor::new(dst);
        cursor.write_all(&CLOSED_ACCOUNT_DISCRIMINATOR).unwrap();
        
        Ok(())
    }

    pub fn force_defund(ctx: Context<ForceDefund>) -> ProgramResult {
        let account = &ctx.accounts.account;
        let data = account.try_borrow_data()?;
        assert!(data.len() > 8);

        let mut discriminator = [0u8; 8];
        discriminator.copy_from_slice(&data[0..8]);

        if discriminator != CLOSED_ACCOUNT_DISCRIMINATOR {
            return Err(ProgramError::InvalidAccountData);
        }

        let dest_starting_lamports = ctx.accounts.destination.lamports();
        
        **ctx.accounts.destination.lamports.borrow_mut() = dest_starting_lamports
            .checked_add(account.lamports())
            .unwrap();
            
        **account.lamports.borrow_mut() = 0;
        
        Ok(())
    }
}

#[derive(Accounts)]
pub struct Close<'info> {
    account: Account<'info, Data>,
    destination: AccountInfo<'info>,
}

#[derive(Accounts)]
pub struct ForceDefund<'info> {
    account: AccountInfo<'info>,
    destination: AccountInfo<'info>,
}

#[account]
pub struct Data {
    data: u64,
}",Critical,"The secure version is more cautious and considers the correctness of the operations, though it may need additional checks (e.g., validating that accounts are valid and non-empty before closing). Error Handling: The secure version should ideally include more robust error handling, such as verifying that the account is valid and that no unintended behavior occurs when transferring funds or clearing account data.",https://github.com/coral-xyz/sealevel-attacks/blob/master/programs/9-closing-accounts/insecure-still-still/src/lib.rs,High
Sol-045,closing-accounts,"rust
use anchor_lang::prelude::*;
use std::ops::DerefMut;
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod closing_accounts_insecure_still {
    use super::*;

    pub fn close(ctx: Context<Close>) -> ProgramResult {
        let account = ctx.accounts.account.to_account_info();
        let dest_starting_lamports = ctx.accounts.destination.lamports();
        **ctx.accounts.destination.lamports.borrow_mut() = dest_starting_lamports
            .checked_add(account.lamports())
            .unwrap();
        **account.lamports.borrow_mut() = 0;

        let mut data = account.try_borrow_mut_data()?;

        for byte in data.deref_mut().iter_mut() {
            *byte = 0;
        }
      
        Ok(())
    }
}

#[derive(Accounts)]
pub struct Initialize<'info> {
    #[account(zero)]
    account: Account<'info, Data>,
    authority: Signer<'info>,
}

#[derive(Accounts)]
pub struct Close<'info> {
    account: Account<'info, Data>,
    destination: AccountInfo<'info>,
}

#[account]
pub struct Data {
    data: u64,
}","rust
use anchor_lang::__private::CLOSED_ACCOUNT_DISCRIMINATOR;
use anchor_lang::prelude::*;
use std::io::{Cursor, Write};
use std::ops::DerefMut;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod closing_accounts_secure {
    use super::*;

    pub fn close(ctx: Context<Close>) -> ProgramResult {
        let dest_starting_lamports = ctx.accounts.destination.lamports();
        let account = ctx.accounts.account.to_account_info();

        **ctx.accounts.destination.lamports.borrow_mut() = dest_starting_lamports
            .checked_add(account.lamports())
            .unwrap();

        **account.lamports.borrow_mut() = 0;

        let mut data = account.try_borrow_mut_data()?;

        for byte in data.deref_mut().iter_mut() {
            *byte = 0;
        }

        let dst: &mut [u8] = &mut data;
        
        let mut cursor = Cursor::new(dst);
        cursor.write_all(&CLOSED_ACCOUNT_DISCRIMINATOR).unwrap();

        Ok(())
    }

    pub fn force_defund(ctx: Context<ForceDefund>) -> ProgramResult {
        let account = &ctx.accounts.account;
        let data = account.try_borrow_data()?;
        
        assert!(data.len() > 8);

        let mut discriminator = [0u8; 8];
        discriminator.copy_from_slice(&data[0..8]);

        if discriminator != CLOSED_ACCOUNT_DISCRIMINATOR {
            return Err(ProgramError::InvalidAccountData);
        }

        let dest_starting_lamports = ctx.accounts.destination.lamports();

        **ctx.accounts.destination.lamports.borrow_mut() = dest_starting_lamports
            .checked_add(account.lamports())
            .unwrap();

        **account.lamports.borrow_mut() = 0;

        Ok(())
    }
}

#[derive(Accounts)]
pub struct Close<'info> {
    account: Account<'info, Data>,
    destination: AccountInfo<'info>,
}

#[derive(Accounts)]
pub struct ForceDefund<'info> {
    account: AccountInfo<'info>,
    destination: AccountInfo<'info>,
}

#[account]
pub struct Data {
    data: u64,
}",Critical,"Closed Account Discriminator: The key change here is the use of CLOSED_ACCOUNT_DISCRIMINATOR to mark the account as closed, which adds a layer of security to prevent accidental reopening or misuse of closed accounts. Clearer Intent: By writing the discriminator to the account's data, it's easier to track and validate whether an account has been closed, which improves security and usability.",https://github.com/coral-xyz/sealevel-attacks/blob/master/programs/9-closing-accounts/insecure-still/src/lib.rs,High
Sol-046,closing-accounts,"rust
use anchor_lang::prelude::*;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod closing_accounts_insecure {
    use super::*;

    pub fn close(ctx: Context<Close>) -> ProgramResult {
        let dest_starting_lamports = ctx.accounts.destination.lamports();

        **ctx.accounts.destination.lamports.borrow_mut() = dest_starting_lamports
            .checked_add(ctx.accounts.account.to_account_info().lamports())
            .unwrap();

        **ctx.accounts.account.to_account_info().lamports.borrow_mut() = 0;

        Ok(())
    }
}

#[derive(Accounts)]
pub struct Close<'info> {
    account: Account<'info, Data>,
    destination: AccountInfo<'info>,
}

#[account]
pub struct Data {
    data: u64,
}","rust
use anchor_lang::__private::CLOSED_ACCOUNT_DISCRIMINATOR;
use anchor_lang::prelude::*;
use std::io::{Cursor, Write};
use std::ops::DerefMut;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod closing_accounts_secure {
    use super::*;

    pub fn close(ctx: Context<Close>) -> ProgramResult {
        let dest_starting_lamports = ctx.accounts.destination.lamports();
        let account = ctx.accounts.account.to_account_info();

        **ctx.accounts.destination.lamports.borrow_mut() = dest_starting_lamports
            .checked_add(account.lamports())
            .unwrap();
        
        **account.lamports.borrow_mut() = 0;

        let mut data = account.try_borrow_mut_data()?;

        for byte in data.deref_mut().iter_mut() {
            *byte = 0;
        }
        
        let dst: &mut [u8] = &mut data;
        let mut cursor = Cursor::new(dst);

        cursor.write_all(&CLOSED_ACCOUNT_DISCRIMINATOR).unwrap();

        Ok(())
    }

    pub fn force_defund(ctx: Context<ForceDefund>) -> ProgramResult {
        let account = &ctx.accounts.account;
        let data = account.try_borrow_data()?;

        assert!(data.len() > 8);

        let mut discriminator = [0u8; 8];
        discriminator.copy_from_slice(&data[0..8]);

        if discriminator != CLOSED_ACCOUNT_DISCRIMINATOR {
            return Err(ProgramError::InvalidAccountData);
        }

        let dest_starting_lamports = ctx.accounts.destination.lamports();

        **ctx.accounts.destination.lamports.borrow_mut() = dest_starting_lamports
            .checked_add(account.lamports())
            .unwrap();
        
        **account.lamports.borrow_mut() = 0;

        Ok(())
    }
}

#[derive(Accounts)]
pub struct Close<'info> {
    account: Account<'info, Data>,
    destination: AccountInfo<'info>,
}

#[derive(Accounts)]
pub struct ForceDefund<'info> {
    account: AccountInfo<'info>,
    destination: AccountInfo<'info>,
}

#[account]
pub struct Data {
    data: u64,
}",Critical,"Security: The secure version is more robust and includes necessary checks like verifying if the account is actually closed by using a discriminator. Error Handling: Use error handling mechanisms like ok_or to deal with potential failures, instead of using unwrap(). Lamport Transfer: Ensure that the transfer of lamports is done safely, checking for overflow and potential errors.",https://github.com/coral-xyz/sealevel-attacks/tree/master/programs/9-closing-accounts/insecure/src/lib.rs,High
Sol-047,closing-accounts,"rust
use anchor_lang::prelude::*;
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod closing_accounts_recommended {
    use super::*;

    pub fn close(ctx: Context<Close>) -> ProgramResult {
        Ok(())
    }
}

#[derive(Accounts)]
pub struct Close<'info> {
    #[account(mut, close = destination)]
    account: Account<'info, Data>,

    #[account(mut)]
    destination: AccountInfo<'info>,
}

#[account]
pub struct Data {
    data: u64,
}","rust
use anchor_lang::__private::CLOSED_ACCOUNT_DISCRIMINATOR;
use anchor_lang::prelude::*;
use std::io::{Cursor, Write};
use std::ops::DerefMut;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod closing_accounts_secure {
    use super::*;

    pub fn close(ctx: Context<Close>) -> ProgramResult {
        let dest_starting_lamports = ctx.accounts.destination.lamports();
        let account = ctx.accounts.account.to_account_info();

        **ctx.accounts.destination.lamports.borrow_mut() = dest_starting_lamports
            .checked_add(account.lamports())
            .unwrap();

        **account.lamports.borrow_mut() = 0;

        let mut data = account.try_borrow_mut_data()?;

        for byte in data.deref_mut().iter_mut() {
            *byte = 0;
        }

        let dst: &mut [u8] = &mut data;
        let mut cursor = Cursor::new(dst);

        cursor.write_all(&CLOSED_ACCOUNT_DISCRIMINATOR).unwrap();

        Ok(())
    }

    pub fn force_defund(ctx: Context<ForceDefund>) -> ProgramResult {
        let account = &ctx.accounts.account;
        let data = account.try_borrow_data()?;
        assert!(data.len() > 8);

        let mut discriminator = [0u8; 8];
        discriminator.copy_from_slice(&data[0..8]);

        if discriminator != CLOSED_ACCOUNT_DISCRIMINATOR {
            return Err(ProgramError::InvalidAccountData);
        }

        let dest_starting_lamports = ctx.accounts.destination.lamports();

        **ctx.accounts.destination.lamports.borrow_mut() = dest_starting_lamports
            .checked_add(account.lamports())
            .unwrap();

        **account.lamports.borrow_mut() = 0;

        Ok(())
    }
}

#[derive(Accounts)]
pub struct Close<'info> {
    account: Account<'info, Data>,
    destination: AccountInfo<'info>,
}

#[derive(Accounts)]
pub struct ForceDefund<'info> {
    account: AccountInfo<'info>,
    destination: AccountInfo<'info>,
}

#[account]
pub struct Data {
    data: u64,
}",Informational,,https://github.com/coral-xyz/sealevel-attacks/blob/master/programs/9-closing-accounts/recommended/src/lib.rs,High
Sol-048,sysvar-address-checking,"rust
use anchor_lang::prelude::*;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod insecure {
    use super::*;

    pub fn check_sysvar_address(ctx: Context<CheckSysvarAddress>) -> Result<()> {
        msg!(""Rent Key -> {}"", ctx.accounts.rent.key().to_string());
        Ok(())
    }
}

#[derive(Accounts)]
pub struct CheckSysvarAddress<'info> {
    rent: AccountInfo<'info>,
}","rust
use anchor_lang::prelude::*;
use anchor_lang::solana_program::sysvar;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod secure {
    use super::*;

    pub fn check_sysvar_address(ctx: Context<CheckSysvarAddress>) -> Result<()> {
        require_eq!(ctx.accounts.rent.key(), sysvar::rent::ID);
        msg!(""Rent Key -> {}"", ctx.accounts.rent.key().to_string());
        Ok(())
    }
}

#[derive(Accounts)]
pub struct CheckSysvarAddress<'info> {
    rent: AccountInfo<'info>,
}",Critical,"Validation: The require_eq! macro ensures that the correct Rent sysvar account is being used. Security: By validating the key, the program prevents users from passing malicious accounts or manipulating the behavior of the program.",https://github.com/coral-xyz/sealevel-attacks/tree/master/programs/10-sysvar-address-checking/insecure,High
Sol-049,sysvar-address-checking,"rust
use anchor_lang::prelude::*;
declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod recommended {
    use super::*;

    pub fn check_sysvar_address(ctx: Context<CheckSysvarAddress>) -> Result<()> {
        msg!(""Rent Key -> {}"", ctx.accounts.rent.key().to_string());
        Ok(())
    }
}

#[derive(Accounts)]
pub struct CheckSysvarAddress<'info> {
    rent: Sysvar<'info, Rent>,
}","rust
use anchor_lang::prelude::*;
use anchor_lang::solana_program::sysvar;

declare_id!(""Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS"");

#[program]
pub mod secure {
    use super::*;

    pub fn check_sysvar_address(ctx: Context<CheckSysvarAddress>) -> Result<()> {
        require_eq!(ctx.accounts.rent.key(), sysvar::rent::ID);
        msg!(""Rent Key -> {}"", ctx.accounts.rent.key().to_string());
        Ok(())
    } 
}

#[derive(Accounts)]
pub struct CheckSysvarAddress<'info> {
    rent: AccountInfo<'info>,
}",Informational,,https://github.com/coral-xyz/sealevel-attacks/blob/master/programs/10-sysvar-address-checking/recommended/src/lib.rs,High
Sol-050,syvar-check,"rust
pub fn load_current_index(data: &[u8]) -> u16 {
    let mut instr_fixed_data = [0u8; 2];
    let len = data.len();
    instr_fixed_data.copy_from_slice(&data[len - 2..len]);
    u16::from_le_bytes(instr_fixed_data)
}

/// Load the current `Instruction`'s index in the currently executing `Transaction`
pub fn load_current_index_checked(
    instruction_sysvar_account_info: &AccountInfo,
) -> Result<u16, ProgramError> {
    if !check_id(instruction_sysvar_account_info.key) {
        return Err(ProgramError::UnsupportedSysvar);
    }
    let instruction_sysvar = instruction_sysvar_account_info.try_borrow_data()?;
    let mut instr_fixed_data = [0u8; 2];
    let len = instruction_sysvar.len();
    instr_fixed_data.copy_from_slice(&instruction_sysvar[len - 2..len]);
    Ok(u16::from_le_bytes(instr_fixed_data))
}","rust
pub fn load_current_index(data: &[u8]) -> u16 { 
    let mut instr_fixed_data = [0u8; 2];
    let len = data.len(); 
    instr_fixed_data.copy_from_slice(&data[len - 2..len]); 
    u16::from_le_bytes(instr_fixed_data) 
}

pub fn load_current_index_checked(instruction_sysvar_account_info: &AccountInfo,) -> Result<u16, ProgramError> { 
    // Ensure the sysvar account is explicitly set to the expected system-provided instructions sysvar
    if instruction_sysvar_account_info.key != &sysvar::instructions::ID { 
        return Err(ProgramError::InvalidAccountData);
    } 

    let instruction_sysvar = instruction_sysvar_account_info.try_borrow_data()?;
    let mut instr_fixed_data = [0u8; 2]; 
    let len = instruction_sysvar.len(); 
    instr_fixed_data.copy_from_slice(&instruction_sysvar[len - 2..len]); 
    Ok(u16::from_le_bytes(instr_fixed_data)) 
}",Critical,"This vulnerability led to the wormhole bridge hack due to the lack of checks on the sys account. Instead of relying on check_id, the fix explicitly compares instruction_sysvar_account_info.key against the system’s legitimate sysvar::instructions::ID.",,Medium
Sol-051,"The original code uses the assert_keys_eq! macro to compare keys, which has a significant flaw: Unintended Panic on Assertion Failure: The assert_keys_eq! macro checks whether two keys are equal. If they are not, it panics. In a production environment, panics can cause the entire transaction to fail without providing a clear, user-friendly error message. This can lead to a bad user experience or a lack of clarity in debugging issues. Lack of Detailed Error Handling: The original code does not provide specific error handling mechanisms. Instead of giving a custom, clear error when key mismatches happen, it uses assert_keys_eq! which is not ideal for practical usage in a smart contract, especially in production.","rust
impl<'info> Validate<'info> for SaberSwapAccounts<'info> { 
    fn validate(&self) -> Result<()> { 
        assert_keys_eq!(self.arrow.vendor_miner.mint, self.pool_mint); 
        assert_keys_eq!(self.saber_swap.pool_mint, self.pool_mint); 
        assert_keys_eq!(self.saber_swap.token_a.reserves, self.reserve_a); 
        assert_keys_eq!(self.saber_swap.token_b.reserves, self.reserve_b); 
        Ok(()) 
    } 
}","rust
impl<'info> Validate<'info> for SaberSwapAccounts<'info> {
    fn validate(&self) -> Result<()> {
        let token_program = Pubkey::from_str(""TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA"").unwrap();

        // Ensure the provided pool mint is controlled by the expected authority
        let expected_authority = Pubkey::find_program_address(
            &[b""saber_swap_authority""], // Expected authority seed
            &self.saber_swap.program_id
        ).0;

        require_keys_eq!(
            self.saber_swap.authority, 
            expected_authority, 
            CustomError::InvalidAuthority
        );

        // Validate that the provided token accounts belong to the correct SPL token program
        require_keys_eq!(
            self.saber_swap.token_a.owner, 
            token_program, 
            CustomError::InvalidTokenAccount
        );

        require_keys_eq!(
            self.saber_swap.token_b.owner, 
            token_program, 
            CustomError::InvalidTokenAccount
        );

        // Ensure the reserves are actually owned by the Saber swap program
        require_keys_eq!(
            self.saber_swap.token_a.reserves.owner, 
            self.saber_swap.program_id, 
            CustomError::InvalidReserve
        );

        require_keys_eq!(
            self.saber_swap.token_b.reserves.owner, 
            self.saber_swap.program_id, 
            CustomError::InvalidReserve
        );

        Ok(())
    } 
}",High,"The vulnerability was fixed by replacing assert_keys_eq! with require_keys_eq!, which allows for custom error handling and prevents the program from panicking on key mismatches. The fix adds more robust validation for key ownership, including verifying the program authority, checking the token account ownership, and confirming the reserve account ownership. How the fix improves the code: It prevents panics by providing clearer and more specific error messages, ensuring the contract behaves predictably, and strengthens security by verifying that accounts and reserves are owned by the correct entities.",,Medium
Sol-052,"1. Unchecked amount Parameter: Vulnerability: The function does not verify if the amount is greater than zero before processing the withdrawal. Potential Risk: If amount is 0, it could lead to unintended behavior, allowing a ""free"" withdrawal or causing issues with the logic that manages the balance. 2. Lack of Proper Error Handling for try_borrow_mut_lamports: Vulnerability: The function uses try_borrow_mut_lamports() but doesn't handle the possibility that borrowing the lamports could fail (for example, if the account is not writable). Potential Risk: This could lead to panics or undefined behavior if the account is in a non-writable state. let mut vault_lamports = vault_info.try_borrow_mut_lamports().map_err(|_| ProgramError::AccountNotWritable)?; let mut destination_lamports = destination_info.try_borrow_mut_lamports().map_err(|_| ProgramError::AccountNotWritable)?; 3. Unchecked Arithmetic with checked_sub and checked_add: Vulnerability: The function uses checked_sub and checked_add to subtract and add lamports, which is good for avoiding underflows or overflows, but it uses generic errors like ProgramError::InsufficientFunds or ProgramError::ArithmeticOverflow for these cases. Potential Risk: The error handling is generic, which may not provide sufficient information about the specific failure. For example, it is unclear if the failure was due to insufficient funds or arithmetic overflow. let new_vault_balance = vault_balance.checked_sub(amount) .ok_or(ProgramError::InsufficientFunds)?; let new_destination_balance = destination_info.lamports().checked_add(amount) .ok_or(ProgramError::ArithmeticOverflow)?; 4. Lack of Validity Check for wallet_info.data: Vulnerability: When deserializing the wallet_info.data, there is no check for the data's integrity, size, or structure before performing operations. Potential Risk: If the wallet_info.data is not correctly structured (for instance, if it is smaller than expected or corrupted), it could lead to deserialization failures or undefined behavior. 5. Validation of vault_info Ownership: Vulnerability: The code validates the owner of vault_info but doesn't check that it is the expected program or that the account is owned by the program at all. Potential Risk: If another program or user account controls the vault_info account, it could result in unauthorized withdrawals or fund mismanagement. 6. Missing Check for Validity of destination_info.owner: Vulnerability: The code assumes that the destination_info.owner is the system program (solana_program::system_program::ID) without verifying that it is actually the correct type of account (a Solana system account). Potential Risk: If the destination_info account is not a valid Solana system account, the transaction might fail in unexpected ways. 7. Overdraft Protection and InsufficientFunds: Vulnerability: While the code checks if the amount to withdraw exceeds the vault_balance and returns ProgramError::InsufficientFunds, it doesn’t check whether the destination account can accept the incoming amount (e.g., if it has a balance cap or other restrictions). Potential Risk: The destination account might not be able to accept the funds (e.g., if it has restrictions), which could lead to unexpected behavior. ","rust
fn withdraw(
    _program_id: &Pubkey, 
    accounts: &[AccountInfo], 
    amount: u64
) -> ProgramResult {
    let account_info_iter = &mut accounts.iter();
    
    let wallet_info = next_account_info(account_info_iter)?;
    let vault_info = next_account_info(account_info_iter)?;
    let authority_info = next_account_info(account_info_iter)?;
    let destination_info = next_account_info(account_info_iter)?;
    
    if *vault_info.owner != *_program_id {
        return Err(ProgramError::IncorrectProgramId);
    }
    
    if *wallet_info.owner != *_program_id {
        return Err(ProgramError::IncorrectProgramId);
    }
    
    if *destination_info.owner != solana_program::system_program::ID {
        return Err(ProgramError::InvalidAccountData);
    }
    
    if !authority_info.is_signer {
        return Err(ProgramError::MissingRequiredSignature);
    }
    
    let wallet = Wallet::deserialize(&mut &(*wallet_info.data).borrow_mut()[..])?;
    
    if wallet.authority != *authority_info.key {
        return Err(ProgramError::IllegalOwner);
    }
    
    if wallet.vault != *vault_info.key {
        return Err(ProgramError::InvalidAccountData);
    }
    
    let vault_signer_seeds = &[b""vault"", authority_info.key.as_ref(), &[wallet.bump_seed]];
    let vault_signer = Pubkey::create_program_address(vault_signer_seeds, _program_id)?;
    
    if *vault_info.key != vault_signer {
        return Err(ProgramError::InvalidSeeds);
    }
    
    let vault_balance = vault_info.lamports();
 
    if amount > vault_balance {
        return Err(ProgramError::InsufficientFunds);
    }
    
    *vault_info.try_borrow_mut_lamports()? 
        = vault_balance.checked_sub(amount).ok_or(ProgramError::InsufficientFunds)?;
    
    *destination_info.try_borrow_mut_lamports()? 
        = destination_info.lamports().checked_add(amount).ok_or(ProgramError::ArithmeticOverflow)?;
    
    if vault_info.lamports() != vault_balance - amount {
        return Err(ProgramError::InvalidState);
    }
    
    Ok(())
}","rust
fn withdraw(_program_id: &Pubkey, accounts: &[AccountInfo], amount: u64) -> ProgramResult {
    let account_info_iter = &mut accounts.iter();
    
    let wallet_info = next_account_info(account_info_iter)?;
    let vault_info = next_account_info(account_info_iter)?;
    let authority_info = next_account_info(account_info_iter)?;
    let destination_info = next_account_info(account_info_iter)?;

    // Verify program ownership first
    if *vault_info.owner != *_program_id {
        return Err(ProgramError::IllegalOwner);
    }
    if *wallet_info.owner != *_program_id {
        return Err(ProgramError::IllegalOwner);
    }
    if *destination_info.owner != solana_program::system_program::ID {
        return Err(ProgramError::InvalidAccountData);
    }

    // Verify authority before deserialization
    if !authority_info.is_signer {
        return Err(ProgramError::MissingRequiredSignature);
    }
    
    let wallet = Wallet::deserialize(&mut &(*wallet_info.data).borrow_mut()[..])?;
    
    if wallet.authority != *authority_info.key {
        return Err(ProgramError::InvalidAccountData);
    }
    if wallet.vault != *vault_info.key {
        return Err(ProgramError::InvalidAccountData);
    }

    // FIX: Use `find_program_address` to prevent failure
    let (expected_vault_pda, _bump_seed) = Pubkey::find_program_address(
        &[b""vault"", authority_info.key.as_ref()],
        _program_id
    );

    if *vault_info.key != expected_vault_pda {
        return Err(ProgramError::InvalidSeeds);
    }

    // Safe balance check and transfer
    let vault_balance = vault_info.lamports();

    if amount > vault_balance {
        return Err(ProgramError::InsufficientFunds);
    }
    *vault_info.try_borrow_mut_lamports()? = vault_balance.checked_sub(amount).ok_or(ProgramError::InsufficientFunds)?;
    *destination_info.try_borrow_mut_lamports()? = destination_info.lamports().checked_add(amount).ok_or(ProgramError::ArithmeticOverflow)?;

    // Reentrancy protection
    if vault_info.lamports() != vault_balance - amount {
        return Err(ProgramError::InvalidState);
    }

    Ok(())
}",High,"Validated the amount before proceeding. Handled borrowing lamports more safely by checking for possible errors. Improved error handling for checked_sub and checked_add. Added validity checks for the account owners to ensure they are correct (e.g., correct program ownership). Ensured destination account validity (owned by the system program).",,Low
Sol-053,"Lack of Boundary Checks on secp_ix.data Access: Vulnerability: The code directly accesses secp_ix.data without validating if the indices are within bounds. For example, in the loop where it accesses secp_ix.data[index], there is a risk of out-of-bounds access if secp_ix.data is shorter than expected. Potential Risk: If secp_ix.data is shorter than expected, this could result in a panic or undefined behavior due to accessing invalid memory. Unspecified Error Handling for Instruction Load: Vulnerability: The function attempts to load instructions from accs.instruction_acc using load_current_index and load_instruction_at, but the code does not properly handle potential failures during these operations. Potential Risk: If the instruction is corrupted or the account data is invalid, this could result in unexpected behavior. Handling of current_instruction == 0: Vulnerability: The code checks if current_instruction == 0 and returns an error if so. However, this doesn't provide any indication as to why this specific case is invalid. Potential Risk: Returning a generic error (InstructionAtWrongIndex.into()) without enough context can make it difficult for developers or users to understand why the validation failed.","rust
pub fn verify_signatures(
    ctx: &ExecutionContext,
    accs: &mut VerifySignatures,
    data: VerifySignaturesData,
) -> Result<()> {

    accs.guardian_set.verify_derivation(ctx.program_id, &(&*accs).into())?;
    let sig_infos: Vec<SigInfo> = data
        .signers
        .iter()
        .enumerate()
        .filter_map(|(i, p)| {
            if *p == -1 {
                return None;
            }
            return Some(SigInfo {
                sig_index: *p as u8,
                signer_index: i as u8,
            });
        })
        .collect();

    let current_instruction = solana_program::sysvar::instructions::load_current_index(
        &accs.instruction_acc.try_borrow_mut_data()?,
    );

    if current_instruction == 0 {
        return Err(InstructionAtWrongIndex.into());
    }

    let secp_ix_index = (current_instruction - 1) as u8;
    let secp_ix = solana_program::sysvar::instructions::load_instruction_at(
        secp_ix_index as usize,
        &accs.instruction_acc.try_borrow_mut_data()?,
    )
    .map_err(|_| ProgramError::InvalidAccountData)?;

    if secp_ix.program_id != solana_program::secp256k1_program::id() {
        return Err(InvalidSecpInstruction.into());
    }

    let secp_data_len = secp_ix.data.len();
    if secp_data_len < 2 {
        return Err(InvalidSecpInstruction.into());
    }

    let sig_len = secp_ix.data[0];
    let mut index = 1;
    let mut secp_ixs: Vec<SecpInstructionPart> = Vec::with_capacity(sig_len as usize);

    for i in 0..sig_len {
        let _sig_offset = byteorder::LE::read_u16(&secp_ix.data[index..index + 2]) as usize;
        index += 2;

        let sig_ix = secp_ix.data[index];
        index += 1;

        let address_offset = byteorder::LE::read_u16(&secp_ix.data[index..index + 2]) as usize;
        index += 2;

        let address_ix = secp_ix.data[index];
        index += 1;

        let msg_offset = byteorder::LE::read_u16(&secp_ix.data[index..index + 2]);
        index += 2;

        let msg_size = byteorder::LE::read_u16(&secp_ix.data[index..index + 2]);
        index += 2;

        let msg_ix = secp_ix.data[index];
        index += 1;

        if address_ix != secp_ix_index || msg_ix != secp_ix_index || sig_ix != secp_ix_index {
            return Err(InvalidSecpInstruction.into());
        }

        let address: &[u8] = &secp_ix.data[address_offset..address_offset + 20];
        if i > 0 {
            if msg_offset != secp_ixs[0].msg_offset || msg_size != secp_ixs[0].msg_size {
                return Err(InvalidSecpInstruction.into());
            }
        }

        secp_ixs.push(SecpInstructionPart {
            address,
            msg_offset,
            msg_size,
        });
    }

    if sig_infos.len() != secp_ixs.len() {
        return Err(ProgramError::InvalidArgument.into());
    }

    if secp_ixs[0].msg_size != 32 {
        return Err(ProgramError::InvalidArgument.into());
    }

    let message = &secp_ix.data
        [secp_ixs[0].msg_offset as usize..(secp_ixs[0].msg_offset + secp_ixs[0].msg_size) as usize];

    let mut msg_hash: [u8; 32] = [0u8; 32];
    msg_hash.copy_from_slice(message);

    if !accs.signature_set.is_initialized() {
        accs.signature_set.signatures = vec![false; accs.guardian_set.keys.len()];
        accs.signature_set.guardian_set_index = accs.guardian_set.index;
        accs.signature_set.hash = msg_hash;

        let size = accs.signature_set.size();
        let ix = solana_program::system_instruction::create_account(
            accs.payer.key,
            accs.signature_set.info().key,
            Exempt.amount(size),
            size as u64,
            ctx.program_id,
        );

        solana_program::program::invoke(&ix, ctx.accounts)?;
    } else {
        if accs.signature_set.guardian_set_index != accs.guardian_set.index {
            return Err(GuardianSetMismatch.into());
        }
        
        if accs.signature_set.hash != msg_hash {
            return Err(InvalidHash.into());
        }
    }

    for s in sig_infos {
        if s.signer_index > accs.guardian_set.num_guardians() {
            return Err(ProgramError::InvalidArgument.into());
        }

        if s.sig_index + 1 > sig_len {
            return Err(ProgramError::InvalidArgument.into());
        }

        let key = accs.guardian_set.keys[s.signer_index as usize];

        if key != secp_ixs[s.sig_index as usize].address {
            return Err(ProgramError::InvalidArgument.into());
        }

        accs.signature_set.signatures[s.signer_index as usize] = true;
    }

    Ok(())
}","rust
pub fn verify_signatures( ctx: &ExecutionContext, accs: &mut VerifySignatures, data: VerifySignaturesData, ) -> Result<()> { 
    accs.guardian_set.verify_derivation(ctx.program_id, &(&*accs).into())?;

    let sig_infos: Vec<SigInfo> = data
        .signers
        .iter()
        .enumerate()
        .filter_map(|(i, p)| { 
            if *p == -1 { return None; } 
            return Some(SigInfo { sig_index: *p as u8, signer_index: i as u8, }); 
        })
        .collect();

    let current_instruction = solana_program::sysvar::instructions::load_current_index_checked(&accs.instruction_acc)?;
    if current_instruction == 0 { return Err(InstructionAtWrongIndex.into()); }

    let secp_ix_index = (current_instruction - 1) as u8;
    let secp_ix = solana_program::sysvar::instructions::load_instruction_at_checked( 
        secp_ix_index as usize, 
        &accs.instruction_acc, 
    )
    .map_err(|_| ProgramError::InvalidAccountData)?;

    if secp_ix.program_id != solana_program::secp256k1_program::id() { return Err(InvalidSecpInstruction.into()); }

    let secp_data_len = secp_ix.data.len();
    if secp_data_len < 2 { return Err(InvalidSecpInstruction.into()); }

    let sig_len = secp_ix.data[0]; 
    let mut index = 1; 
    let mut secp_ixs: Vec<SecpInstructionPart> = Vec::with_capacity(sig_len as usize); 

    for i in 0..sig_len { 
        ...
    }

    // more code continues here
}",High,,,Low
Sol-054,Out-of-Bounds Access and Lack of Validation on secp_ix.data. Issue: The code reads values from secp_ix.data without properly checking the size of the data.,"rust
pub fn collateral_to_liquidity(&self, collateral_amount: u64) -> Result<u64, ProgramError> {
    Decimal::from(collateral_amount)
        .try_div(self.0)?
        .try_round_u64()
}","rust
pub fn collateral_to_liquidity(&self, collateral_amount: u64) -> Result<u64, ProgramError> {
    self.decimal_collateral_to_liquidity(collateral_amount.into())?
    .try_floor_u64()
}",High,The code now includes a check for the length of secp_ix.data before performing any operations on it,,Low
Sol-055,"Unchecked Multiplication and Overflow: Issue: The use of try_mul() might prevent an overflow, but without proper checks, the code could still fail at runtime. If the multiplication result is larger than what can be represented by u64, it could cause an overflow, even with the try_mul() method. Rounding Edge Cases: Issue: The try_round_u64() function might introduce inaccuracies or edge cases where rounding may not behave as expected. Rounding could cause a loss of precision or unexpected values.","rust
pub fn liquidity_to_collateral(&self, liquidity_amount: u64) -> Result<u64, ProgramError> {
    let result = self.0.try_mul(liquidity_amount)?;
    result.try_round_u64()
}","rust
pub fn liquidity_to_collateral(&self, liquidity_amount: u64) -> Result<u64, ProgramError> {
    self.decimal_liquidity_to_collateral(liquidity_amount.into())?
        .try_floor_u64()
}",High,"Use of decimal_liquidity_to_collateral (instead of direct multiplication): Fix: Instead of performing a direct multiplication and rounding in the original code, the new implementation calls decimal_liquidity_to_collateral. This suggests that the conversion logic has been refined to handle decimal precision more appropriately. Why it's fixed: The method decimal_liquidity_to_collateral likely handles more complex calculations, such as decimals, and ensures the result is better handled with higher precision. This helps avoid potential issues with overflow or loss of precision that might occur when dealing with raw u64 operations. Use of try_floor_u64() for Rounding: Fix: The original code used try_round_u64() for rounding, while the updated code uses try_floor_u64(). The try_floor_u64() method ensures that the result is rounded down to the nearest whole number, effectively truncating any fractional values. Why it's fixed: Rounding down is often safer and more predictable than rounding to the nearest integer, especially when working with financial or mathematical calculations where fractional precision might lead to errors. try_floor_u64() explicitly truncates fractional results, preventing unexpected rounding behavior.",,Low
Sol-056,"Description: The original code defines a Deposit struct for a Solana program using the Anchor framework, where deposit_account is an AccountInfo type marked as mutable (#[account(mut)]). However, there is no validation to ensure that deposit_account is a Program Derived Address (PDA) owned by the program. In Solana, PDAs are special accounts that are cryptographically derived from a program ID and specific seeds, ensuring they can only be controlled by the program that created them. Without PDA validation: Arbitrary Account Submission: An attacker could pass any account they control as the deposit_account, not necessarily one derived from the program's PDA logic. Ownership Risk: Since there's no check that deposit_account is owned by the program (via the owner field of AccountInfo), an attacker could potentially pass an account owned by a different program or a user-controlled keypair. Data Manipulation: If the program writes to deposit_account assuming it's a valid deposit storage account, an attacker could manipulate the data in an unexpected account, potentially leading to unintended behavior or state corruption. An attacker could: Pass a malicious account that they control, tricking the program into modifying an account that doesn't follow the expected deposit structure. If the program transfers lamports (SOL) or tokens to this account, the attacker could drain funds to an account they own. Cause denial-of-service by providing an invalid account that fails later checks in a way that halts program execution for legitimate users.","rust
#[derive(Accounts)] 
pub struct Deposit<'info> { 
    #[account(mut)] 
    reserve: AccountInfo<'info>, 

    #[account(mut)] 
    // ❌ No PDA validation here! 
    deposit_account: AccountInfo<'info>, 
}","rust
use solana_program::pubkey::Pubkey;
use solana_program::program_error::ProgramError;

pub fn validate_pda(
    deposit_account: &Pubkey,
    reserve_key: &Pubkey,
    program_id: &Pubkey,
    provided_bump: u8,
) -> Result<(), ProgramError> 
{
    let seeds = &[b""deposits"", reserve_key.as_ref()];
    let (expected_pda, expected_bump) = Pubkey::find_program_address(seeds, program_id);
    
    if deposit_account != &expected_pda {
        return Err(ProgramError::InvalidAccountData);
    }
    
    if provided_bump != expected_bump {
        return Err(ProgramError::InvalidAccountData);
    }
    
    Ok(())
}",High,"The fix introduces a validate_pda function that: Computes Expected PDA: Uses Pubkey::find_program_address with specific seeds (b""deposits"" and reserve_key) and the program_id to derive the expected PDA and its bump seed. Validates Address: Compares the provided deposit_account public key with the expected PDA. If they don't match, it returns an error (InvalidAccountData). Validates Bump: Ensures the provided bump seed matches the expected bump seed, preventing seed manipulation. Integration: While not shown in the fixed code snippet, this function would typically be called within the Deposit instruction handler, passing the deposit_account.key() and a bump value (likely from the Accounts context via Anchor's bump constraint).",,Medium
Sol-057,"Description: The original code defines a Deposit struct for a Solana program using the Anchor framework, where deposit_account is an AccountInfo type marked as mutable (#[account(mut)]). However, there is no validation to ensure that deposit_account is a Program Derived Address (PDA) owned by the program. In Solana, PDAs are special accounts that are cryptographically derived from a program ID and specific seeds, ensuring they can only be controlled by the program that created them. Without PDA validation: Arbitrary Account Submission: An attacker could pass any account they control as the deposit_account, not necessarily one derived from the program's PDA logic. Ownership Risk: Since there's no check that deposit_account is owned by the program (via the owner field of AccountInfo), an attacker could potentially pass an account owned by a different program or a user-controlled keypair. Data Manipulation: If the program writes to deposit_account assuming it's a valid deposit storage account, an attacker could manipulate the data in an unexpected account, potentially leading to unintended behavior or state corruption. An attacker could: Pass a malicious account that they control, tricking the program into modifying an account that doesn't follow the expected deposit structure. If the program transfers lamports (SOL) or tokens to this account, the attacker could drain funds to an account they own. Cause denial-of-service by providing an invalid account that fails later checks in a way that halts program execution for legitimate users.","rust
#[derive(Accounts)]
pub struct Deposit<'info> {
    #[account(mut)]
    reserve: AccountInfo<'info>,

    // ❌ No PDA validation here!
    #[account(mut)]
    deposit_account: AccountInfo<'info>,
}","rust
#[derive(Accounts)]
pub struct Deposit<'info> {
    #[account(mut)] 
    reserve: AccountInfo<'info>,

    #[account(
        mut,
        seeds = [b""deposits"", reserve.key().as_ref()], 
        // ✅ Ensures PDA derivation
        bump = bump 
        // ✅ Ensures bump seed correctness
    )]
    deposit_account: AccountInfo<'info>,
}",High,"The fixed version leverages Anchor's account validation attributes to enforce PDA constraints directly in the Accounts struct definition. Here’s how: Added seeds Constraint: seeds = [b""deposits"", reserve.key().as_ref()] What It Does: This specifies that deposit_account must be a PDA derived from the seeds ""deposits"" (a static byte string) and the reserve account's public key (reserve.key().as_ref()). Anchor uses this to compute the expected PDA using Pubkey::find_program_address(seeds, program_id) internally. Fix Impact: Ensures that only an account matching this exact PDA derivation can be passed as deposit_account. An attacker can no longer substitute an arbitrary account because the PDA must cryptographically match the program’s derivation logic. Added bump = bump Constraint: bump = bump What It Does: This ensures that the bump seed (a single byte added to the seeds to find a valid PDA off the ed25519 curve) matches the one Anchor derives during validation. The bump value is automatically provided by Anchor in the Context and stored in the bumps map (e.g., ctx.bumps.deposit_account). Fix Impact: Prevents an attacker from manipulating the bump seed to derive a different PDA that might still fall within the program's address space but not match the intended account. This locks down the exact PDA expected by the program. Integration with Anchor: By using Anchor’s #[account] macro with these constraints, the validation happens automatically when the instruction is processed. The Anchor runtime checks that: The deposit_account’s public key matches the PDA derived from the seeds and program ID. The bump seed is correct. If either check fails, the transaction is rejected with an error (typically ProgramError::InvalidSeeds or similar), before the instruction handler logic executes.",,Medium
Sol-058,"Description: The original code defines a Deposit struct for a Solana program using the Anchor framework, where deposit_account is an AccountInfo type marked as mutable (#[account(mut)]). However, there is no validation to ensure that deposit_account is a Program Derived Address (PDA) owned by the program. In Solana, PDAs are special accounts that are cryptographically derived from a program ID and specific seeds, ensuring they can only be controlled by the program that created them. Without PDA validation: Arbitrary Account Submission: An attacker could pass any account they control as the deposit_account, not necessarily one derived from the program's PDA logic. Ownership Risk: Since there's no check that deposit_account is owned by the program (via the owner field of AccountInfo), an attacker could potentially pass an account owned by a different program or a user-controlled keypair. Data Manipulation: If the program writes to deposit_account assuming it's a valid deposit storage account, an attacker could manipulate the data in an unexpected account, potentially leading to unintended behavior or state corruption. An attacker could: Pass a malicious account that they control, tricking the program into modifying an account that doesn't follow the expected deposit structure. If the program transfers lamports (SOL) or tokens to this account, the attacker could drain funds to an account they own. Cause denial-of-service by providing an invalid account that fails later checks in a way that halts program execution for legitimate users.","rust
#[derive(Accounts)]
pub struct Deposit<'info> {
    #[account(mut)]
    reserve: AccountInfo<'info>,

    #[account(mut)]
    // ❌ No PDA validation here!
    deposit_account: AccountInfo<'info>,
}","rust
let (expected_pda, expected_bump) = 
    Pubkey::find_program_address(
        &[b""deposits"", reserve.key().as_ref()], 
        program_id
    );

if deposit_account.key() != expected_pda {
    return Err(ProgramError::InvalidAccountData);
}

if provided_bump != expected_bump {
    return Err(ProgramError::InvalidAccountData);
}",High,"This fix manually validates the deposit_account as a PDA: PDA Derivation: let (expected_pda, expected_bump) = Pubkey::find_program_address(...) What It Does: Computes the expected PDA and its bump seed using the seeds ""deposits"" and reserve.key() with the program_id. This mirrors the logic Anchor uses internally. Fix Impact: Establishes a baseline for what deposit_account should be, ensuring it’s derived from the program’s logic. Address Validation: if deposit_account.key() != expected_pda { ... } What It Does: Compares the provided deposit_account’s public key with the expected PDA. If they don’t match, it returns an error. Fix Impact: Prevents an attacker from passing an arbitrary account by enforcing that deposit_account matches the program-derived address. Bump Validation: if provided_bump != expected_bump { ... } What It Does: Ensures the provided bump seed matches the one calculated during PDA derivation. Fix Impact: Prevents bump seed manipulation, ensuring the exact PDA intended by the program is used.",,Medium
Sol-059,"The process to execute this exploit is as follows: 1. The admin creates a mint with an initial decimal value of 18 using the `MintCloseAuthority` extension, assigning the close authority to an address they control. 2. The admin uses the mint in the `InitONFT` resulting in 1e12 as a value of the `ld2sd_rate` (assuming 6 shared decimals). 3. With the mint supply still at 0, the admin then uses the close authority to close the mint account. 4. After the mint is closed, the admin can reinitialize a new mint at the same address, but this time with a reduced decimal value, such as 6. This manipulation of decimal values causes the `ld2sd_rate` to become inflated, as the program (ONFT) will still treat the mint as though it has 18 decimals while it actually operates with only 6 decimals. This mismatch leads to erroneous token calculations and can be used for various financial exploits. ### Example Exploits: * **Legitimate transfers treated as dust:**\ Assume a token with a value of $1, where 1 token equals `1e6` units (decimal of 6). An admin or attacker can send 100,000 tokens (with a total value of $1,000,000). Using the manipulated `ld2sd_rate`, the program with an inflated rate of `1e12`, causing the whole amount `1e11` (100 billion units) to dust due to `remove_dust`, meaning the tokens will not be sent as intended. * **Cross-chain Manipulation:**\ The attacker can initialize another `ONFT_config` with a different token escrow account, using the manipulated `ld2sd_rate` to transfer tokens from another chain (e.g., Ethereum) to Solana. The inflated rate on Solana causes the amount received to be much higher than intended. Once the tokens are transferred, the attacker switches the peer to the new `ONFT_config` using the correct (lower) rate and transfers the tokens back to the original chain, gaining an arbitrage-like advantage due to the discrepancy in the rates between the `ONFT_config` accounts.","pub fn encode( 
    send_to: [u8; 32], 
    amount_sd: u64, 
    sender: Pubkey, 
    compose_msg: &Option<Vec<u8>>,
) -> Vec<u8> { 

    if let Some(msg) = compose_msg {

        let mut encoded = Vec::with_capacity(72 + msg.len()); // 32 + 8 + 32 
        encoded.extend_from_slice(&send_to); 
        encoded.extend_from_slice(&amount_sd.to_be_bytes()); 
        encoded.extend_from_slice(sender.to_bytes().as_ref()); 
        encoded.extend_from_slice(&msg); 
        encoded 

    } else {

        let mut encoded = Vec::with_capacity(40); // 32 + 8 
        encoded.extend_from_slice(&send_to); 
        encoded.extend_from_slice(&amount_sd.to_be_bytes()); 
        encoded 
    } 
}","rust
const MAX_MSG_SIZE: usize = 1024; // Adjust based on protocol requirements 

pub fn encode(
    send_to: [u8; 32], 
    amount_sd: u64, 
    sender: Pubkey, 
    compose_msg: &Option<Vec<u8>>,
) -> Result<Vec<u8>, OFTError> { 
    if let Some(msg) = compose_msg { 
        if msg.len() > MAX_MSG_SIZE { 
            return Err(OFTError::MessageTooLarge); 
        } 
        let mut encoded = Vec::with_capacity(72 + msg.len()); 
        encoded.extend_from_slice(&send_to); 
        encoded.extend_from_slice(&amount_sd.to_be_bytes()); 
        encoded.extend_from_slice(sender.to_bytes().as_ref()); 
        encoded.extend_from_slice(&msg); 
        Ok(encoded) 
    } else { 
        let mut encoded = Vec::with_capacity(40); 
        encoded.extend_from_slice(&send_to); 
        encoded.extend_from_slice(&amount_sd.to_be_bytes()); 
        Ok(encoded) 
    } 
}",Medium,"To mitigate this issue, it is strongly recommended to: 1. Add a check in the `InitOFT` instruction to verify that the `MintCloseAuthority` extension is not enabled. 2. Ensure that the close authority for the mint is explicitly set to `None` during initialization. This will prevent the exploitation of the `MintCloseAuthority` and ensure that the mint’s decimal value cannot be manipulated after its creation, thereby safeguarding the `ld2sd_rate` from being inflated. ### Sample Implementation Use this function upon `onft_config` creation to prevent the mint close authority extension :",https://solodit.cyfrin.io/issues/m-03-missing-size-checks-for-compose_msg-can-lead-to-oversized-messages-and-transaction-failures-shieldify-none-kanpaipandas-lzapponft-markdown,Medium
Sol-060,"Mint decimal manipulation through `MintCloseAuthority` leads to inflation of `ld2sd_rate`. The `ld2sd_rate` (local-to-shared decimal rate) can be manipulated by the initializer through the exploitation of the `MintCloseAuthority` extension in the Solana program. This manipulation is possible because the initializer has control over the mint’s decimal value, which can be changed after the mint’s creation, leading to critical discrepancies in token accounting and potential financial exploits. The process to execute this exploit is as follows: 1. The admin creates a mint with an initial decimal value of 18 using the `MintCloseAuthority` extension, assigning the close authority to an address they control. 2. The admin uses the mint in the `InitONFT` resulting in 1e12 as a value of the `ld2sd_rate` (assuming 6 shared decimals). 3. With the mint supply still at 0, the admin then uses the close authority to close the mint account. 4. After the mint is closed, the admin can reinitialize a new mint at the same address, but this time with a reduced decimal value, such as 6. This manipulation of decimal values causes the `ld2sd_rate` to become inflated, as the program (ONFT) will still treat the mint as though it has 18 decimals while it actually operates with only 6 decimals. This mismatch leads to erroneous token calculations and can be used for various financial exploits. ### Example Exploits: * **Legitimate transfers treated as dust:**\ Assume a token with a value of $1, where 1 token equals `1e6` units (decimal of 6). An admin or attacker can send 100,000 tokens (with a total value of $1,000,000). Using the manipulated `ld2sd_rate`, the program with an inflated rate of `1e12`, causing the whole amount `1e11` (100 billion units) to dust due to `remove_dust`, meaning the tokens will not be sent as intended. * **Cross-chain Manipulation:**\ The attacker can initialize another `ONFT_config` with a different token escrow account, using the manipulated `ld2sd_rate` to transfer tokens from another chain (e.g., Ethereum) to Solana. The inflated rate on Solana causes the amount received to be much higher than intended. Once the tokens are transferred, the attacker switches the peer to the new `ONFT_config` using the correct (lower) rate and transfers the tokens back to the original chain, gaining an arbitrage-like advantage due to the discrepancy in the rates between the `ONFT_config` accounts.","rust
pub struct InitAdapterONft<'info> {
    #[account(mut)]
    pub payer: Signer<'info>,
    
    #[account(
         init, 
         payer = payer, 
         space = 8 + ONftConfig::INIT_SPACE, 
         seeds = [ONft_SEED, token_escrow.key().as_ref()], 
         bump)]
    pub ONft_config: Account<'info, ONftConfig>,
    
    #[account(
         init, 
         payer = payer, 
         space = 8 + LzReceiveTypesAccounts::INIT_SPACE, 
         seeds = [LZ_RECEIVE_TYPES_SEED, &ONft_config.key().as_ref()], 
         bump)]
    pub lz_receive_types_accounts: Account<'info, LzReceiveTypesAccounts>,
    
    #[account(mint::token_program = token_program)]
    pub token_mint: InterfaceAccount<'info, Mint>,
    
    #[account(
         init, 
         payer = payer, 
         token::authority = ONft_config, 
         token::mint = token_mint, 
         token::token_program = token_program)]
    pub token_escrow: InterfaceAccount<'info, TokenAccount>,
    
    pub token_program: Interface<'info, TokenInterface>,
    pub system_program: Program<'info, System>,
}

impl InitAdapterONft<'_> {
    pub fn apply(ctx: &mut Context<InitAdapterONft>, params: &InitAdapterONftParams) -> Result<()> {
        ctx.accounts.ONft_config.bump = ctx.bumps.ONft_config;
        ctx.accounts.ONft_config.token_mint = ctx.accounts.token_mint.key();
        ctx.accounts.ONft_config.ext = ONftConfigExt::Adapter(ctx.accounts.token_escrow.key());
        ctx.accounts.ONft_config.token_program = ctx.accounts.token_program.key();
        ctx.accounts.lz_receive_types_accounts.ONft_config = ctx.accounts.ONft_config.key();
        ctx.accounts.lz_receive_types_accounts.token_mint = ctx.accounts.token_mint.key();

        let oapp_signer = ctx.accounts.ONft_config.key();
        ctx.accounts.ONft_config.init(
            params.endpoint_program,
            params.admin,
            params.shared_decimals,
            ctx.accounts.token_mint.decimals,
            ctx.remaining_accounts,
            oapp_signer,
        )
    }
}","rust
pub struct InitAdapterONft<'info> {
    #[account(mut)]
    pub payer: Signer<'info>,
    
    #[account(
        init,
        payer = payer,
        space = 8 + ONftConfig::INIT_SPACE,
        seeds = [ONft_SEED, token_escrow.key().as_ref()],
        bump
    )]
    pub ONft_config: Account<'info, ONftConfig>,
    
    #[account(
        init,
        payer = payer,
        space = 8 + LzReceiveTypesAccounts::INIT_SPACE,
        seeds = [LZ_RECEIVE_TYPES_SEED, &ONft_config.key().as_ref()],
        bump
    )]
    pub lz_receive_types_accounts: Account<'info, LzReceiveTypesAccounts>,

    #[account(mint::token_program = token_program)]
    pub token_mint: InterfaceAccount<'info, Mint>,
    
    #[account(
        init,
        payer = payer,
        token::authority = ONft_config,
        token::mint = token_mint,
        token::token_program = token_program,
    )]
    pub token_escrow: InterfaceAccount<'info, TokenAccount>,
    
    pub token_program: Interface<'info, TokenInterface>,
    pub system_program: Program<'info, System>,
}

pub fn is_supported_mint(mint_account: &InterfaceAccount<Mint>) -> bool {
    let mint_info = mint_account.to_account_info();
    let mint_data = mint_info.data.borrow();
    let mint = StateWithExtensions::<spl_token_2022::state::Mint>::unpack(&mint_data).unwrap();
    let extensions = mint.get_extension_types().unwrap();

    for e in extensions {
        if e == ExtensionType::MintCloseAuthority {
            return false;
        }
    }
    
    true
}

impl InitAdapterONft<'_> {
    pub fn apply(ctx: &mut Context<InitAdapterONft>, params: &InitAdapterONftParams) -> Result<()> {
        if !is_supported_mint(&ctx.accounts.mint) {
            return Err(Error::UnsupportedBaseMint.into());
        }

        ctx.accounts.ONft_config.bump = ctx.bumps.ONft_config;
        ctx.accounts.ONft_config.token_mint = ctx.accounts.token_mint.key();
        ctx.accounts.ONft_config.ext = ONftConfigExt::Adapter(ctx.accounts.token_escrow.key());
        ctx.accounts.ONft_config.token_program = ctx.accounts.token_program.key();
        
        ctx.accounts.lz_receive_types_accounts.ONft_config = ctx.accounts.ONft_config.key();
        ctx.accounts.lz_receive_types_accounts.token_mint = ctx.accounts.token_mint.key();

        let oapp_signer = ctx.accounts.ONft_config.key();

        ctx.accounts.ONft_config.init(
            params.endpoint_program,
            params.admin,
            params.shared_decimals,
            ctx.accounts.token_mint.decimals,
            ctx.remaining_accounts,
            oapp_signer,
        )
    }
}",High,https://solodit.cyfrin.io/issues/c-01-mint-decimal-manipulation-through-mintcloseauthority-leads-to-inflation-of-ld2sd_rate-shieldify-none-kanpaipandas-lzapponft-markdown,https://solodit.cyfrin.io/issues/c-01-mint-decimal-manipulation-through-mintcloseauthority-leads-to-inflation-of-ld2sd_rate-shieldify-none-kanpaipandas-lzapponft-markdown,Medium
Sol-061,"Critical OFT settings vulnerable to Solana restarts. The OFTStore structure contains critical settings that are vulnerable to Solana chain restarts. Specifically, the `paused` and `default_fee_bps` fields can revert to previous states. If Solana restarts to a previous slot: 1. The `paused` field could revert from true to false, reactivating the system when it should be paused for security reasons. This is particularly dangerous if the pause was enacted in response to a detected vulnerability or ongoing attack. 2. The `default_fee_bps` could revert to an outdated value. This might lead to incorrect fee calculations, potentially causing financial losses for users or the protocol itself. These issues arise because Solana's restart mechanism reverts the entire state (when the validators vote for that) to a previous slot, including these critical OFT settings. The current implementation doesn't have safeguards against such cases.","rust
pub struct OFTStore { 
    // ... other fields ... 
    pub default_fee_bps: u16, 
    pub paused: bool, 
    // ... other fields ... 
}","rust
pub struct OFTStore {
    // ... other fields ...
    pub last_updated_slot: u64,
    // ... other fields ...
}

fn is_config_outdated(oft_store: &OFTStore) -> Result<bool> {
    let last_restart_slot = LastRestartSlot::get()?;
    Ok(oft_store.last_updated_slot <= last_restart_slot.last_restart_slot)
}",Low,https://solodit.cyfrin.io/issues/l-07-critical-oft-settings-vulnerable-to-solana-restarts-pashov-audit-group-none-layerzero-september-markdown,,Medium
Sol-062,"When a user proposes a loan via the proposeLoan instruction, the contract accepts a token account containing the NFT to be used as collateral. However, it fails to validate that the token account actually contains the token.","rust
#[account(
    mut, 
    // owner = token::ID, 
    associated_token::mint = nft_mint, 
    associated_token::authority = user
)]
pub nft_user_token_account: Box<Account<'info, TokenAccount>>,","rust
#[account(
    mut, 
    // owner = token::ID, 
    // constraint = nft_user_token_account.amount == TOKEN_MINT_SUPPLY, 
    associated_token::mint = nft_mint, 
    associated_token::authority = user
)]
pub nft_user_token_account: Box<Account<'info, TokenAccount>>,",Critical,Verify that the nft_user_token_account has a balance of one.,https://solodit.cyfrin.io/issues/anchor-and-solana-usage-ottersec-none-frakt-pdf,Medium
Sol-063,"In the redeemWinningLotTicket instruction, the raffle winner purchases the NFT collateral from the protocol, transferring funds to the loan’s liquidity pool. However, this association between loan and liquidity pool is not checked. This allows an attacker who wins the liquidation raffle to transfer funds to a different liquidity pool. Depending on parameters, this can result in the NFT collateral being cheaper than intended.","rust
loan.reward_amount = convert_u128_to_u64(
    u128::from(liquidity_pool.borrow_cumulative)
        .checked_sub(u128::from(
            loan.reward_interest_rate.expect(""no reward staked""),
        )).unwrap()
        .checked_mul(u128::from(loan.amount_to_get)).unwrap()
        .checked_div(u128::from(PRICE_BASED_TIME_DENOMINATOR)).unwrap()
        .checked_div(u128::from(BASE_POINTS)).unwrap()
).unwrap();","rust
#[account(
    mut,
    constraint = loan.loan_status == LoanStatus::Liquidated 
        @ ErrorCodes::LotIsNotLiquidatedYet,
    has_one = nft_mint 
        @ ErrorCodes::WrongNftMintOnLoan,
    has_one = liquidity_pool 
        @ ErrorCodes::WrongLiqPoolOnLoan,
    has_one = collection_info 
        @ ErrorCodes::WrongCollectionInfoOnLoan,
    // constraint = loan.expired_at > now_ts()? || loan.loan_type == LoanType::PriceBased 
    @ ErrorCodes::TimeIsNotExpired
)]",High,Verify that the provided liquidity_pool and collection_info accounts match what is specified in the loan account.,https://solodit.cyfrin.io/issues/anchor-and-solana-usage-ottersec-none-frakt-pdf,Medium
Sol-064,"The create_order function is responsible for creating a new order in the program. It performs several critical tasks, including: Validating the stability of the USDC price obtained from the Pyth Network. Ensuring that sufficient fees are provided for cross-chain operations. Initializing and populating the order with details such as the source and destination chains, token amounts, and involved parties. Transferring USDC from the user’s token account to a vault account for order processing. During the price validation step, the function fetches the USDC price using the Pyth price feed and adjusts it based on the feed's exponent value. However, this implementation does not consider the conf (confidence interval) parameter provided by Pyth, which represents the uncertainty range in the reported price. Ignoring conf might lead to decisions based on potentially unreliable price data, especially during periods of high market volatility. By not incorporating the conf parameter, the program exposes itself to risks where the USDC/USD price might appear stable but has significant uncertainty. This could lead to: Depeg Exploitation: If USDC experiences a depeg and the confidence interval (conf) is not considered, the price could appear valid while being inaccurate due to high uncertainty. Users on the Solana network could exploit this by exchanging depegged USDC tokens on Solana for more valuable tokens on another network, effectively transferring the depeg losses to the program and its users. Systemic Risks Across Chains: As the function facilitates cross-chain operations, overlooking the confidence interval might propagate incorrect exchange rates between networks, leading to financial imbalances or exploits. Inaccurate Price Validation: In volatile market conditions, large conf values signal unreliable data. Ignoring this parameter leaves the program vulnerable to decisions based on incomplete or misleading price information.","rust
msg!(""deposit USDC amount: {:?}"", amount); 

let price_update = &mut ctx.accounts.price_update; 

let feed_id: [u8; 32] = get_feed_id_from_hex(FEED_ID)?;

let price = price_update.get_price_no_older_than(&Clock::get()?, MAXIMUM_AGE, &feed_id)?;

// Adjust price to floating-point by scaling with 10^exponent
let adjusted_price: f64 = (price.price as f64) * 10f64.powi(price.exponent);","rust
let lower_bound = (price.price - price.conf) as f64 * 10f64.powi(price.exponent);
let upper_bound = (price.price + price.conf) as f64 * 10f64.powi(price.exponent);

// Validate price bounds
require!(lower_bound > 0.99, GeniusError::StableCoinPriceTooLow);
require!(upper_bound < MAX_ACCEPTABLE_PRICE, GeniusError::StableCoinPriceTooHigh);",Low,"Modify the price validation logic to incorporate the conf parameter. This ensures that the price used for validation is reliable and falls within an acceptable range. By incorporating the confidence interval, the program can assess the validity of the price more accurately, mitigating risks associated with volatile or unreliable price data.",https://www.halborn.com/audits/shuttle-labs/genius-solana-program,Medium
Sol-065,"The Withdraw instruction of the Waterusdc program allows users to withdraw liquidity from the lending program for a predefined fee. However, instead of transferring the fee to the fee vault as intended, the instruction mistakenly returns the fee to the user. As a result, the protocol is unable to collect fees from users.","rust
let fee_transfer_accounts = TransferChecked {
    from: ctx.accounts.usdc_token_account.to_account_info(),
    to: ctx.accounts.user_ata.to_account_info(),
    authority: ctx.accounts.program_authority.to_account_info(),
    mint: ctx.accounts.usdc_mint.to_account_info(),
};

let fee_amount_context = CpiContext::new_with_signer(
    ctx.accounts.token_program.to_account_info(),
    fee_transfer_accounts,
    signer_seeds,
);

anchor_spl::token::transfer_checked(fee_amount_context, w_fee, 6)?;","use anchor_lang::prelude::*;
use anchor_spl::token::{self, TransferChecked};

// Assuming this is part of a larger program context
#[program]
pub mod waterusdc {
    use super::*;

    pub fn withdraw(ctx: Context<Withdraw>, amount: u64, w_fee: u64) -> Result<()> {
        // Transfer the withdrawal amount (minus fee) to the user
        let user_transfer_accounts = TransferChecked {
            from: ctx.accounts.usdc_token_account.to_account_info(),
            to: ctx.accounts.user_ata.to_account_info(),
            authority: ctx.accounts.program_authority.to_account_info(),
            mint: ctx.accounts.usdc_mint.to_account_info(),
        };

        let signer_seeds = &[/* Define your signer seeds here, e.g., &[b""authority"", &[bump]] */];
        let user_amount_context = CpiContext::new_with_signer(
            ctx.accounts.token_program.to_account_info(),
            user_transfer_accounts,
            signer_seeds,
        );

        // Transfer the withdrawal amount (excluding fee) to the user
        anchor_spl::token::transfer_checked(
            user_amount_context,
            amount.checked_sub(w_fee).ok_or(ProgramError::InvalidArgument)?,
            6, // USDC decimals
        )?;

        // Transfer the fee to the fee vault
        let fee_transfer_accounts = TransferChecked {
            from: ctx.accounts.usdc_token_account.to_account_info(),
            to: ctx.accounts.fee_vault.to_account_info(), // Changed to fee_vault
            authority: ctx.accounts.program_authority.to_account_info(),
            mint: ctx.accounts.usdc_mint.to_account_info(),
        };

        let fee_amount_context = CpiContext::new_with_signer(
            ctx.accounts.token_program.to_account_info(),
            fee_transfer_accounts,
            signer_seeds,
        );

        anchor_spl::token::transfer_checked(fee_amount_context, w_fee, 6)?;

        Ok(())
    }
}

#[derive(Accounts)]
pub struct Withdraw<'info> {
    /// The program's USDC token account holding the liquidity
    #[account(mut)]
    pub usdc_token_account: Account<'info, token::TokenAccount>,

    /// The user's USDC ATA to receive the withdrawn amount (minus fee)
    #[account(mut)]
    pub user_ata: Account<'info, token::TokenAccount>,

    /// The program's authority (likely a PDA) to sign the transfers
    pub program_authority: Signer<'info>,

    /// The USDC mint
    pub usdc_mint: Account<'info, token::Mint>,

    /// The fee vault to collect withdrawal fees
    #[account(
        mut,
        constraint = fee_vault.mint == usdc_mint.key() @ ProgramError::InvalidAccountData,
        constraint = fee_vault.owner == program_authority.key() @ ProgramError::InvalidAccountData
    )]
    pub fee_vault: Account<'info, token::TokenAccount>,

    /// The SPL Token program
    pub token_program: Program<'info, token::Token>,
}",Critical,"To address this issue, it is recommended to correct the destination address so that the fee is sent to the fee vault account.",https://www.halborn.com/audits/vaultka/waterusdc-and-vaultka-solana-programs,Low
Sol-066,"The RemoveApprovedLenders instruction allows the operator to remove an approved lender who will no longer be able to deposit. However, due to a lack of validation in the Deposit instruction, approved lenders who have been removed by the operator can still be able to deposit to keep earning yield and sharing looses.","rust
pub struct Deposit<'info> {
    pub depositor: Signer<'info>,
    #[account(
        mut,
        seeds = [
            LENDER_STATE_SEED,
            tranche_mint.key().as_ref(),
            depositor.key().as_ref(),
        ],
        bump = lender_state.bump,
    )]
    pub lender_state: Box<Account<'info, LenderState>>,
}","use anchor_lang::prelude::*;

// Constants (assumed from context)
const LENDER_STATE_SEED: &[u8] = b""lender_state"";

// Assumed LenderState struct
#[account]
pub struct LenderState {
    pub bump: u8,
    pub is_approved: bool, // Approval status
    pub tranche_mint: Pubkey,
    pub depositor: Pubkey,
    // ... other fields as needed
}

pub mod preconditions {
    use anchor_lang::prelude::*;

    // Precondition to check if the lender is approved
    pub fn only_approved_lender(lender_state: &LenderState) -> Result<()> {
        if !lender_state.is_approved {
            return Err(ProgramError::InvalidAccountData.into()); // Or a custom error
        }
        Ok(())
    }
}

#[derive(Accounts)]
pub struct Deposit<'info> {
    pub depositor: Signer<'info>,
    #[account(
        mut,
        seeds = [
            LENDER_STATE_SEED,
            tranche_mint.key().as_ref(),
            depositor.key().as_ref(),
        ],
        bump = lender_state.bump,
    )]
    pub lender_state: Box<Account<'info, LenderState>>,

    // Assumed additional accounts (based on typical lending program structure)
    pub tranche_mint: Account<'info, Mint>, // Mint of the tranche token
    // ... other accounts like token accounts, authority, etc.
}

pub fn deposit(ctx: Context<Deposit>, amount: u64) -> Result<()> {
    // Validate that the depositor is an approved lender
    preconditions::only_approved_lender(&ctx.accounts.lender_state)?;

    // Proceed with deposit logic
    // ... (e.g., token transfers, updating lender_state, etc.)

    Ok(())
}",Low,"To address this issue, it is recommended to add a call to preconditions::only_approved_lender to verify the lender who is trying to deposit is a current-approved lender.",https://www.halborn.com/audits/huma/huma-protocol,Low
Sol-067,"The create_pool instruction requires several parameters, one of which is the pool name. However, there is currently no validation to ensure that the length of the pool name does not exceed the maximum allowed limit, potentially leading to input that violates expected constraints.","pub(crate) fn create_pool( 
    ctx: Context<CreatePool>, 
    pool_id: Pubkey, 
    pool_name: String, 
    pool_owner_treasury: Pubkey, 
    evaluation_agent: Pubkey, 
    tranches_policy_type: TranchesPolicyType, 
    ) -> Result<()> { 
        
    let pool_config = ctx.accounts.pool_config.as_mut(); 
    pool_config.huma_config = ctx.accounts.huma_config.key(); 
    pool_config.pool_id = pool_id; 
    pool_config.bump = ctx.bumps.pool_config; 
    pool_config.pool_authority_bump = ctx.bumps.pool_authority; 
    pool_config.pool_owner = ctx.accounts.owner.key(); 
    pool_config.pool_name = pool_name.clone(); 

}","use anchor_lang::prelude::*;

// Assume this constant is defined somewhere in the program
const MAX_POOL_NAME_LENGTH: usize = 32; // Example value; adjust as needed

#[derive(Accounts)]
pub struct CreatePool<'info> {
    #[account(
        init,
        payer = owner,
        space = 8 + PoolConfig::SIZE, // Adjust size based on struct
        seeds = [b""pool_config"", pool_id.as_ref()],
        bump,
    )]
    pub pool_config: Account<'info, PoolConfig>,
    pub huma_config: AccountInfo<'info>, // Assumed account
    #[account(mut)]
    pub owner: Signer<'info>,
    pub pool_authority: AccountInfo<'info>, // Assumed PDA authority
    pub system_program: Program<'info, System>,
}

// Assume this is the PoolConfig struct
#[account]
pub struct PoolConfig {
    pub huma_config: Pubkey,
    pub pool_id: Pubkey,
    pub bump: u8,
    pub pool_authority_bump: u8,
    pub pool_owner: Pubkey,
    pub pool_name: String,
    // ... other fields
}

impl PoolConfig {
    pub const SIZE: usize = 32 + 32 + 1 + 1 + 32 + 4 + MAX_POOL_NAME_LENGTH; // Example size
}

pub(crate) fn create_pool(
    ctx: Context<CreatePool>,
    pool_id: Pubkey,
    pool_name: String,
    pool_owner_treasury: Pubkey,
    evaluation_agent: Pubkey,
    tranches_policy_type: TranchesPolicyType,
) -> Result<()> {
    // Validate pool_name length
    if pool_name.len() > MAX_POOL_NAME_LENGTH {
        return Err(ProgramError::InvalidArgument.into()); // Or a custom error
    }

    let pool_config = ctx.accounts.pool_config.as_mut();
    pool_config.huma_config = ctx.accounts.huma_config.key();
    pool_config.pool_id = pool_id;
    pool_config.bump = ctx.bumps.pool_config;
    pool_config.pool_authority_bump = ctx.bumps.pool_authority;
    pool_config.pool_owner = ctx.accounts.owner.key();
    pool_config.pool_name = pool_name.clone();

    // ... (rest of the logic, e.g., setting pool_owner_treasury, evaluation_agent, etc.)
    Ok(())
}",Low,"To address this issue, it is recommended to add a validation to verify the pool name provided to not exceed the MAX_POOL_NAME_LENGTH.",https://www.halborn.com/audits/huma/huma-protocol,Low
Sol-068,"The CreateReceivable instruction requires some values as parameters, one of them is the currency code. However this value is not validated to check if its length exceeds the max length allowed.","rust
receivable_info.set_inner(
    ReceivableInfo::new(
        ctx.bumps.receivable_info,
        args.currency_code.clone(),
        args.receivable_amount,
        timestamp,
        args.maturity_date,
        ctx.accounts.owner.key(),
    ),
);","use anchor_lang::prelude::*;

// Assume this constant defines the maximum length for currency_code
const MAX_CURRENCY_CODE_LENGTH: usize = 3;

// Assumed ReceivableInfo struct
#[account]
#[derive(Default)]
pub struct ReceivableInfo {
    pub bump: u8,
    pub currency_code: String,
    pub receivable_amount: u64,
    pub created_at: i64,
    pub maturity_date: i64,
    pub owner: Pubkey,
}

impl ReceivableInfo {
    pub fn new(
        bump: u8,
        currency_code: String,
        receivable_amount: u64,
        created_at: i64,
        maturity_date: i64,
        owner: Pubkey,
    ) -> Self {
        Self {
            bump,
            currency_code,
            receivable_amount,
            created_at,
            maturity_date,
            owner,
        }
    }
}

#[derive(Accounts)]
pub struct CreateReceivable<'info> {
    #[account(
        init,
        payer = owner,
        space = 8 + ReceivableInfo::SIZE, // Adjust size based on struct
        seeds = [b""receivable"", owner.key().as_ref()],
        bump,
    )]
    pub receivable_info: Account<'info, ReceivableInfo>,
    #[account(mut)]
    pub owner: Signer<'info>,
    pub system_program: Program<'info, System>,
}

// Assumed arguments struct
#[derive(AnchorSerialize, AnchorDeserialize, Clone)]
pub struct CreateReceivableArgs {
    pub currency_code: String,
    pub receivable_amount: u64,
    pub maturity_date: i64,
}

pub fn create_receivable(
    ctx: Context<CreateReceivable>,
    args: CreateReceivableArgs,
) -> Result<()> {
    // Validate currency_code length
    if args.currency_code.len() > MAX_CURRENCY_CODE_LENGTH {
        return Err(ProgramError::InvalidArgument.into()); // Or a custom error
    }

    let timestamp = Clock::get()?.unix_timestamp;

    // Set the receivable info
    ctx.accounts.receivable_info.set_inner(
        ReceivableInfo::new(
            ctx.bumps.receivable_info,
            args.currency_code.clone(),
            args.receivable_amount,
            timestamp,
            args.maturity_date,
            ctx.accounts.owner.key(),
        ),
    );

    Ok(())
}",Low,"To resolve this issue, it is recommended to verify the correct maximal length of the currency code to be 3 bytes.",https://www.halborn.com/audits/huma/huma-protocol,Low
Sol-069,The instruction CreateReceivable allows anyone to create a receivable NFT. The instruction requires also passing the PoolConfig and PoolState accounts and verifies that the pool is not disabled. However the instructions SubmitReceivable nor ApproveReceivable do not verify that the NFT is being approved for the same pool as it was created for. It is therefore possible to create Receivables for an arbitrary pool where the borrower has approved credit that is enabled and later submit or approve them for another pool.,"rust
pub struct CreateReceivable<'info> {
    /// The address of the new receivable. 
    #[account(mut)] 
    pub asset: Signer<'info>, 

    /// This will be the `authority`, `owner` and `update_authority` of the receivable, 
    /// as well as the one paying for account storage. 
    #[account(mut)] 
    pub owner: Signer<'info>, 

    /// CHECK: Read only authority. 
    #[account( seeds = [ HUMA_PROGRAM_AUTHORITY_SEED ], bump)] 
    pub huma_program_authority: UncheckedAccount<'info>, 

    #[account( seeds = [ HUMA_CONFIG_SEED, huma_config.id.as_ref(), ], 
               bump = huma_config.bump, 
    )] 
    pub huma_config: Box<Account<'info, HumaConfig>>, 

    #[account( seeds = [ POOL_CONFIG_SEED, pool_config.pool_id.as_ref(), ], 
               bump = pool_config.bump, 
               has_one = huma_config @ Error::InvalidHumaConfig, 
    )] 
    pub pool_config: Box<Account<'info, PoolConfig>>, 

    #[account( seeds = [ POOL_STATE_SEED, pool_config.key().as_ref(), ], 
               bump = pool_state.bump, 
    )] 
    pub pool_state: Box<Account<'info, PoolState>>
}","use anchor_lang::prelude::*;

// Constants (assumed)
const HUMA_CONFIG_SEED: &[u8] = b""huma_config"";
const POOL_CONFIG_SEED: &[u8] = b""pool_config"";
const POOL_STATE_SEED: &[u8] = b""pool_state"";
const HUMA_PROGRAM_AUTHORITY_SEED: &[u8] = b""huma_authority"";

// Assumed structs
#[account]
pub struct HumaConfig {
    pub id: Pubkey,
    pub bump: u8,
}

#[account]
pub struct PoolConfig {
    pub pool_id: Pubkey,
    pub bump: u8,
    pub huma_config: Pubkey,
    // ... other fields
}

#[account]
pub struct PoolState {
    pub bump: u8,
    pub is_disabled: bool,
    // ... other fields
}

#[account]
pub struct ReceivableInfo {
    pub pool_id: Pubkey, // Added to track the pool
    pub owner: Pubkey,
    pub bump: u8,
    // ... other fields
}

// --- CreateReceivable ---
#[derive(Accounts)]
pub struct CreateReceivable<'info> {
    #[account(mut)]
    pub asset: Signer<'info>,
    #[account(mut)]
    pub owner: Signer<'info>,
    #[account(seeds = [HUMA_PROGRAM_AUTHORITY_SEED], bump)]
    pub huma_program_authority: UncheckedAccount<'info>,
    #[account(
        seeds = [HUMA_CONFIG_SEED, huma_config.id.as_ref()],
        bump = huma_config.bump,
    )]
    pub huma_config: Box<Account<'info, HumaConfig>>,
    #[account(
        seeds = [POOL_CONFIG_SEED, pool_config.pool_id.as_ref()],
        bump = pool_config.bump,
        has_one = huma_config @ Error::InvalidHumaConfig,
    )]
    pub pool_config: Box<Account<'info, PoolConfig>>,
    #[account(
        seeds = [POOL_STATE_SEED, pool_config.key().as_ref()],
        bump = pool_state.bump,
        constraint = !pool_state.is_disabled @ Error::PoolDisabled,
    )]
    pub pool_state: Box<Account<'info, PoolState>>,
    #[account(
        init,
        payer = owner,
        space = 8 + 32 + 32 + 1, // Adjust size
        seeds = [b""receivable"", asset.key().as_ref()],
        bump,
    )]
    pub receivable_info: Account<'info, ReceivableInfo>,
    pub system_program: Program<'info, System>,
}

pub fn create_receivable(ctx: Context<CreateReceivable>) -> Result<()> {
    ctx.accounts.receivable_info.set_inner(ReceivableInfo {
        pool_id: ctx.accounts.pool_config.pool_id,
        owner: ctx.accounts.owner.key(),
        bump: ctx.bumps.receivable_info,
    });
    Ok(())
}

// --- SubmitReceivable ---
#[derive(Accounts)]
pub struct SubmitReceivable<'info> {
    pub owner: Signer<'info>,
    #[account(
        seeds = [b""receivable"", receivable_info.key().as_ref()],
        bump = receivable_info.bump,
    )]
    pub receivable_info: Account<'info, ReceivableInfo>,
    #[account(
        seeds = [POOL_CONFIG_SEED, pool_config.pool_id.as_ref()],
        bump = pool_config.bump,
        constraint = pool_config.pool_id == receivable_info.pool_id @ Error::InvalidPool,
    )]
    pub pool_config: Box<Account<'info, PoolConfig>>,
    // ... other accounts as needed
}

pub fn submit_receivable(ctx: Context<SubmitReceivable>) -> Result<()> {
    // Pool validation is in the constraint
    // ... submit logic
    Ok(())
}

// --- ApproveReceivable ---
#[derive(Accounts)]
pub struct ApproveReceivable<'info> {
    pub authority: Signer<'info>,
    #[account(
        seeds = [b""receivable"", receivable_info.key().as_ref()],
        bump = receivable_info.bump,
    )]
    pub receivable_info: Account<'info, ReceivableInfo>,
    #[account(
        seeds = [POOL_CONFIG_SEED, pool_config.pool_id.as_ref()],
        bump = pool_config.bump,
        constraint = pool_config.pool_id == receivable_info.pool_id @ Error::InvalidPool,
    )]
    pub pool_config: Box<Account<'info, PoolConfig>>,
    // ... other accounts as needed
}

pub fn approve_receivable(ctx: Context<ApproveReceivable>) -> Result<()> {
    // Pool validation is in the constraint
    // ... approve logic
    Ok(())
}

// Assumed custom errors
#[error_code]
pub enum Error {
    #[msg(""Invalid Huma config"")]
    InvalidHumaConfig,
    #[msg(""Pool is disabled"")]
    PoolDisabled,
    #[msg(""Receivable does not belong to this pool"")]
    InvalidPool,
}",Low,"To resolve this issue, it is recommended to either verify the correct pool also in both the SubmitReceivable and ApproveReceivable instructions, or, if the receivable is not meant to be tied to a specific pool, remove the PoolState and PoolConfig accounts from the CreateReceivable instruction.",https://www.halborn.com/audits/huma/huma-protocol,Low
Sol-070,"The ReallocPoolConfig instruction allows both the huma owner and the pool owner to reallocate pools from the old format to the new format, adding a padding field and the auto_redemption_after_lockup flag in LPConfig. However, this instruction lacks a validation mechanism to determine the format of the provided pool_config. If a pool_config in the new format is supplied, the instruction still attempts to process it as if it were in the old format. The deserialization of the new format data into the old format structure does not fail because the fields shared between the two formats are located at the same positions in memory, and the additional fields in the new format (e.g., padding and auto_redemption_after_lockup) are ignored during the deserialization process. This behavior can cause misinterpretation of data if the additional bytes in the new format result in misaligned field values during deserialization. When the instruction subsequently writes back the data in the new format, the misinterpreted values from the deserialization process overwrite the original ones, leading to inconsistencies in the final pool_config. This vulnerability could result in corrupted or incorrect pool configurations, particularly when migrating or reallocating pools already in the new format, as the instruction fails to distinguish between the two formats","rust
pub(crate) fn realloc_pool_config(ctx: Context<ReallocPoolConfig>) -> Result<()> { 

    let old_pool_config = { 
        let data: &[u8] = &mut ctx.accounts.pool_config.try_borrow_data()?; 
        let old_pool_config = old_version::PoolConfig::try_deserialize(&mut &data[..])?;
        Box::new(old_pool_config) 
    }; 

    let pool_config_account = ctx.accounts.pool_config.to_account_info();
}","use anchor_lang::prelude::*;

// Constants (assumed)
const POOL_CONFIG_SEED: &[u8] = b""pool_config"";

// Old format (assumed)
pub mod old_version {
    use super::*;
    #[account]
    pub struct PoolConfig {
        pub pool_id: Pubkey,
        pub bump: u8,
        // ... other fields without padding or auto_redemption_after_lockup
    }

    impl PoolConfig {
        pub const SIZE: usize = 8 + 32 + 1; // Discriminator + Pubkey + u8 (example)
    }
}

// New format (assumed)
#[account]
pub struct PoolConfig {
    pub pool_id: Pubkey,
    pub bump: u8,
    pub padding: [u8; 32],               // Added in new format
    pub auto_redemption_after_lockup: bool, // Added in new format
    // ... other fields
}

impl PoolConfig {
    pub const SIZE: usize = 8 + 32 + 1 + 32 + 1; // Adjusted for new fields
}

#[derive(Accounts)]
pub struct ReallocPoolConfig<'info> {
    #[account(
        mut,
        seeds = [POOL_CONFIG_SEED, pool_config.pool_id.as_ref()],
        bump = pool_config.bump,
    )]
    pub pool_config: Account<'info, PoolConfig>, // Will be reallocated
    #[account(mut)]
    pub payer: Signer<'info>, // Huma owner or pool owner paying for realloc
    pub system_program: Program<'info, System>,
}

pub(crate) fn realloc_pool_config(ctx: Context<ReallocPoolConfig>) -> Result<()> {
    let pool_config_account = &mut ctx.accounts.pool_config;
    let data: &[u8] = &mut pool_config_account.try_borrow_data()?;

    // Validate that the pool_config is in the old format by checking its length
    if data.len() != old_version::PoolConfig::SIZE {
        return Err(Error::InvalidPoolConfigFormat.into());
    }

    // Deserialize the old format
    let old_pool_config = {
        let mut data_slice = &data[..];
        let old_pool_config = old_version::PoolConfig::try_deserialize(&mut data_slice)?;
        Box::new(old_pool_config)
    };

    // Reallocate to the new size
    pool_config_account.realloc(PoolConfig::SIZE, false)?;

    // Convert to new format and update
    pool_config_account.set_inner(PoolConfig {
        pool_id: old_pool_config.pool_id,
        bump: old_pool_config.bump,
        padding: [0; 32],                    // Initialize new field
        auto_redemption_after_lockup: false, // Default value for new field
        // ... copy other fields
    });

    Ok(())
}

// Custom errors
#[error_code]
pub enum Error {
    #[msg(""Provided pool config is not in the old format"")]
    InvalidPoolConfigFormat,
}",Low,"Although the likelihood of this occurring is very low because the responsibility for performing the reallocation lies with the huma owner and the pool owner, it is essential to carry out this operation with great care to avoid inconsistencies and potential failures. It is also advisable to add a validation mechanism in the instruction handler to ensure that the provided pool configuration is in the old format before proceeding.",https://www.halborn.com/audits/huma/huma-protocol,Low
Sol-071,"In the swap instruction, amount_out is calculated using the entire params.amount_in value, which represents the total number of input tokens provided by the user. The fees are calculated based on the params.amount_in and amount_out values. However, these fees are not subtracted from the user’s input before calculating the amount_out.  As a result, the user receives the full value of their input tokens converted to output tokens without the fees being deducted upfront. Nevertheless, the swap instruction still calculates the fee amount and subsequently distributes the fees after the amount is transferred to the user. This implies that the fees are taken from the pool’s funds rather than from the user’s input.  Effectively, this means the user is not bearing the cost of the fees. Over time, as more swaps are executed, the pool’s value diminishes because it continuously pays out fees from its own funds. This gradual depletion results in an imbalance where the pool loses value, affecting the liquidity providers.","rust
pub fn swap(ctx: Context<Swap>, params: &SwapParams) -> Result<()> { 
    // ...
    let fees_in_amount = match is_internal_swap { 
        true => 0, 
        false => pool.get_swap_in_fees(
            token_id_in, 
            params.amount_in, 
            &receiving_custody, 
            &received_token_price_high, 
            &dispensing_custody,
        )?, 
    }; 
    // ...
}","pub fn swap(ctx: Context<Swap>, params: &SwapParams) -> Result<()> { 
    // ...
    let fees_in_amount = match is_internal_swap { 
        true => 0, 
        false => pool.get_swap_in_fees(
            token_id_in, 
            params.amount_in, 
            &receiving_custody, 
            &received_token_price_high, 
            &dispensing_custody,
        )?, 
    };
    
    // Calculate effective amount after deducting fees
    let effective_amount_in = params.amount_in.checked_sub(fees_in_amount)
        .ok_or(ProgramError::InvalidArgument)?;
    
    // Use effective_amount_in instead of params.amount_in for swap calculations
    // ...
}",Critical,"ensures that:

Fees are properly deducted from the user's input amount

The user bears the cost of the fees rather than the pool

The pool's value is preserved as fees are taken from the user's input before the swap

The original vulnerability where fees were effectively paid from pool funds is fixed",https://solodit.cyfrin.io/issues/unauthorized-owner-modification-ottersec-none-adrena-pdf,Low
Sol-072,"The remove_liquidity instruction contains a potential vulnerability that may result in an artificial inflation of custody.assets.owned. The function calculates the fee_amount based on the removal amount and pool configuration. In some cases, the code may temporarily increase the remove_liquidity fees stored in custody.fees.remove_liquidity if the price confidence value is high.  The code correctly subtracts the withdrawal amount from custody.assets.owned to reflect the decrease in owned assets due to the user receiving tokens. However, it then incorrectly adds the fee_amount back to custody.assets.owned. The fee_amount already represents a portion of the user’s original asset ownership that is taken as a fee. Adding it back essentially double-counts that portion, inflating the total owned assets.  The pool AUM (Assets Under Management) calculation, which considers total custody assets, may be skewed, resulting in inaccurate pool valuations. Among other uses, this affects the calculation of LP (Liquidity Provider) token values. Inflating the pool AUM also leads to an artificial increase in LP token value, allowing liquidity providers to withdraw more assets with their LP tokens than they are truly worth. Other calculations relying on custody.assets.owned may also be affected.  Proof of Concept: A user deposits 100 token A and is the only depositor of token A. The custody account correctly reflects 100 token A as owned assets. The user initiates a removal with 100 LP tokens, representing their entire 100 token A deposit. The function calculates a remove_liquidity fee of 10 token A. The user receives 90 token A after the fee is applied. The function correctly subtracts 90 token A from custody.assets.owned to reflect the user’s withdrawal. However, the function incorrectly adds the 10 token fee back to custody.assets.owned. As a result, custody now incorrectly shows 10 token A, even though the pool actually has zero.","rust
pub fn remove_liquidity(
    ctx: Context<RemoveLiquidity>, 
    params: &RemoveLiquidityParams, 
) -> Result<()> { 
    // Update custody stats 
    { 
        [...] 

        // Fees that will be distributed later will impact the owned assets
        // For now, we can account all fees as owned by custody
        //
        // Note: doing this influence a tiny bit the update_borrow_rate calculations
        // but it's barely minimal. It's acceptable.

        custody.assets.owned += fee_amount; 
        custody.update_borrow_rate(curtime)?;
    } 

    [...] 
}","pub fn remove_liquidity(
    ctx: Context<RemoveLiquidity>, 
    params: &RemoveLiquidityParams, 
) -> Result<()> { 
    // Update custody stats 
    { 
        [...] 

        // The fee_amount is already included in the assets.owned calculation
        // as part of the total assets, so we should NOT add it back here.
        // The fee will be distributed later through the normal fee distribution mechanism.
        
        custody.update_borrow_rate(curtime)?;
    } 

    [...] 
}",Critical,"Removed the line custody.assets.owned += fee_amount; which was causing the double-counting

Added explanatory comments clarifying why we don't need to add the fee amount back

Kept the borrow rate update as it's still needed for proper interest calculations

This fix ensures that:

The fee is properly accounted for in the initial withdrawal calculation

The custody's assets.owned value accurately reflects the true remaining assets in the pool

There's no artificial inflation of the pool's AUM

LP token valuations remain accurate

The fee distribution will still happen through the normal fee distribution mechanisms",https://solodit.cyfrin.io/issues/unauthorized-owner-modification-ottersec-none-adrena-pdf,Low
Sol-073,"The remove_liquid_stake function checks if the amount to remove (params.amount) is greater than the overlap_amount (user_staking.liquid_stake.overlap_amount). However, since overlap_amount is set to zero before the subtraction, the entire params.amount is subtracted from total_stake, even though the overlap_amount was never added to total_stake in the first place.  This results in an incorrect reduction of total_stake, inflating the current round’s rate and delegating more rewards than allocated.  Additionally, the following else block should not decrease total_stake at all because, in this case, tokens are entirely removed from the overlapping amount, and the overlapping amount hasn’t been added to total_stake.  Currently, with this line of code present, whenever params.amount is less than overlap_amount, the instruction will fail. This happens because, in the other block, params.amount is subtracted from overlap_amount, resulting in a negative value.  This negative value is then subtracted from total_stake, which leads to an error, as subtracting a negative value from a u64 type results in an invalid operation.","rust
pub fn remove_liquid_stake(
    ctx: Context<RemoveLiquidStake>, 
    params: &RemoveLiquidStakeParams, ) 
    -> Result<()> { 
        // In case of overlap, takes overlapped tokens first (last tokens put in staking)
        // if there are not enough tokens, takes it up from long lasting staked tokens reserve
        if params.amount > user_staking.liquid_stake.overlap_amount { 
            user_staking.liquid_stake.overlap_amount = 0; 
            staking.current_staking_round.total_stake -= params.amount - user_staking.liquid_stake.overlap_amount; 
        } else { 
            user_staking.liquid_stake.overlap_amount -= params.amount; 
            staking.current_staking_round.total_stake -= params.amount - user_staking.liquid_stake.overlap_amount; 
        } 
       // Rest of the code...
   }","pub fn remove_liquid_stake(
    ctx: Context<RemoveLiquidStake>, 
    params: &RemoveLiquidStakeParams,
) -> Result<()> { 
    // In case of overlap, takes overlapped tokens first (last tokens put in staking)
    // if there are not enough tokens, takes it up from long lasting staked tokens reserve
    if params.amount > user_staking.liquid_stake.overlap_amount {
        // First subtract the overlap amount from params.amount
        let non_overlap_amount = params.amount - user_staking.liquid_stake.overlap_amount;
        // Then subtract only the non-overlapped portion from total_stake
        staking.current_staking_round.total_stake -= non_overlap_amount;
        // Finally set overlap_amount to zero
        user_staking.liquid_stake.overlap_amount = 0;
    } else {
        // Only subtract from overlap_amount, no need to modify total_stake
        user_staking.liquid_stake.overlap_amount -= params.amount;
    }
    // Rest of the code...
}",Critical,"Key fixes made:

In the if block:

First calculate the non-overlapped amount (params.amount - overlap_amount)

Subtract only this non-overlapped portion from total_stake

Then set overlap_amount to zero

This ensures we only subtract from total_stake what wasn't in the overlap

In the else block:

Completely removed the line that was subtracting from total_stake

Now only subtracts from overlap_amount since these tokens were never added to total_stake

This fixes the following issues:

Prevents incorrect reduction of total_stake when removing overlapped tokens

Avoids potential arithmetic underflow/overflow issues

Maintains accurate accounting of staked amounts

Ensures proper reward distribution calculations

Removes the problematic subtraction of a potentially negative value",https://solodit.cyfrin.io/issues/unauthorized-owner-modification-ottersec-none-adrena-pdf,Low
Sol-074,"There is a potential vulnerability in the add_genesis_liquidity instruction related to the interaction between claim_reserved_grant_amount and sanity_check within GenesisLock.  The reserved_grant_amounts variable stores the initial allocated grant amount for each reserved grant recipient, while reserved_amount represents the total reserved grant pool amount. When a recipient claims their reserved grant, claim_reserved_grant_amount correctly reduces the corresponding element in reserved_grant_amounts. However, reserved_amount remains unchanged after a successful claim.  If at least one private (insider) grant owner claims their entire allocation, the reserved_amount will no longer reflect the actual available reserved funds. Despite this, the sanity_check in add_genesis_liquidity will still pass because the sum of the potentially depleted reserved_grant_amounts might coincidentally still equal the (outdated) reserved_amount.  This inconsistency allows users who claim public grants (after a private grant has already been claimed) to potentially receive more than intended, exceeding the total reserved pool amount.  ","rust
pub fn sanity_check(&self) -> Result<()> { 
    [...] 
    if !self.has_transitioned_to_fully_public() { 
        [...] 
        require!(total_reserved_grant_amounts == self.reserved_amount, AdrenaError::InvalidGenesisLockState ); 
    } 
}

pub fn claim_reserved_grant_amount(&mut self, pubkey: &Pubkey, amount: u64) -> Result<u64> { 
    [...] 
    for i in 0..Self::RESERVED_GRANTS_COUNT { 
        let amount_available = self.reserved_grant_amounts[i]; 
        if amount <= amount_available && self.reserved_grant_owners[i] == *pubkey { 
            self.reserved_grant_amounts[i] -= amount; 
            return Ok(amount); 
        } 
    } 
    Ok(0) 
}","pub struct GenesisLock {
    // ... existing fields ...
    reserved_amount: u64,
    reserved_grant_amounts: [u64; Self::RESERVED_GRANTS_COUNT],
    reserved_grant_owners: [Pubkey; Self::RESERVED_GRANTS_COUNT],
    // New field to track claimed amounts
    reserved_amount_claimed: u64,
}

pub fn sanity_check(&self) -> Result<()> { 
    [...] 
    if !self.has_transitioned_to_fully_public() { 
        [...] 
        let total_reserved_grant_amounts: u64 = self.reserved_grant_amounts.iter().sum();
        require!(
            total_reserved_grant_amounts == self.reserved_amount.saturating_sub(self.reserved_amount_claimed),
            AdrenaError::InvalidGenesisLockState
        ); 
    } 
    Ok(())
}

pub fn claim_reserved_grant_amount(&mut self, pubkey: &Pubkey, amount: u64) -> Result<u64> { 
    [...] 
    for i in 0..Self::RESERVED_GRANTS_COUNT { 
        let amount_available = self.reserved_grant_amounts[i]; 
        if amount <= amount_available && self.reserved_grant_owners[i] == *pubkey { 
            self.reserved_grant_amounts[i] -= amount; 
            self.reserved_amount_claimed = self.reserved_amount_claimed.saturating_add(amount);
            return Ok(amount); 
        } 
    } 
    Ok(0) 
}",High,"This fix ensures that:

The total reserved pool is properly accounted for

Claims are tracked separately from allocations

The sanity check properly validates available funds

No arithmetic overflows/underflows can occur

Public grant recipients can't claim more than intended

The system maintains accurate accounting throughout its lifecycle",https://solodit.cyfrin.io/issues/unauthorized-owner-modification-ottersec-none-adrena-pdf,Low
Sol-075,"There is an inconsistency in how fees are determined based on the stability of tokens within the swap mechanism.  In the swap instruction logic, a specific adjustment is made if a token is high-confidence. If receiving_custody is a stable token, then fees.stable_swap_in is directly modified to potentially increase the fee.  In contrast, pool::get_swap_fees determines a stable_swap flag based on whether both custody tokens (custody_in and custody_out) are stable. This stable_swap flag then dictates whether to utilize fees.stable_swap_in or fees.swap_in for calculating fees.  Thus, while the swap instruction correctly adjusts fees based on the stability of the receiving token (fees.stable_swap_in), get_swap_fees uses a broader criterion. If a high-confidence token (receiving_custody) is involved in a swap where get_swap_fees utilizes fees.stable_swap_in (which may not have been adjusted), the calculated fee may not reflect the intended higher fee associated with high-confidence tokens.","rust
pub fn swap(ctx: Context<Swap>, params: &SwapParams) -> Result<()> {
    // If the confidence_value is too high, 
    // add an extra fee to protect the protocol
    // both confidence_value and fee are expressed in BPS
    let (high_confidence_value_protection_activated_in, 
        high_confidence_value_protection_activated_out,) = {
        
        let high_confidence_value_protection_activated_in = 
            if (nominal_swap_in_fee == 0 && received_token_price.conf > 50) 
                || (nominal_swap_in_fee != 0 && received_token_price.conf > nominal_swap_in_fee as u64) {
                //...
            };
        
        let fee = if receiving_custody.is_stable() {
            &mut receiving_custody.fees.stable_swap_in
        } else {
            &mut receiving_custody.fees.swap_in
        };
        //...
    };
    //...
}

pub fn get_swap_fees (
    &self, 
    token_id_in: usize, 
    token_id_out: usize, 
    amount_in: u64, 
    amount_out: u64,
    custody_in: &Custody,
    token_price_in: &OraclePrice,
    custody_out: &Custody,
    token_price_out: &OraclePrice,
) -> Result<(u64, u64)> {
    let stable_swap = custody_in.is_stable() && custody_out.is_stable();
    //...
}","pub fn swap(ctx: Context<Swap>, params: &SwapParams) -> Result<()> {
    // Determine if we should use stable swap fees based on both tokens' stability
    let use_stable_fees = receiving_custody.is_stable() && dispensing_custody.is_stable();
    
    let (high_confidence_value_protection_activated_in, 
         high_confidence_value_protection_activated_out) = {
        
        let high_confidence_value_protection_activated_in = 
            if (nominal_swap_in_fee == 0 && received_token_price.conf > 50) 
                || (nominal_swap_in_fee != 0 && received_token_price.conf > nominal_swap_in_fee as u64) {
                //...
            };
        
        let fee = if use_stable_fees {
            &mut receiving_custody.fees.stable_swap_in
        } else {
            &mut receiving_custody.fees.swap_in
        };
        //...
    };
    //...
}

pub fn get_swap_fees(
    &self, 
    token_id_in: usize, 
    token_id_out: usize, 
    amount_in: u64, 
    amount_out: u64,
    custody_in: &Custody,
    token_price_in: &OraclePrice,
    custody_out: &Custody,
    token_price_out: &OraclePrice,
) -> Result<(u64, u64)> {
    // Use the same stability criteria as in swap()
    let stable_swap = custody_in.is_stable() && custody_out.is_stable();
    //...
}",High,"Key improvements:

Consistent Stability Check:

Both swap() and get_swap_fees() now use the same criteria for determining stable swaps (custody_in.is_stable() && custody_out.is_stable())

This ensures fee calculations are consistent across the system

Single Source of Truth:

The stability determination logic is now identical in both functions

Removes the inconsistency where one function looked at just the receiving token while the other looked at both tokens

Maintained High-Confidence Protection:

The high-confidence value protection logic remains intact

Still applies to the appropriate fee structure based on the now-consistent stability determination

Clearer Code Structure:

The use_stable_fees variable in swap() makes the intention clearer

Matches the stable_swap variable naming in get_swap_fees()

This fix ensures that:

Fee calculations are consistent throughout the system

High-confidence tokens are properly protected

The intended fee structure is always applied correctly

Both swap directions (in and out) are treated consistently

The protocol's economic model works as designed",https://solodit.cyfrin.io/issues/unauthorized-owner-modification-ottersec-none-adrena-pdf,Low
Sol-076,"In the current implementation of pool::get_fee, final_fee is calculated by taking the maximum value between the sum of fee_adjustment and base_fee, and zero. If fee_adjustment is a negative value (smaller than the negative of base_fee), the max function will return zero, and no fees will be charged.  If a user has high confidence about the price of a particular token in the pool, they may strategically add or remove a small amount of the token. This manipulation may slightly deviate the token’s ratio from the target. Due to the current implementation, if the calculated fee_adjustment is a minuscule negative value (due to the small change in the ratio), the final fee will be zero.  As a result, the user may:  Add tokens to the pool at a lower price than they believe is fair (since the price is based on the pool’s ratio), essentially buying at a discount. Remove tokens from the pool at a higher price than they believe is fair, profiting from the imbalanced ratio. Fees are meant to incentivize users to add or remove tokens in a way that maintains the target ratios for each token within the pool. By allowing users to avoid fees through minor manipulations, the system may become imbalanced, causing significant deviations from the target ratios over time.","rust
fn get_fee( [...] ) -> Result<u64> {
    [...] 
    let fee_adjustment: i64 = (
        (slope_numerator * new_ratio) + 
        (fee_min * slope_denominator) - 
        (target_ratio * slope_numerator)
    ) / slope_denominator;

    let final_fee = math::checked_as_u16(
        std::cmp::max(fee_adjustment + base_fee, 0)
    )?;
    [...] 
}","fn get_fee( [...] ) -> Result<u64> {
    [...] 
    let fee_adjustment: i64 = (
        (slope_numerator * new_ratio) + 
        (fee_min * slope_denominator) - 
        (target_ratio * slope_numerator)
    ) / slope_denominator;

    // Ensure we always charge at least the base_fee
    let final_fee = math::checked_as_u16(
        std::cmp::max(fee_adjustment + base_fee, base_fee)
    )?;
    [...] 
}", High,"Minimum Fee Guarantee:

Changed max(..., 0) to max(..., base_fee)

Ensures the protocol always collects at least the base_fee regardless of adjustment

Prevents Fee Avoidance:

Users can no longer strategically manipulate ratios to avoid fees entirely

Maintains economic incentives for maintaining target ratios

Preserves Dynamic Fee Logic:

Still allows for dynamic fee adjustments above the base fee

Maintains the original fee curve behavior for positive adjustments

Same Safety Checks:

Keeps the checked_as_u16 conversion for type safety

Maintains all existing error handling",https://solodit.cyfrin.io/issues/unauthorized-owner-modification-ottersec-none-adrena-pdf,Low
Sol-077,"The current implementation allows the input token mint to have a freeze authority, which can result in a potential denial of service (DoS) attack on the pool. If the input token mint’s freeze authority exercises control, the pool’s input token vault can be frozen, leading to a **permanent loss of funds** for users. This is a critical issue, as frozen token accounts cannot transfer tokens, rendering the pool inoperable. ","rust
#[account(
    mint::token_program = token_program,
)]
input_token_mint: Box<InterfaceAccount<'info, Mint>>,

#[account(
    mut,
    associated_token::authority = pool,
    associated_token::mint = input_token_mint,
    associated_token::token_program = token_program
)]
pool_input_token_vault: Box<InterfaceAccount<'info, TokenAccount>>,","rust
#[account(
     mint::freeze_authority = COption::None, // Ensure no freeze authority exists     
     mint::token_program = token_program, 
)] 
input_token_mint: Box<InterfaceAccount<'info, Mint>>,",Medium,"Ensure that the input token mint does not have a freeze authority or that the pool controls the freeze authority, preventing any external actor from freezing the pool's input token vault. ",https://solodit.cyfrin.io/issues/m-01-arbitrary-input-tokens-and-token-extensions-leading-to-invariant-manipulation-shieldify-none-adrastea-markdown,High
Sol-078,"There are no checks to ensure that the `deposit_token` matches the `allowed_token` in the `solana_vault::deposit` function. This allows an attacker to deposit any tokens and get minted USDC on the other chain. The system assumes that an allowed token is deposited every time and this assumption is wrong.  ### Root Cause  In [deposit.rs](https://github.com/sherlock-audit/2024-09-orderly-network-solana-contract/blob/main/solana-vault/packages/solana/contracts/programs/solana-vault/src/instructions/vault_instr/deposit.rs#L22), the `Deposit` struct lacks a constraint to verify that `deposit_token.key()` matches the `allowed_token.mint_account`.  This check could also be added inside the `solana_vault::deposit` or the `deposit.rs::apply` functions directly, but currently, none of these functions have this check either.  ","rust
#[account()]
pub deposit_token: Box<Account<'info, Mint>>,","rust
#[account(
    constraint = deposit_token.key() == allowed_token.mint_account 
    @ VaultError::TokenNotAllowed,
     mint::token_program = token_program 
)]",Medium,Add a new `constraint` in `deposit.rs::Deposit` struct.  Update the `deposit_token` account definition in `deposit.rs` to include a `constraint` that ensures the `deposit_token` mint matches the `allowed_token.mint_account`. ,https://solodit.cyfrin.io/issues/h-1-h-1-sherlock-orderly-solana-vault-contract-git,High
Sol-079,"The implementation of the seeds function is incorrect because the correct seed needs to include the full seed phrase and the bump, but the seeds function does not include the bump.","rust
use crate::constants::*;
use crate::errors::ErrorCode;
use anchor_lang::prelude::*;

pub const ADMIN_AUTH_MAX_LEN: usize = 5;

#[account]
#[derive(InitSpace)]
pub struct RebateManager {
    pub authority: Pubkey, // 32
    #[max_len(ADMIN_AUTH_MAX_LEN)]
    pub admin_authority: Vec<Pubkey>,
    pub quote_token_mint: Pubkey, // 32
    pub token_vault: Pubkey, // 32
}

impl RebateManager {
    pub fn seeds(&self) -> [&[u8]; 2] {
        [
            REBATEMANAGER_SEED.as_bytes(),
            self.quote_token_mint.as_ref(),
        ]
    }

    pub fn initialize(
        &mut self, 
        authority: Pubkey, 
        quote_token_mint: Pubkey, 
        token_vault: Pubkey,
    ) -> Result<()> {
        self.authority = authority;
        self.quote_token_mint = quote_token_mint;
        self.token_vault = token_vault;
        Ok(())
    }

    pub fn set_admin_authority(&mut self, admin_authority: Vec<Pubkey>) -> Result<()> {
        require!(
            admin_authority.len() <= ADMIN_AUTH_MAX_LEN,
            ErrorCode::TooManyAuthorities
        );
        self.admin_authority = admin_authority;
        Ok(())
    }
}","rust
use crate::constants::*;
use crate::errors::ErrorCode;
use anchor_lang::prelude::*;

pub const ADMIN_AUTH_MAX_LEN: usize = 5;

#[account]
#[derive(InitSpace)]
pub struct RebateManager {
    pub authority: Pubkey, // 32
    #[max_len(ADMIN_AUTH_MAX_LEN)]
    pub admin_authority: Vec<Pubkey>,
    
    pub quote_token_mint: Pubkey, // 32
    pub token_vault: Pubkey, // 32
    pub rebate_manager_bump: [u8; 1], // added this line
}

impl RebateManager {
    pub fn seeds(&self) -> [&[u8]; 2] {
        [
            REBATEMANAGER_SEED.as_bytes(),
            self.quote_token_mint.as_ref(),
            self.rebate_manager_bump.as_ref(), // added this line
        ]
    }

    pub fn initialize(
        &mut self,
        authority: Pubkey,
        quote_token_mint: Pubkey,
        token_vault: Pubkey,
        bump: u8, // added this line as parameter
    ) -> Result<()> {
        self.authority = authority;
        self.quote_token_mint = quote_token_mint;
        self.token_vault = token_vault;
        self.rebate_manager_bump = [bump]; // added this line
        Ok(())
    }
}

pub fn handler(ctx: Context<CreateRebateManager>) -> Result<()> {
    let authority = ctx.accounts.authority.key();
    let quote_token_mint = ctx.accounts.quote_token_mint.key();
    let token_vault = ctx.accounts.token_vault.key();
    let bump = ctx.bumps.rebate_manager; // added this line

    let rebate_manager = &mut ctx.accounts.rebate_manager;
    
    rebate_manager.initialize(authority, quote_token_mint, token_vault, bump); // added bump as third argument
}",Medium,The rebate_manager's bump is now stored in the account and included in its seeds(). The issue is fixed and transfers from the rebate_manager will succeed.,https://solodit.cyfrin.io/issues/h-1-rebate_info-and-rebate_manager-are-unable-to-sign-the-cpi-call-due-to-an-incorrect-implementation-of-the-seeds-function-sherlock-woofi-swap-on-solana-git,High
Sol-080,"Missing permission control in create_oracle. From the above code, it is clear that the permission control for create\_pool requires its authority to match wooracle.authority. However, since anyone can create an oracle, an attacker could create an oracle and then create a pool based on that oracle. This breaks the statement made in the README. ""Functions need admin authority: claim\_fee claim\_rebate\_fee create\_oracle create\_pool create\_rebate\_pool deposit set\_pool\_admin set\_pool\_state (all handlers in this file) set\_woo\_admin set\_woo\_state(all handlers in this file)"" ","rust
#[derive(Accounts)]
pub struct CreateWooracle<'info> {
    pub wooconfig: Box<Account<'info, WooConfig>>,
    pub token_mint: Account<'info, Mint>,
    
    #[account(
         init,
         payer = admin,
         space = 8 + Wooracle::INIT_SPACE,
         seeds = [
             WOORACLE_SEED.as_bytes(),
             wooconfig.key().as_ref(),
             token_mint.key().as_ref(),
             feed_account.key().as_ref(),
             price_update.key().as_ref()
         ],
         bump,
    )]
    wooracle: Account<'info, Wooracle>,
    
    #[account(mut)] 
    admin: Signer<'info>,
    
    system_program: Program<'info, System>,
    
    /// CHECK: This is the Pyth feed account
    feed_account: AccountInfo<'info>,
    
    // Add this account to any instruction Context that needs price data.
    // Warning:
    // users must ensure that the account passed to their instruction is owned by the Pyth pull oracle program.
    // Using Anchor with the Account<'info, PriceUpdateV2> type will automatically perform this check.
    // However, if you are not using Anchor, it is your responsibility to perform this check.
    price_update: Account<'info, PriceUpdateV2>,
    
    quote_token_mint: Account<'info, Mint>,
    
    /// CHECK: This is the Quote token's pyth feed account
    quote_feed_account: AccountInfo<'info>,
    
    // Add this account to any instruction Context that needs price data.
    // Warning:
    // users must ensure that the account passed to their instruction is owned by the Pyth pull oracle program.
    // Using Anchor with the Account<'info, PriceUpdateV2> type will automatically perform this check.
    // However, if you are not using Anchor, it is your responsibility to perform this check.
    quote_price_update: Account<'info, PriceUpdateV2>,
}

pub fn handler(ctx: Context<CreateWooracle>, maximum_age: u64) -> Result<()> {
    ctx.accounts.wooracle.wooconfig = ctx.accounts.wooconfig.key();
    ctx.accounts.wooracle.authority = ctx.accounts.admin.key();
    ctx.accounts.wooracle.token_mint = ctx.accounts.token_mint.key();
    ctx.accounts.wooracle.feed_account = ctx.accounts.feed_account.key();
    ctx.accounts.wooracle.price_update = ctx.accounts.price_update.key();
    //----skip 
}","rust
#[derive(Accounts)]
pub struct CreateWooracle<'info> {
    pub wooconfig: Box<Account<'info, WooConfig>>,
    pub token_mint: Account<'info, Mint>,

    #[account(
        init,
        payer = admin,
        space = 8 + Wooracle::INIT_SPACE,
        seeds = [
            WOORACLE_SEED.as_bytes(),
            wooconfig.key().as_ref(),
            token_mint.key().as_ref(),
            feed_account.key().as_ref(),
            price_update.key().as_ref()
        ],
        bump,
    )]
    wooracle: Account<'info, Wooracle>,

    #[account(mut)]
    admin: Signer<'info>,
    system_program: Program<'info, System>,

    /// CHECK: This is the Pyth feed account
    feed_account: AccountInfo<'info>,

    // Add this account to any instruction Context that needs price data.
    // Warning:
    // users must ensure that the account passed to their instruction is owned by the Pyth pull oracle program.
    // Using Anchor with the Account<'info, PriceUpdateV2> type will automatically perform this check.
    // However, if you are not using Anchor, it is your responsibility to perform this check.
    price_update: Account<'info, PriceUpdateV2>,

    quote_token_mint: Account<'info, Mint>,

    /// CHECK: This is the Quote token's pyth feed account
    quote_feed_account: AccountInfo<'info>,

    // Add this account to any instruction Context that needs price data.
    // Warning:
    // users must ensure that the account passed to their instruction is owned by the Pyth pull oracle program.
    // Using Anchor with the Account<'info, PriceUpdateV2> type will automatically perform this check.
    // However, if you are not using Anchor, it is your responsibility to perform this check.
    quote_price_update: Account<'info, PriceUpdateV2>,
}  

pub fn handler(ctx: Context<CreateWooracle>, maximum_age: u64) -> Result<()> {
    ctx.accounts.wooracle.wooconfig = ctx.accounts.wooconfig.key();
    ctx.accounts.wooracle.authority = ctx.accounts.wooconfig.authority();

    ctx.accounts.wooracle.token_mint = ctx.accounts.token_mint.key();
    ctx.accounts.wooracle.feed_account = ctx.accounts.feed_account.key();
    ctx.accounts.wooracle.price_update = ctx.accounts.price_update.key();

    // ----skip 
}",Medium,Set the admin parameter in CreateWooracle to admin = wooconfig.authority.,https://solodit.cyfrin.io/issues/m-2-missing-permission-control-in-create_oracle-and-create_pool-sherlock-woofi-swap-on-solana-git,High
Sol-081,"Ability To Initialize Multiple Times. In the Initialize instruction, while initializing the staking parameters, the use of init_if_needed allows the staking parameters to be altered multiple times by anyone.  The ability to initialize the staking parameters repeatedly may result in security vulnerabilities. For example, an attacker could repeatedly call the Initialize instruction with different parameters, altering the staking configuration and disrupting the entire protocol.  ","rust
#[derive(Accounts)]
pub struct Initialize<'info> {
    #[account(mut)] 
    pub admin: Signer<'info>, 

    #[account(init_if_needed, payer = admin, seeds = [STAKING_PARAMS_SEED, TEST_SEED], bump, space = 1024)] 
    pub staking_params: Account<'info, StakingParams>, 

    pub rewards_token_mint: Account<'info, Mint>, 

    #[account(init_if_needed, payer = admin, seeds = [REWARDS_SEED, TEST_SEED], bump, token::mint = rewards_token_mint, token::authority = staking_params)] 
    pub rewards_token_account: Account<'info, TokenAccount>, 

    token_program: Program<'info, Token>, 

    system_program: Program<'info, System>,
}","rust
#[derive(Accounts)]
pub struct Initialize<'info> {
    #[account(mut)]
    pub admin: Signer<'info>,
    
    #[account(init, payer = admin, seeds = [STAKING_PARAMS_SEED, TEST_SEED], bump, space = 1024)]
    pub staking_params: Account<'info, StakingParams>,
    
    pub rewards_token_mint: Account<'info, Mint>,
    
    #[account(init, payer = admin, seeds = [REWARDS_SEED, TEST_SEED], bump, token::mint = rewards_token_mint, token::authority = staking_params)]
    pub rewards_token_account: Account<'info, TokenAccount>,
    
    token_program: Program<'info, Token>,
    
    system_program: Program<'info, System>,
}",Critical,Use init instead of init_if_needed for the Initialize instruction. This ensures that initialization can only happen once.,https://solodit.cyfrin.io/issues/discrepancies-in-deposit-functionality-ottersec-none-composablefi-pdf,High
Sol-082,"Discrepancies In Deposit  Functionality. The deposit function uses remaining_accounts for the CPI call to the guest chain program (solana_ibc::cpi::set_stake). However, the function lacks explicit validation checks on remaining_accounts within the deposit instruction. Similarly, solana_ibc::cpi::set_stake also lacks explicit validation checks for the accounts passed in the CpiContext.  Additionally, when invoking solana_ibc::cpi::set_stake, it is crucial to include parameters that identify the specific mint of the staked amount. Tokens on Solana may have different decimal places, and each mint may have a different scale. Without passing information about the mint of the staked amount, there is a risk of updating the stake value with an incorrect scale.","rust
use solana_ibc::CHAIN_SEED;

pub mod constants;
mod token;

use constants::{ /* ... */ };

pub mod restaking {
    // ...
    pub fn update_staking_params(ctx: &mut Ctx, staking_cap: u128) -> ProgramResult {
        let staking_params = &mut ctx.accounts.staking_params;
        staking_params.admin = ctx.accounts.admin.key();
        staking_params.whitelisted_tokens = whitelisted_tokens;
        staking_params.is_guest_chain_initialized = false;
        staking_params.staking_cap = staking_cap;
        staking_params.rewards_token_mint = ctx.accounts.rewards_token_mint.key();

        // ...
    }

    pub fn update_guest_chain_initialization(ctx: Context<UpdateStakingParams>) -> Result<()> {
        let staking_params = &mut ctx.accounts.staking_params;
        staking_params.is_guest_chain_initialized = true;

        Ok(())
    }

    pub fn claim_rewards(ctx: Context<Claim>) -> Result<()>, {
        let staking_params = &ctx.accounts.staking_params;

        if !staking_params.is_guest_chain_initialized {
            return Err(error!(ErrorCodes::OperationNotAllowed));
        }
        
        // ...
    }

    // ...

    pub struct StakingParams {
        // ...
        pub admin: Pubkey,
        #[max_len(20)]
        pub whitelisted_tokens: Vec<Pubkey>,
        pub is_guest_chain_initialized: bool,
        pub rewards_token_mint: Pubkey,
        // None means there is not staking cap
        pub staking_cap: u128,
        // ...
    }

    // ...

    pub enum ErrorCodes {
        // ...
        StakingCapExceeded,
        #[msg(""New staking cap should be more than existing one"")]
        NewStakingCapShouldBeMoreThanExistingOne,
        // ...
    }
}","rust
use solana_ibc::CHAIN_SEED;
pub mod constants;
mod validation;
mod token;

use constants::{
    // omitted part...
};

pub mod restaking {
    // code omitted for brevity...
    
    staking_params.admin = ctx.accounts.admin.key();
    staking_params.whitelisted_tokens = whitelisted_tokens;
    staking_params.guest_chain_program_id = None;
    staking_params.staking_cap = staking_cap;
    staking_params.rewards_token_mint = ctx.accounts.rewards_token_mint.key();    
    
    // code omitted for brevity...
    
    let current_time = Clock::get()?.unix_timestamp;
    let guest_chain_program_id = staking_params.guest_chain_program_id;
    vault_params.service = service;
    vault_params.stake_timestamp_sec = current_time;

    // code omitted for brevity...

    token::mint_nft(ctx.accounts.into(), seeds)?;
    
    if guest_chain_program_id.is_some() {
        validation::validate_remaining_accounts(ctx.remaining_accounts, &guest_chain_program_id.unwrap())?;
        let cpi_accounts = Chain {
            sender: ctx.accounts.depositor.to_account_info(),
            storage: ctx.remaining_accounts[0].clone(),
            // code omitted for brevity...
        }
        
        // code omitted for brevity...
        
        if staking_params.guest_chain_program_id.is_none() {
            return Err(error!(ErrorCodes::OperationNotAllowed));
        }
        
        // code omitted for brevity...

        Ok(())
    }

    // code omitted for brevity...

    pub fn claim_rewards(ctx: Context<Claim>) -> Result<()> {
        let staking_params = &ctx.accounts.staking_params;

        if staking_params.guest_chain_program_id.is_none() {
            return Err(error!(ErrorCodes::OperationNotAllowed));
        }
    }

    // code omitted for brevity...

    pub enum ErrorCodes {
        StakingCapExceeded,
        #[msg(""New staking cap should be more than existing one"")]
        NewStakingCapShouldBeMoreThanExistingOne,

        #[msg(""Guest chain can only be initialized once"")]
        GuestChainAlreadyInitialized,

        #[msg(""Account validation for CPI call to the guest chain"")]
        AccountValidationFailedForCPI
    }
}

// code omitted for brevity...

use anchor_lang::prelude::*;
use anchor_spl::associated_token::get_associated_token_address_with_program_id;
use solana_ibc::{CHAIN_SEED, SOLANA_IBC_STORAGE_SEED, TRIE_SEED};
use crate::ErrorCodes;

pub fn validate_remaining_accounts<'a>(
    accounts: &[AccountInfo<'a>], 
    expected_guest_chain_program_id: &Pubkey
) -> Result<()> {
    
    // code omitted for brevity...
}",Critical,"Add validation checks in both deposit and solana_ibc::cpi::set_stake to ensure that the required accounts are present, have the correct ownership, and include the mint information as a parameter when calling set_stake.",https://solodit.cyfrin.io/issues/discrepancies-in-deposit-functionality-ottersec-none-composablefi-pdf,High
Sol-083,"Missing Receipt Token Balance Check In the implementation of the set_service instruction, there is a section of code that sets the service for a stake that was deposited before guest chain initialization, but it does not explicitly check whether the depositor’s receipt_token_account has a non-zero balance.  The code assumes that the depositor still holds a sufficient balance in their receipt_token_account to cover the stake, but fails to check for it explicitly. Proof of Concept A malicious user calls the set_service instruction using a genuine user’s vault_params and an arbitrary Service.  Since the code does not check for a non-zero balance in the receipt_token_account, the malicious user can abuse the system by setting an unauthorized stake for themselves using the original depositor’s vault_params.","rust
/// This method sets the service for the stake which was deposited before guest chain initialization
///
/// This method can only be called if the service was not set during the depositing and
/// can only be called once. Calling otherwise would panic.
///
/// The accounts for CPI are sent as remaining accounts similar to `deposit` method.
pub fn set_service<'a, 'info>(
    ctx: Context<'a, 'a, 'a, 'info, SetService<'info>>,
    service: Service,
) -> Result<()> {
    let vault_params = &mut ctx.accounts.vault_params;
    let staking_params = &mut ctx.accounts.staking_params;

    if staking_params.guest_chain_program_id.is_none() {
        return Err(error!(ErrorCodes::OperationNotAllowed));
    }

    if vault_params.service.is_some() {
        return Err(error!(ErrorCodes::ServiceAlreadySet));
    }

    vault_params.service = Some(service);

    let guest_chain_program_id = 
        staking_params.guest_chain_program_id.unwrap(); // Infallible
    let amount = vault_params.stake_amount;

    validation::validate_remaining_accounts(
        ctx.remaining_accounts,
        &guest_chain_program_id,
    )?;

    let bump = ctx.bumps.staking_params;
    let seeds = [STAKING_PARAMS_SEED, TEST_SEED, core::slice::from_ref(&bump)];
    let seeds = seeds.as_ref();
    let seeds = core::slice::from_ref(&seeds);

    let cpi_accounts = SetStake {
        sender: ctx.accounts.depositor.to_account_info(),
        stake_mint: ctx.accounts.stake_mint.to_account_info(),
        chain: ctx.remaining_accounts[0].clone(),
        trie: ctx.remaining_accounts[1].clone(),
        system_program: ctx.accounts.system_program.to_account_info(),
        instruction: ctx.accounts.instruction.to_account_info(),
    };

    let cpi_program = ctx.remaining_accounts[2].clone();

    let cpi_ctx = 
        CpiContext::new_with_signer(cpi_program, cpi_accounts, seeds);

    solana_ibc::cpi::set_stake(cpi_ctx, amount as u128)?;

    Ok(())
}","rust
/// This method sets the service for the stake which was deposited before guest chain
/// initialization
///
/// This method can only be called if the service was not set during the depositing and
/// can only be called once. Calling otherwise would panic.
///
/// The accounts for CPI are sent as remaining accounts similar to `deposit` method.
pub fn set_service<'a, 'info>(
    ctx: Context<'a, 'a, 'a, 'info, SetService<'info>>,
    service: Service,
) -> Result<()> {
    let vault_params = &mut ctx.accounts.vault_params;
    let staking_params = &mut ctx.accounts.staking_params;

    if staking_params.guest_chain_program_id.is_none() {
        return Err(error!(ErrorCodes::OperationNotAllowed));
    }

    if vault_params.service.is_some() {
        return Err(error!(ErrorCodes::ServiceAlreadySet));
    }

    let token_account = &ctx.accounts.receipt_token_account;

    if token_account.amount < 1 {
        return Err(error!(ErrorCodes::InsufficientReceiptTokenBalance));
    }

    vault_params.service = Some(service);

    let guest_chain_program_id = staking_params.guest_chain_program_id.unwrap();
    let amount = vault_params.stake_amount;

    validation::validate_remaining_accounts(
        ctx.remaining_accounts, 
        &guest_chain_program_id,
    )?;

    let bump = ctx.bumps.staking_params;

    let seeds = [
        STAKING_PARAMS_SEED, 
        TEST_SEED, 
        core::slice::from_ref(&bump)
    ];

    let seeds = seeds.as_ref();
    let seeds = core::slice::from_ref(&seeds);

    let cpi_accounts = SetStake {
        sender: ctx.accounts.depositor.to_account_info(),
        stake_mint: ctx.accounts.stake_mint.to_account_info(),
        chain: ctx.remaining_accounts[0].clone(),
        trie: ctx.remaining_accounts[1].clone(),
        system_program: ctx.accounts.system_program.to_account_info(),
        instruction: ctx.accounts.instruction.to_account_info(),
    };

    let cpi_program = ctx.remaining_accounts[2].clone();

    let cpi_ctx = CpiContext::new_with_signer(cpi_program, cpi_accounts, seeds);

    solana_ibc::cpi::set_stake(cpi_ctx, amount as u128)?;

    Ok(())
}",Critical,Explicitly check if the depositor’s receipt_token_account has a non-zero balance before proceeding with the stake setting. This check ensures that the depositor has access to their respective vault_params,https://github.com/ComposableFi/emulated-light-client/commit/e10222d8a13d420615c0e46b4ce5a66b7556f684,High
Sol-084,"Potential Fund Lockup  The deposit instruction includes an optional service parameter of type Option<Service>. This parameter is used to specify a service associated with a staking operation.  The vulnerability arises because the presence of the service parameter is later used as a condition during withdrawal. Specifically, the withdrawal logic includes a check that assumes service will always be Some(service).  However, if a deposit is made with None for the service parameter, this condition will not be met during withdrawal.  As a result, if the withdrawal logic unconditionally checks for service.is_some(), and the deposit was made with None, the user may be unable to withdraw funds, leading to a potential permanent lockup.","rust
pub fn deposit<'a, 'info>(
    ctx: Context<'a, 'a, 'a, 'info, Deposit<'info>>,
    service: Option<Service>,
    amount: u64,
) -> Result<()> {
    [...] 
    vault_params.service = if guest_chain_program_id.is_some() {
        service 
    } else { 
        None 
    }; 
    [...]
}","rust
/// This method sets the service for the stake which was deposited before guest chain
/// initialization
///
/// This method can only be called if the service was not set during the depositing and
/// can only be called once. Calling otherwise would panic.
///
/// The accounts for CPI are sent as remaining accounts similar to `deposit` method.
pub fn set_service<'a, 'info>(
    ctx: Context<'a, 'a, 'a, 'info, SetService<'info>>,
    service: Service,
) -> Result<()> {
    let vault_params = &mut ctx.accounts.vault_params;
    let staking_params = &mut ctx.accounts.staking_params;

    if staking_params.guest_chain_program_id.is_none() {
        return Err(error!(ErrorCodes::OperationNotAllowed));
    }

    if vault_params.service.is_some() {
        return Err(error!(ErrorCodes::ServiceAlreadySet));
    }

    vault_params.service = Some(service);

    let guest_chain_program_id = staking_params.guest_chain_program_id.unwrap(); // Infallible
    let amount = vault_params.stake_amount;

    validation::validate_remaining_accounts(
        ctx.remaining_accounts,
        &guest_chain_program_id,
    )?;

    let bump = ctx.bumps.staking_params;
    let seeds = [STAKING_PARAMS_SEED, TEST_SEED, core::slice::from_ref(&bump)];
    let seeds = seeds.as_ref();
    let seeds = core::slice::from_ref(&seeds);

    let cpi_accounts = Chain {
        sender: ctx.accounts.depositor.to_account_info(),
        storage: ctx.remaining_accounts[0].clone(),
        chain: ctx.remaining_accounts[1].clone(),
        trie: ctx.remaining_accounts[2].clone(),
        system_program: ctx.accounts.system_program.to_account_info(),
        instruction: ctx.accounts.instruction.to_account_info(),
    };

    let cpi_program = ctx.remaining_accounts[3].clone();
    let cpi_ctx = CpiContext::new_with_signer(cpi_program, cpi_accounts, seeds);

    solana_ibc::cpi::set_stake(cpi_ctx, amount as u128)?;

    Ok(())
}",Low,Fixed by adding the set_service instruction to allow setting the service parameter after depositing funds.,https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/1441a8bd-31eb-44b7-b22d-0730dd0225c4/composable_audit_final.pdf?table=block&id=b924da7f-7c9e-4d03-b3db-b701ecbeab60&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742954400000&signature=Fs-jgCwXekywE6_iIh9BkPz4MhqR7d0SOwa0JlA3eRo&downloadName=composable_audit_final.pdf,High
Sol-085,"Lack of Instruction Sysvar Validation. The instruction sysvar account is passed to both the deposit and set_service instructions, but its validation is not performed in validate_remaining_accounts and set_stake.  As a result, it may be possible to replace or manipulate the instruction sysvar account. This could allow an attacker to inject unauthorized instructions into the CPI calls.","rust
#[derive(Accounts)] 
pub struct SetService<'info> {     
    #[account(mut)]     
    depositor: Signer<'info>,      
    #[account(mut, seeds = [VAULT_PARAMS_SEED, receipt_token_mint.key().as_ref()], bump, has_one = stake_mint)]     
    pub vault_params: Box<Account<'info, Vault>>,     
    #[account(mut, seeds = [STAKING_PARAMS_SEED, TEST_SEED], bump)]     
    pub staking_params: Box<Account<'info, StakingParams>>,      
    #[account(mut, mint::decimals = 0)]     
    pub receipt_token_mint: Box<Account<'info, Mint>>,     
    #[account(mut, token::mint = receipt_token_mint, token::authority = depositor)]     
    pub receipt_token_account: Box<Account<'info, TokenAccount>>,      
    #[account(mut)]     
    pub stake_mint: Account<'info, Mint>,      
    ///CHECK:         
    pub instruction: AccountInfo<'info>,      
    pub system_program: Program<'info, System>, 
} 

#[derive(Accounts)] 
pub struct SetStake<'info> {     
    #[account(mut)]     
    sender: Signer<'info>,      
    /// The guest blockchain data.     
    #[account(mut, seeds = [CHAIN_SEED], bump)]     
    chain: Account<'info, chain::ChainData>,      
    /// The account holding the trie which corresponds to guest blockchain’s     
    /// state root.     
    ///     
    /// CHECK: Account’s owner is checked by [`storage::get_provable_from`]     
    /// function.     
    #[account(mut, seeds = [TRIE_SEED], bump)]     
    trie: UncheckedAccount<'info>,      
    /// We would support only SOL as stake which has decimal of 9     
    #[account(mut, mint::decimals = 9)]     
    stake_mint: Account<'info, Mint>,      
    system_program: Program<'info, System>,       
    /// CHECK: Used for getting the caller program id to verify if the right     
    /// program is calling the method.     
    instruction: AccountInfo<'info>, 
}","rust
#[derive(Accounts)] 
pub struct SetService<'info> {
    #[account(mut)]     
    depositor: Signer<'info>,      
    
    #[account(mut, seeds = [VAULT_PARAMS_SEED, receipt_token_mint.key().as_ref()], bump, has_one = stake_mint)]     
    pub vault_params: Box<Account<'info, Vault>>,     

    #[account(mut, seeds = [STAKING_PARAMS_SEED, TEST_SEED], bump)]     
    pub staking_params: Box<Account<'info, StakingParams>>,      

    #[account(mut, mint::decimals = 0)]     
    pub receipt_token_mint: Box<Account<'info, Mint>>,     

    #[account(mut, token::mint = receipt_token_mint, token::authority = depositor)]     
    pub receipt_token_account: Box<Account<'info, TokenAccount>>,      

    #[account(mut)]     
    pub stake_mint: Account<'info, Mint>,      

    ///CHECK:        
    #[account(address = solana_program::sysvar::instructions::ID)]     
    pub instruction: AccountInfo<'info>,      

    pub system_program: Program<'info, System>, 
} 

#[derive(Accounts)] 
pub struct SetStake<'info> {
    #[account(mut)]     
    sender: Signer<'info>,      

    /// The guest blockchain data.  
    #[account(mut, seeds = [CHAIN_SEED], bump)]     
    chain: Account<'info, chain::ChainData>,      

    /// The account holding the trie which corresponds to guest blockchain’s     
    /// state root.     
    ///     
    /// CHECK: Account’s owner is checked by [`storage::get_provable_from`]     
    /// function.  
    #[account(mut, seeds = [TRIE_SEED], bump)]     
    trie: UncheckedAccount<'info>,      

    /// We would support only SOL as stake which has decimal of 9     
    #[account(mut, mint::decimals = 9)]     
    stake_mint: Account<'info, Mint>,      

    system_program: Program<'info, System>,      

    #[account(address = solana_program::sysvar::instructions::ID)]     
    /// CHECK: Used for getting the caller program id to verify if the right     
    /// program is calling the method.
    instruction: AccountInfo<'info>,
}",High,Both validation::validate_remaining_accounts and set_stake should include explicit validation for the instruction sysvar account. The validation should ensure that the account’s address matches the expected value.,https://github.com/ComposableFi/emulated-light-client/commit/b221448ddb53bab446d6f979395aebbcaa6594c9,High
Sol-086,"Inaccurate Reward Calculation. In withdrawal_request, the last_received_rewards_height parameter of vault_params is not updated to the current_height after rewards are calculated and transferred.  If a user cancels a withdrawal request and later requests withdrawal again, the function erroneously considers the last_received_rewards_height as the height when the last rewards were claimed, rather than the height when the last withdrawal request was raised.  This affects the reward calculation, as it will be based on outdated information.","rust
/// Creates a withdrawal request by escrowing the receipt token. Once the unbonding     
/// period ends, the token from the escrow would be burnt and returned to the user.     
///     
/// This method transfers all the pending rewards to the user. The stake on the     
/// guest chain is only updated after unbonding period ends in `withdraw` method.     
///
/// Closes the receipt token account.     
pub fn withdrawal_request(ctx: Context<WithdrawalRequest>) -> Result<()> {  
    let vault_params = &mut ctx.accounts.vault_params;         
    let staking_params = &mut ctx.accounts.staking_params;         
    let stake_token_mint = ctx.accounts.token_mint.key();

    if staking_params.guest_chain_program_id.is_none() {             
        return Err(error!(ErrorCodes::OperationNotAllowed));         
    }

    if stake_token_mint != vault_params.stake_mint {             
        return Err(error!(ErrorCodes::InvalidTokenMint));         
    }

    let current_timestamp = Clock::get()?.unix_timestamp as u64;         
    let withdrawal_request_params = WithdrawalRequestParams {             
        timestamp_in_sec: current_timestamp,             
        owner: ctx.accounts.withdrawer.key(),             
        token_account: ctx.accounts.withdrawer_token_account.key(),         
    };
    vault_params.withdrawal_request = Some(withdrawal_request_params); 

    let chain = &ctx.accounts.guest_chain;         
    let service = vault_params             
        .service             
        .as_ref()             
        .ok_or_else(|| error!(ErrorCodes::MissingService))?;
    let validator_key = match service {             
        Service::GuestChain { validator } => validator,         
    };

    /*          
    * Get the rewards from guest blockchain.          
    */          
    let (rewards, _current_height) = chain.calculate_rewards(             
        vault_params.last_received_rewards_height,             
        *validator_key,             
        vault_params.stake_amount,         
    )?;

    let bump = ctx.bumps.staking_params;         
    let seeds = [STAKING_PARAMS_SEED, TEST_SEED, core::slice::from_ref(&bump)];         
    let seeds = seeds.as_ref();         
    let seeds = core::slice::from_ref(&seeds); 

    // Transfer rewards from platform wallet         
    token::transfer(
        token::TransferAccounts {             
            from: ctx
                .accounts
                .platform_rewards_token_account
                .to_account_info(),
            to: ctx
                .accounts
                .depositor_rewards_token_account
                .to_account_info(),
            authority: ctx.accounts.staking_params.to_account_info(),
            token_program: ctx.accounts.token_program.to_account_info(),
        },
        seeds,
        rewards,
    )?;

    // Transfer receipt token to escrow
    token::transfer(ctx.accounts.into(), &[], 1)?;

    // Closing receipt NFT token account         
    let close_instruction = CloseAccount {             
        account: ctx.accounts.receipt_token_account.to_account_info(),
        destination: ctx.accounts.withdrawer.to_account_info(),             
        authority: ctx.accounts.withdrawer.to_account_info(),         
    }; 

    let cpi_ctx = CpiContext::new(             
        ctx.accounts.token_program.to_account_info(),
        close_instruction,         
    );
    anchor_spl::token::close_account(cpi_ctx)     
}
/// Cancels the withdraw request and returns the receipt NFT.
///
/// Even if the unbonding period is over and the withdraw is pending, 
/// this method would cancel the withdrawal request and return back the","rust
/// Creates a withdrawal request by escrowing the receipt token. Once the unbonding 
/// period ends, the token from the escrow would be burnt and returned to the user.     
/// 
/// This method transfers all the pending rewards to the user. The stake on the     
/// guest chain is only updated after unbonding period ends in `withdraw` method.     
///
/// Closes the receipt token account.     
pub fn withdrawal_request(ctx: Context<WithdrawalRequest>) -> Result<()> {         
    let vault_params = &mut ctx.accounts.vault_params;         
    let staking_params = &mut ctx.accounts.staking_params;         
    let stake_token_mint = ctx.accounts.token_mint.key();          

    if staking_params.guest_chain_program_id.is_none() {             
        return Err(error!(ErrorCodes::OperationNotAllowed));         
    }          

    if stake_token_mint != vault_params.stake_mint {             
        return Err(error!(ErrorCodes::InvalidTokenMint));         
    }          

    let current_timestamp = Clock::get()?.unix_timestamp as u64;         
    let withdrawal_request_params = WithdrawalRequestParams {             
        timestamp_in_sec: current_timestamp,             
        owner: ctx.accounts.withdrawer.key(),             
        token_account: ctx.accounts.withdrawer_token_account.key(),
    };         
    vault_params.withdrawal_request = Some(withdrawal_request_params);          

    let chain = &ctx.accounts.guest_chain;         
    let service = vault_params             
        .service
        .as_ref()
        .ok_or_else(|| error!(ErrorCodes::MissingService))?;         
    let validator_key = match service {             
        Service::GuestChain { validator } => validator,
    };          

    /*          
    * Get the rewards from guest blockchain.          
    */          

    let (rewards, current_height) = chain.calculate_rewards(   
        vault_params.last_received_rewards_height,             
        *validator_key,             
        vault_params.stake_amount,
    )?;          

    vault_params.last_received_rewards_height = current_height;          

    let bump = ctx.bumps.staking_params;         
    let seeds = [STAKING_PARAMS_SEED, TEST_SEED, core::slice::from_ref(&bump)];
    let seeds = seeds.as_ref();         
    let seeds = core::slice::from_ref(&seeds);          

    // Transfer rewards from platform wallet         
    token::transfer(
        token::TransferAccounts {                 
            from: ctx                     
                .accounts                     
                .platform_rewards_token_account                     
                .to_account_info(),
            to: ctx                     
                .accounts                     
                .depositor_rewards_token_account                     
                .to_account_info(),
            authority: ctx.accounts.staking_params.to_account_info(),
            token_program: ctx.accounts.token_program.to_account_info(),
        },
        seeds,
        rewards,
    )?;          

    // Transfer receipt token to escrow         
    token::transfer(ctx.accounts.into(), &[], 1)?;          

    // Closing receipt NFT token account         
    let close_instruction = CloseAccount {             
        account: ctx.accounts.receipt_token_account.to_account_info(),
        destination: ctx.accounts.withdrawer.to_account_info(),
        authority: ctx.accounts.withdrawer.to_account_info(),
    };          

    let cpi_ctx = CpiContext::new(             
        ctx.accounts.token_program.to_account_info(),             
        close_instruction,         
    );         
    anchor_spl::token::close_account(cpi_ctx)     
}",High,Update the last_received_rewards_height parameter to the current height after rewards are calculated and transferred within withdrawal_request.,https://github.com/ComposableFi/emulated-light-client/commit/e69bba333bffa3498edbf87d265f24409cbc0ad3,High
Sol-087,"Unauthorized Configuration Changes Description The redeemer_config account is declared with the init_if_needed attribute in InitializeBridgeV1. This attribute allows the creation of multiple bridges with a different pair of wrndr_mint and rndr_mint sharing the same underlying redeemer_config account. However, this poses a problem since every part of the codebase assumes that only one bridge exists.. This shared configuration may have unintended consequences, such as conflicts or misconfigurations, as multiple bridges may inadvertently utilize the same parameters. This may be suitable for one bridge, but not for others, resulting in the manipulation of shared configuration data. The most critical shared configuration between all the bridges is the ForeignContract account which allows the initialization of a BridgeV1 account with a random address and a malicious wrndr_mint that has the same chain value as the original one. This creates a BridgeV1 account in the same chain as the original, pointing to a different address. This address may call RegisterForeignContractV1, providing the same chain value as the original wrndr_mint, creating a ForeignContract with the same chain, essentially overwriting the address stored inside the program derived address.","rust
#[derive(Accounts)]
#[instruction(args: RegisterForeignContractArgsV1)]
pub struct RegisterForeignContractV1<'info> {
    // ...
    
    #[account(
        init_if_needed, 
        payer = owner, 
        seeds = [ 
            ForeignContract::SEED_PREFIX, 
            &args.chain.to_le_bytes()[..] 
        ], 
        bump, 
        space = ForeignContract::MAXIMUM_SIZE 
    )]
    /// Foreign Contract account. Create this account if an emitter has not been
    /// registered yet for this Wormhole chain ID. If there already is a
    /// contract address saved in this account, overwrite it.
    pub foreign_contract: Box<Account<'info, ForeignContract>>,
    
    // ...
}","rust
pub struct InitializeBridgeV1<'info> { 
    //... some fields not shown

    #[account(
        // - init_if_needed, // This line seems to be commented out and incorrect
        init,
        payer = owner,
        seeds = [RedeemerConfig::SEED_PREFIX],
        bump,
        space = RedeemerConfig::MAXIMUM_SIZE,
    )]
    /// Redeemer Config account, which saves program data useful for other
    /// instructions, specifically for inbound transfers. Also saves the payer
    /// of the [`initialize`](crate::initialize) instruction as the program's
    /// owner.
    pub redeemer_config: Box, // Type of Box is undefined.
    
    //... some fields not shown
}",High,Limit the creation of multiple bridges by changing init_if_needed to init.,https://solodit.cyfrin.io/issues/unauthorized-configuration-changes-ottersec-none-render-network-pdf,High
Sol-088,"Integer Overflow. There is a potential for integer overflow in the mechanism for calculating incentives for token transfers. The code tracks an incentive_counter, representing the cumulative incentives earned, and checks whether this cumulative amount exceeds a configured incentive_threshold. If it does, a new incentive epoch begins, and the incentives adjust accordingly.","rust
let threshold = b.incentive_threshold;
let inc = b.incentive_counter + transfer.amount;

if inc >= threshold {
    // count towards the future epoch
    if inc - threshold > threshold - b.incentive_counter {
        epoch += 1 
    }
    b.incentive_counter = inc - threshold;
    b.incentive_epoch += 1;
} else {
    b.incentive_counter += inc;
}","rust
let threshold = b.incentive_threshold;
let inc = b.incentive_counter + transfer.amount;

if inc >= threshold {
    // count towards the future epoch
    if inc - threshold > threshold.saturating_sub(b.incentive_counter) {
        epoch += 1
    }
    b.incentive_counter = inc - threshold;
    b.incentive_epoch += 1;
} else {
    b
}",High,Utilize saturating_sub to avoid the denial of service while keeping the original functionality.,https://solodit.cyfrin.io/issues/unauthorized-configuration-changes-ottersec-none-render-network-pdf,High
Sol-089,"The vulnerabilities pertain to specific edge cases when delta_fee is computed, where malicious provers may manipulate the parameters to create valid proofs that, when processed, result in a loss of funds from the destination account. This occurs as in both edge cases, proofs may be verified even though the value of fee_to_encrypt is greater than that of transfer_amount, thus resulting in the loss of funds scenario.","rust
#[cfg(not(target_os = ""solana""))]
use {
    crate::{
        encryption::{
            elgamal::{ElGamalCiphertext, ElGamalKeypair, ElGamalPubkey, ElGamalSecretKey},
            pedersen::{Pedersen, PedersenCommitment, PedersenOpening},
        },
        errors::{ProofGenerationError, ProofVerificationError},
        instruction::{
            errors::InstructionError,
            transfer::{
                combine_lo_hi_ciphertexts, combine_lo_hi_commitments, combine_lo_hi_openings,
                combine_lo_hi_u64,
                encryption::{FeeEncryption, TransferAmountCiphertext},
                split_u64, FeeParameters, Role,
            },
        },
        range_proof::RangeProof,
        sigma_proofs::{
            batched_grouped_ciphertext_validity_proof::BatchedGroupedCiphertext2HandlesValidityProof,
            ciphertext_commitment_equality_proof::CiphertextCommitmentEqualityProof,
            fee_proof::FeeSigmaProof,
        },
        transcript::TranscriptProtocol,
    },
    bytemuck::bytes_of,
    curve25519_dalek::scalar::Scalar,
    merlin::Transcript,
    std::convert::TryInto,
    subtle::{ConditionallySelectable, ConstantTimeGreater},
};

use {
    crate::{
        instruction::{ProofType, ZkProofData},
        zk_token_elgamal::pod,
    },
    bytemuck::{Pod, Zeroable},
};

#[cfg(not(target_os = ""solana""))]
const MAX_FEE_BASIS_POINTS: u64 = 10_000;
#[cfg(not(target_os = ""solana""))]
const ONE_IN_BASIS_POINTS: u128 = MAX_FEE_BASIS_POINTS as u128;
#[cfg(not(target_os = ""solana""))]
const TRANSFER_SOURCE_AMOUNT_BITS: usize = 64;
#[cfg(not(target_os = ""solana""))]
const TRANSFER_AMOUNT_LO_BITS: usize = 16;
#[cfg(not(target_os = ""solana""))]
const TRANSFER_AMOUNT_HI_BITS: usize = 32;
#[cfg(not(target_os = ""solana""))]
const TRANSFER_DELTA_BITS: usize = 48;
#[cfg(not(target_os = ""solana""))]
const FEE_AMOUNT_LO_BITS: usize = 16;

#[cfg(not(target_os = ""solana""))]
lazy_static::lazy_static!","rust

#[cfg(not(target_os = ""solana""))] 
use {     
    crate::{         
        encryption::{
            elgamal::{
                ElGamalCiphertext, 
                ElGamalKeypair, 
                ElGamalPubkey, 
                ElGamalSecretKey
            }, 
            pedersen::{
                Pedersen, 
                PedersenCommitment, 
                PedersenOpening
            },         
        },         
        errors::{
            ProofGenerationError, 
            ProofVerificationError
        },         
        instruction::{             
            errors::InstructionError,             
            transfer::{
                combine_lo_hi_ciphertexts, 
                combine_lo_hi_commitments, 
                combine_lo_hi_openings,                 
                combine_lo_hi_u64,                 
                encryption::{
                    FeeEncryption, 
                    TransferAmountCiphertext
                },                 
                split_u64, 
                FeeParameters, 
                Role,             
            },         
        },         
        range_proof::RangeProof,         
        sigma_proofs::{
            batched_grouped_ciphertext_validity_proof::BatchedGroupedCiphertext2HandlesValidityProof,             
            ciphertext_commitment_equality_proof::CiphertextCommitmentEqualityProof,             
            fee_proof::FeeSigmaProof,         
        },         
        transcript::TranscriptProtocol,     
    },     
    bytem",Critical,"Solution: Implement a range proof of transfer_amount - fee_to_encrypt or change the constant MAX_FEE_BASIS_POINTS to 9999. Fixed the off-by-one error Added an additional range proof to certify that the transfer fee is at most the transfer amount. Specifically, in the batched range proof condition, I added the condition transfer_amount - transfer_fee is a positive 64-bit number. Since the range proofs are batched, this additional condition does not increase the cost or size of the range proof itself. Removed unchecked arithmetic.",https://github.com/solana-labs/solana/pull/34314/files,High
Sol-090,"The vulnerability pertains to the potential risk of a dishonest prover creating a crafted proof containing more commitments (bit-lengths) than the maximum permissible limit, resulting in incorrect verification without raising any error. This situation may occur as the number of commitments is checked before creating a proof to ensure they do not exceed the limit specified in MAX_COMMITMENTS. However, the verifier does not adequately check the length of the bit_lengths vector to ensure it is less than or equal to MAX_COMMITMENTS before verification.","//! Errors related to proving and verifying proofs.

use {
    crate::{
        encryption::elgamal::ElGamalError,
        range_proof::errors::{
            RangeProofGenerationError,
            RangeProofVerificationError,
        },
        sigma_proofs::errors::*,
    },
    thiserror::Error,
};

#[derive(Error, Clone, Debug, Eq, PartialEq)]
pub enum ProofGenerationError {
    #[error(""not enough funds in account"")]
    NotEnoughFunds,
    #[error(""transfer fee calculation error"")]
    FeeCalculation,
    #[error(""illegal number of commitments"")]
    IllegalCommitmentLength,
    #[error(""illegal amount bit length"")]
    IllegalAmountBitLength,
    #[error(""invalid commitment"")]
    InvalidCommitment,
    #[error(""range proof generation failed"")]
    RangeProof(#[from] RangeProofGenerationError),
    #[error(""unexpected proof length"")]
    ProofLength,
}

#[derive(Error, Clone, Debug, Eq, PartialEq)]
pub enum ProofVerificationError {
    #[error(""range proof verification failed"")]
    RangeProof(#[from] RangeProofVerificationError),
    #[error(""sigma proof verification failed"")]
    SigmaProof(SigmaProofType, SigmaProofVerificationError),
    #[error(""ElGamal ciphertext or public key error"")]
    ElGamal(#[from] ElGamalError),
    #[error(""Invalid proof context"")]
    ProofContext,
} 

#[derive(Clone, Debug, Eq, PartialEq)]
pub enum SigmaProofType {
    EqualityProof,
    ValidityProof,
    ZeroBalanceProof,
    FeeSigmaProof,
    PubkeyValidityProof,
}

#[derive(Error, Clone, Debug, Eq, PartialEq)]
pub enum TranscriptError {
    #[error(""point is the identity"")]
    ValidationError,
}

impl From<EqualityProofVerificationError> for ProofVerificationError {
    fn from(err: EqualityProofVerificationError) -> Self {
        Self::SigmaProof(SigmaProofType::EqualityProof, err.0)
    }
}

impl From<FeeSigmaProofVerificationError> for ProofVerificationError {
    fn from(err: FeeSigmaProofVerificationError) -> Self {
        Self::SigmaProof(SigmaProofType::FeeSigmaProof, err.0)
    }
}

impl From<ZeroBalanceProofVerificationError> for ProofVerificationError {
    fn from(err: ZeroBalanceProofVerificationError) -> Self {
        Self::SigmaProof(SigmaProofType::ZeroBalanceProof, err.0)
    }
}

impl From<ValidityProofVerificationError> for ProofVerificationError {
    fn from(err: ValidityProofVerificationError) -> Self {
        Self::SigmaProof(SigmaProofType::ValidityProof, err.0)
    }
}

impl From<PubkeyValidityProofVerificationError> for ProofVerificationError {
    fn from(err: PubkeyValidityProofVerificationError) -> Self {
        Self::SigmaProof(SigmaProofType::PubkeyValidityProof, err.0)
    }
}","rust
//! Errors related to proving and verifying proofs. 

use {
    crate::{
        encryption::elgamal::ElGamalError,
        range_proof::errors::{RangeProofGenerationError, RangeProofVerificationError},
        sigma_proofs::errors::*,
    },
    thiserror::Error,
};

#[derive(Error, Clone, Debug, Eq, PartialEq)]
pub enum ProofGenerationError {
    #[error(""not enough funds in account"")]
    NotEnoughFunds,

    #[error(""transfer fee calculation error"")]
    FeeCalculation,

    #[error(""illegal number of commitments"")]
    IllegalCommitmentLength,

    #[error(""illegal amount bit length"")]
    IllegalAmountBitLength,

    #[error(""invalid commitment"")]
    InvalidCommitment,

    #[error(""range proof generation failed"")]
    RangeProof(#[from] RangeProofGenerationError),

    #[error(""unexpected proof length"")]
    ProofLength,
}

#[derive(Error, Clone, Debug, Eq, PartialEq)]
pub enum ProofVerificationError {
    #[error(""range proof verification failed"")]
    RangeProof(#[from] RangeProofVerificationError),

    #[error(""sigma proof verification failed"")]
    SigmaProof(SigmaProofType, SigmaProofVerificationError),

    #[error(""ElGamal ciphertext or public key error"")]
    ElGamal(#[from] ElGamalError),

    #[error(""Invalid proof context"")]
    ProofContext,

    #[error(""illegal commitment length"")]
    IllegalCommitmentLength,
}

#[derive(Clone, Debug, Eq, PartialEq)] 
pub enum SigmaProofType {
    EqualityProof,
    ValidityProof,
    ZeroBalanceProof,
    FeeSigmaProof,
    PubkeyValidityProof,
}

#[derive(Error, Clone, Debug, Eq, PartialEq)]
pub enum TranscriptError {
    #[error(""point is the identity"")]
    ValidationError,
}

impl From<EqualityProofVerificationError> for ProofVerificationError {
    fn from(err: EqualityProofVerificationError) -> Self {
        Self::SigmaProof(SigmaProofType::EqualityProof, err.0)
    }
}

impl From<FeeSigmaProofVerificationError> for ProofVerificationError {
    fn from(err: FeeSigmaProofVerificationError) -> Self {
        Self::SigmaProof(SigmaProofType::FeeSigmaProof, err.0)
    }
}

impl From<ZeroBalanceProofVerificationError> for ProofVerificationError {
    fn from(err: ZeroBalanceProofVerificationError) -> Self {
        Self::SigmaProof(SigmaProofType::ZeroBalanceProof, err.0)
    }
}

impl From<ValidityProofVerificationError> for ProofVerificationError {
    fn from(err: ValidityProofVerificationError) -> Self {
        Self::SigmaProof(SigmaProofType::ValidityProof, err.0)
    }
}

impl From<PubkeyValidityProofVerificationError> for ProofVerificationError {
    fn from(err: PubkeyValidityProofVerificationError) -> Self {
        Self::SigmaProof(SigmaProofType::PubkeyValidityProof, err.0)
    }
}",High,"Ensure to verify the length of bit_lengths, such that it is not greater than MAX_COMMITMENTS.",https://github.com/solana-labs/solana/pull/34165/commits/8bb153b550b9df07622506427387a334acc172b7,High
Sol-091,"The ONFT implementation currently lacks explicit size checks for the `compose_msg` parameter in its encoding functions. This omission could potentially lead to the creation of oversized messages, which might cause issues with cross-chain communication and Solana transaction processing. Solana imposes a maximum transaction size limit of 1232 bytes, and exceeding this size can result in failed transactions. ","rust
pub fn encode(
    send_to: [u8; 32], 
    amount_sd: u64, 
    sender: Pubkey, 
    compose_msg: &Option<Vec<u8>>
) -> Vec<u8> {
    if let Some(msg) = compose_msg {
        let mut encoded = Vec::with_capacity(72 + msg.len()); // 32 + 8 + 32
        encoded.extend_from_slice(&send_to);
        encoded.extend_from_slice(&amount_sd.to_be_bytes());
        encoded.extend_from_slice(sender.to_bytes().as_ref());
        encoded.extend_from_slice(&msg);
        encoded
    } else {
        let mut encoded = Vec::with_capacity(40); // 32 + 8
        encoded.extend_from_slice(&send_to);
        encoded.extend_from_slice(&amount_sd.to_be_bytes());
        encoded
    }
}","rust
pub fn encode(
    send_to: [u8; 32],
    amount_sd: u64,
    sender: Pubkey,
    compose_msg: &Option<Vec<u8>>,
) -> Result<Vec<u8>, OFTError> {
    if let Some(msg) = compose_msg {
        if msg.len() > MAX_MSG_SIZE {
            return Err(OFTError::MessageTooLarge);
        }
        
        let mut encoded = Vec::with_capacity(72 + msg.len());
        
        encoded.extend_from_slice(&send_to);
        encoded.extend_from_slice(&amount_sd.to_be_bytes());
        encoded.extend_from_slice(sender.to_bytes().as_ref());
        encoded.extend_from_slice(&msg);
        
        Ok(encoded)
    } else {
        let mut encoded = Vec::with_capacity(40);
        
        encoded.extend_from_slice(&send_to);
        encoded.extend_from_slice(&amount_sd.to_be_bytes());
        
        Ok(encoded)
    }
}",Medium,Implement a maximum size limit for the `compose_msg` parameter to avoid oversized messages. Add a constant to enforce the limit during message composition.,https://solodit.cyfrin.io/issues/m-03-missing-size-checks-for-compose_msg-can-lead-to-oversized-messages-and-transaction-failures-shieldify-none-kanpaipandas-lzapponft-markdown,High
Sol-092,"In the swap function's buy tokens validation, the code only checks if the user's total SOL balance is sufficient for the swap amount, without considering rent exemption.This check uses `get_lamports()` which returns the total balance including the rent exemption amount. The transaction will succeed even if it depletes the account below rent exemption, causing the account to:* Enter a non-rent-exempt state * Get charged rent over time by the Solana runtime, eventually be purged if the balance is fully depleted.  ","rust
require!(
    ctx.accounts.user.get_lamports() >= exact_in_amount,
    ContractError::InsufficientUserSOL,
);","rust
let rent = Rent::get()?;

let min_rent = rent.minimum_balance(0); 
// 0 for data size since this is just a native SOL account

require!(
    ctx.accounts.user.get_lamports() >= exact_in_amount.checked_add(min_rent).unwrap(),
    ContractError::InsufficientUserSOL,
);",Low,Add a more comprehensive balance check that accounts for rent exemption:,https://solodit.cyfrin.io/issues/l-01-insufficient-sol-balance-check-ignores-rent-exemption-pashov-audit-group-none-pumpscience_2024-12-24-markdown_,Medium
Sol-093,There are no checks to ensure that the `deposit_token` matches the `allowed_token` in the `solana_vault::deposit` function. This allows an attacker to deposit any tokens and get minted USDC on the other chain. The system assumes that an allowed token is deposited every time and this assumption is wrong.,"rust
use anchor_lang::prelude::*;
use anchor_spl::{
    associated_token::AssociatedToken,
    token::{transfer, Mint, Token, TokenAccount, Transfer},
};
use oapp::endpoint::{instructions::SendParams as EndpointSendParams, MessagingReceipt};
use crate::instructions::{
    LzMessage, MsgType, VaultDepositParams, BROKER_SEED, ENFORCED_OPTIONS_SEED, OAPP_SEED, PEER_SEED,
    TOKEN_SEED, VAULT_AUTHORITY_SEED,
};
use crate::errors::VaultError;
use crate::events::{OAppSent, VaultDeposited};
use crate::state::{
    AllowedBroker, AllowedToken, EnforcedOptions, OAppConfig, Peer, VaultAuthority,
};

#[derive(Accounts)]
#[instruction(deposit_params: DepositParams, oapp_params: OAppSendParams)]
pub struct Deposit<'info> {
    #[account(mut)]
    pub user: Signer<'info>,
    #[account(
        mut,
        associated_token::mint = deposit_token,
        associated_token::authority = user
    )]
    pub user_token_account: Box<Account<'info, TokenAccount>>,
    #[account(mut, seeds = [VAULT_AUTHORITY_SEED], bump = vault_authority.bump)]
    pub vault_authority: Box<Account<'info, VaultAuthority>>,
    #[account(
        init_if_needed,
        payer = user,
        associated_token::mint = deposit_token,
        associated_token::authority = vault_authority
    )]
    pub vault_token_account: Box<Account<'info, TokenAccount>>,
    #[account()]
    pub deposit_token: Box<Account<'info, Mint>>,
}
// The code has been split here for readability

impl<'info> Deposit<'info> {
    pub fn transfer_token_ctx(&self) -> CpiContext<'_, '_, '_, 'info, Transfer<'info>> {
        let cpi_accounts = Transfer {
            from: self.user_token_account.to_account_info(),
            to: self.vault_token_account.to_account_info(),
            authority: self.user.to_account_info(),
        };

        let cpi_program = self.token_program.to_account_info();
        CpiContext::new(cpi_program, cpi_accounts)
    }

    pub fn apply(
        ctx: &mut Context<'_, '_, '_, 'info, Deposit<'info>>,
        deposit_params: &DepositParams,
        oapp_params: &OAppSendParams,
    ) -> Result<MessagingReceipt> {
        transfer(
            ctx.accounts.transfer_token_ctx(),
            deposit_params.token_amount as u128,
        )?;

        msg!(""User deposited : {}"", deposit_params.token_amount);
        ctx.accounts.vault_authority.deposit_nonce += 1;

        let vault_deposit_params = VaultDepositParams {
            account_id: deposit_params.account_id,
            broker_hash: deposit_params.broker_hash,
            user_address: deposit_params.user_address,
            src_chain_id: ctx.accounts.vault_authority.sol_chain_id,
            token_amount: deposit_params.token_amount as u128,
            src_chain_deposit_nonce: ctx.accounts.vault_authority.deposit_nonce,
        };

        emit!(Into::<VaultDeposited>::into(vault_deposit_params.clone()));

        let seeds = &[OAPP_SEED, &[ctx.accounts.oapp_config.bump]];
        let deposit_msg = VaultDepositParams::encode(&vault_deposit_params);
        let lz_message = LzMessage::encode(&LzMessage {
            msg_type: MsgType::Deposit as u8,
            payload: deposit_msg,
        });

        let options =
            EnforcedOptions::get_enforced_options(&ctx.accounts.enforced_options, &None);

        let endpoint_send_params = EndpointSendParams {
            dst_eid: ctx.accounts.vault_authority.dst_eid,
            receiver: ctx.accounts.peer.address,
            message: lz_message,
            options: options,
            native_fee: oapp_params.native_fee,
            lz_token_fee: oapp_params.lz_token_fee,
        };

        let receipt = oapp::endpoint_cpi::send(
            ctx.accounts.oapp_config.endpoint_program,
            ctx.accounts.oapp_config.key(),
            ctx.remaining_accounts,
            seeds,
            endpoint_send_params,
        )?;

        emit!(OAppSent {
            guid: receipt.guid,
            dst_eid: ctx.accounts.vault_authority.dst_eid,
        });

        Ok(receipt)
    }
}

#[derive(Debug, Clone, AnchorSerialize, AnchorDeserialize)]
pub struct DepositParams {
    pub account_id: [u8; 32],
    pub broker_hash: [u8; 32],
    pub token_hash: [u8; 32],
    pub user_address: [u8; 32],
    pub token_amount: u64,
}

#[derive(Clone, AnchorSerialize, AnchorDeserialize)]
pub struct OAppSendParams {
    pub native_fee: u64,
    pub lz_token_fee: u64,
}","rust
use anchor_lang::prelude::*;
use anchor_spl::{
    associated_token::AssociatedToken,
    token::{
        transfer, 
        Mint, 
        Token, 
        TokenAccount, 
        Transfer
    }, 
};
use oapp::endpoint::{
    instructions::SendParams as EndpointSendParams, 
    MessagingReceipt
};
use crate::instructions::{
    LzMessage, 
    MsgType, 
    VaultDepositParams, 
    BROKER_SEED, 
    ENFORCED_OPTIONS_SEED, 
    OAPP_SEED, 
    PEER_SEED, 
    TOKEN_SEED, 
    VAULT_AUTHORITY_SEED,
};
use crate::errors::VaultError;
use crate::events::{
    OAppSent, 
    VaultDeposited
};
use crate::state::{
    AllowedBroker, 
    AllowedToken, 
    EnforcedOptions, 
    OAppConfig, 
    Peer, 
    VaultAuthority,
};

#[derive(Accounts)]
#[instruction(deposit_params: DepositParams, oapp_params: OAppSendParams)]
pub struct Deposit<'info> {
    #[account(mut)]
    pub user: Signer<'info>,
    #[account(
        mut, 
        associated_token::mint = deposit_token,
        associated_token::authority = user
    )]
    pub user_token_account: Box<Account<'info, TokenAccount>>,
    #[account(
        mut, 
        seeds = [VAULT_AUTHORITY_SEED],
        bump = vault_authority.bump
    )]
    pub vault_authority: Box<Account<'info, VaultAuthority>>,
    #[account(
        init_if_needed, 
        payer = user,
        associated_token::mint = deposit_token,
        associated_token::authority = vault_authority
    )]
    pub vault_token_account: Box<Account<'info, TokenAccount>>,
    #[account(
        constraint = deposit_token.key() == allowed_token.mint_account @ VaultError::TokenNotAllowed,
        mint::token_program = token_program
    )]
    pub deposit_token: Box<Account<'info, Mint>>,
    #[account(
        constraints = [
            peers::Src => oapp_config,
            peers::Dst => vault_authority
        ], 
        mut
    )]
    pub peer: Box<Account<'info, Peer>>,
    #[account(
        seeds = [ENFORCED_OPTIONS_SEED, &oapp_config.key().to_bytes(), &vault_authority.dst_eid.to_be_bytes()],
        bump = enforced_options.bump
    )]
    pub enforced_options: Box<Account<'info, EnforcedOptions>>,
    #[account(
         seeds=[OAPP_SEED],
         bump=oapp_config.bump
    )]
    pub oapp_config: Box<Account<'info, OAppConfig>>,
    #[account(
         seeds=[BROKER_SEED, deposit_params.broker_hash.as_ref()],
         bump=allowed_broker.bump,
         constraint = allowed_broker.allowed == true @ VaultError::BrokerNotAllowed 
    )]
    pub allowed_broker: Box<Account<'info, AllowedBroker>>,
    #[account(
         seeds=[TOKEN_SEED, deposit_params.token_hash.as_ref()],
         bump=allowed_token.bump,
         constraint = allowed_token.allowed == true @ VaultError::TokenNotAllowed 
    )]
    pub allowed_token: Box<Account<'info, AllowedToken>>,
    pub token_program: Program<'info, Token>,
    pub associated_token_program: Program<'info, AssociatedToken>,
    pub system_program: Program<'info, System>,
}

impl<'info> Deposit<'info> {
    pub fn transfer_token_ctx(&self) -> CpiContext<'_, '_, '_, 'info, Transfer<'info>> {
        let cpi_accounts = Transfer {
            from: self.user_token_account.to_account_info(),
            to: self.vault_token_account.to_account_info(),
            authority: self.user.to_account_info(),
        };

        let cpi_program = self.token_program.to_account_info();

        CpiContext::new(cpi_program, cpi_accounts)
    }

    pub fn apply(
        ctx: &mut Context<'_, '_, '_, 'info, Deposit<'info>>,
        deposit_params: &DepositParams,
        oapp_params: &OAppSendParams,
    ) -> Result<MessagingReceipt> {
        transfer(
            ctx.accounts.transfer_token_ctx(),
            deposit_params.token_amount as u128, // should be u64 here
        )?;
        msg!(""User deposited : {}"", deposit_params.token_amount);

        Expand Down
        ctx.accounts.vault_authority.deposit_nonce += 1;

        let vault_deposit_params = VaultDepositParams {
            account_id: deposit_params.account_id,
            broker_hash: deposit_params.broker_hash,
            user_address: deposit_params.user_address,
            // token_hash: deposit_params.token_hash,
            src_chain_id: ctx.accounts.vault_authority.sol_chain_id,
            token_amount: deposit_params.token_amount as u128,
            src_chain_deposit_nonce: ctx.accounts.vault_authority.deposit_nonce,
        };

        emit!(Into::<VaultDeposited>::into(vault_deposit_params.clone()));

        let seeds = &[OAPP_SEED, &[ctx.accounts.oapp_config.bump]];

        let deposit_msg = VaultDepositParams::encode(&vault_deposit_params);

        let lz_message = LzMessage::encode(&LzMessage {
            msg_type: MsgType::Deposit as u8,
            payload: deposit_msg,
        });

        let options = EnforcedOptions::get_enforced_options(&ctx.accounts.enforced_options, &None);

        let endpoint_send_params = EndpointSendParams {
            dst_eid: ctx.accounts.vault_authority.dst_eid,
            receiver: ctx.accounts.peer.address,
            message: lz_message,
            options: options,
            native_fee: oapp_params.native_fee,
            lz_token_fee: oapp_params.lz_token_fee,
        };

        let receipt = oapp::endpoint_cpi::send(
            ctx.accounts.oapp_config.endpoint_program,
            ctx.accounts.oapp_config.key(),
            ctx.remaining_accounts,
            seeds,
            endpoint_send_params,
        )?;

        emit!(OAppSent {
            guid: receipt.guid,
            dst_eid: ctx.accounts.vault_authority.dst_eid,
        });

        Ok(receipt)
    }
}

#[derive(Debug, Clone, AnchorSerialize, AnchorDeserialize)]
pub struct DepositParams {
    pub account_id: [u8; 32],
    pub broker_hash: [u8; 32],
    pub token_hash: [u8; 32],
    pub user_address: [u8; 32],
    pub token_amount: u64,
}

#[derive(Clone, AnchorSerialize, AnchorDeserialize)]
pub struct OAppSendParams {
    pub native_fee: u64,
    pub lz_token_fee: u64,
}",High,"Add a new `constraint` in `deposit.rs::Deposit` struct. Update the `deposit_token` account definition in `deposit.rs` to include a `constraint` that ensures the `deposit_token` mint matches the `allowed_token.mint_account`.
",https://solodit.cyfrin.io/issues/h-1-h-1-sherlock-orderly-solana-vault-contract-git,High
Sol-094,"A malicious user can withdrawals another user's money. A shared vault authority signing mechanism will cause unauthorized withdrawals for users, as User A can withdraw funds belonging to User B. In the OAppLzReceive, the vault_authority_seeds are shared across all users, allowing any user with valid withdrawal parameters to use the same PDA signing authority. As a result, any valid withdrawal request can be signed by the vault without distinguishing which user is performing the withdrawal. Also, there is no check that the wallet receiving the funds belongs to the same user for whom the withdrawal request was initiated. The system only checks that the withdrawal message comes from a valid sender (peer.address == params.sender), but does not verify that the user account corresponds to the sender.","rust
pub fn apply(
    ctx: &mut Context<OAppLzReceive>, 
    params: &OAppLzReceiveParams
) -> Result<()> 
{","rust
pub fn apply(
  ctx: &mut Context<OAppLzReceive>, 
  params: &OAppLzReceiveParams
) -> Result<()> {
}",High,A check was added to oapp_lz_receive() that validates that the recipient of the withdrawal is the receiver specified in the withdrawal payload.,https://github.com/OrderlyNetwork/solana-vault/commit/a9f56db5e63562df9eb6a39803f3df12b7959032,High
Sol-095,"There is a potential vulnerability related to the settlement instructions for auctions involving the Wormhole CCTP bridge. The code assumes that the total transferable amount equals order.amount_in retrieved from the fastVAA. However, during the settlement process, it does not verify whether this amount actually matches the funds in the prepared_custody_token account. Before settling the PrepareOrderResponse, if a small amount of tokens is transferred to the prepared_custody_token account, the settlement instruction fails when attempting to close the prepared_custody_token account via token::close_account. This failure occurs because only order.amount_in is transferred from the account instead of the total balance, leaving non-zero funds in the account and causing the closure to fail.","rust
mod cctp; 
pub use cctp::*; 
mod local; 
pub use local::*; 

use crate::{
    composite::*,
    error::MatchingEngineError,
    state::{Auction, AuctionStatus, PreparedOrderResponse},
}; 

use anchor_lang::prelude::*; 
use anchor_spl::token; 
use common::messages::Fill; 

struct SettleNoneAndPrepareFill<'ctx, 'info> {
    prepared_order_response: &'ctx mut Account<'info, PreparedOrderResponse>,
    prepared_custody_token: &'ctx UncheckedAccount<'info>,
    auction: &'ctx mut Account<'info, Auction>,
    fee_recipient_token: &'ctx Account<'info, token::TokenAccount>,
    custodian: &'ctx CheckedCustodian<'info>,
    token_program: &'ctx Program<'info, token::Token>,
}

struct SettledNone {
    user_amount: u64,
    fill: Fill,
}

fn settle_none_and_prepare_fill(
    accounts: SettleNoneAndPrepareFill<'_, '_>,
    auction_bump_seed: u8,
) -> Result<SettledNone> {
    let SettleNoneAndPrepareFill {
        prepared_order_response,
        prepared_custody_token,
        auction,
        fee_recipient_token,
        custodian,
        token_program,
    } = accounts;

    let prepared_order_response_signer_seeds = &[
        PreparedOrderResponse::SEED_PREFIX,
        prepared_order_response.fast_vaa_hash.as_ref(),
        &[prepared_order_response.bump],
    ];

    let fee = prepared_order_response
        .base_fee
        .saturating_add(prepared_order_response.init_auction_fee);
    
    token::transfer(
        CpiContext::new_with_signer(
            token_program.to_account_info(),
            token::Transfer {
                from: prepared_custody_token.to_account_info(),
                to: fee_recipient_token.to_account_info(),
                authority: prepared_order_response.to_account_info(),
            },
            &[prepared_order_response_signer_seeds],
        ),
        fee,
    )?;

    token::set_authority(
        CpiContext::new_with_signer(
            token_program.to_account_info(),
            token::SetAuthority {
                current_authority: prepared_order_response.to_account_info(),
                account_or_mint: prepared_custody_token.to_account_info(),
            },
            &[prepared_order_response_signer_seeds],
        ),
        token::spl_token::instruction::AuthorityType::AccountOwner,
        Some(custodian.key()),
    )?;

    auction.set_inner(Auction {
        bump: auction_bump_seed,
        vaa_hash: prepared_order_response.fast_vaa_hash,
        vaa_timestamp: prepared_order_response.fast_vaa_timestamp,
        target_protocol: prepared_order_response.to_endpoint.protocol,
        status: AuctionStatus::Settled {
            fee,
            total_penalty: None,
        },
        info: None,
    });

    emit!(crate::events::AuctionSettled {
        auction: auction.key(),
        best_offer_token: Default::default(),
        token_balance_after: fee_recipient_token.amount.saturating_add(fee),
    });

    Ok(SettledNone {
        user_amount: prepared_order_response.amount_in.saturating_sub(fee),
        fill: Fill {
            source_chain: prepared_order_response.source_chain,
            order_sender: prepared_order_response.sender,
            redeemer: prepared_order_response.redeemer,
            redeemer_message: std::mem::take(&mut prepared_order_response.redeemer_message)
                .try_into()
                .map_err(|_| MatchingEngineError::RedeemerMessageTooLarge)?,
        },
    })
}","rust
mod cctp;
pub use cctp::*;
mod local;
pub use local::*;

use crate::{
    composite::*,
    error::MatchingEngineError,
    state::{
        Auction, 
        AuctionStatus, 
        PreparedOrderResponse},
};

use anchor_lang::prelude::*;
use anchor_spl::token;
use common::messages::Fill;

struct SettleNoneAndPrepareFill<'ctx, 'info> {
    prepared_order_response: &'ctx mut Account<'info, PreparedOrderResponse>,
    prepared_custody_token: &'ctx Account<'info, token::TokenAccount>,
    auction: &'ctx mut Account<'info, Auction>,
    fee_recipient_token: &'ctx Account<'info, token::TokenAccount>,
    custodian: &'ctx CheckedCustodian<'info>,
    token_program: &'ctx Program<'info, token::Token>,
}

struct SettledNone {
    user_amount: u64,
    fill: Fill,
}

fn settle_none_and_prepare_fill(
    accounts: SettleNoneAndPrepareFill<'_, '_>, 
    auction_bump_seed: u8,
) -> Result<SettledNone> {
    let SettleNoneAndPrepareFill {
        prepared_order_response, 
        prepared_custody_token, 
        auction, 
        fee_recipient_token, 
        custodian, 
        token_program,
    } = accounts;
    
    let prepared_order_response_signer_seeds = &[
        PreparedOrderResponse::SEED_PREFIX, 
        prepared_order_response.fast_vaa_hash.as_ref(), 
        &[prepared_order_response.bump],
    ];
    
    let fee = prepared_order_response
        .base_fee
        .saturating_add(prepared_order_response.init_auction_fee);
    
    token::transfer(
        CpiContext::new_with_signer(
            token_program.to_account_info(), 
            token::Transfer {
                from: prepared_custody_token.to_account_info(),
                to: fee_recipient_token.to_account_info(),
                authority: prepared_order_response.to_account_info(),
            },
            &[prepared_order_response_signer_seeds],
        ), 
        fee,
    )?;
    token::set_authority(
        CpiContext::new_with_signer(
            token_program.to_account_info(), 
            token::SetAuthority {
                current_authority: prepared_order_response.to_account_info(),
                account_or_mint: prepared_custody_token.to_account_info(),
            },
            &[prepared_order_response_signer_seeds],
        ), 
        token::spl_token::instruction::AuthorityType::AccountOwner, 
        Some(custodian.key()),
    )?;
    
    auction.set_inner(Auction {
        bump: auction_bump_seed,
        vaa_hash: prepared_order_response.fast_vaa_hash,
        vaa_timestamp: prepared_order_response.fast_vaa_timestamp,
        target_protocol: prepared_order_response.to_endpoint.protocol,
        status: AuctionStatus::Settled {
            fee, 
            total_penalty: None,
        },
        info: None,
    });
    
    emit!(crate::events::AuctionSettled {
        auction: auction.key(),
        best_offer_token: Default::default(),
        token_balance_after: fee_recipient_token.amount.saturating_add(fee),
    });
    
    Ok(SettledNone {
        user_amount: prepared_custody_token.amount.saturating_sub(fee),
        fill: Fill {
            source_chain: prepared_order_response.source_chain,
            order_sender: prepared_order_response.sender,
            redeemer: prepared_order_response.redeemer,
            redeemer_message: std::mem::take(&mut prepared_order_response.redeemer_message)
                .try_into()
                .map_err(|_| MatchingEngineError::RedeemerMessageTooLarge)?,
        },
    })
}",High,"Instead of relying solely on order.amount_in from the fastVAA, the code should use the actual token balance in the prepared_custody_token account before attempting to close it. This ensures that all funds are accounted for, preventing non-zero balance errors when calling token::close_account.",https://github.com/wormhole-foundation/example-liquidity-layer/commit/307cc2844b6aaf33d2df11ffd7821292114536a9,High
Sol-096,"There is a potential vulnerability related to the settlement instructions for auctions involving the Wormhole CCTP bridge. The code assumes that the total transferable amount equals order.amount_in retrieved from the fastVAA. However, during the settlement process, it does not verify whether this amount actually matches the funds in the prepared_custody_token account. Before settling the PrepareOrderResponse, if a small amount of tokens is transferred to the prepared_custody_token account, the settlement instruction fails when attempting to close the prepared_custody_token account via token::close_account. This failure occurs because only order.amount_in is transferred from the account instead of the total balance, leaving non-zero funds in the account and causing the closure to fail.","rust
use std::ops::{Deref, DerefMut}; 

use crate::{ 
    error::MatchingEngineError, 
    state::{
        Auction, 
        AuctionStatus, 
        Custodian, 
        FastFillSequencer, 
        MessageProtocol, 
        PreparedOrderResponse, 
        ReservedFastFillSequence, 
        RouterEndpoint, 
    }, 
    utils::{self, VaaDigest}, 
}; 

use anchor_lang::prelude::*; 
use anchor_spl::token; 

use common::{ 
    admin::utils::{
        assistant::only_authorized, 
        ownable::only_owner
    }, 
    messages::raw::LiquidityLayerMessage, 
    wormhole_cctp_solana::{
        cctp::{
            message_transmitter_program, 
            token_messenger_minter_program
        }, 
        wormhole::{
            core_bridge_program, 
            VaaAccount
        }, 
    }, 
};

#[derive(Accounts)]
pub struct Usdc<'info> {
    /// CHECK: This address must equal [USDC_MINT](common::USDC_MINT).
    #[account(address = common::USDC_MINT)]
    pub mint: UncheckedAccount<'info>,
}

impl<'info> Deref for Usdc<'info> {
    type Target = UncheckedAccount<'info>;

    fn deref(&self) -> &Self::Target {
        &self.mint
    }
}

/// Mint recipient token account, which is encoded as the mint recipient in the CCTP message.
/// The CCTP Token Messenger Minter program will transfer the amount encoded in the CCTP message
/// from its custody account to this account.
///
/// CHECK: Mutable. Seeds must be \[""custody""\].
///
/// NOTE: This account must be encoded as the mint recipient in the CCTP message.
#[derive(Accounts)]
pub struct CctpMintRecipientMut<'info> {
    #[account( mut, address = crate::CCTP_MINT_RECIPIENT )]
    pub mint_recipient: Box<Account<'info, token::TokenAccount>>,
}

impl<'info> Deref for CctpMintRecipientMut<'info> {
    type Target = Account<'info, token::TokenAccount>;

    fn deref(&self) -> &Self::Target {
        &self.mint_recipient
    }
}

#[derive(Accounts)]
pub struct LiquidityLayerVaa<'info> {
    /// CHECK: This VAA account must be a posted VAA from the Wormhole Core Bridge program.
    #[account( constraint = {
        // NOTE: This load performs an owner check.
        let vaa = VaaAccount::load(&vaa)?;

        // Is it a legitimate LL message?
        LiquidityLayerMessage::try_from(vaa.payload())
        .map_err(|_| MatchingEngineError::InvalidVaa)?;

        // Done.
        true
    })]
    pub vaa: UncheckedAccount<'info>,
}

impl<'info> LiquidityLayerVaa<'info> {
    pub fn load_unchecked(&self) -> VaaAccount<'_> {
        VaaAccount::load_unchecked(self)
    }
}

impl<'info> Deref for LiquidityLayerVaa<'info> {
    type Target = UncheckedAccount<'info>;

    fn deref(&self) -> &Self::Target {
        &self.vaa
    }
}

#[derive(Accounts)]
pub struct CheckedCustodian<'info> {
    #[account(
       seeds = [Custodian::SEED_PREFIX],
       bump = Custodian::BUMP,
    )]
    pub custodian: Account<'info, Custodian>,
}

impl<'info> Deref for CheckedCustodian<'info> {
    type Target = Account<'info, Custodian>;

    fn deref(&self) -> &Self::Target {
        &self.custodian
    }
}

#[derive(Accounts)]
pub struct OwnerOnly<'info> {
    #[account(
       constraint = only_owner(
          &custodian,
          &owner,
          error!(MatchingEngineError::OwnerOnly)
       )?
    )]
    pub owner: Signer<'info>,
    pub custodian: CheckedCustodian<'info>,
}

...

// The rest of the code follows the same formatting","rust
use std::ops::{Deref, DerefMut}; 
use crate::{ 
    error::MatchingEngineError, 
    state::{ 
        Auction, 
        AuctionStatus, 
        Custodian, 
        FastFillSequencer, 
        MessageProtocol, 
        PreparedOrderResponse, 
        ReservedFastFillSequence, 
        RouterEndpoint, 
    }, 
    utils::{self, VaaDigest}, 
}; 
use anchor_lang::prelude::*; 
use anchor_spl::token; 
use common::{ 
    admin::utils::{assistant::only_authorized, ownable::only_owner}, 
    messages::raw::LiquidityLayerMessage, 
    wormhole_cctp_solana::{ 
        cctp::{message_transmitter_program, token_messenger_minter_program},
        wormhole::{core_bridge_program, VaaAccount},
    },
};
 
#[derive(Accounts)] 
pub struct Usdc<'info> { 
    /// CHECK: This address must equal [USDC_MINT](common::USDC_MINT).
    #[account(address = common::USDC_MINT)] 
    pub mint: UncheckedAccount<'info>, 
} 

impl<'info> Deref for Usdc<'info> { 
    type Target = UncheckedAccount<'info>; 
    fn deref(&self) -> &Self::Target { 
        &self.mint 
    } 
} 

/// Mint recipient token account, which is encoded as the mint recipient in the CCTP message.
/// The CCTP Token Messenger Minter program will transfer the amount encoded in the CCTP message
/// from its custody account to this account.
///
/// CHECK: Mutable. Seeds must be \[""custody""\].
///
/// NOTE: This account must be encoded as the mint recipient in the CCTP message.
#[derive(Accounts)] 
pub struct CctpMintRecipientMut<'info> { 
    #[account( mut, address = crate::CCTP_MINT_RECIPIENT )]
    pub mint_recipient: Box<Account<'info, token::TokenAccount>>, 
} 

impl<'info> Deref for CctpMintRecipientMut<'info> { 
    type Target = Account<'info, token::TokenAccount>; 
    fn deref(&self) -> &Self::Target { 
        &self.mint_recipient 
    } 
} 

#[derive(Accounts)] 
pub struct LiquidityLayerVaa<'info> { 
    /// CHECK: This VAA account must be a posted VAA from the Wormhole Core Bridge program.
    #[account( 
        constraint = { 
            // NOTE: This load performs an owner check.
            let vaa = VaaAccount::load(&vaa)?; 
            // Is it a legitimate LL message?
            LiquidityLayerMessage::try_from(vaa.payload())
            .map_err(|_| MatchingEngineError::InvalidVaa)?; 
            // Done.
            true 
        } 
    )]
    pub vaa: UncheckedAccount<'info>, 
} 

impl<'info> LiquidityLayerVaa<'info> { 
    pub fn load_unchecked(&self) -> VaaAccount<'_> { 
        VaaAccount::load_unchecked(self) 
    } 
} 

impl<'info> Deref for LiquidityLayerVaa<'info> { 
    type Target = UncheckedAccount<'info>; 
    fn deref(&self) -> &Self::Target { 
        &self.vaa 
    } 
}

.
.
. 
(rest of formatting is omitted due to character limitation)",High,"Implement checks to ensure that the account is a valid token account and explicitly verify the mint for the token accounts, rather than relying solely on data_is_empty: pub fn checked_deserialize_token_account( acc_info: &AccountInfo, expected_mint: &Pubkey, ) -> Option<token::TokenAccount> { if acc_info.owner != &token::ID { None } else { let data = acc_info.try_borrow_data().ok()?; token::TokenAccount::try_deserialize(&mut &data[..]) .ok() .filter(|token_data| &token_data.mint == expected_mint && !token_data.is_frozen()) } }",https://github.com/wormhole-foundation/example-liquidity-layer/pull/188/files,High
Sol-097,"There is a potential vulnerability related to the settlement instructions for auctions involving the Wormhole CCTP bridge. The code assumes that the total transferable amount equals order.amount_in retrieved from the fastVAA. However, during the settlement process, it does not verify whether this amount actually matches the funds in the prepared_custody_token account. Before settling the PrepareOrderResponse, if a small amount of tokens is transferred to the prepared_custody_token account, the settlement instruction fails when attempting to close the prepared_custody_token account via token::close_account. This failure occurs because only order.amount_in is transferred from the account instead of the total balance, leaving non-zero funds in the account and causing the closure to fail.","rust
mod cctp;
pub use cctp::*;
mod local;
pub use local::*;

use crate::{
    composite::*,
    error::MatchingEngineError,
    state::{Auction, AuctionStatus, MessageProtocol},
    utils::{self, auction::DepositPenalty},
};
use anchor_lang::prelude::*;
use anchor_spl::token;
use common::messages::{
    raw::{LiquidityLayerMessage, MessageToVec},
    Fill,
};

struct PrepareFastExecution<'ctx, 'info> {
    execute_order: &'ctx mut ExecuteOrder<'info>,
    custodian: &'ctx CheckedCustodian<'info>,
    token_program: &'ctx Program<'info, token::Token>,
}

struct PreparedOrderExecution<'info> {
    pub user_amount: u64,
    pub fill: Fill,
    pub beneficiary: Option<AccountInfo<'info>>,
}

fn prepare_order_execution<'info>(
    accounts: PrepareFastExecution<'_, 'info>,
) -> Result<PreparedOrderExecution<'info>> {
    let PrepareFastExecution {
        execute_order,
        custodian,
        token_program,
    } = accounts;

    let auction = &mut execute_order.active_auction.auction;
    let fast_vaa = &execute_order.fast_vaa;
    let custody_token = &execute_order.active_auction.custody_token;
    let config = &execute_order.active_auction.config;
    let executor_token = &execute_order.executor_token;
    let best_offer_token = &execute_order.active_auction.best_offer_token;
    let initial_offer_token = &execute_order.initial_offer_token;
    let initial_participant = &execute_order.initial_participant;

    let vaa = fast_vaa.load_unchecked();
    let order = LiquidityLayerMessage::try_from(vaa.payload())
        .unwrap()
        .to_fast_market_order_unchecked();

    let (user_amount, new_status, beneficiary) = {
        let auction_info = auction.info.as_ref().unwrap();
        let current_slot = Clock::get().unwrap().slot;

        // We extend the grace period for locally executed orders. Reserving a sequence number for
        // the fast fill will most likely require an additional transaction, so this buffer allows
        // the best offer participant to perform his duty without the risk of getting slashed by
        // another executor.
        let additional_grace_period = match auction.target_protocol {
            MessageProtocol::Local { .. } => {
                crate::EXECUTE_FAST_ORDER_LOCAL_ADDITIONAL_GRACE_PERIOD.into()
            }
            _ => None,
        };

        let DepositPenalty { penalty, user_reward, } = utils::auction::compute_deposit_penalty(
            config,
            auction_info,
            current_slot,
            additional_grace_period,
        );

        let init_auction_fee = order.init_auction_fee();

        let user_amount = auction_info
            .amount_in
            .saturating_sub(auction_info.offer_price)
            .saturating_sub(init_auction_fee)
            .saturating_add(user_reward);

        // Keep track of the remaining amount in the custody token account. Whatever remains will go
        // to the executor.
        let mut remaining_custodied_amount = custody_token.amount.saturating_sub(user_amount);

        // Offer price + security deposit was checked in placing the initial offer.
        let mut deposit_and_fee = auction_info
            .offer_price
            .saturating_add(auction_info.security_deposit)
            .saturating_sub(user_reward);

        let auction_signer_seeds = &[
            Auction::SEED_PREFIX,
            auction.vaa_hash.as_ref(),
            &[auction.bump],
        ];

        let penalized = penalty > 0;

        if penalized && best_offer_token.key() != executor_token.key() {
            deposit_and_fee = deposit_and_fee.saturating_sub(penalty);
        }

        let mut beneficiary = None;

        // If the initial offer token account doesn't exist anymore, we have nowhere to send the
        // init auction fee. The executor will get these funds instead.
        if !initial_offer_token.data_is_empty() {
            // Deserialize to token account to find owner. We know this is a legitimate token
            // account, so it is safe to borrow and unwrap here.
            {
                let mut acc_data: &[_] = &initial_offer_token.data.borrow();
                let token_data = token::TokenAccount::try_deserialize(&mut acc_data).unwrap();
                require_keys_eq!(
                    token_data.owner,
                    initial_participant.key(),
                    ErrorCode::ConstraintTokenOwner
                );

                beneficiary.replace(initial_participant.to_account_info());
            }

            if best_offer_token.key() != initial_offer_token.key() {
                // Pay the auction initiator their fee.
                token::transfer(
                    CpiContext::new_with_signer(
                        token_program.to_account_info(),
                        anchor_spl::token::Transfer {
                            from: custody_token.to_account_info(),
                            to: initial_offer_token.to_account_info(),
                            authority: auction.to_account_info(),
                        },
                        &[auction_signer_seeds],
                    ),
                    init_auction_fee,
                )?;

                // Because the initial offer token was paid this fee, we account for it here.
                remaining_custodied_amount = remaining_custodied_amount.saturating_sub(init_auction_fee);
            } else {
                // Add it to the reimbursement.
                deposit_and_fee = deposit_and_fee
                    .checked_add(init_auction_fee)
                    .ok_or(MatchingEngineError::U64Overflow)?;
            }
        }

        // Return the security deposit and the fee to the highest bidder.
        if best_offer_token.key() == executor_token.key() {
            // If the best offer token is equal to the executor token, just send whatever remains in the
            // custody token account.
            token::transfer(
                CpiContext::new_with_signer(
                    token_program.to_account_info(),
                    anchor_spl::token::Transfer {
                        from: custody_token.to_account_info(),
                        to: best_offer_token.to_account_info(),
                        authority: auction.to_account_info(),
                    },
                    &[auction_signer_seeds],
                ),
                remaining_custodied_amount,
            )?;
        } else {
            if !best_offer_token.data_is_empty() {
                token::transfer(
                    CpiContext::new_with_signer(
                        token_program.to_account_info(),
                        anchor_spl::token::Transfer {
                            from: custody_token.to_account_info(),
                            to: best_offer_token.to_account_info(),
                            authority: auction.to_account_info(),
                        },
                        &[auction_signer_seeds],
                    ),
                    deposit_and_fee,
                )?;

                remaining_custodied_amount = remaining_custodied_amount.saturating_sub(deposit_and_fee);
            }

            // And pay the executor whatever remains in the auction custody token account.
            if remaining_custodied_amount > 0 {
                token::transfer(
                    CpiContext::new_with_signer(
                        token_program.to_account_info(),
                        anchor_spl::token::Transfer {
                            from: custody_token.to_account_info(),
                            to: executor_token.to_account_info(),
                            authority: auction.to_account_info(),
                        },
                        &[auction_signer_seeds],
                    ),
                    remaining_custodied_amount,
                )?;
            }
        }

        // Set the authority of the custody token account to the custodian. He will take over from
        // here.
        token::set_authority(
            CpiContext::new_with_signer(
                token_program.to_account_info(),
                token::SetAuthority {
                    current_authority: auction.to_account_info(),
                    account_or_mint: custody_token.to_account_info(),
                },
                &[auction_signer_seeds],
            ),
            token::spl_token::instruction::AuthorityType::AccountOwner,
            custodian.key().into(),
        )?;

        // Emit the order executed event, which liquidators can listen to if this execution ended up
        // being penalized so they can collect the base fee at settlement.
        emit!(crate::events::OrderExecuted {
            auction: auction.key(),
            vaa: fast_vaa.key(),
            source_chain: auction_info.source_chain,
            target_protocol: auction.target_protocol,
            penalized,
        });

        (
            user_amount,
            AuctionStatus::Completed {
                slot: current_slot,
                execute_penalty: if penalized {
                    penalty.into()
                } else {
                    None
                },
            },
            beneficiary,
        )
    };

    // Set the auction status to completed.
    auction.status = new_status;

    Ok(PreparedOrderExecution {
        user_amount,
        fill: Fill {
            source_chain: vaa.emitter_chain(),
            order_sender: order.sender(),
            redeemer: order.redeemer(),
            redeemer_message: order
                .message_to_vec()
                .try_into()
                .map_err(|_| MatchingEngineError::RedeemerMessageTooLarge)?,
        },
        beneficiary,
    })
}","rust
mod cctp;
pub use cctp::*;
mod local;
pub use local::*;

use crate::{
    composite::*,
    error::MatchingEngineError,
    state::{Auction, AuctionStatus, MessageProtocol},
    utils::{self, auction::DepositPenalty},
};
use anchor_lang::prelude::*;
use anchor_spl::token;
use common::messages::{
    raw::{LiquidityLayerMessage, MessageToVec},
    Fill,
};

struct PrepareFastExecution<'ctx, 'info> {
    execute_order: &'ctx mut ExecuteOrder<'info>,
    custodian: &'ctx CheckedCustodian<'info>,
    token_program: &'ctx Program<'info, token::Token>,
}

struct PreparedOrderExecution<'info> {
    pub user_amount: u64,
    pub fill: Fill,
    pub beneficiary: Option<AccountInfo<'info>>,
}

fn prepare_order_execution<'info>(
    accounts: PrepareFastExecution<'_, 'info>,
) -> Result<PreparedOrderExecution<'info>> {
    let PrepareFastExecution {
        execute_order,
        custodian,
        token_program,
    } = accounts;

    let auction = &mut execute_order.active_auction.auction;
    let fast_vaa = &execute_order.fast_vaa;
    let custody_token = &execute_order.active_auction.custody_token;
    let config = &execute_order.active_auction.config;
    let executor_token = &execute_order.executor_token;
    let best_offer_token = &execute_order.active_auction.best_offer_token;
    let initial_offer_token = &execute_order.initial_offer_token;
    let initial_participant = &execute_order.initial_participant;

    let vaa = fast_vaa.load_unchecked();
    let order = LiquidityLayerMessage::try_from(vaa.payload())
        .unwrap()
        .to_fast_market_order_unchecked();

    let (user_amount, new_status, beneficiary) = {
        // ...
        // omitted for brevity
        // ...
    };

    auction.status = new_status;

    Ok(PreparedOrderExecution {
        user_amount,
        fill: Fill {
            source_chain: vaa.emitter_chain(),
            order_sender: order.sender(),
            redeemer: order.redeemer(),
            redeemer_message: order
                .message_to_vec()
                .try_into()
                .map_err(|_| MatchingEngineError::RedeemerMessageTooLarge)?,
        },
        beneficiary,
    })
}",High,"Implement checks to ensure that the account is a valid token account and explicitly verify the mint for the token accounts, rather than relying solely on data_is_empty: pub fn checked_deserialize_token_account( acc_info: &AccountInfo, expected_mint: &Pubkey, ) -> Option<token::TokenAccount> { if acc_info.owner != &token::ID { None } else { let data = acc_info.try_borrow_data().ok()?; token::TokenAccount::try_deserialize(&mut &data[..]) .ok() .filter(|token_data| &token_data.mint == expected_mint && !token_data.is_frozen()) } }",https://github.com/wormhole-foundation/example-liquidity-layer/pull/188/files,High
Sol-098,"There is a potential vulnerability related to the settlement instructions for auctions involving the Wormhole CCTP bridge. The code assumes that the total transferable amount equals order.amount_in retrieved from the fastVAA. However, during the settlement process, it does not verify whether this amount actually matches the funds in the prepared_custody_token account. Before settling the PrepareOrderResponse, if a small amount of tokens is transferred to the prepared_custody_token account, the settlement instruction fails when attempting to close the prepared_custody_token account via token::close_account. This failure occurs because only order.amount_in is transferred from the account instead of the total balance, leaving non-zero funds in the account and causing the closure to fail.","rust
use crate::{
    composite::*,
    error::MatchingEngineError,
    state::Auction,
    utils
};

use anchor_lang::prelude::*;
use anchor_spl::token;
use common::TRANSFER_AUTHORITY_SEED_PREFIX;

#[derive(Accounts)]
#[instruction(offer_price: u64)]
pub struct ImproveOffer<'info> {
    #[account(
        seeds = [ 
            TRANSFER_AUTHORITY_SEED_PREFIX,
            active_auction.key().as_ref(),
            &offer_price.to_be_bytes() 
        ], 
        bump 
    )]
    transfer_authority: UncheckedAccount<'info>,

    #[account(
        constraint = {
            let info = active_auction.info.as_ref().unwrap();
            require!(
                info.within_auction_duration(&active_auction.config),
                MatchingEngineError::AuctionPeriodExpired
            );
            require!(
                offer_price < utils::auction::compute_min_allowed_offer(&active_auction.config, info),
                MatchingEngineError::CarpingNotAllowed
            );
            true
        }
    )]
    active_auction: ActiveAuction<'info>,

    #[account(
        constraint = {
            offer_token.key() != active_auction.custody_token.key()
        } @ MatchingEngineError::InvalidOfferToken
    )]
    offer_token: Account<'info, token::TokenAccount>,
    token_program: Program<'info, token::Token>,
}

pub fn improve_offer(ctx: Context<ImproveOffer>, offer_price: u64) -> Result<()> {
    let offer_token = &ctx.accounts.offer_token;
    {
        let ActiveAuction {
            auction,
            custody_token,
            best_offer_token,
            config: _,
        } = &ctx.accounts.active_auction;

        let token_program = &ctx.accounts.token_program;

        if offer_token.key() != best_offer_token.key() {
            let total_deposit = ctx
                .accounts
                .active_auction
                .info
                .as_ref()
                .unwrap()
                .total_deposit();

            if !best_offer_token.data_is_empty() {
                token::transfer(
                    CpiContext::new_with_signer(
                        token_program.to_account_info(),
                        anchor_spl::token::Transfer {
                            from: custody_token.to_account_info(),
                            to: best_offer_token.to_account_info(),
                            authority: auction.to_account_info(),
                        },
                        &[&[
                            Auction::SEED_PREFIX, 
                            auction.vaa_hash.as_ref(), 
                            &[auction.bump]
                        ]],
                    ),
                    total_deposit,
                )?;
            }
            
            token::transfer(
                CpiContext::new_with_signer(
                    token_program.to_account_info(),
                    anchor_spl::token::Transfer {
                        from: offer_token.to_account_info(),
                        to: custody_token.to_account_info(),
                        authority: ctx.accounts.transfer_authority.to_account_info(),
                    },
                    &[&[
                        TRANSFER_AUTHORITY_SEED_PREFIX, 
                        auction.key().as_ref(), 
                        &offer_price.to_be_bytes(), 
                        &[ctx.bumps.transfer_authority]
                    ]],
                ),
                total_deposit,
            )?;
        } 
    }

    let info = ctx.accounts.active_auction.info.as_mut().unwrap();
    info.best_offer_token = offer_token.key();
    info.offer_price = offer_price;
    
    let auction = &ctx.accounts.active_auction;
    let config = &auction.config;
    let info = auction.info.as_ref().unwrap();

    emit!(crate::events::AuctionUpdated {
        config_id: info.config_id,
        auction: auction.key(),
        vaa: Default::default(),
        source_chain: info.source_chain,
        target_protocol: auction.target_protocol,
        redeemer_message_len: info.redeemer_message_len,
        end_slot: info.auction_end_slot(config),
        best_offer_token: offer_token.key(),
        token_balance_before: offer_token.amount,
        amount_in: info.amount_in,
        total_deposit: info.total_deposit(),
        max_offer_price_allowed: utils::auction::compute_min_allowed_offer(config, info).checked_sub(1),
    });

    Ok(())
}","rust
use crate::{
    composite::*,
    error::MatchingEngineError,
    state::Auction,
    utils
};
use anchor_lang::prelude::*;
use anchor_spl::token;
use common::TRANSFER_AUTHORITY_SEED_PREFIX;

#[derive(Accounts)]
#[instruction(offer_price: u64)]
pub struct ImproveOffer<'info> {
    #[account(
        seeds = [
            TRANSFER_AUTHORITY_SEED_PREFIX,
            active_auction.key().as_ref(),
            &offer_price.to_be_bytes()
        ],
        bump
    )]
    transfer_authority: UncheckedAccount<'info>,

    #[account(
        constraint = {
            let info = active_auction.info.as_ref().unwrap();
            require!(
                info.within_auction_duration(&active_auction.config),
                MatchingEngineError::AuctionPeriodExpired
            );
            require!(
                offer_price < utils::auction::compute_min_allowed_offer(&active_auction.config, info),
                MatchingEngineError::CarpingNotAllowed
            );
            true
        }
    )]
    active_auction: ActiveAuction<'info>,

    #[account(
        constraint = { offer_token.key() != active_auction.custody_token.key() }
            @ MatchingEngineError::InvalidOfferToken,
    )]
    offer_token: Account<'info, token::TokenAccount>,

    token_program: Program<'info, token::Token>,
}

pub fn improve_offer(ctx: Context<ImproveOffer>, offer_price: u64) -> Result<()> {
    let offer_token = &ctx.accounts.offer_token;
    let ActiveAuction {
        auction,
        custody_token,
        best_offer_token,
        config: _,
    } = &ctx.accounts.active_auction;
    let token_program = &ctx.accounts.token_program;

    if offer_token.key() != best_offer_token.key() {
        let total_deposit = ctx
            .accounts
            .active_auction
            .info
            .as_ref()
            .unwrap()
            .total_deposit();

        if utils::checked_deserialize_token_account(best_offer_token, &custody_token.mint).is_some() {
            token::transfer(
                CpiContext::new_with_signer(
                    token_program.to_account_info(),
                    anchor_spl::token::Transfer {
                        from: custody_token.to_account_info(),
                        to: best_offer_token.to_account_info(),
                        authority: auction.to_account_info(),
                    },
                    &[&[Auction::SEED_PREFIX, auction.vaa_hash.as_ref(), &[auction.bump]]],
                ),
                total_deposit,
            )?;
        }

        token::transfer(
            CpiContext::new_with_signer(
                token_program.to_account_info(),
                anchor_spl::token::Transfer {
                    from: offer_token.to_account_info(),
                    to: custody_token.to_account_info(),
                    authority: ctx.accounts.transfer_authority.to_account_info(),
                },
                &[&[
                    TRANSFER_AUTHORITY_SEED_PREFIX,
                    auction.key().as_ref(),
                    &offer_price.to_be_bytes(),
                    &[ctx.bumps.transfer_authority],
                ]],
            ),
            total_deposit,
        )?;
    }

    let info = ctx.accounts.active_auction.info.as_mut().unwrap();

    info.best_offer_token = offer_token.key();
    info.offer_price = offer_price;

    let auction = &ctx.accounts.active_auction;
    let config = &auction.config;
    let info = auction.info.as_ref().unwrap();

    emit!(crate::events::AuctionUpdated {
        config_id: info.config_id,
        auction: auction.key(),
        vaa: Default::default(),
        source_chain: info.source_chain,
        target_protocol: auction.target_protocol,
        redeemer_message_len: info.redeemer_message_len,
        end_slot: info.auction_end_slot(config),
        best_offer_token: offer_token.key(),
        token_balance_before: offer_token.amount,
        amount_in: info.amount_in,
        total_deposit: info.total_deposit(),
        max_offer_price_allowed: utils::auction::compute_min_allowed_offer(config, info).checked_sub(1),
    });

    Ok(())
}",High,"Implement checks to ensure that the account is a valid token account and explicitly verify the mint for the token accounts, rather than relying solely on data_is_empty: pub fn checked_deserialize_token_account( acc_info: &AccountInfo, expected_mint: &Pubkey, ) -> Option<token::TokenAccount> { if acc_info.owner != &token::ID { None } else { let data = acc_info.try_borrow_data().ok()?; token::TokenAccount::try_deserialize(&mut &data[..]) .ok() .filter(|token_data| &token_data.mint == expected_mint && !token_data.is_frozen()) } }",https://github.com/wormhole-foundation/example-liquidity-layer/pull/188/files,High
Sol-099,"The settle_auction_none_local function fails to verify the endpoint information within the PreparedOrderResponse account. Specifically, it does not check whether the to_endpoint field in the PreparedOrderResponse account is set to Local before proceeding with settlement on the Solana chain.","rust
use std::ops::{Deref, DerefMut}; 

use crate::{ 
    error::MatchingEngineError, 
    state::{ 
        Auction, 
        AuctionStatus, 
        Custodian, 
        FastFillSequencer, 
        MessageProtocol, 
        PreparedOrderResponse, 
        ReservedFastFillSequence, 
        RouterEndpoint, 
    }, 
    utils::{self, VaaDigest},
}; 

use anchor_lang::prelude::*; 
use anchor_spl::token; 

use common::{ 
    admin::utils::{assistant::only_authorized, ownable::only_owner}, 
    messages::raw::LiquidityLayerMessage, 
    wormhole_cctp_solana::{ 
        cctp::{message_transmitter_program, token_messenger_minter_program}, 
        wormhole::{core_bridge_program, VaaAccount}, 
    },
}; 

#[derive(Accounts)] 
pub struct Usdc<'info> { 
    /// CHECK: This address must equal [USDC_MINT](common::USDC_MINT). 
    #[account(address = common::USDC_MINT)] 
    pub mint: UncheckedAccount<'info>, 
} 

impl<'info> Deref for Usdc<'info> { 
    type Target = UncheckedAccount<'info>; 

    fn deref(&self) -> &Self::Target { 
        &self.mint 
    } 
}

// More codes....
// Please complete & reformat remaining codes as needed","rust
use std::ops::{Deref, DerefMut};
use crate::{
    error::MatchingEngineError,
    state::{
        Auction,
        AuctionStatus,
        Custodian,
        FastFillSequencer,
        MessageProtocol,
        PreparedOrderResponse,
        ReservedFastFillSequence,
        RouterEndpoint,
    },
    utils::{self, VaaDigest},
};
use anchor_lang::prelude::*;
use anchor_spl::token;
use common::{
    admin::utils::{
        assistant::only_authorized,
        ownable::only_owner
    },
    messages::raw::LiquidityLayerMessage,
    wormhole_cctp_solana::{
        cctp::{
            message_transmitter_program,
            token_messenger_minter_program
        },
        wormhole::{
            core_bridge_program, 
            VaaAccount,
        },
    },
};

#[derive(Accounts)]
pub struct Usdc<'info> {
    /// CHECK: This address must equal [USDC_MINT](common::USDC_MINT).
    #[account(address = common::USDC_MINT)]
    pub mint: UncheckedAccount<'info>,
}

impl<'info> Deref for Usdc<'info> {
    type Target = UncheckedAccount<'info>;

    fn deref(&self) -> &Self::Target {
        &self.mint
    }
}

/// Mint recipient token account, which is encoded as the mint recipient in the CCTP message.
/// The CCTP Token Messenger Minter program will transfer the amount encoded in the CCTP message
/// from its custody account to this account.
///
/// CHECK: Mutable. Seeds must be \[""custody""\].
///
///
/// NOTE: This account must be encoded as the mint recipient in the CCTP message.
#[derive(Accounts)]
pub struct CctpMintRecipientMut<'info> {
    #[account(mut, address = crate::CCTP_MINT_RECIPIENT )]
    pub mint_recipient: Box<Account<'info, token::TokenAccount>>,
}

impl<'info> Deref for CctpMintRecipientMut<'info> {
    type Target = Account<'info, token::TokenAccount>;

    fn deref(&self) -> &Self::Target {
        &self.mint_recipient
    }
}

#[derive(Accounts)]
pub struct LiquidityLayerVaa<'info> {
    /// CHECK: This VAA account must be a posted VAA from the Wormhole Core Bridge program.
    #[account(constraint = {
        // NOTE: This load performs an owner check.
        let vaa = VaaAccount::load(&vaa)?;
        // Is it a legitimate LL message?
        LiquidityLayerMessage::try_from(vaa.payload())
            .map_err(|_| MatchingEngineError::InvalidVaa)?;

        // Done.
        true
    })]
    pub vaa: UncheckedAccount<'info>,
}

impl<'info> LiquidityLayerVaa<'info> {
    pub fn load_unchecked(&self) -> VaaAccount<'_> {
        VaaAccount::load_unchecked(self)
    }
}

impl<'info> Deref for LiquidityLayerVaa<'info> {
    type Target = UncheckedAccount<'info>;

    fn deref(&self) -> &Self::Target {
        &self.vaa
    }
}

#[derive(Accounts)]
pub struct CheckedCustodian<'info> {
    #[account(
        seeds = [Custodian::SEED_PREFIX],
        bump = Custodian::BUMP,
    )]
    pub custodian: Account<'info, Custodian>,
}

impl<'info> Deref for CheckedCustodian<'info> {
    type Target = Account<'info, Custodian>;

    fn deref(&self) -> &Self::Target {
        &self.custodian
    }
}

#[derive(Accounts)]
pub struct OwnerOnly<'info> {
    #[account(
        constraint = only_owner(
            &custodian,
            &owner,
            error!(MatchingEngineError::OwnerOnly),
        )?,
    )]
    pub owner: Signer<'info>,
    pub custodian: CheckedCustodian<'info>,
}

#[derive(Accounts)]
pub struct OwnerOnlyMut<'info> {
    #[account(
        constraint = only_owner(
            &custodian,
            &owner,
            error!(MatchingEngineError::OwnerOnly),
        )?,
    )]
    pub owner: Signer<'info>,
    #[account(
        mut,
        seeds = [Custodian::SEED_PREFIX],
        bump = Custodian::BUMP,
    )]
    pub custodian: Account<'info, Custodian>,
}

#[derive(Accounts)]
pub struct Admin<'info> {
    #[account(
        constraint = only_authorized(
            &custodian,
            &owner_or_assistant,
            error!(MatchingEngineError::OwnerOrAssistantOnly),
        )?,
    )]
    pub owner_or_assistant: Signer<'info>,
    pub custodian: CheckedCustodian<'info>,
}

#[derive(Accounts)]
pub struct AdminMut<'info> {
    #[account(
        constraint = only_authorized(
            &custodian,
            &owner_or_assistant,
            error!(MatchingEngineError::OwnerOrAssistantOnly),
        )?,
    )]
    pub owner_or_assistant: Signer<'info>,
    #[account(
        mut,
        seeds = [Custodian::SEED_PREFIX],
        bump = Custodian::BUMP,
    )]
    pub custodian: Account<'info, Custodian>,
}

#[derive(Accounts)]
pub struct LocalTokenRouter<'info> {
    /// CHECK: Must be an executable (the Token Router program), whose ID will be used to derive the
    /// emitter (router endpoint) address.
    #[account(executable)]
    pub token_router_program: UncheckedAccount<'info>,
    /// CHECK: The Token Router program's emitter PDA (a.k.a. its custodian) will have account data.
    #[account(
        seeds = [b""emitter""],
        bump,
        seeds::program = token_router_program,
        owner = token_router_program.key() @ MatchingEngineError::InvalidEndpoint,
        constraint = !token_router_emitter.data_is_empty() @ MatchingEngineError::InvalidEndpoint,
    )]
    pub token_router_emitter: UncheckedAccount<'info>,
    #[account(
        associated_token::mint = common::USDC_MINT,
        associated_token::authority = token_router_emitter,
    )]
    pub token_router_mint_recipient: Account<'info, token::TokenAccount>,
}

#[derive(Accounts)]
pub struct ExistingMutRouterEndpoint<'info> {
    #[account(
        mut,
        seeds = [
            RouterEndpoint::SEED_PREFIX,
            &endpoint.chain.to_be_bytes(),
        ],
        bump = endpoint.bump,
    )]
    pub endpoint: Account<'info, RouterEndpoint>,
}

impl<'info> Deref for ExistingMutRouterEndpoint<'info> {
    type Target = Account<'info, RouterEndpoint>;

    fn deref(&self) -> &Self::Target {
        &self.endpoint
    }
}

impl<'info> DerefMut for ExistingMutRouterEndpoint<'info> {
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.endpoint
    }
}

#[derive(Accounts)]
pub struct LiveRouterEndpoint<'info> {
    #[account(
        seeds = [
            RouterEndpoint::SEED_PREFIX,
            &endpoint.chain.to_be_bytes(),
        ],
        bump = endpoint.bump,
        constraint = {
            endpoint.protocol != MessageProtocol::None
        } @ MatchingEngineError::EndpointDisabled,
    )]
    pub endpoint: Box<Account<'info, RouterEndpoint>>,
}

impl<'info> Deref for LiveRouterEndpoint<'info> {
    type Target = Account<'info, RouterEndpoint>;

    fn deref(&self) -> &Self::Target {
        &self.endpoint
    }
}

#[derive(Accounts)]
pub struct LiveRouterPath<'info> {
    pub from_endpoint: LiveRouterEndpoint<'info>,
    #[account(
        constraint = from_endpoint.chain != to_endpoint.chain @ MatchingEngineError::SameEndpoint
    )]
    pub to_endpoint: LiveRouterEndpoint<'info>,
}

#[derive(Accounts)]
pub struct FastOrderPath<'info> {
    #[account(
        constraint = {
            let vaa = fast_vaa.load_unchecked();
            require_eq!(
                path.from_endpoint.chain,
                vaa.emitter_chain(),
                MatchingEngineError::InvalidSourceRouter,
            );
            require!(
                path.from_endpoint.address == vaa.emitter_address(),
                MatchingEngineError::InvalidSourceRouter,
            );
            let message = LiquidityLayerMessage::try_from(vaa.payload()).unwrap();
            let order = message
                .fast_market_order()
                .ok_or_else(|| MatchingEngineError::NotFastMarketOrder)?;
            require_eq!(
                path.to_endpoint.chain,
                order.target_chain(),
                MatchingEngineError::InvalidTargetRouter,
            );
            true
        },
    )]
    pub fast_vaa: LiquidityLayerVaa<'info>,
    pub path: LiveRouterPath<'info>,
}

impl<'info> Deref for FastOrderPath<'info> {
    type Target = LiveRouterPath<'info>;

    fn deref(&self) -> &Self::Target {
        &self.path
    }
}

#[derive(Accounts)]
pub struct ActiveAuction<'info> {
    #[account(
        mut,
        seeds = [
            Auction::SEED_PREFIX,
            auction.vaa_hash.as_ref(),
        ],
        bump = auction.bump,
        constraint = {
            matches!(auction.status, AuctionStatus::Active) 
        } @ MatchingEngineError::AuctionNotActive,
    )]
    pub auction: Box<Account<'info, Auction>>,
    #[account(
        mut,
        seeds = [
            crate::AUCTION_CUSTODY_TOKEN_SEED_PREFIX,
            auction.key().as_ref(),
        ],
        bump = auction.info.as_ref().unwrap().custody_token_bump,
    )]
    pub custody_token: Box<Account<'info, token::TokenAccount>>,
    #[account(
        constraint = {
            require_eq!(
                auction.info.as_ref().unwrap().config_id,
                config.id,
                MatchingEngineError::AuctionConfigMismatch,
            );
            true
        },
    )]
    pub config: Box<Account<'info, crate::state::AuctionConfig>>,
    /// CHECK: Mutable. Must have the same key in auction data.
    #[account(
        mut,
        address = auction.info.as_ref().unwrap().best_offer_token,
    )]
    pub best_offer_token: UncheckedAccount<'info>,
}

impl<'info> VaaDigest for ActiveAuction<'info> {
    fn digest(&self) -> [u8; 32] {
        self.auction.vaa_hash
    }
}

impl<'info> Deref for ActiveAuction<'info> {
    type Target = Account<'info, Auction>;

    fn deref(&self) -> &Self::Target {
        &self.auction
    }
}

impl<'info> DerefMut for ActiveAuction<'info> {
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.auction
    }
}

#[derive(Accounts)]
pub struct ExecuteOrder<'info> {
    /// CHECK: Must be owned by the Wormhole Core Bridge program.
    #[account(
        constraint = utils::require_vaa_hash_equals(&active_auction, &fast_vaa.load_unchecked())?
    )]
    pub fast_vaa: LiquidityLayerVaa<'info>,
    #[account(
        constraint = {
            let info = active_auction.info.as_ref().unwrap();
            require!(
                !info.within_auction_duration(&active_auction.config),
                MatchingEngineError::AuctionPeriodNotExpired,
            );
            true
        },
    )]
    pub active_auction: ActiveAuction<'info>,
    /// Must be a token account, whose mint is [common::USDC_MINT].
    #[account(
        mut,
        token::mint = common::USDC_MINT,
    )]
    pub executor_token: Box<Account<'info, token::TokenAccount>>,
    /// CHECK: Mutable. Must equal [initial_offer](Auction::initial_offer).
    #[account(
        mut,
        address = active_auction.info.as_ref().unwrap().initial_offer_token,
    )]
    pub initial_offer_token: UncheckedAccount<'info>,
    /// CHECK: Must be the payer of the initial auction (see [Auction::prepared_by]).
    #[account(
        mut,
        address = active_auction.prepared_by,
    )]
    pub initial_participant: UncheckedAccount<'info>,
}

#[derive(Accounts)]
pub struct WormholePublishMessage<'info> {
    /// CHECK: Seeds must be \[""Bridge""\] (Wormhole Core Bridge program).
    #[account(mut)]
    pub config: UncheckedAccount<'info>,
    /// CHECK: Seeds must be \[""Sequence""\, custodian] (Wormhole Core Bridge program).
    #[account(mut)]
    pub emitter_sequence: UncheckedAccount<'info>,
    /// CHECK: Seeds must be \[""fee_collector""\] (Wormhole Core Bridge program).
    #[account(mut)]
    pub fee_collector: UncheckedAccount<'info>,
    /// CHECK: Must equal Wormhole Core Bridge program ID.
    #[account(address = core_bridge_program::id())]
    pub core_bridge_program: UncheckedAccount<'info>,
}

#[derive(Accounts)]
pub struct CctpDepositForBurn<'info> {
    /// Circle-supported mint.
    ///
    /// CHECK: Mutable. This token account's mint must be the same as the one found in the CCTP
    /// Token Messenger Minter program's local token account.
    #[account(mut)]
    pub mint: UncheckedAccount<'info>,
    /// CHECK: Seeds must be \[""sender_authority""\] (CCTP Token Messenger Minter program).
    pub token_messenger_minter_sender_authority: UncheckedAccount<'info>',
    /// CHECK: Mutable. Seeds must be \[""message_transmitter""\] (CCTP Message Transmitter program).
    #[account(mut)]
    pub message_transmitter_config: UncheckedAccount<'info>,
    /// CHECK: Seeds must be \[""token_messenger""\] (CCTP Token Messenger Minter program).
    pub token_messenger: UncheckedAccount<'info>,
    /// CHECK: Seeds must be \[""remote_token_messenger""\, remote_domain.to_string()] (CCTP Token
    /// Messenger Minter program).
    pub remote_token_messenger: UncheckedAccount<'info>,
    /// CHECK Seeds must be \[""token_minter""\] (CCTP Token Messenger Minter program).
    pub token_minter: UncheckedAccount<'info>,
    /// Local token account, which this program uses to validate the `mint` used to burn.
    ///
    /// CHECK: Mutable. Seeds must be \[""local_token"", mint\] (CCTP Token Messenger Minter program).
    #[account(mut)]
    pub local_token: UncheckedAccount<'info>,
    /// CHECK: Seeds must be \[""__event_authority""\] (CCTP Token Messenger Minter program).
    pub token_messenger_minter_event_authority: UncheckedAccount<'info>,
    /// CHECK: Must equal CCTP Token Messenger Minter program ID.
    #[account(address = token_messenger_minter_program::id())]
    pub token_messenger_minter_program: UncheckedAccount<'info>,
    /// CHECK: Must equal CCTP Message Transmitter program ID.
    #[account(address = message_transmitter_program::id())]
    pub message_transmitter_program: UncheckedAccount<'info>,
}

#[derive(Accounts)]
pub struct CctpReceiveMessage<'info> {
    pub mint_recipient: CctpMintRecipientMut<'info>,
    /// CHECK: Seeds must be \[""message_transmitter_authority""\] (CCTP Message Transmitter program).
    pub message_transmitter_authority: UncheckedAccount<'info>,
    /// CHECK: Seeds must be \[""message_transmitter""\] (CCTP Message Transmitter program).
    pub message_transmitter_config: UncheckedAccount<'info>,
    /// CHECK: Mutable. Seeds must be \[""used_nonces"", remote_domain.to_string(),
    /// first_nonce.to_string()\] (CCTP Message Transmitter program).
    #[account(mut)]
    pub used_nonces: UncheckedAccount<'info>,
    /// CHECK: Seeds must be \[""__event_authority""\] (CCTP Message Transmitter program)).
    pub message_transmitter_event_authority: UncheckedAccount<'info>,
    /// CHECK: Seeds must be \[""token_messenger""\] (CCTP Token Messenger Minter program).
    pub token_messenger: UncheckedAccount<'info>,
    /// CHECK: Seeds must be \[""remote_token_messenger""\, remote_domain.to_string()] (CCTP Token
    /// Messenger Minter program).
    pub remote_token_messenger: UncheckedAccount<'info>,
    /// CHECK: Seeds must be \[""token_minter""\] (CCTP Token Messenger Minter program).
    pub token_minter: UncheckedAccount<'info>,
    /// Token Messenger Minter's Local Token account. This program uses the mint of this account to
    /// validate the `mint_recipient` token account",High,The settle_auction_none_local function should verify that order_response.to_endpoint is set to Local before proceeding with settlement.,https://github.com/wormhole-foundation/example-liquidity-layer/pull/194/files,High
Sol-100,"The prepare_market_order function calculates a hash based on several order details to generate a temporary Program-Derived Address (PDA) (transfer_authority) for token transfer authorization. However, this hash calculation does not include the refund_token field (the user’s designated token account for refunds).","rust
use crate::{
    composite::*,
    error::TokenRouterError,
    state::{OrderType, PreparedOrder, PreparedOrderInfo},
};
use anchor_lang::prelude::*;
use anchor_spl::token;
use common::TRANSFER_AUTHORITY_SEED_PREFIX;
use solana_program::keccak;

/// Accounts required for [prepare_market_order].
#[derive(Accounts)]
#[instruction(args = PrepareMarketOrderArgs)]
pub struct PrepareMarketOrder<'info> {
    #[account(mut)]
    payer: Signer<'info>,
    custodian: CheckedCustodian<'info>,
    #[account(
        seeds = [
            TRANSFER_AUTHORITY_SEED_PREFIX, 
            prepared_order.key().as_ref(), 
            &args.hash().0
        ],
        bump,
        constraint = {
            require_eq!(
                sender_token.delegated_amount,
                args.amount_in,
                TokenRouterError::DelegatedAmountMismatch,
            );
            true
        }
    )]
    program_transfer_authority: Option<UncheckedAccount<'info>>,
    sender: Option<Signer<'info>>,
    #[account(
        init,
        payer = payer,
        space = PreparedOrder::compute_size(args.redeemer_message.len()),
        constraint = {
            require!(args.amount_in > 0, TokenRouterError::InsufficientAmount);
            require!(args.redeemer != [0; 32], TokenRouterError::InvalidRedeemer);
            require!(
                args.redeemer_message.len() <= crate::MAX_REDEEMER_MESSAGE_SIZE,
                TokenRouterError::RedeemerMessageTooLarge
            );

            if let Some(min_amount_out) = args.min_amount_out {
                require!(
                    min_amount_out <= args.amount_in,
                    TokenRouterError::MinAmountOutTooHigh,
                );
            }
            true
        }
    )]
    prepared_order: Account<'info, PreparedOrder>,
    #[account(mut)]
    sender_token: Box<Account<'info, token::TokenAccount>>,
    #[account(token::mint = usdc)]
    refund_token: Account<'info, token::TokenAccount>,
    #[account(
        init,
        payer = payer,
        token::mint = usdc,
        token::authority = custodian,
        seeds = [ crate::PREPARED_CUSTODY_TOKEN_SEED_PREFIX, prepared_order.key().as_ref()],
        bump
    )]
    prepared_custody_token: Account<'info, token::TokenAccount>,
    usdc: Usdc<'info>,
    token_program: Program<'info, token::Token>,
    system_program: Program<'info, System>,
}

/// Arguments for [prepare_market_order].
#[derive(Debug, AnchorSerialize, AnchorDeserialize, Clone)]
pub struct PrepareMarketOrderArgs {
    /// Amount of tokens to transfer.
    pub amount_in: u64,
    /// If provided, minimum amount of tokens to receive in exchange for [amount_in](Self::amount_in).
    pub min_amount_out: Option<u64>,
    /// The Wormhole chain ID of the network to transfer tokens to.
    pub target_chain: u16,
    /// The address of the redeeming contract on the target chain.
    pub redeemer: [u8; 32],
    /// Arbitrary payload to be sent to the [redeemer](Self::redeemer),
    /// which can be used to encode instructions or data for another network's smart contract.
    pub redeemer_message: Vec<u8>,
}

impl PrepareMarketOrderArgs {
    pub fn hash(&self) -> keccak::Hash {
        match self.min_amount_out {
            Some(min_amount_out) => keccak::hashv(&[
                &self.amount_in.to_be_bytes(),
                &min_amount_out.to_be_bytes(),
                &self.target_chain.to_be_bytes(),
                &self.redeemer,
                &self.redeemer_message,
            ]),
            None => keccak::hashv(&[
                &self.amount_in.to_be_bytes(),
                &self.target_chain.to_be_bytes(),
                &self.redeemer,
                &self.redeemer_message,
            ]),
        }
    }
}

pub fn prepare_market_order(
    ctx: Context<PrepareMarketOrder>,
    args: PrepareMarketOrderArgs,
) -> Result<()> {
    let hashed_args = args.hash();
    let PrepareMarketOrderArgs {
        amount_in,
        min_amount_out,
        target_chain,
        redeemer,
        redeemer_message,
    } = args;

    let order_sender = match (
        ctx.accounts.sender.as_ref(),
        ctx.accounts.program_transfer_authority.as_ref(),
    ) {
        (Some(sender), None) => {
            token::transfer(
                CpiContext::new(
                    ctx.accounts.token_program.to_account_info(),
                    token::Transfer {
                        from: ctx.accounts.sender_token.to_account_info(),
                        to: ctx.accounts.prepared_custody_token.to_account_info(),
                        authority: sender.to_account_info(),
                    },
                ),
                amount_in,
            )?;
            sender.key()
        }
        (None, Some(program_transfer_authority)) => {
            let sender_token = &ctx.accounts.sender_token;
            token::transfer(
                CpiContext::new_with_signer(
                    ctx.accounts.token_program.to_account_info(),
                    token::Transfer {
                        from: sender_token.to_account_info(),
                        to: ctx.accounts.prepared_custody_token.to_account_info(),
                        authority: program_transfer_authority.to_account_info(),
                    },
                    &[
                        &[
                            TRANSFER_AUTHORITY_SEED_PREFIX,
                            ctx.accounts.prepared_order.key().as_ref(),
                            &hashed_args.0,
                            &[ctx.bumps.program_transfer_authority.unwrap()],
                        ],
                    ],
                ),
                amount_in,
            )?;
            sender_token.owner
        }
        _ => return err!(TokenRouterError::EitherSenderOrProgramTransferAuthority),
    };

    ctx.accounts.prepared_order.set_inner(PreparedOrder {
        info: PreparedOrderInfo {
            order_sender,
            prepared_by: ctx.accounts.payer.key(),
            order_type: OrderType::Market {
                min_amount_out,
            },
            src_token: ctx.accounts.sender_token.key(),
            refund_token: ctx.accounts.refund_token.key(),
            target_chain,
            redeemer,
            prepared_custody_token_bump: ctx.bumps.prepared_custody_token,
        },
        redeemer_message,
    });

    Ok(())
}","rust
use crate::{
    composite::*,
    error::TokenRouterError,
    state::{OrderType, PreparedOrder, PreparedOrderInfo},
};
use anchor_lang::prelude::*;
use anchor_spl::token;
use common::TRANSFER_AUTHORITY_SEED_PREFIX;
use solana_program::keccak;

/// Accounts required for [prepare_market_order].
#[derive(Accounts)]
#[instruction(args: PrepareMarketOrderArgs)]
pub struct PrepareMarketOrder<'info> {
    #[account(mut)]
    payer: Signer<'info>,
    custodian: CheckedCustodian<'info>,

    #[account(
        seeds = [
            TRANSFER_AUTHORITY_SEED_PREFIX,
            prepared_order.key().as_ref(),
            &args.hash().0,
            refund_token.key().as_ref()
        ],
        bump,
        constraint = {
            require_eq!(sender_token.delegated_amount, args.amount_in, TokenRouterError::DelegatedAmountMismatch);
            true
        }
    )]
    program_transfer_authority: Option<UncheckedAccount<'info>>,

    sender: Option<Signer<'info>>,

    #[account(
        init,
        payer = payer,
        space = PreparedOrder::compute_size(args.redeemer_message.len()),
        constraint = {
            require!(args.amount_in > 0, TokenRouterError::InsufficientAmount);
            require!(args.redeemer != [0; 32], TokenRouterError::InvalidRedeemer);
            require!(args.redeemer_message.len() <= crate::MAX_REDEEMER_MESSAGE_SIZE, TokenRouterError::RedeemerMessageTooLarge);
            if let Some(min_amount_out) = args.min_amount_out {
                require!(min_amount_out <= args.amount_in, TokenRouterError::MinAmountOutTooHigh );
            }
            true
        }
    )]
    prepared_order: Account<'info, PreparedOrder>,

    #[account(mut)]
    sender_token: Box<Account<'info, token::TokenAccount>>,

    #[account( token::mint = usdc )]
    refund_token: Account<'info, token::TokenAccount>,

    #[account(
        init,
        payer = payer,
        token::mint = usdc,
        token::authority = custodian,
        seeds = [ crate::PREPARED_CUSTODY_TOKEN_SEED_PREFIX, prepared_order.key().as_ref() ],
        bump,
    )]
    prepared_custody_token: Account<'info, token::TokenAccount>,

    usdc: Usdc<'info>,
    token_program: Program<'info, token::Token>,
    system_program: Program<'info, System>,
}

/// Arguments for [prepare_market_order].
#[derive(Debug, AnchorSerialize, AnchorDeserialize, Clone)]
pub struct PrepareMarketOrderArgs {
    pub amount_in: u64,
    pub min_amount_out: Option<u64>,
    pub target_chain: u16,
    pub redeemer: [u8; 32],
    pub redeemer_message: Vec<u8>,
}

impl PrepareMarketOrderArgs {
    pub fn hash(&self) -> keccak::Hash {
        match self.min_amount_out {
            Some(min_amount_out) => keccak::hashv(&[
                &self.amount_in.to_be_bytes(),
                &min_amount_out.to_be_bytes(),
                &self.target_chain.to_be_bytes(),
                &self.redeemer,
                &self.redeemer_message,
            ]),
            None => keccak::hashv(&[
                &self.amount_in.to_be_bytes(),
                &self.target_chain.to_be_bytes(),
                &self.redeemer,
                &self.redeemer_message,
            ]),
        }
    }
}

pub fn prepare_market_order(
    ctx: Context<PrepareMarketOrder>,
    args: PrepareMarketOrderArgs,
) -> Result<()> {
    let hashed_args = args.hash();
    let PrepareMarketOrderArgs { amount_in, min_amount_out, target_chain, redeemer, redeemer_message } = args;
    let token_program = &ctx.accounts.token_program;
    let sender_token = &ctx.accounts.sender_token;
    let custody_token = &ctx.accounts.prepared_custody_token;
    let refund_token = &ctx.accounts.refund_token;
    let prepared_order = &mut ctx.accounts.prepared_order;
    let prepared_order_key = prepared_order.key();

    let order_sender = match (
        ctx.accounts.sender.as_ref(),
        ctx.accounts.program_transfer_authority.as_ref(),
    ) {
        (Some(sender), None) => {
            token::transfer(
                CpiContext::new(
                    token_program.to_account_info(),
                    token::Transfer {
                        from: sender_token.to_account_info(),
                        to: custody_token.to_account_info(),
                        authority: sender.to_account_info(),
                    },
                ),
                amount_in,
            )?;
            sender.key()
        }
        (None, Some(program_transfer_authority)) => {
            token::transfer(
                CpiContext::new_with_signer(
                    token_program.to_account_info(),
                    token::Transfer {
                        from: sender_token.to_account_info(),
                        to: custody_token.to_account_info(),
                        authority: program_transfer_authority.to_account_info(),
                    },
                    &[&[
                        TRANSFER_AUTHORITY_SEED_PREFIX,
                        prepared_order_key.as_ref(),
                        &hashed_args.0,
                        refund_token.key().as_ref(),
                        &[ctx.bumps.program_transfer_authority.unwrap()],
                    ]],
                ),
                amount_in,
            )?;
            sender_token.owner
        }
        _ => return err!(TokenRouterError::EitherSenderOrProgramTransferAuthority),
    };

    prepared_order.set_inner(PreparedOrder {
        info: PreparedOrderInfo {
            order_sender,
            prepared_by: ctx.accounts.payer.key(),
            order_type: OrderType::Market { min_amount_out },
            src_token: sender_token.key(),
            refund_token: refund_token.key(),
            target_chain,
            redeemer,
            prepared_custody_token_bump: ctx.bumps.prepared_custody_token,
        },
        redeemer_message,
    });

    Ok(())
}",Medium,"To prevent tampering with the refund_token account utilized for the prepared_order, the refund_token field must be included in the hash calculation used for generating the transfer_authority PDA.",https://github.com/wormhole-foundation/example-liquidity-layer/commit/ed87b5bb9f3ad63e597fdfbafc59ce0fc6905fcb,High
Sol-101,"In machine_engine::AuctionHistory, the code aims to calculate the maximum number of AuctionEntry objects that can fit within an AuctionHistory account. It takes the maximum account size as 10 * 1024 * 1000. However, based on MAX_PERMITTED_DATA_LENGTH defined by Solana, it should be 10 * 1024 * 1024. This underestimates the actual available space for storing auction entries, as the calculated MAX_ENTRIES will be lower than the actual maximum number of entries that would fit in the account.","//! The auction history state does not follow the same pattern as the other account schemas. 
//! Because we do not lean on [AccountSerialize] and [AccountDeserialize] in account contexts for 
//! the full auction history, we will be using a header to perform these operations to validate 
//! just the beginning of each of these accounts. The history itself will be read in using [UncheckedAccount].

use std::ops::{Deref, DerefMut};
use anchor_lang::{prelude::*, Discriminator};
use super::AuctionInfo;

#[account]
#[derive(Debug, Default)]
pub struct AuctionHistory {
    pub header: AuctionHistoryHeader,
    pub data: Vec<AuctionEntry>,
}

impl Deref for AuctionHistory {
    type Target = AuctionHistoryHeader;
    fn deref(&self) -> &Self::Target { &self.header }
}

#[derive(Debug, AnchorSerialize, AnchorDeserialize, Clone, InitSpace)]
pub struct AuctionEntry {
    pub vaa_hash: [u8; 32],
    pub vaa_timestamp: u32,
    pub info: AuctionInfo,
}

#[derive(Debug, AnchorSerialize, AnchorDeserialize, Clone, InitSpace, Default)]
pub struct AuctionHistoryHeader {
    pub id: u64,
    pub min_timestamp: Option<u32>,
    pub max_timestamp: Option<u32>,
}

impl AuctionHistoryHeader {
    pub fn new(id: u64) -> Self {
        Self { id, 
               min_timestamp: Default::default(), 
               max_timestamp: Default::default(), 
        }
    }
}

impl AuctionHistory {
    pub const SEED_PREFIX: &'static [u8] = b""auction-history"";
    pub const START: usize = 8; // DISCRIMINATOR + AuctionHistoryHeader::INIT_SPACE + 4 // data len

    cfg_if::cfg_if! {
        if #[cfg(feature = ""integration-test"")] {
            pub const MAX_ENTRIES: u32 = 2;
        } else {
            /// This value is calculated based on the maximum account size of 10MB.
            ///
            /// NOTE: This value is guaranteed to be less than u32::MAX.
            #[allow(clippy::as_conversions)]
            #[allow(clippy::cast_possible_truncation)]
            #[allow(clippy::integer_division)]
            pub const MAX_ENTRIES: u32 = ((10 * 1024 * 1000 - Self::START) / AuctionEntry::INIT_SPACE) as u32;
        }
    }
}

#[derive(Debug, AnchorSerialize, AnchorDeserialize, Clone)]
pub struct AuctionHistoryInternal {
    pub header: AuctionHistoryHeader,
    pub num_entries: u32,
}

impl Discriminator for AuctionHistoryInternal {
    const DISCRIMINATOR: [u8; 8] = AuctionHistory::DISCRIMINATOR;
}

impl AccountDeserialize for AuctionHistoryInternal {
    fn try_deserialize(buf: &mut &[u8]) -> Result<Self> {
        if buf[..8] != Self::DISCRIMINATOR {
            err!(ErrorCode::AccountDiscriminatorMismatch)
        } else {
            Self::try_deserialize_unchecked(buf)
        }
    }

    fn try_deserialize_unchecked(buf: &mut &[u8]) -> Result<Self> {
        *buf = &buf[8..];
        Ok(Self {
            header: AnchorDeserialize::deserialize(buf)?,
            num_entries: AnchorDeserialize::deserialize(buf)?,
        })
    }
}

impl AccountSerialize for AuctionHistoryInternal {
    fn try_serialize<W: std::io::prelude::Write>(&self, writer: &mut W) -> Result<()> {
        <AuctionHistory as anchor_lang::Discriminator>::DISCRIMINATOR.serialize(writer)?;
        self.header.serialize(writer)?;
        self.num_entries.serialize(writer)?;
        Ok(())
    }
}

impl Owner for AuctionHistoryInternal {
    fn owner() -> Pubkey {
        crate::id()
    }
}

impl Deref for AuctionHistoryInternal {
    type Target = AuctionHistoryHeader;
    fn deref(&self) -> &Self::Target { &self.header }
}

impl DerefMut for AuctionHistoryInternal {
    fn deref_mut(&mut self) -> &mut Self::Target { &mut self.header }
}

#[cfg(test)]
mod test {
    #![allow(clippy::integer_division)]

    use super::*;

    #[test]
    fn check_max_entries() {
        const MAX: usize = (10 * 1024 * 1000 - AuctionHistory::START) / AuctionEntry::INIT_SPACE;
        assert!(MAX <= u32::MAX.try_into().unwrap());
    }
}","rust
//! The auction history state does not follow the same pattern as the other account schemas. 
//! Because we do not lean on [AccountSerialize] and [AccountDeserialize] in account contexts 
//! for the full auction history, we will be using a header to perform these operations 
//! to validate just the beginning of each of these accounts. The history itself will be 
//! read in using [UncheckedAccount].

use std::ops::{Deref, DerefMut};
use anchor_lang::{prelude::*, Discriminator};
use super::AuctionInfo;

#[account]
#[derive(Debug, Default)]
pub struct AuctionHistory {
    pub header: AuctionHistoryHeader,
    pub data: Vec<AuctionEntry>,
}

impl Deref for AuctionHistory {
    type Target = AuctionHistoryHeader;

    fn deref(&self) -> &Self::Target {
        &self.header
    }
}

#[derive(Debug, AnchorSerialize, AnchorDeserialize, Clone, InitSpace)]
pub struct AuctionEntry {
    pub vaa_hash: [u8; 32],
    pub vaa_timestamp: u32,
    pub info: AuctionInfo,
}

#[derive(Debug, AnchorSerialize, AnchorDeserialize, Clone, InitSpace, Default)]
pub struct AuctionHistoryHeader {
    pub id: u64,
    pub min_timestamp: Option<u32>,
    pub max_timestamp: Option<u32>,
}

impl AuctionHistoryHeader {
    pub fn new(id: u64) -> Self {
        Self {
            id,
            min_timestamp: Default::default(),
            max_timestamp: Default::default(),
        }
    }
}

...

#[cfg(test)]
mod test {
    #![allow(clippy::integer_division)]
    use super::*;

    #[test]
    fn check_max_entries() {
        const MAX: usize = (10 * 1024 * 1024 - AuctionHistory::START) / AuctionEntry::INIT_SPACE;
        assert!(MAX <= u32::MAX.try_into().unwrap());
    }
}",Low,"The calculation of MAX_ENTRIES should be updated to use the correct value based on the maximum account size to prevent overflows, underflows, or unintended memory constraints.",https://github.com/wormhole-foundation/example-liquidity-layer/pull/189/files,High
Sol-102,"In matching_engine::update_cctp_router_endpoint, there is no proper validation to ensure that args.chain equals the existing chain ID router_endpoint.chain before invoking handle_add_cctp_router_endpoint, which updates the router endpoint with args. Consequently, when any instruction attempts to access the router_endpoint account using the ExistingMutRouterEndpoint accounts, the PDA address derivation will fail if router_endpoint.chain is incorrect since it was used as a seed. Allowing router_endpoint.chain to update without proper validation could lead to a denial-of-service attack, preventing multiple instructions from functioning correctly.","use crate::{
    composite::*,
    utils::{self, admin::AddCctpRouterEndpointArgs},
};

use anchor_lang::prelude::*;
use common::wormhole_cctp_solana::cctp::token_messenger_minter_program::{
    self,
    RemoteTokenMessenger,
};

#[derive(Accounts)]
#[instruction(args: AddCctpRouterEndpointArgs)]
pub struct UpdateCctpRouterEndpoint<'info> {
    admin: OwnerOnly<'info>,
    router_endpoint: ExistingMutRouterEndpoint<'info>,
    /// CHECK: Seeds must be [""remote_token_messenger"", remote_domain.to_string()] (CCTP Token Expand Down 
    /// Messenger Minter program).
    #[account( 
        seeds = [ 
            RemoteTokenMessenger::SEED_PREFIX, 
            args.cctp_domain.to_string().as_ref() 
        ], 
        bump, 
        seeds::program = token_messenger_minter_program::id(),
    )]
    remote_token_messenger: Account<'info, RemoteTokenMessenger>,
}

pub fn update_cctp_router_endpoint(
    ctx: Context<UpdateCctpRouterEndpoint>,
    args: AddCctpRouterEndpointArgs,
) -> Result<()> {
    utils::admin::handle_add_cctp_router_endpoint(&mut ctx.accounts.router_endpoint, args, None)
}","use crate::{ 
    composite::*, 
    utils::{
        self, 
        admin::AddCctpRouterEndpointArgs
    }, 
}; 

use anchor_lang::prelude::*; 
use common::wormhole_cctp_solana::cctp::token_messenger_minter_program::{ self, RemoteTokenMessenger, }; 

#[derive(Accounts)] 
#[instruction(args: AddCctpRouterEndpointArgs)] 
pub struct UpdateCctpRouterEndpoint<'info> { 
    admin: OwnerOnly<'info>, 
    
    #[account( 
        constraint = { 
            require_eq!( args.chain, router_endpoint.chain, crate::error::MatchingEngineError::InvalidEndpoint, ); true 
        } 
    )] 
    router_endpoint: ExistingMutRouterEndpoint<'info>, 

    /// CHECK: Seeds must be \[""remote_token_messenger""\, remote_domain.to_string()] (CCTP Token Expand Down 
    /// Messenger Minter program). 

    #[account( 
        seeds = [ 
            RemoteTokenMessenger::SEED_PREFIX, 
            args.cctp_domain.to_string().as_ref() 
        ], bump, 
        seeds::program = token_messenger_minter_program::id(), 
    )] 
    remote_token_messenger: Account<'info, RemoteTokenMessenger>, 
} 

pub fn update_cctp_router_endpoint( 
    ctx: Context<UpdateCctpRouterEndpoint>, 
    args: AddCctpRouterEndpointArgs,) -> Result<()> { 

    utils::admin::handle_add_cctp_router_endpoint(&mut ctx.accounts.router_endpoint, args, None) 
}",Low,"Ensure to explicitly check if args.chain matches router_endpoint.chain before proceeding in update_cctp_router_endpoint. This validation will prevent incorrect updates to the router_endpoint.chain field, ensuring that PDA derivation remains valid and mitigating potential denial-of-service vulnerabilities.",https://github.com/wormhole-foundation/example-liquidity-layer/pull/190/files,High
Sol-103,"Lack Of Mint Account Verification. process_approve_account ensures that a given token account is configured correctly for confidential transfers by authorizing the account’s authority. However, it lacks a crucial check to validate that the associated mint of the token account (token_account.base.mint) matches the mint for which the confidential transfer approval is being granted (mint_info.key). Thus, this enables the approval of a token account for confidential transfers, even if it is associated with a different mint. Ideally, token accounts should only be allowed to hold tokens from the specific mint they are associated with. By not checking the mint consistency, the function effectively approves arbitrary token accounts for confidential transfers. Such unauthorized token mixing may have security and financial implications, as it could result in loss of value or assets for users who rely on the token system’s integrity.","rust
/// Processes an [ApproveAccount] instruction.
fn process_approve_account(accounts: &[AccountInfo]) -> ProgramResult {
    let account_info_iter = &mut accounts.iter();
    let token_account_info = next_account_info(account_info_iter)?;
    let mint_info = next_account_info(account_info_iter)?;
    let authority_info = next_account_info(account_info_iter)?;

    check_program_account(token_account_info.owner)?;

    let token_account_data = &mut token_account_info.data.borrow_mut();
    let mut token_account = StateWithExtensionsMut::<Account>::unpack(token_account_data)?;

    check_program_account(mint_info.owner)?;

    let mint_data = &mint_info.data.borrow_mut();
    let mint = StateWithExtensions::<Mint>::unpack(mint_data)?;
    let confidential_transfer_mint = mint.get_extension::<ConfidentialTransferMint>()?;

    let maybe_confidential_transfer_mint_authority: Option<Pubkey> = 
        confidential_transfer_mint.authority.into();
    
    let confidential_transfer_mint_authority =
        maybe_confidential_transfer_mint_authority
        .ok_or(TokenError::NoAuthorityExists)?;

    if authority_info.is_signer && *authority_info.key == confidential_transfer_mint_authority {
        let confidential_transfer_state =
            token_account.get_extension_mut::<ConfidentialTransferAccount>()?;

        confidential_transfer_state.approved = true.into();

        Ok(())
    } else {
        Err(ProgramError::MissingRequiredSignature)
    }
}","rust
/// Processes an [ApproveAccount] instruction.
fn process_approve_account(accounts: &[AccountInfo]) -> ProgramResult {
    let account_info_iter = &mut accounts.iter();

    let token_account_info = next_account_info(account_info_iter)?;
    let mint_info = next_account_info(account_info_iter)?;
    let authority_info = next_account_info(account_info_iter)?;

    check_program_account(token_account_info.owner)?;

    let token_account_data = &mut token_account_info.data.borrow_mut();
    let mut token_account = StateWithExtensionsMut::<Account>::unpack(token_account_data)?;

    if *mint_info.key != token_account.base.mint {
        return Err(TokenError::MintMismatch.into());
    }

    check_program_account(mint_info.owner)?;

    let mint_data = &mint_info.data.borrow_mut();
    let mint = StateWithExtensions::<Mint>::unpack(mint_data)?;

    let confidential_transfer_mint = mint.get_extension::<ConfidentialTransferMint>()?;
    let maybe_confidential_transfer_mint_authority: Option<Pubkey> =
        confidential_transfer_mint.authority.into();
    let confidential_transfer_mint_authority =
        maybe_confidential_transfer_mint_authority.ok_or(TokenError::NoAuthorityExists)?;

    if authority_info.is_signer && *authority_info.key == confidential_transfer_mint_authority {
        let confidential_transfer_state =
            token_account.get_extension_mut::<ConfidentialTransferAccount>()?;
        confidential_transfer_state.approved = true.into();

        Ok(())
    } else {
        Err(ProgramError::MissingRequiredSignature)
    }
}",Medium,Incorporate the following verification within process_approve_account to confirm that the token account’s associated mint aligns with the mint for which the confidential transfer approval is sought.,"https://github.com/solana-labs/solana-program-library/pull/5901/files#diff-8a2747b10b71ae983dd511b549f3ffcbdcf328a23e655ea79a7c38e01ec383d9, https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/e21cbb09-5ce7-48c8-954e-5077c486a579/solana_token22_audit_final.pdf?table=block&id=88fc9b14-b183-49ee-aa0a-29c29c1eaf89&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742961600000&signature=H_I1MmWaBTT1ZTabCmBV6FDaHowAV7WGiNbDzY0_3Yc&downloadName=solana_token22_audit_final.pdf",High
Sol-104,"Missing Signer Check On Accounts. The vulnerability pertains to the management of multi-signature accounts when constructing withdrawal instructions for withheld tokens within the confidential transfer fee extension in both withdraw_withheld_tokens_from_mint and withdraw_withheld_tokens_from_accounts. The problem concerns the handling of multi-signature accounts as non-signer accounts within inner_withdraw_withheld_tokens_from_mint and inner_withdraw_withheld_tokens_from_accounts. In the context of the withdrawal operation, the program should recognize multi-signature accounts as signers, but currently, it treats them incorrectly as non-signers. This may result in transaction failures when multiple signers are involved, primarily during the owner check for multi-signature accounts. Proof of Concept 1. There exists a multi signature account named multisig_account configured to require three signers: signer1, signer2, and signer3. The purpose of this multi-signature account is to authorize the withdrawal of withheld tokens. 2. When creating the withdrawal instruction through inner_withdraw_withheld_tokens_from_mint, multisig_account is specified as a read-only, non-signer account. 3. In a transaction, if signer1, signer2, and signer3 provide their signatures to authorize the withdrawal, the Solana runtime may fail to recognize their authorization due to the way the instruction was constructed. 4. Consequently, this may result in transaction failure as the code incorrectly categorizes the multisignature account as a non-signer account.","rust
/// Create an inner `WithdrawWithheldTokensFromMint` instruction 
/// 
/// This instruction is suitable for use with a cross-program `invoke` 
pub fn inner_withdraw_withheld_tokens_from_mint(
    token_program_id: &Pubkey, 
    mint: &Pubkey, 
    destination: &Pubkey, 
    new_decryptable_available_balance: &DecryptableBalance, 
    authority: &Pubkey, 
    multisig_signers: &[&Pubkey], 
    proof_data_location: ProofLocation<CiphertextCiphertextEqualityProofData>,
) -> Result<Instruction, ProgramError> {
    check_program_account(token_program_id)?;
    
    let mut accounts = vec![
        AccountMeta::new(*mint, false), 
        AccountMeta::new(*destination, false),
    ];
    
    let proof_instruction_offset = match proof_data_location {
        ProofLocation::InstructionOffset(proof_instruction_offset, _) => {
            accounts.push(AccountMeta::new_readonly(sysvar::instructions::id(), false));
            proof_instruction_offset.into() 
        } 
        ProofLocation::ContextStateAccount(context_state_account) => {
            accounts.push(AccountMeta::new_readonly(*context_state_account, false)); 
            0 
        } 
    };
    
    accounts.push(AccountMeta::new_readonly(
        *authority, 
        multisig_signers.is_empty(),
    ));
    
    for multisig_signer in multisig_signers.iter() {
        accounts.push(AccountMeta::new(**multisig_signer, false));
    } 
    
    Ok(encode_instruction(
        token_program_id,
        accounts,
        TokenInstruction::ConfidentialTransferFeeExtension,
        ConfidentialTransferFeeInstruction::WithdrawWithheldTokensFromMint,
        &WithdrawWithheldTokensFromMintData {
            proof_instruction_offset,
            new_decryptable_available_balance: *new_decryptable_available_balance,
        },
    )) 
}

/// Create an inner `WithdrawWithheldTokensFromMint` instruction 
/// 
/// This instruction is suitable for use with a cross-program `invoke` 
#[allow(clippy::too_many_arguments)]
pub fn inner_withdraw_withheld_tokens_from_accounts(
    token_program_id: &Pubkey, 
    mint: &Pubkey, 
    destination: &Pubkey, 
    new_decryptable_available_balance: &DecryptableBalance, 
    authority: &Pubkey, 
    multisig_signers: &[&Pubkey], 
    sources: &[&Pubkey], 
    proof_data_location: ProofLocation<CiphertextCiphertextEqualityProofData>,
) -> Result<Instruction, ProgramError> {
    check_program_account(token_program_id)?;
    
    let num_token_accounts =
        u8::try_from(sources.len()).map_err(|_| ProgramError::InvalidInstructionData)?;
    
    let mut accounts = vec![
        AccountMeta::new(*mint, false), 
        AccountMeta::new(*destination, false),
    ];
    
    let proof_instruction_offset = match proof_data_location {
        ProofLocation::InstructionOffset(proof_instruction_offset, _) => {
            accounts.push(AccountMeta::new_readonly(sysvar::instructions::id(), false));
            proof_instruction_offset.into() 
        } 
        ProofLocation::ContextStateAccount(context_state_account) => {
            accounts.push(AccountMeta::new_readonly(*context_state_account, false)); 
            0 
        }
    };
    
    accounts.push(AccountMeta::new_readonly(
        *authority, 
        multisig_signers.is_empty(),
    ));
    
    for multisig_signer in multisig_signers.iter() {
        accounts.push(AccountMeta::new(**multisig_signer, false)); 
    } 
    
    for source in sources.iter() {
        accounts.push(AccountMeta::new(**source, false)); 
    }
    
    Ok(encode_instruction(
        token_program_id,
        accounts,
        TokenInstruction::ConfidentialTransferFeeExtension,
        ConfidentialTransferFeeInstruction::WithdrawWithheldTokensFromAccounts,
        &WithdrawWithheldTokensFromAccountsData {
            proof_instruction_offset,
            num_token_accounts,
            new_decryptable_available_balance: *new_decryptable_available_balance,
        },
    )) 
}","/// Create an inner `WithdrawWithheldTokensFromMint` instruction
///
/// This instruction is suitable for use with a cross-program `invoke`
pub fn inner_withdraw_withheld_tokens_from_mint(
    token_program_id: &Pubkey,
    mint: &Pubkey,
    destination: &Pubkey,
    new_decryptable_available_balance: &DecryptableBalance,
    authority: &Pubkey,
    multisig_signers: &[&Pubkey],
    proof_data_location: ProofLocation<CiphertextCiphertextEqualityProofData>,
) -> Result<Instruction, ProgramError> {
    check_program_account(token_program_id)?;
    
    let mut accounts = vec![
        AccountMeta::new(*mint, false),
        AccountMeta::new(*destination, false),
    ];

    let proof_instruction_offset = match proof_data_location {
        ProofLocation::InstructionOffset(proof_instruction_offset, _) => {
            accounts.push(AccountMeta::new_readonly(sysvar::instructions::id(), false));
            proof_instruction_offset.into()
        }
        ProofLocation::ContextStateAccount(context_state_account) => {
            accounts.push(AccountMeta::new_readonly(*context_state_account, false));
            0
        }
    };

    accounts.push(AccountMeta::new_readonly(
        *authority,
        multisig_signers.is_empty(),
    ));

    for multisig_signer in multisig_signers.iter() {
        accounts.push(AccountMeta::new_readonly(**multisig_signer, true));
    }

    Ok(encode_instruction(
        token_program_id,
        accounts,
        TokenInstruction::ConfidentialTransferFeeExtension,
        ConfidentialTransferFeeInstruction::WithdrawWithheldTokensFromMint,
        &WithdrawWithheldTokensFromMintData {
            proof_instruction_offset,
            new_decryptable_available_balance: *new_decryptable_available_balance,
        },
    ))
}

/// Create an inner `WithdrawWithheldTokensFromMint` instruction
///
/// This instruction is suitable for use with a cross-program `invoke`
#[allow(clippy::too_many_arguments)]
pub fn inner_withdraw_withheld_tokens_from_accounts(
    token_program_id: &Pubkey,
    mint: &Pubkey,
    destination: &Pubkey,
    new_decryptable_available_balance: &DecryptableBalance,
    authority: &Pubkey,
    multisig_signers: &[&Pubkey],
    sources: &[&Pubkey],
    proof_data_location: ProofLocation<CiphertextCiphertextEqualityProofData>,
) -> Result<Instruction, ProgramError> {
    check_program_account(token_program_id)?;

    let num_token_accounts = u8::try_from(sources.len())
        .map_err(|_| ProgramError::InvalidInstructionData)?;

    let mut accounts = vec![
        AccountMeta::new(*mint, false),
        AccountMeta::new(*destination, false),
    ];

    let proof_instruction_offset = match proof_data_location {
        ProofLocation::InstructionOffset(proof_instruction_offset, _) => {
            accounts.push(AccountMeta::new_readonly(sysvar::instructions::id(), false));
            proof_instruction_offset.into()
        }
        ProofLocation::ContextStateAccount(context_state_account) => {
            accounts.push(AccountMeta::new_readonly(*context_state_account, false));
            0
        }
    };

    accounts.push(AccountMeta::new_readonly(
        *authority,
        multisig_signers.is_empty(),
    ));

    for multisig_signer in multisig_signers.iter() {
        accounts.push(AccountMeta::new_readonly(**multisig_signer, true));
    }

    for source in sources.iter() {
        accounts.push(AccountMeta::new(**source, false));
    }

    Ok(encode_instruction(
        token_program_id,
        accounts,
        TokenInstruction::ConfidentialTransferFeeExtension,
        ConfidentialTransferFeeInstruction::WithdrawWithheldTokensFromAccounts,
        &WithdrawWithheldTokensFromAccountsData {
            proof_instruction_offset,
            num_token_accounts,
            new_decryptable_available_balance: *new_decryptable_available_balance,
        },
    ))
}",Low,Designate multi-signature accounts as signers for authorizing transactions.,"https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/e21cbb09-5ce7-48c8-954e-5077c486a579/solana_token22_audit_final.pdf?table=block&id=88fc9b14-b183-49ee-aa0a-29c29c1eaf89&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742961600000&signature=H_I1MmWaBTT1ZTabCmBV6FDaHowAV7WGiNbDzY0_3Yc&downloadName=solana_token22_audit_final.pdf, https://github.com/solana-labs/solana-program-library/pull/5900/files",High
Sol-105,"BatchedRangeProofU128Data::new creates a new BatchedRangeProofU128Data instance, which includes generating a batched range proof for a set of commitments, values, bit lengths, and openings. It performs validation to ensure that the sum of bit lengths is 128 (128 bits in a 128-bit value), and it checks for potential overflows during bit length calculations. It is similar in BatchedRangeProofU256Data::new. In BatchedRangeProofU128Data::new, a calculation of batched_bit_length represents the total number of bits required to represent the batched range of values. This calculation is performed by iterating through the the bit_lengths vector and summing all the bit lengths. The issue is related to the potential of right shift operations (>>) causing an overflow panic when dealing with u128 and u256 range proofs, especially when elements in the bit_lengths vector are greater than 64. This occurs as bit lengths are not validated, as shown in BatchedRangeProofU128Data::new above. Proof of Concept 1. The protocol accepts a list of commitments that is less than or equal to MAX_COMMITMENTS. 2. Suppose we need to create a batched u128 range proof for a set of 3 commitments where one commitment has a bit length greater than 64. 3. Here is a simplified example of such data: let bit_lengths = vec![70, 30, 28]; 4. In this case, the bit_lengths vector contains three elements: 70, 30, and 28. 5. When the batched_bit_length is calculated, it will sum up these values: let batched_bit_length = 70 + 30 + 28; 6. The value of batched_bit_length will be 128, which satisfies the u128 type, but the bit length for the first commitment is 70, which is greater than 64, which will cause a panic. 7. Attempting to perform a right shift operation (>>) on this element would cause an overflow panic as u128 may only represent values up to 2 128 − 1.","rust
use {
    crate::{
        range_proof::{
            errors::{RangeProofGenerationError, RangeProofVerificationError},
            util,
        },
        transcript::TranscriptProtocol,
    },
    core::iter,
    curve25519_dalek::{
        ristretto::{CompressedRistretto, RistrettoPoint},
        scalar::Scalar,
        traits::{MultiscalarMul, VartimeMultiscalarMul},
    },
    merlin::Transcript,
    std::borrow::Borrow,
};

#[allow(non_snake_case)] 
#[derive(Clone)]
pub struct InnerProductProof {
    pub L_vec: Vec<CompressedRistretto>, // 32 * log(bit_length) 
    pub R_vec: Vec<CompressedRistretto>, // 32 * log(bit_length)
    pub a: Scalar, // 32 bytes
    pub b: Scalar, // 32 bytes
}

#[allow(non_snake_case)] 
impl InnerProductProof {
    #[allow(clippy::too_many_arguments)]
    pub fn new(
        Q: &RistrettoPoint,
        G_factors: &[Scalar],
        H_factors: &[Scalar],
        mut G_vec: Vec<RistrettoPoint>,
        mut H_vec: Vec<RistrettoPoint>,
        mut a_vec: Vec<Scalar>,
        mut b_vec: Vec<Scalar>,
        transcript: &mut Transcript,
    ) -> Result<Self, RangeProofGenerationError> {
        
        let mut G = &mut G_vec[..];
        let mut H = &mut H_vec[..];
        let mut a = &mut a_vec[..];
        let mut b = &mut b_vec[..];

        let mut n = G.len();

        if G.len() != n || H.len() != n || a.len() != n || b.len() != n || G_factors.len() != n || H_factors.len() != n {
            return Err(RangeProofGenerationError::GeneratorLengthMismatch);
        }

        if !n.is_power_of_two() {
            return Err(RangeProofGenerationError::InvalidBitSize);
        }

        transcript.innerproduct_domain_separator(n as u64);

        let lg_n = n.next_power_of_two().trailing_zeros() as usize;
        let mut L_vec = Vec::with_capacity(lg_n);
        let mut R_vec = Vec::with_capacity(lg_n);

        if n != 1 {
            n /= 2;
        
            let (a_L, a_R) = a.split_at_mut(n);
            let (b_L, b_R) = b.split_at_mut(n);
            let (G_L, G_R) = G.split_at_mut(n);
        
            let (H_L, H_R) = H.split_at_mut(n);
            let c_L = util::inner_product(a_L, b_R);
            let c_R = util::inner_product(a_R, b_L);

            let L = RistrettoPoint::multiscalar_mul(
                a_L.iter()
                    .zip(G_factors[n..2 * n].iter())
                    .map(|(a_L_i, g)| a_L_i * g)
                    .chain(b_R.iter().zip(H_factors[0..n].iter()).map(|(b_R_i, h)| b_R_i * h))
                    .chain(iter::once(c_L)),
                G_R.iter().chain(H_L.iter()).chain(iter::once(Q)),
            )
            .compress();

            let R = RistrettoPoint::multiscalar_mul(
                a_R.iter()
                    .zip(G_factors[0..n].iter())
                    .map(|(a_R_i, g)| a_R_i * g)
                    .chain(b_L.iter().zip(H_factors[n..2 * n].iter()).map(|(b_L_i, h)| b_L_i * h))
                    .chain(iter::once(c_R)),
                G_L.iter().chain(H_R.iter()).chain(iter::once(Q)),
            )
            .compress();

            L_vec.push(L);
            R_vec.push(R);

            transcript.append_point(b""L"", &L);
            transcript.append_point(b""R"", &R);

            let u = transcript.challenge_scalar(b""u"");
            let u_inv = u.invert();

            for i in 0..n {
                a_L[i] = a_L[i] * u + u_inv * a_R[i];
                b_L[i] = b_L[i] * u_inv + u * b_R[i];

                G_L[i] = RistrettoPoint::multiscalar_mul(
                    &[u_inv * G_factors[i], u * G_factors[n + i]],
                    &[G_L[i], G_R[i]],
                );

                H_L[i] = RistrettoPoint::multiscalar_mul(
                    &[u * H_factors[i], u_inv * H_factors[n + i]],
                    &[H_L[i], H_R[i]],
                );
            }

            a = a_L;
            b = b_L;
            G = G_L;
            H = H_L;
        }

        while n != 1 {
            n /= 2;

            let (a_L, a_R) = a.split_at_mut(n);
            let (b_L, b_R) = b.split_at_mut(n);
            let (G_L, G_R) = G.split_at_mut(n);

            let (H_L, H_R) = H.split_at_mut(n);
            let c_L = util::inner_product(a_L, b_R);
            let c_R = util::inner_product(a_R, b_L);

            let L = RistrettoPoint::multiscalar_mul(
                a_L.iter().chain(b_R.iter()).chain(iter::once(&c_L)),
                G_R.iter().chain(H_L.iter()).chain(iter::once(Q)),
            )
            .compress();

            let R = RistrettoPoint::multiscalar_mul(
                a_R.iter().chain(b_L.iter()).chain(iter::once(&c_R)),
                G_L.iter().chain(H_R.iter()).chain(iter::once(Q)),
            )
            .compress();

            L_vec.push(L);
            R_vec.push(R);

            transcript.append_point(b""L"", &L);
            transcript.append_point(b""R"", &R);

            let u = transcript.challenge_scalar(b""u"");
            let u_inv = u.invert();

            for i in 0..n {
                a_L[i] = a_L[i] * u + u_inv * a_R[i];
                b_L[i] = b_L[i] * u_inv + u * b_R[i];
                G_L[i] = RistrettoPoint::multiscalar_mul(&[u_inv, u], &[G_L[i], G_R[i]]);
                H_L[i] = RistrettoPoint::multiscalar_mul(&[u, u_inv], &[H_L[i], H_R[i]]);
            }

            a = a_L;
            b = b_L;
            G = G_L;
            H = H_L;
        }

        Ok(InnerProductProof {
            L_vec,
            R_vec,
            a: a[0],
            b: b[0],
        })
    }

    pub(crate) fn verification_scalars(
        &self,
        n: usize,
        transcript: &mut Transcript,
    ) -> Result<(Vec<Scalar>, Vec<Scalar>, Vec<Scalar>), RangeProofVerificationError> {
        let lg_n = self.L_vec.len();

        if lg_n == 0 || lg_n >= 32 {
            return Err(RangeProofVerificationError::InvalidBitSize);
        }

        if n != (1 << lg_n) {
            return Err(RangeProofVerificationError::InvalidBitSize);
        }

        transcript.innerproduct_domain_separator(n as u64);

        let mut challenges = Vec::with_capacity(lg_n);
        
        for (L, R) in self.L_vec.iter().zip(self.R_vec.iter()) {
            transcript.validate_and_append_point(b""L"", L)?;
            transcript.validate_and_append_point(b""R"", R)?;
            challenges.push(transcript.challenge_scalar(b""u""));
        }

        let mut challenges_inv = challenges.clone();
        let allinv = Scalar::batch_invert(&mut challenges_inv);

        for i in 0..lg_n {
            challenges[i] = challenges[i] * challenges[i];
            challenges_inv[i] = challenges_inv[i] * challenges_inv[i];
        }

        let challenges_sq = challenges;
        let challenges_inv_sq = challenges_inv;

        let mut s = Vec::with_capacity(n);
        s.push(allinv);
        
        for i in 1..n {
            let lg_i = (32 - 1 - (i as u32).leading_zeros()) as usize;
            let k = 1 << lg_i;
            let u_lg_i_sq = challenges_sq[(lg_n - 1) - lg_i];

            s.push(s[i - k] * u_lg_i_sq);
        }

        Ok((challenges_sq, challenges_inv_sq, s))
    }
}","rust
use {
    crate::{
        range_proof::{
            errors::{RangeProofGenerationError, RangeProofVerificationError},
            util,
        },
        transcript::TranscriptProtocol
    },
    core::iter,
    curve25519_dalek::{
        ristretto::{CompressedRistretto, RistrettoPoint},
        scalar::Scalar,
        traits::{MultiscalarMul, VartimeMultiscalarMul},
    },
    merlin::Transcript,
    std::borrow::Borrow,
};

#[allow(non_snake_case)]
#[derive(Clone)]
pub struct InnerProductProof {
    pub L_vec: Vec<CompressedRistretto>,
    pub R_vec: Vec<CompressedRistretto>,
    pub a: Scalar,
    pub b: Scalar,
}

#[allow(non_snake_case)]
impl InnerProductProof {
    #[allow(clippy::too_many_arguments)]
    pub fn new(
        Q: &RistrettoPoint,
        G_factors: &[Scalar],
        H_factors: &[Scalar],
        mut G_vec: Vec<RistrettoPoint>,
        mut H_vec: Vec<RistrettoPoint>,
        mut a_vec: Vec<Scalar>,
        mut b_vec: Vec<Scalar>,
        transcript: &mut Transcript,
    ) -> Result<Self, RangeProofGenerationError> {

        let mut G = &mut G_vec[..];
        let mut H = &mut H_vec[..];
        let mut a = &mut a_vec[..];
        let mut b = &mut b_vec[..];
        let mut n = G.len();

        if G.len() != n || H.len() != n || a.len() != n || b.len() != n || G_factors.len() != n || H_factors.len() != n {
            return Err(RangeProofGenerationError::GeneratorLengthMismatch);
        }

        if !n.is_power_of_two() {
            return Err(RangeProofGenerationError::InvalidBitSize);
        }

        transcript.innerproduct_domain_separator(n as u64);
        let lg_n = n.next_power_of_two().trailing_zeros() as usize;
        let mut L_vec = Vec::with_capacity(lg_n);
        let mut R_vec = Vec::with_capacity(lg_n);

        if n != 1 {
            n = n.checked_div(2).unwrap();
            let (a_L, a_R) = a.split_at_mut(n);
            let (b_L, b_R) = b.split_at_mut(n);
            let (G_L, G_R) = G.split_at_mut(n);
            
            let (H_L, H_R) = H.split_at_mut(n);
            let c_L = util::inner_product(a_L, b_R);
            let c_R = util::inner_product(a_R, b_L);

            // ... and so on
    }

    // Other methods like verification_scalars, etc.
}",High,Ensure that a right shift operation will not overflow for bit lengths exceeding 64 bits.,https://github.com/solana-labs/solana/pull/34065/commits/c155a204810ea2d39ff9869300b309e3fe90733a,High
Sol-106,"In discrete_log, set_compression_batch_size enables users to set the compression batch size utilized during the discrete logarithm computation. The compression_batch_size parameter determines how many Ristretto points are processed together in each batch during the discrete logarithm computation. Currently, there is no check to ensure if compression_batch_size is set to zero, resulting in no points being processed in a batch.The issue arises in decode_u32, designed to iterate through the Ristretto points in batches. Consequently, when the batch size is set to zero, this iteration logic breaks down, as there are no points to process in each batch. The code in decode_u32 expects to process a non-empty batch of points and is unable to handle the scenario of an empty batch properly, resulting in a panic.","rust
/// Adjusts inversion batch size in a discrete log instance. 
pub fn set_compression_batch_size(
    &mut self,
    compression_batch_size: usize,
) -> Result<(), DiscreteLogError> {
    if compression_batch_size >= TWO16 as usize {
        return Err(DiscreteLogError::DiscreteLogBatchSize);
    }

    self.compression_batch_size = compression_batch_size;

    Ok(())
}","rust
/// Adjusts inversion batch size in a discrete log instance. 
pub fn set_compression_batch_size(&mut self, compression_batch_size: usize,) -> Result<(), DiscreteLogError> {
    if compression_batch_size >= TWO16 as usize || compression_batch_size == 0 {
        return Err(DiscreteLogError::DiscreteLogBatchSize);
    }
    self.compression_batch_size = compression_batch_size;

    Ok(())
}",Medium,Ensure that compression_batch_size is always set to a positive value greater than zero. Add a validation check in set_compression_batch_size to prevent setting it to zero:,https://github.com/solana-labs/solana/pull/33699/commits/4c0dc00f9e41e46b23f2aa271e8b603decd593a5,High
Sol-107,"The issue arises due to a lack of explicit checks or restrictions on the length of the seed input, which may result in issues, including a stack overflow or panic if the seed length is very high. The code recursively calls Self::from_seed(seed)?, resulting in a panic.","rust
impl SeedDerivable for AeKey { 
    fn from_seed(seed: &[u8]) -> Result<Self, Box<dyn error::Error>> {
        const MINIMUM_SEED_LEN: usize = AE_KEY_LEN; 
        if seed.len() < MINIMUM_SEED_LEN { 
            return Err(AuthenticatedEncryptionError::SeedLengthTooShort.into()); 
        }
        let mut hasher = Sha3_512::new(); 
        hasher.update(seed); 
        // Missing addition/deletions here
    }
   
    // Some tests...
    mod tests { 
        // Some further tests here...
    }
}","rust
impl SeedDerivable for AeKey {
    fn from_seed(seed: &[u8]) -> Result<Self, Box<dyn error::Error>> { 
        const MINIMUM_SEED_LEN: usize = AE_KEY_LEN; 
        const MAXIMUM_SEED_LEN: usize = 65535; 

        if seed.len() < MINIMUM_SEED_LEN { 
            return Err(AuthenticatedEncryptionError::SeedLengthTooShort.into()); 
        }

        if seed.len() > MAXIMUM_SEED_LEN { 
            return Err(AuthenticatedEncryptionError::SeedLengthTooLong.into()); 
        }
        
        let mut hasher = Sha3_512::new(); 
        hasher.update(seed); 

        Expand Down 
        Expand Up 
        @@ -278,4 +284,16 @@ mod tests { let result = hasher.finalize(); 

        Ok(Self(result[..AE_KEY_LEN].try_into()?)) 
    }

    fn from_seed_and_derivation_path(
        _seed: &[u8], 
        _derivation_path: Option<DerivationPath>,
    ) -> Result<Self, Box<dyn error::Error>> { 
        Err(AuthenticatedEncryptionError::DerivationMethodNotSupported.into()) 
    }
}",Medium,Implement a check that ensures the seed length does not exceed a preset value.,https://github.com/solana-labs/solana/pull/33700/files#diff-8e0f5e2484afe07494baa6995029cfde17aaa6c3e7030c98f7a0d266790c4a66,High
Sol-108,"Rent Misallocation. In approve_redeem_request.rs, the rent for closing the RedeemRequest is directed to the merchant. However, it should be assigned to merchant_authority, which represents the account that executed the initial payment.","rust
pub merchant: Account<'info, Merchant>,
#[account(mut, close = merchant, has_one = merchant, )]
pub redeem_request: Account<'info, RedeemRequest>,
pub token_program: Program<'info, Token>,
}","rust
pub merchant: Account<'info, Merchant>,
#[account(mut, close = merchant_authority, has_one = merchant, )]
pub redeem_request: Account<'info, RedeemRequest>,
pub token_program: Program<'info, Token>,",Medium,Change the value of close in the ApproveRedeemRequestAccounts struct’s redeem_request from merchant to merchant_authority.,https://github.com/solana-labs/wbtc/commit/b559f5bca487a067ecdd2b3df115c252b13ca057,High
Sol-109,"There is no delay mechanism on updating deposit fees and an upper bound of 100%. A user that submits a large deposit could be front-run by a pool manager who sets the fee close to 100% (ensuring that user still receives 1 pool token), receives almost the full value of the deposit, and then reduces the fee afterward.","rust
/// Creates instructions required to deposit into a stake pool, given a stake 
pub fn deposit_stake(
    program_id: &Pubkey,
    stake_pool: &Pubkey,
    validator_list_storage: &Pubkey,
    stake_pool_withdraw_authority: &Pubkey,
    deposit_stake_address: &Pubkey,
    deposit_stake_withdraw_authority: &Pubkey,
    referrer_pool_tokens_account: &Pubkey,
    pool_mint: &Pubkey,
    token_program_id: &Pubkey,
) -> Vec<Instruction>{
    // Function logic goes here...
}

/// Creates instructions required to deposit into a stake pool, given a stake 
pub fn deposit_stake_with_authority(
    pool_mint: &Pubkey, 
    token_program_id: &Pubkey,
) -> Vec<Instruction> {
    // Function logic goes here...
}

/// Creates instructions required to deposit SOL directly into a stake pool.
pub fn deposit_sol(
    program_id: &Pubkey,
    stake_pool: &Pubkey,
    stake_pool_withdraw_authority: &Pubkey,
    referrer_pool_tokens_account: &Pubkey,
    pool_mint: &Pubkey,
    token_program_id: &Pubkey,
    amount: u64,
) -> Instruction {
    // Function logic goes here...
}

/// Creates instruction required to deposit SOL directly into a stake pool. The difference with `deposit_sol()` is that a deposit authority must sign this instruction.
pub fn deposit_sol_with_authority(
    referrer_pool_tokens_account: &Pubkey,
    pool_mint: &Pubkey,
    token_program_id: &Pubkey,
    amount: u64,
) -> Instruction {
    // Function logic goes here...
}

// And so on...","rust
/// Deposit some stake into the pool, with a specified slippage constraint. 
/// The output is a ""pool"" token representing ownership into the pool. 
/// Inputs are converted at the current ratio. 
/// 
/// 0. `[w]` Stake pool 
/// 1. `[w]` Validator stake list storage account 
/// 2. `[s]/[]` Stake pool deposit authority 
/// 3. `[]` Stake pool withdraw authority 
/// 4. `[w]` Stake account to join the pool (withdraw authority for the stake account should be first set to the stake pool deposit authority) 
/// 5. `[w]` Validator stake account for the stake account to be merged with 
/// 6. `[w]` Reserve stake account, to withdraw rent exempt reserve 
/// 7. `[w]` User account to receive pool tokens 
/// 8. `[w]` Account to receive pool fee tokens 
/// 9. `[w]` Account to receive a portion of pool fee tokens as referral fees 
/// 10. `[w]` Pool token mint account 
/// 11. '[]' Sysvar clock account 
/// 12. '[]' Sysvar stake history account 
/// 13. `[]` Pool token program id, 
/// 14. `[]` Stake program id, 
DepositStakeWithSlippage { 
/// Minimum amount of pool tokens that must be received 
minimum_pool_tokens_out: u64, },
/// Withdraw the token from the pool at the current ratio, specifying a 
/// minimum expected output lamport amount. 
/// 
... 
// Rest of the code",High,Add instructions that allow the user to specify the minimum amount of tokens they expect to receive.,"https://github.com/solana-labs/solana-program-library/pull/3980, https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/f5079737-734d-4b73-88a5-4c00eb20015d/Solana_Stake_Pool_audit_final.pdf?table=block&id=353af6fc-8c19-4e59-aefc-3aebc813b926&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743307200000&signature=ga0AQbGGoM7PDHTRtRK5aEOAatzTupp7GT5nQAkWS80&downloadName=Solana+Stake+Pool+Audit+Report.pdf",High
Sol-110,"There is no delay mechanism on updating deposit fees and an upper bound of 100%. A user that submits a large deposit could be front-run by a pool manager who sets the fee close to 100% (ensuring that user still receives 1 pool token), receives almost the full value of the deposit, and then reduces the fee afterward.","rust
fn process_deposit_stake(program_id: &Pubkey, accounts: &[AccountInfo]) -> ProgramResult { 
    let account_info_iter = &mut accounts.iter(); 
    let stake_pool_info = next_account_info(account_info_iter)?; 
    let validator_list_info = next_account_info(account_info_iter)?; 

    // ... 

    if condition { // Replace with actual condition
        return Err(StakePoolError::DepositTooSmall.into()); 
    } 

    Self::token_mint_to( 
        stake_pool_info.key, 
        token_program_info.clone(),
        // ... 
    );

    // ... 
    
    let new_reserve_lamports = reserve_stake_info
        .lamports()
        .saturating_sub(withdraw_lamports); 

    // ... 
}","rust
fn process_deposit_stake( 
    program_id: &Pubkey, 
    accounts: &[AccountInfo], 
    minimum_pool_tokens_out: Option<u64>,
) -> ProgramResult { 
    let account_info_iter = &mut accounts.iter(); 
    let stake_pool_info = next_account_info(account_info_iter)?; 
    let validator_list_info = next_account_info(account_info_iter)?;
    // Rest of the code trimmed for clarity
}",High,Add instructions that allow the user to specify the minimum amount of tokens they expect to receive.,https://github.com/solana-labs/solana-program-library/pull/3980,High
Sol-111,"The rightmost_proof.index value represents the index of first empty leaf. In case the tree is full, it’s value is equal to 1<<MAX_DEPTH which doesn’t correspond to any valid leaf index. In functions set_leaf() and prove_leaf() the leaf index is compared to value of rightmost_proof.index to determine whether it is valid.Proof of Concept 1. Initialize concurrent merkle tree with MAX_DEPTH=3 2. Append 8 leafs in order to fill the tree and set rightmost_proof.index to 8==1<<MAX_DEPTH 3. Run set_leaf() with following parameters: • current_root set to current root value • previous_leaf set to value of leaf with index 0 • new_leaf with the desired new value • proof_vec with the proof for leaf with index 0 • index set to 8","rust
pub fn prove_leaf( 
    &self, 
    current_root: Node, 
    leaf: Node, 
    proof_vec: &[Node], 
    leaf_index: u32, 
) -> Result<(), ConcurrentMerkleTreeError> { 
    check_bounds(MAX_DEPTH, MAX_BUFFER_SIZE); 

    if leaf_index > self.rightmost_proof.index { 
        solana_logging!(
            ""Received an index larger than the rightmost index {} > {}"", 
            leaf_index, 
            self.rightmost_proof.index 
        ); 

        Err(ConcurrentMerkleTreeError::LeafIndexOutOfBounds) 
    } else { 
        let mut proof: [Node; MAX_DEPTH] = [Node::default(); MAX_DEPTH]; 
        fill_in_proof::<MAX_DEPTH>(proof_vec, &mut proof); 
        
        let valid_root = self.check_valid_leaf(current_root, leaf, &mut proof, leaf_index, true)?; 
        
        if !valid_root { 
            solana_logging!(""Proof failed to verify""); 
            return Err(ConcurrentMerkleTreeError::InvalidProof); 
        } 
        
        Ok(()) 
    } 
}","rust
pub fn prove_leaf(
    &self, 
    current_root: Node, 
    leaf: Node, 
    proof_vec: &[Node], 
    leaf_index: u32, 
) -> Result<(), ConcurrentMerkleTreeError> {
    check_bounds(MAX_DEPTH, MAX_BUFFER_SIZE);

    if leaf_index > self.rightmost_proof.index || leaf_index >= 1 << MAX_DEPTH {
        solana_logging!(
            ""Received an index larger than the rightmost index {} > {}"", 
            leaf_index, 
            self.rightmost_proof.index
        );

        Err(ConcurrentMerkleTreeError::LeafIndexOutOfBounds)
    } else {
        let mut proof: [Node; MAX_DEPTH] = [Node::default(); MAX_DEPTH];
        fill_in_proof::<MAX_DEPTH>(proof_vec, &mut proof);
        
        let valid_root = self.check_valid_leaf(current_root, leaf, &mut proof, leaf_index, true)?;
        
        if !valid_root {
            solana_logging!(""Proof failed to verify"");
            return Err(ConcurrentMerkleTreeError::InvalidProof);
        }
        
        Ok(())
    }
}",Medium,Any function that takes an index as a parameter should confirm that it is • less than or equal to rightmost_proof.index • less than 1<<MAX_DEPTH,https://solodit.cyfrin.io/issues/off-by-one-in-leaf-index-ottersec-none-solana-account-compression-pdf,High
Sol-112,"Owners can place sell orders on their NFTs by sending either a ListNftForSale instruction or a ListEditionForSale instruction to the program. Either instruction handler transfers the token’s authority to an account address derived from the program’s ID and a static seed and creates an order account. This account stores the ask price, NFT mint and several other parameters. Sellers may choose to cancel their orders before they’re filled. To accomplish that, they can send either a CancelNftSale or a CancelEditionSale. Either instruction handler transfers the NFT’s authority back to the seller (NFT owner) and closes the order account, sending the rent back to the seller. However, because neither the CancelNftSale instruction handler nor the CancelEditionSale instruction handler verifies if the NFT owner is, in fact, a transaction signer, an anonymous attacker may cause a DoS of the program by cancelling all sell orders.","rust
processor/cancel_listing.rs
pub fn process_cancel_listing(accounts: &[AccountInfo], program_id: &Pubkey) -> ProgramResult {
    let account_info_iter = &mut accounts.iter();

    let seller_wallet_account = next_account_info(account_info_iter)?;
    let selling_nft_token_account = next_account_info(account_info_iter)?;
    let sell_order_data_storage_account = next_account_info(account_info_iter)?;
    let nft_store_signer_pda_account = next_account_info(account_info_iter)?;
    let token_program = next_account_info(account_info_iter)?;

    ...

    if sell_order_data.seller_wallet != *seller_wallet_account.key {
        msg!(""PhantasiaError::SellerMismatched"");
        return Err(PhantasiaError::SellerMismatched.into());
    }
}","rust
pub fn process_cancel_listing(accounts: &[AccountInfo], program_id: &Pubkey) -> ProgramResult {
    let account_info_iter = &mut accounts.iter();
    let seller_wallet_account = next_account_info(account_info_iter)?;
    let selling_nft_token_account = next_account_info(account_info_iter)?;
    let sell_order_data_storage_account = next_account_info(account_info_iter)?;
    let nft_store_signer_pda_account = next_account_info(account_info_iter)?;
    let token_program = next_account_info(account_info_iter)?;

    if !seller_wallet_account.is_signer {
        msg!(""PhantasiaError::UnauthorizedCancellation"");
        return Err(PhantasiaError::UnauthorizedCancellation.into());
    }

    if sell_order_data.seller_wallet != *seller_wallet_account.key {
        msg!(""PhantasiaError::SellerMismatched"");
        return Err(PhantasiaError::SellerMismatched.into());
    }
}",High,Verify if the NFT owner (seller) is indeed the signer of CancelNftSale and CancelEditionSale instructions before updating the state.,https://solodit.cyfrin.io/issues/anonymous-sell-order-cancelling-halborn-none-phantasia-sports-ntf-store-solana-program-pdf,High
Sol-113,Sandwich Attack,"rust
pub mod state;

use anchor_lang::prelude::*;
use anchor_spl::token::{self, Mint, Token, TokenAccount, Approve};
use whirlpool::{ self, state::{Whirlpool, TickArray, Position}, math::sqrt_price_from_tick_index, math::{mul_u256, U256Muldiv}, manager::liquidity_manager::calculate_liquidity_token_deltas, cpi::accounts::ModifyLiquidity, cpi::accounts::UpdateFeesAndRewards, cpi::accounts::CollectFees};
use solana_program::{pubkey::Pubkey, program::invoke_signed};
use spl_token::instruction::{burn_checked, mint_to};

pub use state::*;

declare_id!(""7ahQGWysExobjeZ91RTsNqTCN3kWyHGZ43ud2vB7VVoZ"");

#[program]
pub mod liquidity_lockbox {
    use super::*;
    use solana_program::pubkey;

    // Program Id
    const PROGRAM_ID: Pubkey = pubkey!(""7ahQGWysExobjeZ91RTsNqTCN3kWyHGZ43ud2vB7VVoZ"");

    // Orca Whirlpool program address
    const ORCA: Pubkey = pubkey!(""whirLbMiicVdio4qvUfM5KAg6Ct8VwpYzGff3uctyCc"");

    // OLAS-SOL Whirlpool address
    const WHIRLPOOL: Pubkey = pubkey!(""5dMKUYJDsjZkAD3wiV3ViQkuq9pSmWQ5eAzcQLtDnUT3"");

    // SOL address
    const SOL: Pubkey = pubkey!(""So11111111111111111111111111111111111111112"");

    // OLAS address
    const OLAS: Pubkey = pubkey!(""Ez3nzG9ofodYCvEmw73XhQ87LWNYVRM2s7diB5tBZPyM"");

    // Position account discriminator
    const POSITION_HEADER: [u8; 8] = [0xaa, 0xbc, 0x8f, 0xe4, 0x7a, 0x40, 0xf7, 0xd0];

    // Full range lower and upper indexes
    const TICK_LOWER_INDEX: i32 = -443584;
    const TICK_UPPER_INDEX: i32 = 443584;

    // Bridged token decimals
    const BRIDGED_TOKEN_DECIMALS: u8 = 8;

    /// Initializes a Lockbox account that stores state data.
    pub fn initialize(ctx: Context<InitializeLiquidityLockbox>) -> Result<()> {
        let whirlpool = ctx.accounts.position.whirlpool;
        let position_mint = ctx.accounts.position.position_mint;
        let liquidity = ctx.accounts.position.liquidity;
        let tick_lower_index = ctx.accounts.position.tick_lower_index;
        let tick_upper_index = ctx.accounts.position.tick_upper_index;

        // Check the whirlpool
        if whirlpool != WHIRLPOOL {
            return Err(ErrorCode::WrongWhirlpool.into());
        }

        // Check the discriminator
        let account = &ctx.accounts.position.to_account_info();
        let data = account.try_borrow_data()?;
        assert!(data.len() > 8);

        let mut discriminator = [0u8; 8];
        discriminator.copy_from_slice(&data[0..8]);

        if discriminator != POSITION_HEADER {
            return Err(ErrorCode::WrongPositionHeader.into());
        }

        // Check for the minimum liquidity in position
        if liquidity != 0 {
            return Err(ErrorCode::LiquidityNotZero.into());
        }

        // Check tick values
        if tick_lower_index != TICK_LOWER_INDEX || tick_upper_index != TICK_UPPER_INDEX {
            return Err(ErrorCode::OutOfRange.into());
        }

        // Check the PDA ownership
        if ctx.accounts.position.to_account_info().owner != &ORCA {
            return Err(ErrorCode::WrongOwner.into());
        }

        // Check the position PDA address correctness
        let position_pda = Pubkey::find_program_address(&[b""position"", position_mint.as_ref()], &ORCA);

        if position_pda.0 != ctx.accounts.position.key() {
            return Err(ErrorCode::WrongPositionPDA.into());
        }

        // Check that the first token mint is SOL
        if ctx.accounts.fee_collector_token_owner_account_a.mint != SOL {
            return Err(ErrorCode::WrongTokenMint.into());
        }

        // Check that the second token mint is OLAS
        if ctx.accounts.fee_collector_token_owner_account_b.mint != OLAS {
            return Err(ErrorCode::WrongTokenMint.into());
        }

        // Get the lockbox account
        let lockbox = &mut ctx.accounts.lockbox;

        // Get the anchor-derived bump
        let bump = *ctx.bumps.get(""lockbox"").unwrap();

        // Initialize lockbox account
        lockbox.initialize(
            bump,
            ctx.accounts.bridged_token_mint.key(),
            ctx.accounts.fee_collector_token_owner_account_a.key(),
            ctx.accounts.fee_collector_token_owner_account_b.key(),
            ctx.accounts.position.key(),
            ctx.accounts.pda_position_account.key()
        )?;
        Ok(())
    }

    // ... Remaining functions left out for brevity
}","pub mod state;

use anchor_lang::prelude::*;
use anchor_spl::token::{self, Mint, Token, TokenAccount, Approve};
use whirlpool::{
    self,
    state::{Whirlpool, TickArray, Position},
    cpi::accounts::ModifyLiquidity,
    cpi::accounts::UpdateFeesAndRewards,
    cpi::accounts::CollectFees
};
use solana_program::{pubkey::Pubkey, program::invoke_signed};
use spl_token::instruction::{burn_checked, mint_to};

pub use state::*;

declare_id!(""7ahQGWysExobjeZ91RTsNqTCN3kWyHGZ43ud2vB7VVoZ"");

#[program]
pub mod liquidity_lockbox {
    use super::*;
    use solana_program::pubkey;

    // Program Id
    const PROGRAM_ID: Pubkey = pubkey!(""7ahQGWysExobjeZ91RTsNqTCN3kWyHGZ43ud2vB7VVoZ"");

    // Orca Whirlpool program address
    const ORCA: Pubkey = pubkey!(""whirLbMiicVdio4qvUfM5KAg6Ct8VwpYzGff3uctyCc"");

    // OLAS-SOL Whirlpool address
    const WHIRLPOOL: Pubkey = pubkey!(""5dMKUYJDsjZkAD3wiV3ViQkuq9pSmWQ5eAzcQLtDnUT3"");

    // SOL address
    const SOL: Pubkey = pubkey!(""So11111111111111111111111111111111111111112"");

    // OLAS address
    const OLAS: Pubkey = pubkey!(""Ez3nzG9ofodYCvEmw73XhQ87LWNYVRM2s7diB5tBZPyM"");

    // Position account discriminator
    const POSITION_HEADER: [u8; 8] = [0xaa, 0xbc, 0x8f, 0xe4, 0x7a, 0x40, 0xf7, 0xd0];

    // Full range lower and upper indexes
    const TICK_LOWER_INDEX: i32 = -443584;
    const TICK_UPPER_INDEX: i32 = 443584;

    // Bridged token decimals
    const BRIDGED_TOKEN_DECIMALS: u8 = 8;

    /// Initializes a Lockbox account that stores state data.
    pub fn initialize(
        ctx: Context<InitializeLiquidityLockbox>
    ) -> Result<()> {
        let whirlpool = ctx.accounts.position.whirlpool;
        let position_mint = ctx.accounts.position.position_mint;
        let liquidity = ctx.accounts.position.liquidity;
        let tick_lower_index = ctx.accounts.position.tick_lower_index;
        let tick_upper_index = ctx.accounts.position.tick_upper_index;

        // Check the whirlpool
        if whirlpool != WHIRLPOOL {
            return Err(ErrorCode::WrongWhirlpool.into());
        }

        // Check the discriminator
        let account = &ctx.accounts.position.to_account_info();
        let data = account.try_borrow_data()?;
        assert!(data.len() > 8);
        let mut discriminator = [0u8; 8];
        discriminator.copy_from_slice(&data[0..8]);
        if discriminator != POSITION_HEADER {
            return Err(ErrorCode::WrongPositionHeader.into());
        }

        // Check for the minimum liquidity in position
        if liquidity != 0 {
            return Err(ErrorCode::LiquidityNotZero.into());
        }

        // Check tick values
        if tick_lower_index != TICK_LOWER_INDEX || tick_upper_index != TICK_UPPER_INDEX {
            return Err(ErrorCode::OutOfRange.into());
        }

        // Check the PDA ownership
        if ctx.accounts.position.to_account_info().owner != &ORCA {
            return Err(ErrorCode::WrongOwner.into());
        }

        // Check the position PDA address correctness
        let position_pda = Pubkey::find_program_address(
            &[b""position"", position_mint.as_ref()],
            &ORCA
        );
        if position_pda.0 != ctx.accounts.position.key() {
            return Err(ErrorCode::WrongPositionPDA.into());
        }

        // Check that the first token mint is SOL
        if ctx.accounts.fee_collector_token_owner_account_a.mint != SOL {
            return Err(ErrorCode::WrongTokenMint.into());
        }

        // Check that the second token mint is OLAS
        if ctx.accounts.fee_collector_token_owner_account_b.mint != OLAS {
            return Err(ErrorCode::WrongTokenMint.into());
        }

        // Get the lockbox account
        let lockbox = &mut ctx.accounts.lockbox;

        // Get the anchor-derived bump
        let bump = *ctx.bumps.get(""lockbox"").unwrap();

        // Initialize lockbox account
        lockbox.initialize(
            bump,
            ctx.accounts.bridged_token_mint.key(),
            ctx.accounts.fee_collector_token_owner_account_a.key(),
            ctx.accounts.fee_collector_token_owner_account_b.key(),
            ctx.accounts.position.key(),
            ctx.accounts.pda_position_account.key()
        )?;

        Ok(())
    }

    /// Deposits an NFT position under the Lockbox management and gets bridged tokens minted in return.
    ///
    /// ### Parameters
    /// - `liquidity_amount` - Requested liquidity amount.
    /// - `token_max_a` - Max amount of SOL token to be added for liquidity.
    /// - `token_max_b` - Max amount of OLAS token to be added for liquidity.
    pub fn deposit(
        ctx: Context<DepositPositionForLiquidity>,
        liquidity_amount: u64,
        token_max_a: u64,
        token_max_b: u64,
    ) -> Result<()> {
        // Check the initial token amounts
        if token_max_a == 0 || token_max_b == 0 {
            return Err(ErrorCode::LiquidityZero.into());
        }

        // Check the position account
        if ctx.accounts.position.key() != ctx.accounts.lockbox.position {
            return Err(ErrorCode::WrongPositionPDA.into());
        }

        // Check the position PDA address correctness
        let position_pda = Pubkey::find_program_address(
            &[b""position"", ctx.accounts.position.position_mint.as_ref()],
            &ORCA
        );
        if position_pda.0 != ctx.accounts.position.key() {
            return Err(ErrorCode::WrongPositionPDA.into());
        }

        // Check the lockbox PDA address correctness
        let lockbox_pda = Pubkey::find_program_address(
            &[b""liquidity_lockbox""],
            &PROGRAM_ID
        );
        if lockbox_pda.0 != ctx.accounts.lockbox.key() {
            return Err(ErrorCode::WrongLockboxPDA.into());
        }

        // Check the whirlpool
        if ctx.accounts.whirlpool.key() != WHIRLPOOL {
            return Err(ErrorCode::WrongWhirlpool.into());
        }

        // Check the Orca Whirlpool program address
        if ctx.accounts.whirlpool_program.key() != ORCA {
            return Err(ErrorCode::WrongOrcaAccount.into());
        }

        // Check that the first token mint is SOL
        if ctx.accounts.token_owner_account_a.mint != SOL || 
           ctx.accounts.token_vault_a.mint != SOL {
            return Err(ErrorCode::WrongTokenMint.into());
        }

        // Check that the second token mint is OLAS
        if ctx.accounts.token_owner_account_b.mint != OLAS || 
           ctx.accounts.token_vault_b.mint != OLAS {
            return Err(ErrorCode::WrongTokenMint.into());
        }

        // Check tick arrays owner
        if ctx.accounts.tick_array_lower.to_account_info().owner != &ORCA || 
           ctx.accounts.tick_array_upper.to_account_info().owner != &ORCA {
            return Err(ErrorCode::WrongOwner.into());
        }

        // Calculate token deltas
        let tick_index_lower = ctx.accounts.position.tick_lower_index;
        let tick_index_upper = ctx.accounts.position.tick_upper_index;
        let tick_index_current = ctx.accounts.whirlpool.tick_current_index;

        // assuming InRange status
        if tick_index_current < tick_index_lower || tick_index_upper <= tick_index_current {
            return Err(ErrorCode::OutOfRange.into());
        }

        // Total liquidity update with the check
        ctx.accounts.lockbox.total_liquidity = ctx.accounts.lockbox
            .total_liquidity
            .checked_add(liquidity_amount)
            .unwrap_or_else(|| panic!(""Liquidity overflow""));

        // Approve SOL tokens for the lockbox
        token::approve(
            CpiContext::new(
                ctx.accounts.token_program.to_account_info(),
                Approve {
                    to: ctx.accounts.token_owner_account_a.to_account_info(),
                    delegate: ctx.accounts.lockbox.to_account_info(),
                    authority: ctx.accounts.signer.to_account_info(),
 ragion: liquidity_lockbox {                },
            ),
            token_max_a,
        )?;

        // Approve OLAS tokens for the lockbox
        token::approve(
            CpiContext::new(
                ctx.accounts.token_program.to_account_info(),
                Approve {
                    to: ctx.accounts.token_owner_account_b.to_account_info(),
                    delegate: ctx.accounts.lockbox.to_account_info(),
                    authority: ctx.accounts.signer.to_account_info(),
                },
            ),
            token_max_b,
        )?;

        // Get lockbox signer seeds
        let signer_seeds = &[&ctx.accounts.lockbox.seeds()[..]];

        // CPI call to increase liquidity
        let cpi_program_modify_liquidity = ctx.accounts.whirlpool_program.to_account_info();
        let cpi_accounts_modify_liquidity = ModifyLiquidity {
            whirlpool: ctx.accounts.whirlpool.to_account_info(),
            position: ctx.accounts.position.to_account_info(),
            position_authority: ctx.accounts.lockbox.to_account_info(),
            position_token_account: ctx.accounts.pda_position_account.to_account_info(),
            tick_array_lower: ctx.accounts.tick_array_lower.to_account_info(),
            tick_array_upper: ctx.accounts.tick_array_upper.to_account_info(),
            token_owner_account_a: ctx.accounts.token_owner_account_a.to_account_info(),
            token_owner_account_b: ctx.accounts.token_owner_account_b.to_account_info(),
            token_vault_a: ctx.accounts.token_vault_a.to_account_info(),
            token_vault_b: ctx.accounts.token_vault_b.to_account_info(),
            token_program: ctx.accounts.token_program.to_account_info(),
        };
        let cpi_ctx_modify_liquidity = CpiContext::new_with_signer(
            cpi_program_modify_liquidity,
            cpi_accounts_modify_liquidity,
            signer_seeds
        );
        whirlpool::cpi::increase_liquidity(
            cpi_ctx_modify_liquidity,
            liquidity_amount as u128,
            token_max_a,
            token_max_b
        )?;

        // Mint bridged tokens in the amount of position liquidity
        invoke_signed(
            &mint_to(
                ctx.accounts.token_program.key,
                ctx.accounts.bridged_token_mint.to_account_info().key,
                ctx.accounts.bridged_token_account.to_account_info().key,
                ctx.accounts.lockbox.to_account_info().key,
                &[ctx.accounts.lockbox.to_account_info().key],
                liquidity_amount,
            )?,
            &[
                ctx.accounts.bridged_token_mint.to_account_info(),
                ctx.accounts.bridged_token_account.to_account_info(),
                ctx.accounts.lockbox.to_account_info(),
                ctx.accounts.token_program.to_account_info(),
            ],
            &[&ctx.accounts.lockbox.seeds()],
        )?;

        // Revoke approval for unused SOL tokens
        token::approve(
            CpiContext::new(
                ctx.accounts.token_program.to_account_info(),
                Approve {
                    to: ctx.accounts.token_owner_account_a.to_account_info(),
                    delegate: ctx.accounts.lockbox.to_account_info(),
                    authority: ctx.accounts.signer.to_account_info(),
                },
            ),
            0,
        )?;

        // Revoke approval for OLAS tokens
        token::approve(
            CpiContext::new(
                ctx.accounts.token_program.to_account_info(),
                Approve {
                    to: ctx.accounts.token_owner_account_b.to_account_info(),
                    delegate: ctx.accounts.lockbox.to_account_info(),
                    authority: ctx.accounts.signer.to_account_info(),
                },
            ),
            0,
        )?;

        emit!(DepositEvent {
            signer: ctx.accounts.signer.key(),
            position: ctx.accounts.position.key(),
            deposit_liquidity: liquidity_amount,
            total_liquidity: ctx.accounts.lockbox.total_liquidity
        });

        Ok(())
    }

    /// Withdraws a specified amount of liquidity for supplied bridged tokens.
    ///
    /// ### Parameters
    /// - `amount` - Amount of bridged tokens corresponding to the position liquidity amount to withdraw.
    /// - `token_min_a` - The minimum amount of SOL the signer is willing to withdraw.
    /// - `token_min_b` - The minimum amount of OLAS the signer is willing to withdraw.
    pub fn withdraw(
        ctx: Context<WithdrawLiquidityForTokens>,
        amount: u64,
        token_min_a: u64,
        token_min_b: u64
    ) -> Result<()> {
        // Check if there is any liquidity left in the Lockbox
        if ctx.accounts.position.liquidity == 0 {
            return Err(ErrorCode::LiquidityZero.into());
        }

        // Check the token amount
        if amount == 0 {
            return Err(ErrorCode::LiquidityZero.into());
        }

        // Check the lockbox PDA address correctness
        let lockbox_pda = Pubkey::find_program_address(
            &[b""liquidity_lockbox""],
            &PROGRAM_ID
        );
        if lockbox_pda.0 != ctx.accounts.lockbox.key() {
            return Err(ErrorCode::WrongLockboxPDA.into());
        }

        // Check the Orca Whirlpool program address
        if ctx.accounts.whirlpool_program.key() != ORCA {
            return Err(ErrorCode::WrongOrcaAccount.into());
        }

        // Check that the first token mint is SOL
        if ctx.accounts.token_owner_account_a.mint != SOL || 
           ctx.accounts.token_vault_a.mint != SOL {
            return Err(ErrorCode::WrongTokenMint.into());
        }

        // Check that the second token mint is OLAS
        if ctx.accounts.token_owner_account_b.mint != OLAS || 
           ctx.accounts.token_vault_b.mint != OLAS {
            return Err(ErrorCode::WrongTokenMint.into());
        }

        // Check tick arrays owner
        if ctx.accounts.tick_array_lower.to_account_info().owner != &ORCA || 
           ctx.accounts.tick_array_upper.to_account_info().owner != &ORCA {
            return Err(ErrorCode::WrongOwner.into());
        }

        // Check the requested amount to be smaller or equal than the position liquidity
        if amount > ctx.accounts.position.liquidity as u64 {
            return Err(ErrorCode::AmountExceedsPositionLiquidity.into());
        }

        // Burn provided amount of bridged tokens
        invoke_signed(
            &burn_checked(
                ctx.accounts.token_program.key,
                ctx.accounts.bridged_token_account.to_account_info().key,
                ctx.accounts.bridged_token_mint.to_account_info().key,
                ctx.accounts.signer.to_account_info().key,
                &[],
                amount,
                BRIDGED_TOKEN_DECIMALS,
            )?,
            &[
                ctx.accounts.token_program.to_account_info(),
                ctx.accounts.bridged_token_account.to_account_info(),
                ctx.accounts.bridged_token_mint.to_account_info(),
                ctx.accounts.signer.to_account_info(),
            ],
            &[]
        )?;

        // Get program signer seeds
        let signer_seeds = &[&ctx.accounts.lockbox.seeds()[..]];

        // Update fees for the position
        let cpi_program_update_fees = ctx.accounts.whirlpool_program.to_account_info();
        let cpi_accounts_update_fees = UpdateFeesAndRewards {
            whirlpool: ctx.accounts.whirlpool.to_account_info(),
            position: ctx.accounts.position.to_account_info(),
            tick_array_lower: ctx.accounts.tick_array_lower.to_account_info(),
            tick_array_upper: ctx.accounts.tick_array_upper.to_account_info()
        };
        let cpi_ctx_update_fees = CpiContext::new_with_signer(
            cpi_program_update_fees,
            cpi_accounts_update_fees,
            signer_seeds
        );
        whirlpool::cpi::update_fees_and_rewards(cpi_ctx_update_fees)?;

        // Collect fees from the position
        let cpi_program_collect_fees = ctx.accounts.whirlpool_program.to_account_info();
        let cpi_accounts_collect_fees = CollectFees {
            whirlpool: ctx.accounts.whirlpool.to_account_info(),
            position_authority: ctx.accounts.lockbox.to_account_info(),
            position: ctx.accounts.position.to_account_info(),
            position_token_account: ctx.accounts.pda_position_account.to_account_info(),
            token_owner_account_a: ctx.accounts.fee_collector_token_owner_account_a.to_account_info(),
            token_owner_account_b: ctx.accounts.fee_collector_token_owner_account_b.to_account_info(),
            token_vault_a: ctx.accounts.token_vault_a.to_account_info(),
            token_vault_b: ctx.accounts.token_vault_b.to_account_info(),
            token_program: ctx.accounts.token_program.to_account_info()
        };
        let cpi_ctx_collect_fees = CpiContext::new_with_signer(
            cpi_program_collect_fees,
            cpi_accounts_collect_fees,
            signer_seeds
        );
        whirlpool::cpi::collect_fees(cpi_ctx_collect_fees)?;

        // CPI to decrease liquidity
        let cpi_program_modify_liquidity = ctx.accounts.whirlpool_program.to_account_info();
        let cpi_accounts_modify_liquidity = ModifyLiquidity {
            whirlpool: ctx.accounts.whirlpool.to_account_info(),
            position: ctx.accounts.position.to_account_info(),
            position_authority: ctx.accounts.lockbox.to_account_info(),
            position_token_account: ctx.accounts.pda_position_account.to_account_info(),
            tick_array_lower: ctx.accounts.tick_array_lower.to_account_info(),
            tick_array_upper: ctx.accounts.tick_array_upper.to_account_info(),
            token_owner_account_a: ctx.accounts.token_owner_account_a.to_account_info(),
            token_owner_account_b: ctx.accounts.token_owner_account_b.to_account_info(),
            token_vault_a: ctx.accounts.token_vault_a.to_account_info(),
            token_vault_b: ctx.accounts.token_vault_b.to_account_info(),
            token_program: ctx.accounts.token_program.to_account_info()
        };
        let cpi_ctx_modify_liquidity = CpiContext::new_with_signer(
            cpi_program_modify_liquidity,
            cpi_accounts_modify_liquidity,
            signer_seeds
        );
        whirlpool::cpi::decrease_liquidity(
            cpi_ctx_modify_liquidity,
            amount as u128,
            token_min_a,
            token_min_b
        )?;

        // Update the position liquidity
        ctx.accounts.lockbox.total_liquidity = ctx.accounts.lockbox
            .total_liquidity
            .checked_sub(amount)
            .unwrap_or_else(|| panic!(""Liquidity underflow""));

        emit!(WithdrawEvent {
            signer: ctx.accounts.signer.key(),
            position: ctx.accounts.position.key(),
            token_owner_account_a: ctx.accounts.token_owner_account_a.key(),
            token_owner_account_b: ctx.accounts.token_owner_account_b.key(),
            withdraw_liquidity: amount,
            total_liquidity: ctx.accounts.lockbox.total_liquidity
        });

        Ok(())
    }
}

#[derive(Accounts)]
pub struct InitializeLiquidityLockbox<'info> {
    #[account(mut)]
    pub signer: Signer<'info>,
    #[account(
        init,
        seeds = [b""liquidity_lockbox"".as_ref()],
        bump,
        payer = signer,
        space = LiquidityLockbox::LEN
    )]
    pub lockbox: Box<Account<'info, LiquidityLockbox>>,
    #[account(
        constraint = bridged_token_mint.mint_authority.unwrap() == lockbox.key()
    )]
    pub bridged_token_mint: Box<Account<'info, Mint>>,
    #[account(
        constraint = signer.key == &fee_collector_token_owner_account_a.owner,
        constraint = fee_collector_token_owner_account_a.key() != fee_collector_token_owner_account_b.key()
    )]
    pub fee_collector_token_owner_account_a: Box<Account<'info, TokenAccount>>,
    #[account(
        constraint = signer.key == &fee_collector_token_owner_account_b.owner
    )]
    pub fee_collector_token_owner_account_b: Box<Account<'info, TokenAccount>>,
    #[account(has_one = whirlpool)]
    pub position: Box<Account<'info, Position>>,
    #[account(
        mut,
        constraint = pda_position_account.mint == position.position_mint,
        constraint = pda_position_account.amount == 1,
        constraint = lockbox.key() == pda_position_account.owner
    )]
    pub pda_position_account: Box<Account<'info, TokenAccount>>,
    pub whirlpool: Box<Account<'info, Whirlpool>>,
    #[account(address = token::ID)]
    pub token_program: Program<'info, Token>,
    pub system_program: Program<'info, System>,
    pub rent: Sysvar<'info, Rent>
}

#[derive(Accounts)]
pub struct DepositPositionForLiquidity<'info> {
    #[account(mut)]
    pub signer: Signer<'info>,
    #[account(
        mut,
        address = lockbox.position,
        has_one = whirlpool
    )]
    pub position: Box<Account<'info, Position>>,
    #[account(
        mut,
        constraint = lockbox.key() == pda_position_account.owner,
        constraint = pda_position_account.mint == position.position_mint,
        constraint = pda_position_account.amount == 1
    )]
    pub pda_position_account: Box<Account<'info, TokenAccount>>,
    #[account(
        mut,
        address = position.whirlpool
    )]
    pub whirlpool: Box<Account<'info, Whirlpool>>,
    #[account(
        mut,
        constraint = token_owner_account_a.mint == whirlpool.token_mint_a,
        constraint = token_owner_account_a.mint != token_owner_account_b.mint,
        constraint = signer.key == &token_owner_account_a.owner
    )]
    pub token_owner_account_a: Box<Account<'info, TokenAccount>>,
    #[account(
        mut,
        constraint = token_owner_account_b.mint == whirlpool.token_mint_b,
        constraint = signer.key == &token_owner_account_b.owner
    )]
    pub token_owner_account_b: Box<Account<'info, TokenAccount>>,
    #[account(
        mut,
        constraint = token_vault_a.key() == whirlpool.token_vault_a,
        constraint = token_vault_a.key() != token_vault_b.key()
    )]
    pub token_vault_a: Box<Account<'info, TokenAccount>>,
    #[account(
        mut,
        constraint = token_vault_b.key() == whirlpool.token_vault_b
    )]
    pub token_vault_b: Box<Account<'info, TokenAccount>>,
    #[account(
        mut,
        has_one = whirlpool,
        constraint = tick_array_lower.key() != tick_array_upper.key()
    )]
    pub tick_array_lower: AccountLoader<'info, TickArray>,
    #[account(
        mut,
        has_one = whirlpool
    )]
    pub tick_array_upper: AccountLoader<'info, TickArray>,
    #[account(
        mut,
        address = lockbox.bridged_token_mint
    )]
    pub bridged_token_mint: Box<Account<'info, Mint>>,
    #[account(
        mut,
        constraint = bridged_token_account.mint == lockbox.bridged_token_mint,
        constraint = bridged_token_mint.key() == lockbox.bridged_token_mint,
        constraint = signer.key == &bridged_token_account.owner
    )]
    pub bridged_token_account: Box<Account<'info, TokenAccount>>,
    #[account(mut)]
    pub lockbox: Box<Account<'info, LiquidityLockbox>>,
    pub whirlpool_program: Program<'info, whirlpool::program::Whirlpool>,
    #[account(address = token::ID)]
    pub token_program: Program<'info, Token>,
    pub system_program: Program<'info, System>,
    pub rent: Sysvar<'info, Rent>,
}

#[derive(Accounts)]
pub struct WithdrawLiquidityForTokens<'info> {
    #[account(
        mut,
        address = position.whirlpool
    )]
    pub whirlpool: Box<Account<'info, Whirlpool>>,
    pub signer: Signer<'info>,
    #[account(
        mut,
        address = lockbox.bridged_token_mint
    )]
    pub bridged_token_mint: Box<Account<'info, Mint>>,
    #[account(
        mut,
        constraint = bridged_token_account.mint == lockbox.bridged_token_mint,
        constraint = lockbox.bridged_token_mint == bridged_token_mint.key(),
        constraint = signer.key == &bridged_token_account.owner
    )]
    pub bridged_token_account: Box<Account<'info, TokenAccount>>,
    #[account(
        mut,
        address = lockbox.position,
        has_one = whirlpool,
        has_one = position_mint
    )]
    pub position: Box<Account<'info, Position>>,
    #[account(
        mut,
        constraint = pda_position_account.mint == position.position_mint,
        constraint = pda_position_account.amount == 1,
        constraint = lockbox.key() == pda_position_account.owner
    )]
    pub pda_position_account: Box<Account<'info, TokenAccount>>,
    #[account(
        mut,
        address = position.position_mint,
        constraint = position_mint.supply == 1
    )]
    pub position_mint: Box<Account<'info, Mint>>,
    #[account(
        mut,
        constraint = token_owner_account_a.mint == whirlpool.token_mint_a,
        constraint = token_owner_account_a.mint != token_owner_account_b.mint,
        constraint = signer.key == &token_owner_account_a.owner
    )]
    pub token_owner_account_a: Box<Account<'info, TokenAccount>>,
    #[account(
        mut,
        constraint = token_owner_account_b.mint == whirlpool.token_mint_b,
        constraint = signer.key == &token_owner_account_b.owner
    )]
    pub token_owner_account_b: Box<Account<'info, TokenAccount>>,
    #[account(
        mut,
        address = lockbox.fee_collector_token_owner_account_a
    )]
    pub fee_collector_token_owner_account_a: Box<Account<'info, TokenAccount>>,
    #[account(
        mut,
        address = lockbox.fee_collector_token_owner_account_b
    )]
    pub fee_collector_token_owner_account_b: Box<Account<'info, TokenAccount>>,
    #[account(
        mut,
        constraint = token_vault_a.key() == whirlpool.token_vault_a,
        constraint = token_vault_a.key() != token_vault_b.key()
    )]
    pub token_vault_a: Box<Account<'info, TokenAccount>>,
    #[account(
        mut,
        constraint = token_vault_b.key() == whirlpool.token_vault_b
    )]
    pub token_vault_b: Box<Account<'info, TokenAccount>>,
    #[account(
        mut,
        has_one = whirlpool,
        constraint = tick_array_lower.key() != tick_array_upper.key()
    )]
    pub tick_array_lower: AccountLoader<'info, TickArray>,
    #[account(
        mut,
        has_one = whirlpool
    )]
    pub tick_array_upper: AccountLoader<'info, TickArray>,
    #[account(mut)]
    pub lockbox: Box<Account<'info, LiquidityLockbox>>,
    pub whirlpool_program: Program<'info, whirlpool::program::Whirlpool>,
    #[account(address = token::ID)]
    pub token_program: Program<'info, Token>
}

#[error_code]
pub enum ErrorCode {
    #[msg(""Liquidity value overflow"")]
    LiquidityOverflow,
    #[msg(""Liquidity value underflow"")]
    LiquidityUnderflow,
    #[msg(""Wrong whirlpool address"")]
    WrongWhirlpool,
    #[msg(""Wrong position PDA header"")]
    WrongPositionHeader,
    #[msg(""Wrong position ID"")]
    WrongPositionId,
    #[msg(""Liquidity is zero"")]
    LiquidityZero,
    #[msg(""Liquidity is not zero"")]
    LiquidityNotZero,
    #[msg(""Delta token amount bigger than the max allowed one"")]
    DeltaAmountOverflow,
    #[msg(""Requested amount exceeds a position liquidity"")]
    AmountExceedsPositionLiquidity,
    #[msg(""Requested amount exceeds total liquidity"")]
    AmountExceedsTotalLiquidity,
    #[msg(""Tick out of range"")]
    OutOfRange,
    #[msg(""Wrong account owner"")]
    WrongOwner,
    #[msg(""Provided wrong position PDA"")]
    WrongPositionPDA,
    #[msg(""Provided wrong lockbox PDA"")]
    WrongLockboxPDA,
    #[msg(""Provided wrong position ATA"")]
    WrongPositionAccount,
    #[msg(""Provided wrong PDA position ATA"")]
    WrongPDAPositionAccount,
    #[msg(""Provided wrong Orca program account"")]
    WrongOrcaAccount,
    #[msg(""Wrong token mint"")]
    WrongTokenMint,
    #[msg(""Whirlpool number downcast"")]
    WhirlpoolNumberDownCastError
}

#[event]
pub struct DepositEvent {
    // Signer (user)
    #[index]
    pub signer: Pubkey,
    // Liquidity position
    #[index]
    pub position: Pubkey,
    // Deposit liquidity amount
    pub deposit_liquidity: u64,
    // Total position liquidity
    pub total_liquidity: u64
}

#[event]
pub struct WithdrawEvent {
    // Signer (user)
    #[index]
    pub signer: Pubkey,
    // Liquidity position
    #[index]
    pub position: Pubkey,
    // User ATA token A
    pub token_owner_account_a: Pubkey,
    // User ATA token B
    pub token_owner_account_b: Pubkey,
    // Withdraw liquidity amount
    pub withdraw_liquidity: u64,
    // Total position liquidity
    pub total_liquidity: u64
}",High,"After introduction of a liquidity_amount parameter in the deposit() function, it is ensured the a user receives the expected liquidity_amount of bridged tokens while only spending token_max_a of SOL and token_max_b of OLAS in the worst-case. As a consequence of those in- and output constraints, a user is sufficiently protected from a sandwich attack. Furthermore, the direct use of liquidity_amount, token_max_a and token_max_b with the underlying Whirlpool program led to obsolete code, which was previously used for the computation of the liquidity & token b amounts, that facilitated the sandwich attack in the first place. Consequently, the get_liquidity_from_token_a() function became obsolete too and was removed and therefore also resolved the Division before multiplication in liquidity_lockbox::get_liquidity_from_token_a(...) #50 issue. In addition, the approval of any unused SOL & OLAS tokens (not all of token_max_a/token_max_b used) is revoked (set to 0).",https://gist.github.com/MarioPoneder/b7f287884607958eda81f3419efbc1e8,High
Sol-114,"Users can deposit their stSol in order to get bSol and Anker maintains an stSol reserve to back the bSOL supply at a 1 bSOL = 1 SOL exchange rate. However since stSol appreciate in value, Anker has been fitted with a SellRewards instruction to sell off any exess stSol value build-up. This instruction is supposed to be called by crankers and therefore is permissionless. Anker uses Orca’s deployment of SPL token-swap program to swap stSol for UST. The issue is that SellRewards never verifies that it is actually dealing with Orca’s token-swap program, allowing an attacker to supply an arbitrary program. This program will subsequently be called using Solana’s invoke_signed() API and signed by the token_swap_authority. An attacker can craft their own malicious fork of the SPL token-swap program, that withdraws all the funds from the reserve to an attacker controlled account.","rust
let (solido, mut anker) = deserialize_anker(program_id, accounts.anker, accounts.solido)?;
solido.check_manager(accounts.manager)?;

let current_token_swap = anker.get_token_swap_instance(accounts.current_token_swap_pool)?;

// `get_token_swap_instance` compares the account to the one stored in
// `anker.token_swap_pool`. We assign first so we have the correct value to
// compare. If the check fails, the transaction will revert.
anker.token_swap_pool = *accounts.new_token_swap_pool.key;

let new_token_swap = anker.get_token_swap_instance(accounts.new_token_swap_pool)?;

anker.check_change_token_swap_pool(&solido, current_token_swap, new_token_swap)?;

anker.save(accounts.anker)","rust
let (solido, mut anker) = deserialize_anker(program_id, accounts.anker, accounts.solido)?;
solido.check_manager(accounts.manager)?;

let current_token_swap_program_id = accounts.current_token_swap_pool.owner;

let current_token_swap = anker.get_token_swap_instance(
    accounts.current_token_swap_pool,
    current_token_swap_program_id,
)?;

// `get_token_swap_instance` compares the account to the one stored in
// `anker.token_swap_pool`. We assign first so we have the correct value to
// compare. If the check fails, the transaction will revert.
anker.token_swap_pool = *accounts.new_token_swap_pool.key;

let new_token_swap_program_id = accounts.new_token_swap_pool.owner;

let new_token_swap = anker.get_token_swap_instance(
    accounts.new_token_swap_pool,
    new_token_swap_program_id,
)?;

anker.check_change_token_swap_pool(&solido, current_token_swap, new_token_swap)?;
anker.save(accounts.anker);",Critical,The Anker team responded immediately by adding a regression test and adding the missing check,https://github.com/ChorusOne/solido/pull/512/commits/676d6bee310b13c39b3c8e1adc6a26a4db2f8482,High
Sol-115,"Anker sells off exess stSol by using an Orca stSol<−>UST token swap and sending the resulting UST through Wormhole to a rewards account on the Terra side. Lido’s exchange rate is used to compute rewards for an epoch and the swap gets performed at the start of the next epoch. The full amount is swapped in a single operation without slippage protection, which could lead to a lot of slippage in a low liquidity pool. An even bigger issue however is that since this instruction is intended to be called by crankers, a malicious cranker can exploit this by sandwiching the sale between two of their own swaps to steal the rewards.","rust
use lido::token::Lamports;
use solana_program::{
    account_info::AccountInfo,
    entrypoint::ProgramResult,
    msg, program::{
        invoke, 
        invoke_signed
    }, 
};

use crate::{
    find_st_sol_reserve_account,
    instruction::{ 
        AnkerInstruction, 
        ChangeTerraRewardsDestinationAccountsInfo, 
        ChangeTokenSwapPoolAccountsInfo, 
        DepositAccountsInfo, 
        InitializeAccountsInfo, 
        SellRewardsAccountsInfo, 
        SendRewardsAccountsInfo, 
        WithdrawAccountsInfo, 
    }, 
    logic::{
        burn_b_sol, 
        deserialize_anker, 
        mint_b_sol_to
    }, 
    metrics::Metrics, 
    wormhole::{
        get_wormhole_transfer_instruction, 
        TerraAddress
    }, 
    find_ust_reserve_account, 
    ANKER_STSOL_RESERVE_ACCOUNT, 
    ANKER_UST_RESERVE_ACCOUNT
};

use crate::{
    logic::{
        create_account, 
        initialize_spl_account, 
        swap_rewards
    }, 
    state::ExchangeRate, 
};

use crate::{
    state::ANKER_LEN, 
    ANKER_RESERVE_AUTHORITY
};

fn process_initialize(
    program_id: &Pubkey,
    accounts_raw: &[AccountInfo],
    terra_rewards_destination: TerraAddress,
) -> ProgramResult {
    let accounts = InitializeAccountsInfo::try_from_slice(accounts_raw)?;
    let rent = Rent::from_account_info(accounts.sysvar_rent)?;

    let solido = Lido::deserialize_lido(accounts.solido_program.key, accounts.solido)?;

    // ... other code continues...
}","rust
use lido::token::Lamports; 
use solana_program::{
    account_info::AccountInfo, 
    clock::Clock, 
    entrypoint::ProgramResult, 
    msg, 
    program::{invoke, invoke_signed},
};
use crate::{
    find_st_sol_reserve_account, 
    instruction::{
        AnkerInstruction, 
        ChangeTerraRewardsDestinationAccountsInfo, 
        ChangeTokenSwapPoolAccountsInfo, 
        DepositAccountsInfo, 
        FetchPoolPriceAccountsInfo, 
        InitializeAccountsInfo, 
        SellRewardsAccountsInfo, 
        SendRewardsAccountsInfo, 
        WithdrawAccountsInfo,
    }, 
    logic::{
        burn_b_sol, 
        deserialize_anker, 
        mint_b_sol_to
    }, 
    metrics::Metrics, 
    wormhole::{
        get_wormhole_transfer_instruction, 
        TerraAddress
    },
};

use crate::{
    find_ust_reserve_account, 
    ANKER_STSOL_RESERVE_ACCOUNT, 
    ANKER_UST_RESERVE_ACCOUNT
}; 

use crate::{
    instruction::ChangeSellRewardsMinOutBpsAccountsInfo, 
    logic::get_one_st_sol_for_ust_price_from_pool, 
    state::HistoricalStSolPriceArray, 
    POOL_PRICE_MAX_SAMPLE_AGE, 
    POOL_PRICE_MIN_SAMPLE_DISTANCE
};

use crate::{
    logic::{
        create_account, 
        initialize_spl_account, 
        swap_rewards
    }, 
    state::ExchangeRate
};

use crate::{
    state::ANKER_LEN, 
    ANKER_RESERVE_AUTHORITY
};

#[inline(never)]
fn process_initialize(
    program_id: &Pubkey,
    accounts_raw: &[AccountInfo],
    terra_rewards_destination: TerraAddress,
    sell_rewards_min_out_bps: u64,
) -> ProgramResult {
    // (Code here...)
}

#[inline(never)]
fn process_deposit(
    program_id: &Pubkey,
    accounts_raw: &[AccountInfo],
) -> ProgramResult {
    // (Code here...)
}

#[inline(never)]
fn process_fetch_pool_price(program_id: &Pubkey, accounts_raw: &[AccountInfo]) -> ProgramResult {
    // (Code here...)
}

#[inline(never)]
fn process_sell_rewards(
    program_id: &Pubkey, 
    accounts_raw: &[AccountInfo]
) -> ProgramResult {
    // (Code here...)
}

#[inline(never)]
fn process_withdraw(
    program_id: &Pubkey,
    accounts_raw: &[AccountInfo],
) -> ProgramResult {
    // (Code here...)
}

#[inline(never)]
fn process_change_terra_rewards_destination(
    program_id: &Pubkey,
    accounts_raw: &[AccountInfo],
    terra_rewards_destination: TerraAddress,
) -> ProgramResult {
    // (Code here...)
}

#[inline(never)]
fn process_change_token_swap_pool(
    program_id: &Pubkey,
    accounts_raw: &[AccountInfo],
    token_swap_pool: Pubkey,
) -> ProgramResult {
    // (Code here...)
}

#[inline(never)]
fn process_change_sell_rewards_min_out_bps(
    program_id: &Pubkey,
    accounts_raw: &[AccountInfo],
    sell_rewards_min_out_bps: u64,
) -> ProgramResult {
    // (Code here...)
}

#[inline(never)]
fn process_send_rewards(
    program_id: &Pubkey,
    accounts_raw: &[AccountInfo],
    wormhole_nonce: u8,
) -> ProgramResult {
    // (Code here...)
}",High,"Because Anker is permissionless, everybody can call SellRewards if there are rewards to sell. This means that the caller could sandwich the SellRewards between two instructions that swap against the same stSOL/UST pool that Anker uses, to give us a bad price, and take the difference. To mitigate this risk, we set a min_out on the swap instruction, but in order to do so, we need a “fair” price. For that, we sample 5 past prices, at least some number of slots apart (enough that they are produced by different leaders), but also not too old, to make sure the price is still fresh. Then we take the median of that as a “fair” price and set min_out based on that. Now if anybody is trying to sandwich us, they would also have to sandwich 3 of those 5 times where we sample the price (and they pay swap fees), and they are competing with our honest maintenance bot for that (and possibly with others). Also, having a recent price ensures that we don’t sell rewards at times of extreme volatility.",https://github.com/ChorusOne/solido/pull/511/files#diff-89f65dd63171a4df2fb15491cdd3609e804ff3b1a270c9131cfa6e6b74269ba6,High
Sol-116,"The program instruction liquidate_sundial_profilerounds up the amount of collateral received by the liquidator. This results in the liquidators being able to create an undercollateralized account by repaying much less than the value of the collateral received repeatedly. Notice how the ` withdraw _ amount` is ceilinged in the calculation. The minimum amount received by the liquidator is one collateral token as long as the repay token has a non zero liquidation_value. If the value of the repaid token is lower than the collateral token, a liquidator can then repeatedly repay with a low valued repay token and receive a much higher valued collateral token. While each repayment only causes a small discrepancy between the collateral and obligation amount, eventually an attacker will be able to push the value of the collateral lower than the obligation. Note that each of these operations is still profitable to the attacker, similar to the previous spl-token-lending rounding bug. Because the attacker is profiting from such a transaction, the lending protocol must be losing money. This leads to a loss of funds scenario for the Sundial program. Proof of Concept More concretely, consider the following scenario: 1. Attacker deposits some token A, which has a high value per minimum token unit (BTC for example) 2. Attacker borrows some token B, which has a low value per minimum token unit (SOL for example) 3. 4. 5. The price of SOL goes up, which makes the attacker liquidatable The attacker liquidates themselves, repaying a single lamport and receiving 1 satoshi. Because such a liquidation lowers the health of the account, the user is able to do this repeatedly, and the account remains liquidatable throughout. 6. The loan is never repaid fully and the collateral is drained by the liquidator. The lending protocol ends up with an undercollateralized account. 7. The attacker keeps both the collateral and the borrowed asset, in essence stealing the obligation from the lending protocol We constructed a proof-of-concept which creates an undercollateralized account by repeatedly repaying a low-value token while receiving a high value collateral token. In our proof-of-concept for demonstration purposes, we used two fake tokens with a large value diﬀerence. A real world example of this with less extreme value diﬀerentials could be found between USDC and BTC. A er a series of malicious liquidation operations, we are able to entirely drain the lower value collateral, leaving behind a severely undercollateralized account. total collateral value before: 100000283919052573356860 total loan value before: 90200000000000000000000 total collateral value after: 100000000000000000 total loan value: 90180000000000000000000 This leads to a loss of funds scenario for the lending protocol. If an attacker maliciously creates an undercollateralized account, they could simply keep the loan, never repaying the obligation. Because the value of the loan is higher than the collateral, the lending protocol would be forced to make up the diﬀerence.","rust
programs/sundial/src/instructions/borrowing_instructions/liquidate_sundial_profile.rs

use crate::helpers::*;
use crate::state::{Sundial, SundialCollateral, SundialProfile};
use anchor_lang::prelude::*;
use anchor_spl::token::{Token, TokenAccount};

//...
use crate::error::SundialError;
use solana_maths::{Decimal, Rate, TryMul, U192};

/// Percentage of a [Profile] that can be repaid during /// each liquidation call due to price change

//...

pub struct LiquidateSundialProfile<'info> {
    //...
    pub fn process_liquidate_sundial_profile(ctx: Context<LiquidateSundialProfile>) -> ProgramResult {
        let user_wallet = &ctx.accounts.user_repay_liquidity_wallet;
        let sundial_profile = &mut ctx.accounts.sundial_profile;
        let current_ts = ctx.accounts.clock.unix_timestamp;
        
        let no_overtime_loans = !sundial_profile
            .loans
            //...

        let sundial_key = ctx.accounts.sundial.key();
        let is_unhealthy = log_then_prop_err!(sundial_profile.check_if_unhealthy());

        let allowed_repay_value_when_no_overtime = log_then_prop_err!(sundial_profile
            .get_borrowed_value()
            .and_then(|d| d.try_mul(Rate::from_percent(LIQUIDATION_CLOSE_FACTOR))));

        let (collaterals, loans) = sundial_profile.get_mut_collaterals_and_loans();
        let (loan_pos, loan_to_repay) = vipers::unwrap_opt!( loans.iter_mut().find_position(|l| l.sundial == sundial_key),

        //...

        if log_then_prop_err!(loan_to_repay.asset.reduce_amount(repay_amount)) == 0 { 
            loans.remove(loan_pos); 
        };

        if log_then_prop_err!(collateral_to_withdraw.asset.reduce_amount(withdraw_amount)) == 0 { 
            collaterals.remove(collateral_pos); 
        };
        
        emit!(LiquidateSundialProfileEvent { 
            profile: ctx.accounts.sundial_profile.key(),
            sundial_collateral: ctx.accounts.sundial_collateral.key(),
            sundial: ctx.accounts.sundial.key(),
            repay_amount, 
            withdraw_amount, 
            repay_mint: ctx.accounts.sundial_liquidity_wallet.mint,
            withdraw_mint: ctx.accounts.sundial_collateral.collateral_mint,
            user_wallet: ctx.accounts.user_repay_liquidity_wallet.owner
        });
        Ok(()) 
    } 

programs/sundial/src/state.rs 

#[inline(always)]
pub fn check_if_unhealthy(&self) -> Result<bool, ProgramError> {
    let liquidation_margin = log_then_prop_err!(self.get_liquidation_margin());
    let borrowed_value = log_then_prop_err!(self.get_borrowed_value());
    Ok(borrowed_value >= liquidation_margin) 
} 

#[inline(always)]
//...
}","rust
programs / sundial / src / instructions / borrowing_instructions / liquidate_sundial_profile.rs use crate::helpers::*;
use crate::state::{calculate_risk_factor, Sundial, SundialCollateral, SundialProfile};
use anchor_lang::prelude::*;
use anchor_spl::token::{Token, TokenAccount};

@@ -14,7 +14,7 @@ use anchor_spl::token::transfer;
use crate::error::SundialError;
use solana_maths::{Decimal, Rate, TryMul, TrySub, U192};

/// Percentage of a [Profile] that can be repaid during
/// each liquidation call due to price change
@@ -89,7 +89,6 @@ pub struct LiquidateSundialProfile<'info>
{
    pub fn process_liquidate_sundial_profile(ctx: Context<LiquidateSundialProfile>) -> ProgramResult 
    {
        let user_wallet = &ctx.accounts.user_repay_liquidity_wallet;
        let sundial_profile = &mut ctx.accounts.sundial_profile;
        let current_ts = ctx.accounts.clock.unix_timestamp;
        let no_overtime_loans = !sundial_profile .loans @@ -107,11 +106,14 @@ pub fn process_liquidate_sundial_profile(ctx: Context<LiquidateSundialProfile>)
        let sundial_key = ctx.accounts.sundial.key();
        ...",Critical,"The lending protocol should ensure that in the general case, the health of the account increases. A liquidation should generally never result in bringing the user closer to becoming undercollateralized. At the same time, it will be necessary to ensure that small obligations can be properly liquidated in a profitable manner for the liquidator, even if that liquidation might decrease the health of the account. This could be done similar to spl-token-lending’s reserve.calculate_liquidation function which considers such small amounts as an edge case. // Close out obligations that are too small to liquidate normally if liquidity.borrowed_amount_wads < LIQUIDATION_CLOSE_AMOUNT.into() { // settle_amount is fixed, calculate withdraw_amount and repay_amount settle_amount = liquidity.borrowed_amount_wads; let liquidation_value = liquidity.market_value.try_mul(bonus_rate)?; match liquidation_value.cmp(&collateral.market_value) { Ordering::Greater => {",https://github.com/port-finance/sundial/pull/77/files,High
Sol-117,"When depositing liquidity and minting principal and yield tokens, the user is given one yield token for each underlying liquidity token they deposit. This calculation is incorrect. The user should instead receive one yield token for each principal token. When calculating tokens returned to the user, the principal token amount is properly backdated to the start of Sundial. The intent of this calculation is to ensure that if users deposit tokens late, they receive the same amount of principal tokens as if they had deposited at the start of the Sundial instance. instructions/lending_ instructions/deposit and mint tokens.rs _ _ _ // We calculate how much liquidity is deposited if we deposit it at the very beginning of [Sundial]. let principal_token_amount = start_exchange_rate.collateral_to_liquidity(unwrap_int!(ctx .accounts .sundial_port_lp_wallet .amount .checked_sub(existed_lp_amount)))?; However, this calculation only applies to the minted principal tokens. As seen below, the amount of deposited liquidity is used directly when determining how many yield tokens to mint. instructions/lending_ instructions/deposit and mint _ _ _ pub fn process_deposit_and_mint_tokens( ctx: Context<DepositAndMintTokens>, amount: u64, ) -> ProgramResult { tokens.rs instructions/lending_ instructions/deposit and mint _ _ _ tokens.rs log_then_prop_err!(mint_to( create_mint_to_cpi( © 2022 OtterSec LLC. All Rights Reserved. Port Sundial Audit 13/31 ctx.accounts.yield_token_mint.to_account_info(), ctx.accounts.user_yield_token_wallet.to_account_info(), ctx.accounts.sundial_authority.to_account_info(), seeds!(ctx, sundial, authority), ctx.accounts.token_program.to_account_info(), ), amount )); This relatively subtle bug means that if a user deposits near the end of the period, they will receive more yield tokens then they deserve. A malicious user who deposited a very large amount could take an arbitrarily large proportion of the yield. For example, a user who deposits 100 tokens 1 slot before the end of the period might receive 80 principal tokens and 100 yield tokens. Because the yield token amount is proportionally larger, the user who deposited late takes some yield that would have otherwise gone to the other users, despite providing liquidity for only a single slot. Another way to think about this is: the value of the returned principal tokens and yield tokens must be equal to the deposited liquidity. This creates a misaligned economic structure where users are incentivized to delay adding tokens to the Sundial program until the very end of the period. Proof of Concept More concretely, consider the following scenario 1. 2. Victim deposits liquidity tokens at the beginning of a Sundial Attacker waits until the slot before the Sundial ends and then deposits liquidity tokens. Note that this does not have to be timed perfectly. Doing the deposit anytime close to the end of the Sundial period is enough to be profitable for the attacker. Attacker waits for the next slot and redeems the principle and yield tokens for liquidity tokens, making profit","rust
programs/sundial/src/instructions/borrowing_instructions/change_sundial_collateral_config.rs 

use crate::helpers::*;
use crate::instructions::SundialCollateralConfigParams;
use crate::state::{SundialCollateral, SundialMarket};
use anchor_lang::prelude::*;
use crate::error::SundialError;

@@ -23,6 +23,22 @@ pub fn process_change_sundial_collateral_config(
    ctx: Context<ChangeSundialCollateralConfig>,
    config: SundialCollateralConfigParams,
) -> ProgramResult { 
    ctx.accounts.sundial_collateral.sundial_collateral_config = config.into(); 
    Ok(()) 
} 

programs/sundial/src/instructions/lending_instructions/change_sundial_config.rs 

use crate::helpers::*;
use crate::state::Sundial;
use crate::state::SundialConfig;
use crate::state::SundialMarket;
use anchor_lang::prelude::*;
use crate::instructions::SundialInitConfigParams;

@@ -25,7 +25,15 @@ pub fn process_change_sundial_config(
    ctx: Context<ChangeSundialConfig>,
    config: SundialInitConfigParams,
) -> ProgramResult {
    ctx.accounts.sundial.config = config.into(); 
    emit!(ChangeSundialConfigEvent { 
        sundial: ctx.accounts.sundial.key(), 
        config: ctx.accounts.sundial.config.clone(), 
    }); 
    Ok(()) 
} 

programs/sundial/src/instructions/lending_instructions/deposit_and_mint_tokens.rs 

pub fn process_deposit_and_mint_tokens(
    ctx: Context<DepositAndMintTokens>,
    amount: u64,
) -> ProgramResult { 
    let sundial = &ctx.accounts.sundial; 
    let existed_lp_amount = ctx.accounts.sundial_port_lp_wallet.amount; 
    let start_exchange_rate = CollateralExchangeRate(Rate(U128(sundial.start_exchange_rate))); 
    log_then_prop_err!(deposit_reserve( 
        ctx.accounts.port_accounts.create_deposit_reserve_context( 
            ctx.accounts.user_liquidity_wallet.to_account_info(), 
            ctx.accounts.sundial_port_lp_wallet.to_account_info(), 
            ctx.accounts.user_authority.to_account_info(), 
            ctx.accounts.clock.to_account_info(), 
            ctx.accounts.token_program.to_account_info(), 
            &[&[&[]]], 
        ), 
        amount, 
    )); 
    log_then_prop_err!(ctx.accounts.sundial_port_lp_wallet.reload()); 
    let principal_token_amount = start_exchange_rate.collateral_to_liquidity(unwrap_int!(ctx 
        .accounts 
        .sundial_port_lp_wallet 
        .amount 
        .checked_sub(existed_lp_amount)))?;
    let fee = &sundial.config.lending_fee; 
    let fee_amount = log_then_prop_err!(fee.mint_fee( seeds!(ctx, sundial, authority), ctx.accounts.token_program.to_account_info(), ), amount ));
    let liquidity_cap = &sundial.config.liquidity_cap; 
    log_then_prop_err!(liquidity_cap.check_mint(&mut ctx.accounts.principle_token_mint)); 
    emit!(DepositAndMintTokensEvent { 
        sundial: ctx.accounts.sundial.key(), 
        liquidity_spent: amount, 
        principal_token_minted: principal_token_amount, 
        yield_token_minted: amount 
    }); 
    Ok(()) 
}","rust
programs/sundial/src/instructions/borrowing_instructions/change_sundial_collateral_config.rs 

use crate::helpers::*; 
use crate::instructions::SundialCollateralConfigParams; 
use crate::state::{LiquidationConfig, LiquidityCap, SundialCollateral, SundialMarket, LTV}; 
use anchor_lang::prelude::*; 
use crate::error::SundialError; 

@@ -23,6 +23,22 @@ 

pub fn process_change_sundial_collateral_config(
  ctx: Context<ChangeSundialCollateralConfig>, 
  config: SundialCollateralConfigParams, 
) -> ProgramResult { 
  ctx.accounts
    .sundial_collateral 
    .sundial_collateral_config 
    .ltv = LTV { 
      ltv: config.ltv 
    }; 
    ctx.accounts
      .sundial_collateral 
      .sundial_collateral_config 
      .liquidation_config = LiquidationConfig { 
        liquidation_threshold: config.liquidation_threshold, 
        liquidation_penalty: config.liquidation_penalty, 
      };
    ctx.accounts
      .sundial_collateral 
      .sundial_collateral_config 
      .liquidity_cap = LiquidityCap { 
        lamports: config.liquidity_cap, 
      }; 
    Ok(()) 
  }",High,"The program should mint the same amount of yield tokens as principal tokens. This results in less yield tokens being given to the attacker, resulting in no profit.",https://github.com/port-finance/sundial/pull/78/files,High
Sol-118,"The privileged ChangeSundialConfigand ChangeSundialCollateralConfig instructions clobber the liquidity_decimalsand collateral_decimalsfields respectively. When initializing the Sundial instance, note how the liquidity_decimalsfield is assigned a er the configuration assignment. instructions/lending_ instructions/initialize _ sundial.rs sundial.config = config.into(); sundial.sundial_market = ctx.accounts.sundial_market.key(); sundial.oracle = oracle; sundial.config.liquidity_decimals = ctx.accounts.port_liquidity_mint.decimals; emit!(InitializeSundialEvent { sundial: sundial.key(), duration_in_seconds, }); Ok(()) This is because the implementation for From<SundialInitConfigParams>will silently zero all other fields such as liquidity_decimals. instructions/lending_ instructions/initialize sundial.rs _ impl From<SundialInitConfigParams> for SundialConfig { fn from(config: SundialInitConfigParams) -> Self { SundialConfig { lending_fee: Fee { bips: config.lending_fee, }, borrow_fee: Fee { bips: config.borrow_fee, }, liquidity_cap: LiquidityCap { lamports: config.liquidity_cap, }, ..SundialConfig::default() } } } However, the liquidity_decimalsfield is not reassigned to with the change_sundial_confighandler. This means that when an admin tries to change the sundial configuration, it will silently zero this amount. instructions/lending_ instructions/change sundial _ _ config.rs ctx.accounts.sundial.config = config.into(); emit!(ChangeSundialConfigEvent { sundial: ctx.accounts.sundial.key(), config: ctx.accounts.sundial.config.clone(), }); Ok(()) This field is used when initializing obligations. By zeroing this field, this has the eﬀect of multiplying the value of all new obligations by a large constant factor, leading to a wildly inaccurate price on subsequent transactions. instructions/borrowing_ instructions/mint sundial _ _ liquidity_ with collateral.rs _ SundialProfileLoan::init_loan( amount, oracle_info, ctx.accounts.sundial.key(), &ctx.accounts.clock, ctx.accounts.sundial.end_unix_time_stamp, ctx.accounts.sundial.config.liquidity_decimals, ) A very similar issue exists with changing sundial collateral configuration. instructions/borrowing_ instructions/change -sundial collateral config.rs - ctx.accounts.sundial collateral.sundial collateral _ _ _ config = config.into();Ok(()) This is especially dangerous, because changing the collateral configuration would massively overvalue the user’s collateral, allowing users to borrow endlessly from the Sundial program, draining the pool. Proof of Concept Consider the following scenario 1. A user deposits collateral 2. An admin runs the change_sundial_collateral_configinstruction. This zeroes the collateral decimals field, massively overvaluing any future collateral deposits. The user mints principle tokens for far more than the market value of the collateral. The user redeems the principle tokens a er the Sundial ends, making a massive amount of profit.","rust
programs/sundial/src/instructions/borrowing_instructions/change_sundial_collateral_config.rs

use crate::helpers::*;
use crate::instructions::SundialCollateralConfigParams;
use crate::state::{SundialCollateral, SundialMarket};
use anchor_lang::prelude::*;
use crate::error::SundialError;

@@ -23,6 +23,22 @@
pub fn process_change_sundial_collateral_config(
    ctx: Context<ChangeSundialCollateralConfig>,
    config: SundialCollateralConfigParams,
) -> ProgramResult {
    ctx.accounts.sundial_collateral.sundial_collateral_config = config.into();
    Ok(())
}

programs/sundial/src/instructions/lending_instructions/change_sundial_config.rs

use crate::helpers::*;
use crate::state::Sundial;
use crate::state::SundialConfig;
use crate::state::SundialMarket;
use anchor_lang::prelude::*;
use crate::instructions::SundialInitConfigParams;

@@ -25,7 +25,15 @@
pub fn process_change_sundial_config(
    ctx: Context<ChangeSundialConfig>,
    config: SundialInitConfigParams,
) -> ProgramResult {
    ctx.accounts.sundial.config = config.into();
    emit!(ChangeSundialConfigEvent {
        sundial: ctx.accounts.sundial.key(),
        config: ctx.accounts.sundial.config.clone(),
    });
    Ok(())
}

programs/sundial/src/instructions/lending_instructions/deposit_and_mint_tokens.rs

pub fn process_deposit_and_mint_tokens(
    ctx: Context<DepositAndMintTokens>,
    amount: u64,
) -> ProgramResult {
    let sundial = &ctx.accounts.sundial;
    let existed_lp_amount = ctx.accounts.sundial_port_lp_wallet.amount;
    let start_exchange_rate = CollateralExchangeRate(Rate(U128(sundial.start_exchange_rate)));
    
    log_then_prop_err!(deposit_reserve(
        ctx.accounts.port_accounts.create_deposit_reserve_context(
            ctx.accounts.user_liquidity_wallet.to_account_info(),
            ctx.accounts.sundial_port_lp_wallet.to_account_info(),
            ctx.accounts.user_authority.to_account_info(),
            ctx.accounts.clock.to_account_info(),
            ctx.accounts.token_program.to_account_info(),
            &[&[&[]]],
        ),
        amount,
    ));
    log_then_prop_err!(ctx.accounts.sundial_port_lp_wallet.reload());

    let principal_token_amount = start_exchange_rate.collateral_to_liquidity(unwrap_int!(
        ctx
            .accounts
            .sundial_port_lp_wallet
            .amount
            .checked_sub(existed_lp_amount)))?;

    let fee = &sundial.config.lending_fee;
    let fee_amount = log_then_prop_err!(fee.mint_fee
        (
            seeds!(ctx, sundial, authority),
            ctx.accounts.token_program.to_account_info(),
        ),
        amount
    ));

    let liquidity_cap = &sundial.config.liquidity_cap;
    log_then_prop_err!(liquidity_cap.check_mint(&mut ctx.accounts.principle_token_mint));
    emit!(DepositAndMintTokensEvent {
        sundial: ctx.accounts.sundial.key(),
        liquidity_spent: amount,
        principal_token_minted: principal_token_amount,
        yield_token_minted: amount
    });
    
    Ok(())
}","rust
programs/sundial/src/instructions/borrowing_instructions/change_sundial_collateral_config.rs
use crate::helpers::*;
use crate::instructions::SundialCollateralConfigParams;
use crate::state::{LiquidationConfig, LiquidityCap, SundialCollateral, SundialMarket, LTV};
use anchor_lang::prelude::*;
use crate::error::SundialError;

@@ -23,6 +23,22 @@
pub fn process_change_sundial_collateral_config(
    ctx: Context<ChangeSundialCollateralConfig>,
    config: SundialCollateralConfigParams,
) -> ProgramResult {
    ctx.accounts
        .sundial_collateral
        .sundial_collateral_config
        .ltv = LTV { 
            ltv: config.ltv 
        };
    ctx.accounts
        .sundial_collateral
        .sundial_collateral_config
        .liquidation_config = LiquidationConfig { 
            liquidation_threshold: config.liquidation_threshold, 
            liquidation_penalty: config.liquidation_penalty, 
        };
    ctx.accounts
        .sundial_collateral
        .sundial_collateral_config
        .liquidity_cap = LiquidityCap { 
            lamports: config.liquidity_cap, 
        };
    Ok(())
}

programs/sundial/src/instructions/lending_instructions/change_sundial_config.rs
use crate::helpers::*;
use crate::state::SundialConfig;
use crate::state::SundialMarket;
use crate::state::{Fee, LiquidityCap, Sundial};
use anchor_lang::prelude::*;
use crate::instructions::SundialInitConfigParams;

@@ -25,7 +25,15 @@
pub fn process_change_sundial_config(
    ctx: Context<ChangeSundialConfig>,
    config: SundialInitConfigParams,
) -> ProgramResult {
    ctx.accounts.sundial.config.lending_fee = Fee { 
        bips: config.lending_fee, 
    };
    ctx.accounts.sundial.config.borrow_fee = Fee { 
        bips: config.borrow_fee, 
    };
    ctx.accounts.sundial.config.liquidity_cap = LiquidityCap { 
        lamports: config.liquidity_cap, 
    };
    emit!(ChangeSundialConfigEvent { 
        sundial: ctx.accounts.sundial.key(), 
        config: ctx.accounts.sundial.config.clone(), 
    });
    Ok(())
}

#[event]
/// Event called in [sundial::change_sundial_config].
pub struct ChangeSundialConfigEvent {
    /// The [Sundial].
    #[index] 
    pub sundial: Pubkey,

    /// New [EigenParams].
    pub config: SundialConfig,
}

programs/sundial/src/instructions/lending_instructions/deposit_and_mint_tokens.rs
pub fn process_deposit_and_mint_tokens(
    ctx: Context<DepositAndMintTokens>,
    amount: u64,
) -> ProgramResult {
    let sundial = &ctx.accounts.sundial;
    let existed_lp_amount = ctx.accounts.sundial_port_lp_wallet.amount;
    let start_exchange_rate = CollateralExchangeRate(Rate(U128(sundial.start_exchange_rate)));

    log_then_prop_err!(deposit_reserve(
        ctx.accounts
            .port_accounts
            .create_deposit_reserve_context(
                ctx.accounts.user_liquidity_wallet.to_account_info(),
                ctx.accounts.sundial_port_lp_wallet.to_account_info(),
                ctx.accounts.user_authority.to_account_info(),
                ctx.accounts.clock.to_account_info(),
                ctx.accounts.token_program.to_account_info(),
            &[&[&[]]],
        ),
        amount,
    ));

    log_then_prop_err!(ctx.accounts.sundial_port_lp_wallet.reload());
    let current_lp_amount = ctx.accounts.sundial_port_lp_wallet.amount;

    // We calculate how much liquidity is deposited if we deposit it at the very beginning of [Sundial].
    let principal_token_amount = start_exchange_rate
        .collateral_to_liquidity(unwrap_int!(current_lp_amount.checked_sub(existed_lp_amount)))?;

    let fee = &sundial.config.lending_fee;
    let fee_amount = log_then_prop_err!(fee.mint_fee(
        @@ -158,7 +157,7 @@
        pub fn process_deposit_and_mint_tokens(
            seeds!(ctx, sundial, authority),
            ctx.accounts.token_program.to_account_info(),
        ),
        principal_token_amount
    ));

    let liquidity_cap = &sundial.config.liquidity_cap;
    log_then_prop_err!(liquidity_cap.check_mint(&mut ctx.accounts.principle_token_mint));

    emit!(DepositAndMintTokensEvent {
        sundial: ctx.accounts.sundial.key(),
        liquidity_spent: amount,
        principal_token_minted: principal_token_amount,
        yield_token_minted: amount
    });

    Ok(())
}",High,The program should keep the liquidity_decimalsand collateral_decimals fields the same when the config is changed.,https://github.com/port-finance/sundial/pull/78/files,High
Sol-119,"Both the addresses of Sundialand SundialCollateralare derived from the SundialMarketaddress, but the InitializeSundialinstruction does not use a fixed suﬀix.This results in the owner being able to create a Sundialand a SundialCollateralat the same address by appending b""sundial""to the collateral name and passing it to InitializeSundial. For example, a Sundial instance created with “Xcollateral” would collide with a SundialCollateral instance created with “X” . This could potentially lead to a usability concern if the seeds could be influenced by a malicious user. However, due to the low risk and impact, we rated this as informational as opposed to a denial of service concern.","rust
// Sundial Initialization
#[account(
    init, 
    payer = owner, 
    seeds = [ 
        sundial_market.key().as_ref(), 
        name.as_ref() 
    ], 
    bump = pda_bump 
)]
pub sundial: Account<'info, Sundial>,

// SundialCollateral Initialization
#[account(
    init,
    payer = owner,
    seeds = [
        sundial_market.key().as_ref(),
        name.as_ref(),
        b""collateral""
    ], 
    bump = pda_bump 
)]
pub sundial_collateral: Account<'info, SundialCollateral>","Rust
instructions/lending_instructions/initialize sundial.rs 

_payer = owner;
seeds = [ 
    sundial_market.key().as_ref(), 
    - name.as_ref() + name.as_ref(),
    + b""sundial"" 
];
bump = pda_bump;",Informational,"The seedsfor InitializeSundialshould include a suﬀix such as b""sundial""to prevent collisions.",https://github.com/port-finance/sundial/blob/master/audits/port-finance-sundial-audit-public.pdf (Page 21),High
Sol-120,"Lack of functionality for admin rotation. The program does not provide a mechanism to rotate or update the authority. This is considered a deviation from leading security practices as it limits exibility and poses operational risks, such as the inability to recover from admin key compromise.","rust
pub fn initialize(ctx: Context<Initialize>) -> Result<()> { 
    msg!(""Calling initialize""); 
    
    let global = &mut ctx.accounts.global; 
    
    require!(
        !global.initialized, 
        CurveLaunchpadError::AlreadyInitialized,
    ); 
    
    global.authority = *ctx.accounts.authority.to_account_info().key; 
    global.initialized = true; 
    global.initial_token_supply = DEFAULT_TOKEN_SUPPLY; 
    global.initial_real_sol_reserves = 0; 
    global.initial_real_token_reserves = DEFAULT_TOKEN_SUPPLY; 
    global.initial_virtual_sol_reserves = 30_000_000_000; 
    global.initial_virtual_token_reserves = 1_073_000_000_000_000; 
    global.fee_basis_points = 50; 
    
    msg!(""Initialized global state""); 
    
    Ok(()) 
}","rust
pub fn initialize(ctx: Context<Initialize>) -> Result<()> { 
    msg!(""Calling initialize""); 

    let global = &mut ctx.accounts.global; 

    require!(
        !global.initialized, 
        CurveLaunchpadError::AlreadyInitialized,
    ); 
    
    global.authority = *ctx.accounts.authority.key; 
    global.initialized = true; 
    global.initial_token_supply = DEFAULT_TOKEN_SUPPLY; 
    global.initial_real_sol_reserves = 0; 
    global.initial_real_token_reserves = DEFAULT_TOKEN_SUPPLY; 
    global.initial_virtual_sol_reserves = 30_000_000_000; 
    global.initial_virtual_token_reserves = 1_073_000_000_000_000; 
    global.fee_basis_points = 50; 
    
    msg!(""Initialized global state""); 

    Ok(())
}",Low,"Step 1: Initiate Authority Transfer: The current authority initiates the process by specifying the new authority's public key. This step stores the new authority's public key but does not nalize the transfer. Step 2: Confirm Authority Transfer: The new authority conrms the transfer to nalize the process and update the program's admin key. Issue was partially xed in 0d67840978f3965c343007707618bc37306f4c2b . The protocol implements a way for authority change, however the implemented approach is that old owner have to sign the authority changing transaction with the new owner. This might be problematic, as a new owner have only few minutes for it, as Solana is restricting that timeframe to some specic blocks amount. If the new owner will be, for example, a multisig, such a change might require to be executed on one device, or via some automation.",https://github.com/biswap-org/curve-launchpad/commit/0d67840978f3965c343007707618bc37306f4c2b,High
Sol-121,"Missing functionality to pause program operations.The program lacks a mechanism to pause its operations. This is considered a bad practice as it limits the authority's ability to respond to critical situations, such as: Security Incidents - in the event of a vulnerability or exploit, the inability to pause operations could lead to signicant nancial losses. Operational Failures - Pausing functionality allows the authority to temporarily halt operations while addressing bugs, miscongurations, or other unforeseen issues.","rust
pub fn buy(ctx: Context<Buy>, token_amount: u64, max_sol_cost: u64) -> Result<()> { 
    require!( 
        ctx.accounts.global.initialized, 
        CurveLaunchpadError::NotInitialized 
    ); 

    // Bonding curve is not complete
    require!( 
        !ctx.accounts.bonding_curve.complete, 
        @@ -75,27 +82,28 @@ CurveLaunchpadError::InsufficientTokens,
    );
}","use crate::instructions::CurveLaunchpadError; 
use crate::state::Global; 
use anchor_lang::prelude::*; 

#[derive(Accounts)] 
pub struct Pause<'info> { 
    #[account( mut, seeds = [Global::SEED_PREFIX], bump, )]
    global: Box<Account<'info, Global>>, 
    authority: Signer<'info>, 
    system_program: Program<'info, System>, 
} 

pub fn pause(ctx: Context<Pause>) -> Result<()> { 
    let global = &mut ctx.accounts.global;
    
    //confirm program is initialized 
    require!(global.initialized, CurveLaunchpadError::NotInitialized); 

    //confirm user is the authority 
    require!( 
        global.authority == *ctx.accounts.authority.key, 
        CurveLaunchpadError::InvalidAuthority 
    ); 
    
    global.paused = true; 
    
    Ok(()) 
} 

#[derive(Accounts)] 
pub struct Resume<'info> { 
    #[account( mut, seeds = [Global::SEED_PREFIX], bump, )]
    global: Box<Account<'info, Global>>, 
    authority: Signer<'info>, 
    system_program: Program<'info, System>, 
} 

pub fn resume(ctx: Context<Resume>) -> Result<()> { 
    let global = &mut ctx.accounts.global; 

    //confirm program is initialized
    require!(global.initialized, CurveLaunchpadError::NotInitialized);

    //confirm user is the authority  
    require!( 
        global.authority == *ctx.accounts.authority.key,
        CurveLaunchpadError::InvalidAuthority 
    );

    global.paused = false;

    Ok(()) 
} 

pub fn buy(ctx: Context<Buy>, token_amount: u64, max_sol_cost: u64) -> Result<()> {
   
   //confirm program is initialized 
   require!( 
      ctx.accounts.global.initialized, 
      CurveLaunchpadError::NotInitialized 
   );

   //confirm program is not paused
   require!( 
      !ctx.accounts.global.paused, 
      CurveLaunchpadError::ProgramIsPaused 
   );

   //bonding curve is not complete
   require!( 
      !ctx.accounts.bonding_curve.complete,
      CurveLaunchpadError::InsufficientTokens, 
   );
}",Low,"Implement a pausability mechanism controlled by the authority. The program should maintain a state variable to indicate whether operations are paused, and all instructions should check this state before executing. Issue was xed in 7d4bc557c2954f96b0723f5ea464774336710dd6 by creation of pausing and resuming mechanism.",https://github.com/biswap-org/curve-launchpad/commit/7d4bc557c2954f96b0723f5ea464774336710dd6,High
Sol-122,"Lack of validation for set_fee edge values - Low. The program does not validate the fee_amount value set during the set_fee call This allows authority to supply an arbitrary high values, what might discourage usage of the protocol due to the too big fee for the potential users. Additionally, authority can potentially frontrun user operations, collecting high fees.","rust
pub fn set_fee(ctx: Context<SetFee>, fee_amount: u64) -> Result<()> {
    let global = &mut ctx.accounts.global; 

    // confirm program is initialized
    require!(
        global.initialized, 
        CurveLaunchpadError::NotInitialized
    ); 

    // confirm user is the authority
    require!(
        global.authority == *ctx.accounts.user.to_account_info().key, 
        CurveLaunchpadError::InvalidAuthority
    ); 
    
    global.fee_basis_points = fee_amount; 
    Ok(())
} 

pub fn set_params(
    ctx: Context<SetParams>,
    fee_recipient: Pubkey,
    withdraw_authority: Pubkey,
    initial: Reserves,
    initial_token_supply: u64,
    fee_basis_points: u64,
) -> Result<()> {
    let global = &mut ctx.accounts.global; 

    // confirm program is initialized
    require!(global.initialized, CurveLaunchpadError::NotInitialized); 

    // confirm user is the authority
    require!(
        global.authority == *ctx.accounts.user.key, 
        CurveLaunchpadError::InvalidAuthority
    ); 
    
    global.fee_recipient = fee_recipient;
    global.initial_virtual_token_reserves = initial.virtual_token_reserves;
    global.initial_virtual_sol_reserves = initial.virtual_sol_reserves;
    global.initial_real_token_reserves = initial.real_token_reserves;
    global.initial_token_supply = initial_token_supply;
    global.fee_basis_points = fee_basis_points;
    global.withdraw_authority = withdraw_authority; 

    // TODO: create later method new() for ParamsEven so you pass params without those
    let initial_virtual_token_reserves = initial.virtual_token_reserves;
    let initial_virtual_sol_reserves = initial.virtual_sol_reserves;
    let initial_real_token_reserves = initial.real_token_reserves;

    emit_cpi!(
        SetParamsEvent { 
            fee_recipient,
            withdraw_authority,
            initial_virtual_token_reserves,
            initial_virtual_sol_reserves,
            initial_real_token_reserves,
            initial_token_supply,
            fee_basis_points,
        }
    );

    Ok(())
}","rust
pub fn set_params( 
    ctx: Context<SetParams>, 
    fee_recipient: Pubkey, 
    withdraw_authority: Pubkey, 
    initial: Reserves, 
    initial_token_supply: u64, 
    fee_basis_points: u64, 
) -> Result<()> { 
    let global = &mut ctx.accounts.global; 

    //confirm program is initialized
    require!(
        global.initialized, 
        CurveLaunchpadError::NotInitialized
    ); 

    //confirm user is the authority
    require!( 
        global.authority == *ctx.accounts.user.key, 
        CurveLaunchpadError::InvalidAuthority 
    ); 

    //confirm new fee value is less than 10%
    require!( 
        calculate_fee(100, fee_basis_points) <= 10, 
        CurveLaunchpadError::MaxFeeExceeded 
    ); 

    global.fee_recipient = fee_recipient; 
    global.initial_virtual_token_reserves = initial.virtual_token_reserves; 
    global.initial_virtual_sol_reserves = initial.virtual_sol_reserves; 
    global.initial_real_token_reserves = initial.real_token_reserves; 
    global.initial_token_supply = initial_token_supply; 
    global.fee_basis_points = fee_basis_points; 
    global.withdraw_authority = withdraw_authority; 

    //TODO: create later method new() for ParamsEven so you pass params without those
    let initial_virtual_token_reserves = initial.virtual_token_reserves; 
    let initial_virtual_sol_reserves = initial.virtual_sol_reserves; 
    let initial_real_token_reserves = initial.real_token_reserves; 

    emit_cpi!(
        SetParamsEvent { 
            fee_recipient, 
            withdraw_authority, 
            initial_virtual_token_reserves, 
            initial_virtual_sol_reserves, 
            initial_real_token_reserves, 
            initial_token_supply, 
            fee_basis_points, 
        }
    ); 

    Ok(())
}",Low,Add validation logic to ensure that the fee_amount is between the acceptable bounds.,https://github.com/biswap-org/curve-launchpad/commit/8675be6574a8390696a02ab647de6c67e97013b6,High
Sol-123,The SwapSolForTokens instruction requires integrator_wsol_ata to be provided as read-only while it is a token account dedicated for fees collection. This may lead to the instruction fails due to trying write to read-only account,"rust
#[derive(Accounts)]
pub struct SwapSolForTokens<'info> {
    pub integrator_wsol_ata: Account<'info, TokenAccount>,
    // other fields...
}","rust
#[derive(Accounts)]
pub struct SwapSolForTokens<'info> {
    #[account(mut)] 
    pub integrator_wsol_ata: Account<'info, TokenAccount>,
    // ...
}",Medium,Consider declaring the account as mutable.,https://hacken.io/audits/unizen/sca-unizen-unizen-solana-swap-jan2025/,High
Sol-124,"The protocol does not validate whether the fee specified by the user when creating an order is less than the amount of the order. This allows users to specify a fee greater than the actual order amount, resulting in the protocol accumulating a fee balance that does not exist. Consequently, when orchestrators attempt to withdraw accumulated fees, they may encounter a situation where the total fee balance exceeds the actual funds available, causing withdrawals to fail and halting protocol operations. Create an Order with Insufficient Funds to Cover the Fee: A malicious user creates an order with a small amount but specifies a larger fee. For example: amount = 0.05 SOL fee = 100 SOL The protocol accepts the order, assuming the fee is valid, and adds 100 SOL to the accumulated fee balance. Repeat the Process to Inflate Fee Balances: The user repeats the above step multiple times, creating numerous orders with fees larger than the order amounts. Each time, the protocol incorrectly accumulates fees that do not exist in the vault. Withdraw Fees by Orchestrators: Orchestrators attempt to withdraw accumulated fees. However, the vault balance is insufficient to cover the inflated fee balance. This results in withdrawal failures, disrupting protocol operations and potentially halting orchestrator activities.","rust
impl CreateOrder<'_> {
    pub fn process_instruction(ctx: Context<Self>, ... ) -> Result<()> {
        ...
        let min_fee = ctx.accounts.target_chain_min_fee.min_fee;
        if min_fee > fee { 
            return err!(GeniusError::InsufficientFees); 
        } 
        ...
        ctx.accounts.asset.unclaimed_fees += fee; 
        ctx.accounts.asset.total_fee_collected += fee; 
        
        // Transfer USDC from orchestrator to vault 
        token_transfer_user(
            ctx.accounts.ata_trader.to_account_info().clone(),
            ctx.accounts.trader.to_account_info().clone(),
            ctx.accounts.ata_vault.to_account_info().clone(),
            ctx.accounts.token_program.to_account_info().clone(),
            amount,
        )?;
        ...
        Ok(())
    } 
}","impl CreateOrder<'_> { 
    pub fn process_instruction(ctx: Context<Self>, ...) -> Result<()> { 
        // Extract the order amount and fee from the context 
        let amount = ctx.accounts.order.amount; 
        let fee = ctx.accounts.order.fee; 
        
        // Ensure the fee is less than or equal to the order amount 
        if fee > amount { 
            return Err(GeniusError::InvalidFeeAmount.into()); 
        } 
        
        // Existing check for minimum fee 
        let min_fee = ctx.accounts.target_chain_min_fee.min_fee; 
        if min_fee > fee { 
            return Err(GeniusError::InsufficientFees.into()); 
        } 
        
        // Update unclaimed fees and total fees collected 
        ctx.accounts.asset.unclaimed_fees += fee; 
        ctx.accounts.asset.total_fee_collected += fee; 
        
        // Transfer USDC from trader to vault 
        token_transfer_user( 
            ctx.accounts.ata_trader.to_account_info().clone(), 
            ctx.accounts.trader.to_account_info().clone(), 
            ctx.accounts.ata_vault.to_account_info().clone(), 
            ctx.accounts.token_program.to_account_info().clone(), 
            amount, 
        )?; 
        
        Ok(()) 
    } 
}",Critical,Ensure that the fee specified by the user is less than or equal to the amount of the order and reject orders where fee > amount.,https://hacken.io/audits/shuttle-labs/sca-shuttle-labs-rust-jan2025/,High
Sol-125,"The protocol does not enforce a minimum order amount when creating orders. This allows users to create a large number of orders with negligible amounts, such as near-zero token values. Such behavior can lead to significant inefficiencies and potential denial-of-service (DoS) risks for the off-chain orchestrators responsible for processing these orders. If orchestrators must process thousands of trivial orders, their computational resources and bandwidth could be overwhelmed, leading to delays in legitimate transactions and degraded performance of the off-chain network. This lack of validation creates a vulnerability that could be exploited by malicious users to disrupt the system.","rust
impl CreateOrder<'_> {
    pub fn process_instruction( 
        ctx: Context<Self>, 
        ... 
    ) -> Result<()> { 
        ...
        let min_fee = ctx.accounts.target_chain_min_fee.min_fee;
        
        if min_fee > fee { 
            return err!(GeniusError::InsufficientFees); 
        } 
        
        ...
        
        ctx.accounts.asset.unclaimed_fees += fee;
        ctx.accounts.asset.total_fee_collected += fee; 
        
        // Transfer USDC from orchestrator to vault
        token_transfer_user(
            ctx.accounts.ata_trader.to_account_info().clone(),
            ctx.accounts.trader.to_account_info().clone(),
            ctx.accounts.ata_vault.to_account_info().clone(),
            ctx.accounts.token_program.to_account_info().clone(),
            amount,
        )?;
        
        ...
        Ok(())
    } 
}","rust
const MIN_ORDER_AMOUNT: u64 = 100; // Example value; adjust as needed

impl CreateOrder<'_> {
    pub fn process_instruction(ctx: Context<Self>, ...) -> Result<()> {
        let amount = ctx.accounts.order.amount;
        let fee = ctx.accounts.order.fee;

        // Validate that the order amount meets the minimum requirement
        if amount < MIN_ORDER_AMOUNT {
            return Err(GeniusError::OrderAmountTooLow.into());
        }

        // Existing fee validation
        if fee > amount {
            return Err(GeniusError::InvalidFeeAmount.into());
        }

        let min_fee = ctx.accounts.target_chain_min_fee.min_fee;
        if min_fee > fee {
            return Err(GeniusError::InsufficientFees.into());
        }

        // Update fee records
        ctx.accounts.asset.unclaimed_fees += fee;
        ctx.accounts.asset.total_fee_collected += fee;

        // Transfer assets from trader to vault token_transfer_user(
        ctx.accounts.ata_trader.to_account_info().clone(),
        ctx.accounts.trader.to_account_info().clone(),
        ctx.accounts.ata_vault.to_account_info().clone(),
        ctx.accounts.token_program.to_account_info().clone(),
        amount,
        )?;
        
        Ok(())
    }
}",Medium,Introduce a minimum order amount validation to ensure that only meaningful orders are created. This prevents resource wastage and mitigates the risk of orchestrator overload.,https://hacken.io/audits/shuttle-labs/sca-shuttle-labs-rust-jan2025/,High
Sol-126,"The program does not provide an order cancellation mechanism, leaving the protocol vulnerable to scenarios where funds become stuck if an order cannot be processed. Currently, orchestrators, which are run by the protocol, are required to process orders. If the protocol sets an insufficient minimum fee for processing an order, orchestrators must cover the fee difference to process the order. This can lead to financial losses for the protocol, especially in chains where gas prices vary significantly and are difficult to predict accurately. Without an order cancellation mechanism, the protocol bears the risk of mismanaging fees, forcing it to subsidize the cost of processing orders where the minimum fee was underestimated. Over time, this could lead to unsustainable costs and reduce protocol reliability.","rust
impl SetTargetChainMinFee<'_> {
    pub fn process_instruction(ctx: Context<Self>, dest_chain_id: u32, min_fee: u64) -> Result<()> {
        // shouldn't be verified against fee in cross_chain_fee_bps?
        let target_chain_min_fee = &mut ctx.accounts.target_chain_min_fee;
        target_chain_min_fee.dest_chain_id = dest_chain_id;
        target_chain_min_fee.token_in = ctx.accounts.usdc_mint.key().to_bytes();
        target_chain_min_fee.min_fee = min_fee;
        Ok(())
    }
}","#[derive(Accounts)]
pub struct CancelOrder<'info> {
    #[account(mut)]
    pub order: Account<'info, Order>,
    #[account(mut)]
    pub user: Signer<'info>,
    // Additional accounts as needed
}

impl CancelOrder<'_> {
    pub fn process_instruction(ctx: Context<Self>, order_id: u64) -> Result<()> {
        let order = &mut ctx.accounts.order;
        
        // Validate order can be cancelled
        require!(
            order.status == OrderStatus::Pending,
            ProtocolError::OrderNotCancellable
        );
        require!(
            order.user == ctx.accounts.user.key(),
            ProtocolError::Unauthorized
        );
        
        // Refund locked funds to user
        let refund_amount = order.amount;
        // Implement token transfer logic here
        // ...
        
        // Update order status
        order.status = OrderStatus::Cancelled;
        order.cancelled_at = Clock::get()?.unix_timestamp;
        
        emit!(OrderCancelled {
            order_id,
            user: ctx.accounts.user.key(),
            amount: refund_amount,
            timestamp: order.cancelled_at,
        });
        
        Ok(())
    }
}

#[account]
pub struct Order {
    pub id: u64,
    pub user: Pubkey,
    pub amount: u64,
    pub status: OrderStatus,
    pub created_at: i64,
    pub cancelled_at: Option<i64>,
    // Additional order fields
}

#[derive(AnchorSerialize, AnchorDeserialize, Clone, PartialEq, Eq)]
pub enum OrderStatus {
    Pending,
    Processing,
    Completed,
    Cancelled,
    Failed,
}

#[event]
pub struct OrderCancelled {
    pub order_id: u64,
    pub user: Pubkey,
    pub amount: u64,
    pub timestamp: i64,
}",Low,Introduce an order cancellation mechanism that allows users to cancel their unprocessed orders. This would prevent the protocol from being forced to process orders at a loss in cases of mismanaged fees or volatile gas prices.,https://hacken.io/audits/shuttle-labs/sca-shuttle-labs-rust-jan2025/,Low
Sol-127,"The create_pool instruction requires the associated token account for the pool to be uninitialized. However, a malicious actor can pre-initialize this account before the legitimate creator does, effectively blocking the pool creation process. This creates a Denial of Service (DoS) vulnerability, where an attacker can prevent others from creating pools by pre-initializing the required associated token accounts, disrupting the protocol's functionality and user experience.","rust
#[derive(Accounts)]
pub struct CreateLiquidityPool<'info> {
    // ...
    
    /// The pool's token account that will hold the tokens
    #[account(
        init,
        payer = creator,
        associated_token::mint = mint,
        associated_token::authority = pool,
        associated_token::token_program = token_program,
    )]
    pub pool_token_account: InterfaceAccount<'info, TokenAccount>,
    
    // ...
}","rust
#[derive(Accounts)]
pub struct CreateLiquidityPool<'info> {
    // Other accounts 
    #[account(
        init_if_needed, 
        payer = creator, 
        associated_token::mint = mint, 
        associated_token::authority = pool, 
        associated_token::token_program = token_program,
    )]
    pub pool_token_account: InterfaceAccount<'info, TokenAccount>,
    // Other accounts 
}",High,"Modify the create_pool logic to allow pool creation even if the associated token account is already initialized. This can be achieved by using init_if_needed to ensure that the program initializes the associated token account if it does not already exist, avoiding conflicts.",https://hacken.io/audits/opinions-fun/sca-opinions-fun-opinions-dot-fun-contracts-dec2024/,High
Sol-128,"The transfer_raydium_fees function uses a hardcoded constant (RAYDIUM_FEE_LAMPORTS) to calculate the fee for Raydium pool creation. If Raydium adjusts their fee structure, the hardcoded value will no longer be valid, causing the protocol to fail during pool migration. This dependency on a static value introduces fragility to the protocol's functionality, making it incompatible with future Raydium updates.","rust
/// Transfers the required fees for Raydium pool creation to the pool signer 
/// Amount is defined by RAYDIUM_FEE_LAMPORTS constant 
pub fn transfer_raydium_fees(&self) -> Result<()> { 
    ... 
    transfer(cpi_ctx, RAYDIUM_FEE_LAMPORTS)?; 
    Ok(()) 
}","rust
// Pseudocode for fetching the create_pool_fee 
let amm_config_account = &ctx.accounts.amm_config;
let create_pool_fee = amm_config_account.create_pool_fee;

// Pseudocode for validating the amm_config account
if amm_config_account.key() != expected_amm_config_key { 
    return Err(ProgramError::InvalidAccountData); 
}

// Pseudocode for transferring the create_pool_fee
let cpi_accounts = Transfer { 
    from: ctx.accounts.payer.to_account_info(), 
    to: ctx.accounts.raydium_fee_receiver.to_account_info(), 
    authority: ctx.accounts.payer.to_account_info(), 
};

let cpi_context = CpiContext::new(ctx.accounts.token_program.to_account_info(), cpi_accounts);

token::transfer(cpi_context, create_pool_fee)?;",Medium,"Make **create_pool_fee** Calculation Dynamic: Replace the hardcoded RAYDIUM_FEE_LAMPORTS constant with dynamic fee calculation during the initialize_raydium instruction. Fetch the create_pool_fee value dynamically from Raydium's amm_config account. Validate **amm_config**: Ensure the provided amm_config matches the expected configuration, including the create_pool_fee, to prevent users from supplying unintended or malicious configurations. Update **initialize_raydium** Instruction: Integrate the dynamic fee calculation and amm_config validation into the pool initialization process. Transfer the dynamically calculated create_pool_fee value to Raydium’s fee receiver account. Calculate Rent Dynamically: Include dynamic calculation of rent-exempt lamports required for any new accounts created during the migration process.",https://hacken.io/audits/opinions-fun/sca-opinions-fun-opinions-dot-fun-contracts-dec2024/,High
Sol-129,"Unauthorized Treasury Wallet Withdrawal due to Lack of Signer Validation. The IssuerAccept and InvestorAcceptAndPay instructions of the instruct module utilize the check_acceptance macros to validate the product is ready for acceptance. The macros requires the investor or issuer to be the signer. However, the IssuerAccept instruction is intended solely for the issuer, but it can currently be called by an investor. This oversight allows the investor to Initialize new product, execute IssuerAccept without appropriate signature, and then execute the SettlePayment instruction draining the Treasury Wallet account of the specified issuer. Additionally, the InvestorAcceptAndPay instruction is intended solely for the investor, but it can also be called by the issuer. This undermines the intended access control mechanisms, however, does not significantly impact the system.","rust
macro_rules! check_acceptance {
    ($ctx:expr, $validity_in_seconds:expr, $expected_signer:expr) => {
        // Existing validation logic
        // Note: No explicit check to verify that $expected_signer is a signer
    };
}

//Some other file

pub fn issuer_accept(
    ctx: Context<IssuerAccept>,
    validity_in_seconds: Option<i64>,
) -> Result<()> {
    check_acceptance!(ctx, validity_in_seconds, ctx.accounts.issuer.key());
    ...
}

pub fn investor_accept_and_pay(
    ctx: Context<InvestorAcceptAndPay>,
    validity_in_seconds: Option<i64>,
) -> Result<()> {
    check_acceptance!(ctx, validity_in_seconds, ctx.accounts.investor.key());
    ...
}","rust
macro_rules! check_acceptance {
    (
        $ctx:expr, 
        $validity_in_seconds:expr, 
        $expected_signer:expr
    ) => { 
        // Existing validation logic 
        // Ensure the expected signer is a signer of the transaction
        if !$ctx.accounts.$expected_signer.is_signer {
            return Err(ProgramError::MissingRequiredSignature); 
        } 
        // Additional validation logic 
    }; 
} 

//Some other file
pub fn issuer_accept(
    ctx: Context<IssuerAccept>, 
    validity_in_seconds: Option<i64>, 
) -> Result<()> { 
    check_acceptance!(ctx, validity_in_seconds, ctx.accounts.issuer.key()); 
    // ... 
}

pub fn investor_accept_and_pay(
    ctx: Context<InvestorAcceptAndPay>, 
    validity_in_seconds: Option<i64>, 
) -> Result<()> { 
    check_acceptance!(ctx, validity_in_seconds, ctx.accounts.investor.key());
    // ... 
}",Critical,"The expected_invoker parameter is added to the check_acceptance macros enforcing strict access controls on the IssuerAccept and InvestorAcceptAndPay instructions, ensuring that each instruction can only be invoked by the intended and authorized caller.",https://hacken.io/audits/margarita-finance-by-obligate-ag/sca-obligate-instruct-sep2024/,High
Sol-130,"Invalid Dynamic Payment Currency Set due to Lack of Mint Accounts Validation. The FixPayment instruction of the payment_authority_brc module does not validate the provided cash_mint and underlying_mint accounts correspond to the ones recorded in the barrier_reverse_convertible PDA.The instruction can be called by any user causing the accounts are arbitrary token mints. The instruction aims to fix the dynamic payment amount and mint account. Though, the situation may lead to the dynamic payment be fixed with an invalid mint. An invalid mint account leads to the product issuer lose value from the Treasury Wallet or the payment is defaulted and the investor does not receive the expected funds.","rust
#[derive(Accounts)]
pub struct FixPayment<'info> {
    #[account(...)]
    pub barrier_reverse_convertible: Account<'info, BarrierReverseConvertible>,
    pub cash_mint: InterfaceAccount<'info, Mint>,
    pub underlying_mint: InterfaceAccount<'info, Mint>,
    // ...
}

pub fn fix_payment(ctx: Context<FixPayment>) -> Result<()> {
    // ...

    let final_payment_mint = match final_payment_mint {
        PaymentMint::Cash => &ctx.accounts.cash_mint,
        PaymentMint::Underlying => &ctx.accounts.underlying_mint,
    };

    let cpi_accounts = instruct::cpi::accounts::FixPayment {
        authority: barrier_reverse_convertible.to_account_info(),
        mint: final_payment_mint.to_account_info(),
        structured_product: structured_product.to_account_info(),
        system_program: ctx.accounts.system_program.to_account_info(),
    };

    // ...
}","rust
pub fn fix_payment(ctx: Context<FixPayment>) -> Result<()> {
    let barrier_reverse_convertible = &ctx.accounts.barrier_reverse_convertible;
    //...
    require!(
        ctx.accounts.cash_mint.key() == barrier_reverse_convertible.cash_mint,
        BRCError::InvalidCashMint
    );
    require!(
        ctx.accounts.underlying_mint.key() == barrier_reverse_convertible.underlying_mint,
        BRCError::InvalidUnderlyingMint
    ); 
    //...
}",Critical,Consider validating the mint accounts match the recorded ones.,https://hacken.io/audits/margarita-finance-by-obligate-ag/sca-obligate-instruct-sep2024/,High
Sol-131,"Inability to Issue Product due to Token Account Closure Block. The Issue instruction in the instruct module includes a call to the Token::CloseAccount instruction, which can only be executed if the specified account has a zero balance. While the Issue instruction handles deposits and fees, it does not account for the possibility that an external user could send additional funds to the account. If a malicious user deposits a small amount (dust) into the account, the Issue instruction will fail, causing the transaction to revert due to the non-zero balance. As a result, a malicious user can repeatedly block the contract functionality.","rust
pub fn issue(ctx: Context<Issue>) -> Result<()> {  
    ...  
    token::transfer(  
        ...  
        ctx.accounts.structured_product.issuance_payment_amount,  
    )?;   
    if ctx.accounts.structured_product.fee_amount > 0 {  
        ...  
        token::transfer(  
            ...  
            ctx.accounts.structured_product.fee_amount,  
        )?;  
    }   
    close_escrow_token_account!(...);  
    ... 
}","pub fn issue(ctx: Context<Issue>) -> Result<()> {
    // Existing token transfers token
    token::transfer( 
        CpiContext::new(
            ctx.accounts.token_program.to_account_info(),
            token::Transfer {
                from: ctx.accounts.issuance_payment_account.to_account_info(),
                to: ctx.accounts.structured_product.to_account_info(),
                authority: ctx.accounts.structured_product.to_account_info(),
            },
        ),
        ctx.accounts.structured_product.issuance_payment_amount,
    )?;

    if ctx.accounts.structured_product.fee_amount > 0 {
        token::transfer(
            CpiContext::new(
                ctx.accounts.token_program.to_account_info(),
                token::Transfer {
                    from: ctx.accounts.fee_account.to_account_info(),
                    to: ctx.accounts.structured_product.to_account_info(),
                    authority: ctx.accounts.structured_product.to_account_info(),
                },
            ),
            ctx.accounts.structured_product.fee_amount,
        )?;
    }

    // Transfer any remaining tokens to the treasury account
    let escrow_balance = ctx.accounts.escrow_token_account.amount;
    if escrow_balance > 0 {
        token::transfer(
            CpiContext::new(
                ctx.accounts.token_program.to_account_info(),
                token::Transfer {
                    from: ctx.accounts.escrow_token_account.to_account_info(),
                    to: ctx.accounts.treasury_account.to_account_info(),
                    authority: ctx.accounts.structured_product.to_account_info(),
                },
            ),
            escrow_balance,
        )?;
    }

    // Close the escrow token account
    token::close_account(
        CpiContext::new(
             ctx.accounts.token_program.to_account_info(),
             token::CloseAccount {
                 account: ctx.accounts.escrow_token_account.to_account_info(),
                 destination: ctx.accounts.structured_product.to_account_info(),
                 authority: ctx.accounts.structured_product.to_account_info(),
             },
         ),
     )?;

     Ok(())
}",High,"Consider modifying the Issue instruction to transfer any remaining balance to the issuer treasury address before attempting to close the account. This would ensure the account balance is zero, allowing Token::CloseAccount to execute without disruption.",https://hacken.io/audits/margarita-finance-by-obligate-ag/sca-obligate-instruct-sep2024/,High
Sol-132,"Unexpected Product Closure due to Lack of Time Validation. The Close instruction of the Instruct program allows closing the product if it has not been accepted by one or both parties. However, the function does not validate the time in cases where neither party has accepted the product yet. Since the instruction can be called by any user, a third party may invoke the Close function and close the product before either the issuer or investor has had a chance to accept it. This may lead to a Denial of Service (DoS) situation, preventing the proper issuance of the product.","rust
// Function close
pub fn close(ctx: Context<Close>) -> Result<()> { 
    ... 
    //Verifying conditions using require macro 
    require!(
        structured_product.max_issuance_date.is_some()   // Checking if max_issuance_date is not empty 
        && Clock::get()?.unix_timestamp > structured_product.max_issuance_date.unwrap() // Checking if current UNIX timestamp is greater than max_issuance_date
        
        // Logical OR operator 
        
        || structured_product.investor_accepted.is_none() // Checking if investor_accepted is empty
        && structured_product.issuer_accepted.is_none(),  // Checking if issuer_accepted is empty
        
        StructuredProductError::IssuanceNotExpired        // If any condition fails, IssuanceNotExpired error is thrown
    ); 
    ...
} 

// Struct Close
pub struct Close<'info> { 
    #[account(mut)] pub payer: Signer<'info>, 
    ... 
}","rust
pub fn close(ctx: Context<Close>) -> Result<()> { 
    ... 
    require!(
        structured_product.max_issuance_date.is_some() 
        && Clock::get()?.unix_timestamp > structured_product.max_issuance_date.unwrap() 
        || structured_product.investor_accepted.is_none() 
        && structured_product.issuer_accepted.is_none(), 
        StructuredProductError::IssuanceNotExpired 
    ); 
    ... 
}

pub struct Close<'info> { 
    #[account(mut)] 
    pub payer: Signer<'info>, 
    ... 
}

pub fn initialize(... deadline: i64 ...) -> Result<()> { 
    let structured_product = &mut ctx.accounts.structured_product; 
    structured_product.deadline = deadline; 
    ... 
}

pub fn close(ctx: Context<Close>) -> Result<()> { 
    ... 
    require!(
        structured_product.max_issuance_date.is_some() 
        && Clock::get()?.unix_timestamp > structured_product.max_issuance_date.unwrap() 
        || structured_product.investor_accepted.is_none() 
        && structured_product.issuer_accepted.is_none() 
        && Clock::get()?.unix_timestamp > structured_product.deadline, 
        StructuredProductError::IssuanceNotExpired 
    ); 
    ... 
}

pub struct StructuredProduct { 
    pub deadline: i64, 
    ... 
}",High,"Consider restricting the Close instruction to the product authority. Alternatively, setup the deadline timestamp and allow the closure only as the deadline passed.",https://hacken.io/audits/margarita-finance-by-obligate-ag/sca-obligate-instruct-sep2024/,High
Sol-133,Invalid Payment Amount due to Unchecked Type Cast. The get_final_payment function used in the payment_authority_brc module performs unchecked type cast of i32 to u32 which may result in integer underflow. The FixPayment instruction of the payment_authority_brc module performs unchecked type cast of i64 to u64 which may result in integer underflow.This may lead to incorrect payment amount calculation in case the Oracle returns unexpected data.,"rust
fn get_final_payment(... price_exponent: i32 ...) -> Result<(u64, PaymentMint)> { 
    ...
    -price_exponent as u32 
    ... 
} 

pub fn fix_payment(ctx: Context<FixPayment>) -> Result<()> { 
    ... 
    let final_fixing_price: i64 = 
        price_update.get_price_unchecked(&barrier_reverse_convertible.feed_id)?.price; 
    ... 
    final_fixing_price as u64 
    ... 
}","rust
fn get_final_payment(..., price_exponent: i32, ...) -> Result<(u64, PaymentMint)> { 
    // Validate that price_exponent is non-negative 
    if price_exponent < 0 { 
        return Err(anyhow!(""price_exponent cannot be negative"")); 
    } 
    
    // Safe to cast as price_exponent is non-negative 
    let exponent = price_exponent as u32; 
    
    // Rest of the function logic 
    // ...
} 

pub fn fix_payment(ctx: Context<FixPayment>) -> Result<()> { 
    // Retrieve the price from the Oracle 
    let final_fixing_price: i64 = price_update
        .get_price_unchecked(&barrier_reverse_convertible.feed_id)?
        .price; 
        
    // Validate that final_fixing_price is non-negative 
    if final_fixing_price < 0 { 
        return Err(anyhow!(""final_fixing_price cannot be negative"")); 
    } 
    
    // Safe to cast as final_fixing_price is non-negative 
    let final_price = final_fixing_price as u64; 
    
    // Rest of the function logic
    // ...
}",Medium,"Consider validating the Oracle returned price is greater than zero, process the both positive and negative exponent values.",https://hacken.io/audits/margarita-finance-by-obligate-ag/sca-obligate-instruct-sep2024/,High
Sol-134,Product Misconfiguration due to Lack of Authority Verification. The Initialize instruction of the payment_authority_brc module does not validate the authority account is authorized for the initialization. This allows anyone to initialize the fix payment with malformed data after Initialize is executed in the instruct module and before Initialize is executed in the payment_authority_brc module. This may lead to products misconfiguration in case the setup happens using several transactions.,"rust
pub fn initialize(ctx: Context<Initialize>, args: InitArgs) -> Result<()> { 
    ...
    let barrier_reverse_convertible = &mut ctx.accounts.barrier_reverse_convertible; 
    barrier_reverse_convertible... = ...; 
    ... 
}

#[derive(Accounts)]
pub struct Initialize<'info> { 
    #[account(mut)] 
    pub authority: Signer<'info>, 
    pub structured_product: Account<'info, StructuredProduct>, 
    ...
    #[account(init, seeds=[structured_product.key().as_ref(), &[args.payment_index]], ...)]
    pub barrier_reverse_convertible: Account<'info, BarrierReverseConvertible>, 
    ... 
}","rust
#[derive(Accounts)]
pub struct Initialize<'info> {
    #[account(mut, has_one = authority)]
    pub structured_product: Account<'info, StructuredProduct>,

    #[account(mut)]
    pub authority: Signer<'info>,

    #[account(
        init, 
        seeds = [structured_product.key().as_ref(), &[args.payment_index]], 
        bump, 
        payer = authority, 
        space = BarrierReverseConvertible::LEN,
    )]
    pub barrier_reverse_convertible: Account<'info, BarrierReverseConvertible>,

    pub system_program: Program<'info, System>,
}",Medium,Consider validating the authority recorded in the StructuredProduct matches the authority account provided to the Initialize instruction of the payment_authority_brc module.,https://hacken.io/audits/margarita-finance-by-obligate-ag/sca-obligate-instruct-sep2024/,High
Sol-135,"Unauthorized Treasury Wallet Withdrawal due to Lack of Wallet Owner Verification. The SettlePayment instruction allows to invoke the product payment settlement transferring funds from the issuer Treasury Wallet to the investor, However, the function lacks for validation the provided Treasury Wallet equals to the recorded one. The instruction can be called by any user causing the provided Treasury Wallet is arbitrary. This may lead to the product payment being charged from Treasury Wallet of any issuer which created withdraw authorization for the product.","pub fn settle_payment(ctx: Context<SettlePayment> ...) -> Result<()> { 
    ...
    let cpi_accounts = treasury_wallet::cpi::accounts::Withdraw { 
        treasury_wallet: ctx.accounts.issuer_treasury_wallet.to_account_info(),
        treasury_wallet_token_account: 
            ctx.accounts.issuer_treasury_wallet_token_account.to_account_info(),
        ...
        withdraw_authorization: Some(ctx.accounts.withdraw_authorization.to_account_info()),
        ... 
    }; 
    ...
    treasury_wallet::cpi::withdraw( ... amount, )?;
    ... 
}

pub struct SettlePayment<'info> { 
    #[account(mut)]
    pub payer: Signer<'info>,
    ...
    pub issuer_treasury_wallet: Account<'info, TreasuryWalletAccount>,
    pub withdraw_authorization: Account<'info, WithdrawAuthorization>,
    ...
    #[account(mut, token::authority=issuer_treasury_wallet)]
    pub issuer_treasury_wallet_token_account: InterfaceAccount<'info, TokenAccount>,
...
}","pub fn settle_payment(ctx: Context<SettlePayment> ...) -> Result<()>{ 
    ... 
    let cpi_accounts = treasury_wallet::cpi::accounts::Withdraw { 
        treasury_wallet: ctx.accounts.issuer_treasury_wallet.to_account_info(), 
        treasury_wallet_token_account: ctx.accounts.issuer_treasury_wallet_token_account.to_account_info(), 
        ... 
        withdraw_authorization: Some(ctx.accounts.withdraw_authorization.to_account_info()), 
        ... 
    }; 
    
    ... 
    treasury_wallet::cpi::withdraw( ... amount, )?; 
    ... 
} 

pub struct SettlePayment<'info> { 
    #[account(mut)] 
    pub payer: Signer<'info>, 
    ... 
    pub issuer_treasury_wallet: Account<'info, TreasuryWalletAccount>, 
    pub withdraw_authorization: Account<'info, WithdrawAuthorization>, 
    ... 
    #[account(mut, token::authority=issuer_treasury_wallet)] 
    pub issuer_treasury_wallet_token_account: InterfaceAccount<'info, TokenAccount>, 
    ... 
}",Medium,Consider implementing validation that the Treasury Wallet equals to the recorded one. The Finding is mitigated with the Client team explanation. Each issuer decides on which products to authorize for withdrawal. The described functionality allows the issuer to change funding Treasury Wallet or consciously pay for another issuer product. This provides flexibility in the payment system.,https://hacken.io/audits/margarita-finance-by-obligate-ag/sca-obligate-instruct-sep2024/,High
Sol-136,Inconsistent Price Calculaton due to Potential Price Feed Exponent Change. The Pyth Oracle service does not guarantee the price exponent value never changes. The retrieved price is compared with the stored one disregarding the exponent values may differ. The exponent retrieved from current price is applied to the stored price for Decimal creation. This may lead to the final_payment_amount is calculated incorrectly and wrong final_payment_mint is chosen in case the Pyth Oracle feed changes the exponent value. The wrong payment amount may lead to the product issuer lose value from the Treasury Wallet or the payment is defaulted and the investor does not receive the expected funds,"rust
pub fn fix_payment(ctx: Context<FixPayment>) -> Result<()> { 
    //... 
    let final_fixing_price: i64 = price_update
        .get_price_unchecked(&barrier_reverse_convertible.feed_id)?
        .price; 
    //... 
    
    final_fixing_price as u64 
    //...
}","pub fn initialize(ctx: Context<Initialize>, args: InitArgs) -> Result<()> { 
    ...
    let barrier_reverse_convertible = &mut ctx.accounts.barrier_reverse_convertible; 
    barrier_reverse_convertible... = ...; 
    ... 
}

#[derive(Accounts)] 
pub struct Initialize<'info> { 
    #[account(mut)] 
    pub authority: Signer<'info>, 
    pub structured_product: Account<'info, StructuredProduct>,
    ... 

    #[account(init, seeds=[structured_product.key().as_ref(), &[args.payment_index]], ...)]
    pub barrier_reverse_convertible: Account<'info, BarrierReverseConvertible>, 
    ...
}",Medium,"Consider storing the exponent of the provided initial_fixing_price and barrier_price values and use it for accurate comparisons and calculations. The exponent value is provided at the initialization, used for price comparisons and other calculations.",https://hacken.io/audits/margarita-finance-by-obligate-ag/sca-obligate-instruct-sep2024/,High
Sol-137,"Immutable Ownership. The ownership of the treasury wallet accounts in the treasury_wallet module are currently immutable. In emergency situations where funds need to be withdrawn, the financial product is at risk of default. This is due to the fact that the instruct module depends on the treasury_wallet as a fixed funding source.","rust
#[account]
pub struct TreasuryWalletAccount {  
        pub root_key: Pubkey,  
        pub owner: Pubkey,  
        pub bump: u8, 
}

pub fn initialize(ctx: Context<Initialize>) -> Result<()> {  
        let treasury_wallet = &mut ctx.accounts.treasury_wallet;
        ...  
        treasury_wallet.owner = ctx.accounts.owner.key();  
        ...
}","rust
#[account]
pub struct TreasuryWalletAccount {
    pub root_key: Pubkey,
    pub owner: Pubkey,
    pub emergency_authority: Pubkey,
    pub bump: u8,
}

pub fn initialize(ctx: Context<Initialize>, emergency_authority: Pubkey) -> Result<()> {
    let treasury_wallet = &mut ctx.accounts.treasury_wallet;

    treasury_wallet.owner = ctx.accounts.owner.key();
    treasury_wallet.emergency_authority = emergency_authority;

    Ok(())
}

pub fn emergency_withdraw(ctx: Context<EmergencyWithdraw>, amount: u64) -> Result<()> {
    let treasury_wallet = &mut ctx.accounts.treasury_wallet;

    require!(
        ctx.accounts.emergency_authority.key() == treasury_wallet.emergency_authority,
        CustomError::Unauthorized
    );

    Ok(())
}

#[derive(Accounts)]
pub struct EmergencyWithdraw<'info> {
    #[account(mut, has_one = emergency_authority)]
    pub treasury_wallet: Account<'info, TreasuryWalletAccount>,
    pub emergency_authority: Signer<'info>,
}",Low,"Consider introducing ownership transfer in the treasury_wallet module. This change would allow for the reallocation of ownership in case of emergencies, ensuring that the financial product remains functional even if the original account becomes compromised.",https://hacken.io/audits/margarita-finance-by-obligate-ag/sca-obligate-instruct-sep2024/,High
Sol-138,"Irrelevant and Redundant Limitations on maxtotalclaim and maxnumnodes. The current implementation imposes limitations on max_total_claim and max_num_nodes, which introduces unnecessary complexity and potential issues in the reward distribution process. The max_num_nodes limitation seems irrelevant and does not contribute to the intended functionality of the system. Additionally, the max_total_claim limitation, which is intended to cap the total amount of tokens that can be claimed by all users, contradicts the business logic and can create a first-come, first-served scenario. This limitation is redundant because the amount of tokens that users can claim is inherently limited by the total number of tokens allocated to the RewardDistributor's account. As such, this invariant is unnecessary and does not enhance the security or functionality of the system. Incorrect max_total_claim parameter can lead to locked tokens in the RewardDistributor account. Consider the following scenario: Admin creates a new distribution for 1000 tokens. It is defined in a Merkle tree. By mistake, the admin set max_total_claim as 100 tokens. Admin transfers all expected 1000 tokens to RewardDistributor associated token account. Users can claim only 100 tokens - max_total_claim Other 900 tokens are not claimable and are locked in the RewardDistributor associated token account. Setting the parameters:","rust
pub fn set_merkle_distributor_handler( 
    ctx: Context<NewDistributor>, 
    bump: u8, 
    root: [u8; 32], 
    max_total_claim: u64, 
    max_num_nodes: u64, 
) -> Result<()> { 
    // ...
    distributor.max_total_claim = max_total_claim; 
    distributor.max_num_nodes = max_num_nodes; 
}

// Checks: claim handler
pub fn claim_handler( 
    ctx: Context<Claim>, 
    index: u64, 
    amount: u64, 
    proof: Vec<[u8; 32]>, 
) -> Result<()> { 
    // ...
    // Update the distributor's total amount claimed and number of nodes claimed. 
    let distributor = &mut ctx.accounts.distributor;
    distributor.total_amount_claimed = distributor.total_amount_claimed + amount; 
    require!( distributor.total_amount_claimed <= distributor.max_total_claim, ErrorCode::ExceededMaxClaim ); 
    distributor.num_nodes_claimed += 1; 
    require!( distributor.num_nodes_claimed <= distributor.max_num_nodes, ErrorCode::ExceededMaxNumNodes ); 
}","rust
pub fn claim_handler(
    ctx: Context<Claim>,
    index: u64, 
    amount: u64, 
    proof: Vec<[u8; 32]>, 
) -> Result<()> {
    let distributor = &mut ctx.accounts.distributor;
    let distributor_ata_balance = ctx.accounts.reward_distributor_ata.amount;

    // Ensure the claim amount does not exceed the available balance 
    require!(
        amount <= distributor_ata_balance, 
        ErrorCode::InsufficientFundsInDistributor 
    );

    // Proceed with the claim process 
    // ... 
    Ok(())
}",Medium,"It is recommended to remove the max_num_nodes limitation as it does not serve a relevant purpose. For the max_total_claim, instead of capping the total number of tokens that can be claimed, rely on the total amount of tokens provided to the RewardDistributor's associated token account (ATA). Since users cannot claim more tokens than what is available in the RewardDistributor's ATA, this inherent limitation ensures that the total distributed tokens do not exceed the allocated amount. By tracking the amount of tokens in the RewardDistributor's ATA, the system can maintain fairness and accuracy in reward distribution without the need for redundant checks. This approach aligns with the business logic and simplifies the distribution process.",https://hacken.io/audits/375ai/sca-375ai-smart-contracts-jul2024/,High
Sol-139,"Misconfigured constraints allow anyone to drain all Buy orders. In the swap_tokens_for_sol.rs file, the SwapTokensForSOL validation struct fails to validate the ownership of the creator_token_vault account properly. The constraints applied seem to originate from the validation of the trader_token_vault account since they are the same. More specifically on the vulnerability, any malicious trader can pass their trader_token_vault account as the creator_token_vault account. The constraints on the latter will have no effect on detecting the malicious input as soon as a valid trader_token_vault account is given. This allows the trader to perform the swap and receive both the SOL tokens that are on sale while also keeping their tokens since they are expected to be transferred from the trader_token_vault to the creator_token_vault. swap_tokens_for_sol.rs -> SwapTokensForSOL::creator_token_vault:213","rust
#[derive(Accounts)]
#[instruction(trade: Trade)]
pub struct SwapTokensForSOL<'info> {
    // ...
    #[account(
        mut, 
        constraint = order.creator == creator.key(),
    )]
    pub creator: AccountInfo<'info>,
    // ...

    // Dedaub: These constraints should use the creator_token_vault 
    // instead of the trader_token_vault and the creator.key() value
    #[account(
        mut, 
        constraint = trader_token_vault.mint == token_mint.key(),
        constraint = trader_token_vault.owner == signer.key(),
    )]
    pub creator_token_vault: Box<Account<'info, TokenAccount>>,

    #[account(
        mut, 
        constraint = trader_token_vault.mint == token_mint.key(),
        constraint = trader_token_vault.owner == signer.key(),
    )]
    pub trader_token_vault: Box<Account<'info, TokenAccount>>,
    // ...
}","#[derive(Accounts)]
#[instruction(trade: Trade)]
pub struct SwapTokensForSOL<'info> {
    // ... (existing accounts remain the same)

    #[account(
        mut,
        constraint = creator_token_vault.mint == token_mint.key(),
        constraint = creator_token_vault.owner == creator.key(),  // Validate creator owns the vault
        constraint = creator_token_vault.key() == order.creator_token_vault  // Validate correct vault account
    )]
    pub creator_token_vault: Box<Account<'info, TokenAccount>>,

    #[account(
        mut,
        constraint = trader_token_vault.mint == token_mint.key(),
        constraint = trader_token_vault.owner == signer.key()  // Validate trader owns their vault
    )]
    pub trader_token_vault: Box<Account<'info, TokenAccount>>,
    // ...
}",Critical,"Key security improvements made:

Proper Creator Vault Validation:

Added creator_token_vault.owner == creator.key() to ensure the vault belongs to the order creator

Added creator_token_vault.key() == order.creator_token_vault to verify the correct vault account is used

Separation of Concerns:

Removed incorrect constraints that were checking trader's vault against creator's vault

Each vault now has its own specific validation rules

Maintained Existing Safety:

Kept all mint verification constraints

Preserved trader vault ownership checks

Prevents the Attack Vector:

Malicious traders can no longer substitute their own vault as the creator's vault

Ensures tokens are properly transferred between correct vaults",https://dedaub.com/audits/otsea/otsea-p2p-markets-may-29-2024/,Low
Sol-140,"Traders of Buy orders get fewer SOL tokens than supposed and some also become permanently lost in the order vaults. The swap_tokens_for_sol instruction is responsible for performing the swaps of all the Buy orders which aim to trade SOL tokens for any other SPL Token. On each trade, a fee is applied based on the preconfigured global OTSea parameters which include fish (initialized as 1%), whale (initialized as 0.3%) and partner (initialized as 30% of fish/whale) fees. On every trade, the calculated amount of SOL tokens to be received by the trader is subject to deductions based on those fees. Thus, the calculate_revenue function determines how many of them should be attributed to the revenue vault (and the partners subsequently). However, the amount_output represents the total amount of SOL tokens that should be removed from the order’s SOL vault, but this does not seem to be followed properly. More specifically, the issue becomes apparent following the steps below: A trader requests to swap 100 Tokens for 100 SOL tokens (assuming a 1:1 ratio for simplicity) Let’s assume that the order’s vault holds exactly 100 SOL tokens which means that the order will be fulfilled The execute_trade call from inside the swap_tokens_for_sol instruction returns that 100 SOL tokens should be given to the trader (aka. amount_output = 100), but also increases the order.input_transacted field by 100 which marks the order as fulfilled The calculate_revenue call afterwards calculates how many of these SOL tokens should be withheld based on the preconfigured fees (fish_fee = 1%). As a result, the total_revenue will be 1 SOL token. Then, we transfer the SOL tokens to the trader subtracting the fees calculated, which means that only 99 SOL tokens are sent to the trader However, when it comes to paying the fees to the revenue_vault and the partner, the tokens are taken from the trader’s account and not from the order’s account as they should since the 1 SOL token was already left behind upon the first transfer to the trader. As a result, this leads to the trader losing another 1 SOL token from their earnings and the 1 SOL token that was left in the order_token_vault to be lost there forever since the account should also be closed due to the order being fulfilled. The total losses are as follows: For the funds, 1% of the total SOL tokens used by all the Buy order vaults become permanently lost For the traders, 1% * 99% of the total SOL tokens used by all the Buy order vaults, who lose this amount as it is being sent to the fee receivers It seems that this issue resulted from a misconfigured copy of the code from the other swap instruction (swap_sol_for_tokens) which correctly transfers the SOL tokens from the trader to the fee receivers.","rust
pub fn swap_tokens_for_sol(
    ctx: Context<SwapTokensForSOL>, 
    trade: Trade, 
    fee_type: FeeType, 
) -> Result<()> 
{
    ...
    let amount_output = execute_trade(
        &mut ctx.accounts.order, 
        ctx.accounts.signer.key(), 
        ™, 
        ctx.accounts.token_mint.key()
    )?;
    
    let order = &ctx.accounts.order;
    
    let (total_revenue, distribute_revenue, partner_revenue) = calculate_revenue(
        &ctx.accounts.otsea,
        &ctx.accounts.partner,
        amount_output,
        order.fee_type
    )?;
    
    // transfer SOL(trade amount) from vault to trader 
    let transfer_sol_amount = amount_output.checked_sub(total_revenue).unwrap();
    
    ...
    
    token::transfer(
        CpiContext::new_with_signer(
            ctx.accounts.token_program.to_account_info(),
            token::Transfer {
                from: ctx.accounts.order_token_vault.to_account_info(),
                to: ctx.accounts.trader_sol_token_vault.to_account_info(),
                ...
            },
            ...
        ),
        transfer_sol_amount,
    )?;
    
    // transfer SOL(partner fee) from trader to partner 
    if partner_revenue > 0 {
        ...
        token::transfer(
            CpiContext::new(
                ctx.accounts.token_program.to_account_info(),
                token::Transfer {
                    from: ctx.accounts.trader_sol_token_vault.to_account_info(),
                    to: ctx.accounts.partner_sol_token_account.as_ref().unwrap().to_account_info(),
                    ...
                },
            ),
            partner_revenue,
        )?;
        ...
    }
    
    // transfer wrap SOL(Revenue) from trader to revenue distributor 
    token::transfer(
        CpiContext::new(
            ctx.accounts.token_program.to_account_info(),
            token::Transfer {
                from: ctx.accounts.trader_sol_token_vault.to_account_info(),
                to: ctx.accounts.revenue_vault.to_account_info(),
                ...
            },
        ),
        distribute_revenue,
    )?;
    ...
}","pub fn swap_tokens_for_sol(
    ctx: Context<SwapTokensForSOL>, 
    trade: Trade, 
    fee_type: FeeType, 
) -> Result<()> 
{
    ...
    let amount_output = execute_trade(
        &mut ctx.accounts.order, 
        ctx.accounts.signer.key(), 
        ™, 
        ctx.accounts.token_mint.key()
    )?;
    
    let order = &ctx.accounts.order;
    
    let (total_revenue, distribute_revenue, partner_revenue) = calculate_revenue(
        &ctx.accounts.otsea,
        &ctx.accounts.partner,
        amount_output,
        order.fee_type
    )?;
    
    // Option 1: Transfer full amount to trader first, then deduct fees
    // (Alternative solution mentioned in recommendation)
    
    // Option 2: Directly deduct fees from order vault (implemented below)
    // Transfer trader's portion from order vault
    let transfer_sol_amount = amount_output.checked_sub(total_revenue).unwrap();
    
    token::transfer(
        CpiContext::new_with_signer(
            ctx.accounts.token_program.to_account_info(),
            token::Transfer {
                from: ctx.accounts.order_token_vault.to_account_info(),
                to: ctx.accounts.trader_sol_token_vault.to_account_info(),
                authority: ctx.accounts.order.to_account_info(),
            },
            &[&[b""order"", &order.id.to_le_bytes(), &[order.bump]]],
        ),
        transfer_sol_amount,
    )?;
    
    // Transfer revenue portion from order vault
    if distribute_revenue > 0 {
        token::transfer(
            CpiContext::new_with_signer(
                ctx.accounts.token_program.to_account_info(),
                token::Transfer {
                    from: ctx.accounts.order_token_vault.to_account_info(),
                    to: ctx.accounts.revenue_vault.to_account_info(),
                    authority: ctx.accounts.order.to_account_info(),
                },
                &[&[b""order"", &order.id.to_le_bytes(), &[order.bump]]],
            ),
            distribute_revenue,
        )?;
    }
    
    // Transfer partner portion from order vault
    if partner_revenue > 0 {
        token::transfer(
            CpiContext::new_with_signer(
                ctx.accounts.token_program.to_account_info(),
                token::Transfer {
                    from: ctx.accounts.order_token_vault.to_account_info(),
                    to: ctx.accounts.partner_sol_token_account.as_ref().unwrap().to_account_info(),
                    authority: ctx.accounts.order.to_account_info(),
                },
                &[&[b""order"", &order.id.to_le_bytes(), &[order.bump]]],
            ),
            partner_revenue,
        )?;
    }
    ...
}",High,"To fix this issue, you should either transfer the entire amount_output to the trader and then from their account to the fee receivers or change the from arguments of the SOL token transfer CPIs to be from the order_token_vault and not from the trader.",https://dedaub.com/audits/otsea/otsea-p2p-markets-may-29-2024/,Low
Sol-141,"The whitelist PDA of an order can remain unclosed even after the order gets fulfilled and fully claimed. All the Sell orders that have a lock-up period set (or if the partner has a lock-up override enabled) put the swapped tokens into a lock-up for the users that requested a trade. After the lock-up period expires the traders can claim their tokens by using the lock_up::claim_lock_up instruction. When the last locked-up amount for an order is claimed and the order has been Cancelled by the owner or has been Fulfilled, the PDAs used by that order have to be closed. However, even though the order_token_vault and the order accounts are successfully closed, if the order owner had created a whitelist PDA, this can remain unclosed in case the last trader does not provide it in the context of the called claim instruction since the account is defined as Option<>. As a consequence, this can result in leaving whitelist PDAs open withholding the SOL tokens paid for the account creation from being reimbursed to the order creator.","rust
lock_up::claim_lock_up:71 pub fn claim_lock_up(ctx: Context<ClaimLockUp>, ...) -> Result<()> { 
    ...
    let remain_lockup_amount = order.total_locked_up.checked_sub(order.unlocked_transacted).unwrap(); 
    if (order.state == State::Cancelled || order.state == State::Fulfilled) && remain_lockup_amount == 0 { 
        // close vault 
        token::close_account(...)?;
        // close order account 
        ctx.accounts.order.close(ctx.accounts.creator.to_account_info())?;
        // Dedaub: If the whitelist is not provided but exists and the 
        // last locked-up amount is being claimed for a Cancelled 
        // or Fulfilled order, then the account will remain active 
        // close order whitelist account 
        if ctx.accounts.whitelist.is_some() { 
            ctx.accounts.whitelist.close(ctx.accounts.signer.to_account_info())?; 
        } 
    } 
    ... 
} 

lock_up.rs -> ClaimLockUp::whitelist:153 

#[derive(Accounts)] 
#[instruction(order_id: u64)] 
pub struct ClaimLockUp<'info> { 
    #[account( 
        mut, 
        seeds = [...], 
        bump, 
        constraint = order.whitelist == whitelist.key(), 
    )]
    pub whitelist: Option, 
    ... 
}","pub fn claim_lock_up(ctx: Context<ClaimLockUp>, ...) -> Result<()> {
    ...
    let remain_lockup_amount = order.total_locked_up.checked_sub(order.unlocked_transacted).unwrap();
    
    if (order.state == State::Cancelled || order.state == State::Fulfilled) && remain_lockup_amount == 0 {
        // Close token vault
        token::close_account(...)?;
        
        // Close order account
        ctx.accounts.order.close(ctx.accounts.creator.to_account_info())?;
        
        // Close whitelist account if it exists (even if not provided in context)
        if let Some(whitelist_key) = order.whitelist {
            let whitelist_account = AccountInfo::try_from(&whitelist_key)?;
            if whitelist_account.lamports() > 0 {
                let whitelist_seeds = [
                    b""whitelist"",
                    &order.creator.key().to_bytes(),
                    &order.id.to_le_bytes(),
                    &[order.whitelist_bump],
                ];
                
                token::close_account(CpiContext::new_with_signer(
                    ctx.accounts.token_program.to_account_info(),
                    token::CloseAccount {
                        account: whitelist_account.clone(),
                        destination: ctx.accounts.creator.to_account_info(),
                        authority: ctx.accounts.order.to_account_info(),
                    },
                    &[&whitelist_seeds],
                ))?;
            }
        }
    }
    ...
}

#[derive(Accounts)]
#[instruction(order_id: u64)]
pub struct ClaimLockUp<'info> {
    // Make whitelist account optional but still validate if provided
    #[account(
        mut,
        seeds = [
            b""whitelist"",
            order.creator.key().as_ref(),
            &order.id.to_le_bytes()
        ],
        bump = order.whitelist_bump,
        constraint = whitelist.as_ref().map_or(true, |w| w.key() == order.whitelist.unwrap())
    )]
    pub whitelist: Option<Account<'info, Whitelist>>,
    ...
}",Medium,"Key improvements:

Automatic Whitelist Closure:

Now checks and closes whitelist PDA even if not provided in context

Uses order's stored whitelist key to locate the account

Proper Account Validation:

Updated whitelist account constraints to properly validate when present

Uses order's whitelist_bump for seed derivation

Safe Account Handling:

Checks lamports before attempting to close

Properly signs with whitelist seeds

Returns funds to order creator

Maintained Flexibility:

Still allows whitelist to be optional in the context

Preserves all existing functionality

This solution ensures:

No SOL remains locked in whitelist PDAs

All order-related accounts are properly cleaned up

Funds are returned to the rightful owner (order creator)

Backward compatibility with existing claims

Proper authorization for account closures
",https://dedaub.com/audits/otsea/otsea-p2p-markets-may-29-2024/,Low
Sol-142,"The order owner loses the rent-exempt amount paid for the whitelist PDA of orders with lockups. The order creators can create whitelist PDAs for their orders to only allow specific accounts to perform trades with. However, for the orders that have enabled lock-ups or the partners used have an enabled lock-up override, their owners may not be able to get the SOL paid for the rent exemption of the whitelist PDAs back. This can happen if the order has been Cancelled or Fulfilled, but there are still active lockups to be claimed by the traders. The last trader is responsible for providing the whitelist PDA so once all funds have been claimed all the order-related accounts be closed. However, when closing the whitelist account, the SOL tokens are requested to be transferred to the signer (who is the trader) and not to the order creator as they should.","rust
lock_up::claim_lock_up:72 pub fn claim_lock_up(...) -> Result<()> { 
    ... 
    let remain_lockup_amount = order.total_locked_up.checked_sub(order.unlocked_transacted).unwrap(); 
    
    if (order.state == State::Cancelled || order.state == State::Fulfilled) && remain_lockup_amount == 0 { 
        ... 
        
        // Dedaub: When the whitelist PDA is closed, the funds are 
        // transferred to the trader instead of the order creator
        if ctx.accounts.whitelist.is_some() { 
            ctx.accounts.whitelist.close(ctx.accounts.signer.to_account_info())?;
        } 
    } 
    ... 
}","pub fn claim_lock_up(ctx: Context<ClaimLockUp>, ...) -> Result<()> {
    ...
    let remain_lockup_amount = order.total_locked_up.checked_sub(order.unlocked_transacted).unwrap();
    
    if (order.state == State::Cancelled || order.state == State::Fulfilled) && remain_lockup_amount == 0 {
        // Close token vault
        token::close_account(...)?;
        
        // Close order account
        ctx.accounts.order.close(ctx.accounts.creator.to_account_info())?;
        
        // Close whitelist account if it exists
        if let Some(whitelist) = &ctx.accounts.whitelist {
            // Transfer rent-exempt SOL back to order creator, not trader
            let whitelist_account_info = whitelist.to_account_info();
            let creator_account_info = ctx.accounts.creator.to_account_info();
            
            // Create CPI context with proper authority (order account)
            token::close_account(CpiContext::new_with_signer(
                ctx.accounts.token_program.to_account_info(),
                token::CloseAccount {
                    account: whitelist_account_info.clone(),
                    destination: creator_account_info.clone(),
                    authority: ctx.accounts.order.to_account_info(),
                },
                &[&[
                    b""whitelist"",
                    &order.creator.key().to_bytes(),
                    &order.id.to_le_bytes(),
                    &[order.whitelist_bump],
                ],
            ))?;
        }
    }
    ...
}

#[derive(Accounts)]
#[instruction(order_id: u64)]
pub struct ClaimLockUp<'info> {
    #[account(
        mut,
        seeds = [
            b""whitelist"",
            order.creator.key().as_ref(),
            &order.id.to_le_bytes()
        ],
        bump = order.whitelist_bump,
        constraint = whitelist.as_ref().map_or(true, |w| w.key() == order.whitelist.unwrap())
    )]
    pub whitelist: Option<Account<'info, Whitelist>>,
    ...
}",Medium,"Correct Fund Destination:

Now sends whitelist PDA rent to creator account instead of signer (trader)

Uses proper authority (order account) for closing

Improved Account Handling:

Explicit CPI context creation for whitelist closure

Proper seed derivation using stored whitelist_bump

Better account validation in the accounts struct

Safety Checks:

Maintains all existing constraints

Only attempts closure if whitelist exists

Uses checked arithmetic

Backward Compatibility:

Still allows whitelist to be optional

Preserves all existing functionality",https://dedaub.com/audits/otsea/otsea-p2p-markets-may-29-2024/,Low
Sol-143,"update_whitelist can only be used once for each order In the owner_instructions file. the update_whitelist function is supposed to allow the owner of an order to set and update a whitelist per order. However, the whitelist account which should be provided with the UpdateWhitelistContext validation struct, has the init constraint applied. As a result, this means that a call to update_whitelist is only possible for the first time the owner tries to initialize a whitelist for an order. Any subsequent updates will fail since the init constraint fails the verification if the account provided already exists. We suppose that the expected constraint should be the init_if_needed which initializes the account if it does not exist, but also allows continuous updates on later instruction calls.","rust
// owner_instructions.rs -> UpdateWhitelistContext::whitelist:244
#[derive(Accounts)]
#[instruction(order_id: u64)]
pub struct UpdateWhitelistContext<'info> {

    // Dedaub: This should probably be init_if_needed since this only
    // allows a single initialization and no further updates
    #[account(init, ...)] 
    pub whitelist: Account<'info, Whitelist>,
    ...
}","#[derive(Accounts)]
#[instruction(order_id: u64)]
pub struct UpdateWhitelistContext<'info> {
    #[account(
        init_if_needed,
        payer = owner,
        space = 8 + Whitelist::LEN,
        seeds = [
            b""whitelist"",
            order.creator.key().as_ref(),
            &order.id.to_le_bytes()
        ],
        bump,
    )]
    pub whitelist: Account<'info, Whitelist>,

    #[account(mut)]
    pub owner: Signer<'info>,

    #[account(
        has_one = owner,
        seeds = [
            b""order"",
            owner.key().as_ref(),
            &order_id.to_le_bytes()
        ],
        bump = order.bump,
    )]
    pub order: Account<'info, Order>,

    pub system_program: Program<'info, System>,
}",Low,"Changed Constraint:

Replaced init with init_if_needed to allow both creation and updates

Maintains all other existing constraints and validations

Added Safety Features:

Still requires payer (owner) for initial creation

Maintains space requirements

Keeps proper seed derivation

Preserved Functionality:

First call creates the whitelist if it doesn't exist

Subsequent calls can update the whitelist

All existing account relationships remain enforced",https://dedaub.com/audits/otsea/otsea-p2p-markets-may-29-2024/,Low
Sol-144,"update_lock_up_override incorrectly prevents partners from using the function. In the owner_instructions file, the update_lock_up_override function is meant to allow the admin and the partners to modify their lock-up parameter. However, the checks applied to ensure that the correct accounts were given have conflicting conditions which effectively only allows the admin to try to update a not initialized partner account. More precisely, the first require statement should check if the partner’s public key has been initialized and is not the default key.","rust
owner_instructions::update_lock_up_override:140 pub fn update_lock_up_override( 
    ctx: Context<LockupOverrideContext>, 
    enforce: bool 
) -> Result<()> { 

    let partner = &mut ctx.accounts.partner; 
    
    // Dedaub: To ensure the initialization of the partner account the 
    // check should be != instead of == 
    require!( 
        partner.public_key == system_program::ID, 
        OTSeaErrorCode::NotAvailable 
    ); 
    
    require!( 
        partner.public_key == ctx.accounts.signer.key() || ctx.accounts.otsea.admin == ctx.accounts.signer.key(), 
        OTSeaErrorCode::Unauthorized 
    ); 

    // Code continues here
    ...
}","pub fn update_lock_up_override(
    ctx: Context<LockupOverrideContext>,
    enforce: bool
) -> Result<()> {
    let partner = &mut ctx.accounts.partner;

    // Check if partner account is initialized (public_key != system_program::ID)
    require!(
        partner.public_key != system_program::ID,
        OTSeaErrorCode::PartnerNotInitialized
    );

    // Verify either the signer is the partner or admin
    require!(
        partner.public_key == ctx.accounts.signer.key() || 
        ctx.accounts.otsea.admin == ctx.accounts.signer.key(),
        OTSeaErrorCode::Unauthorized
    );

    partner.enforce_lock_up = enforce;

    emit!(LockUpOverrideUpdated {
        partner: partner.public_key,
        admin: ctx.accounts.otsea.admin,
        enforce,
        timestamp: Clock::get()?.unix_timestamp,
    });

    Ok(())
}",Low,,https://dedaub.com/audits/otsea/otsea-p2p-markets-may-29-2024/,Low
Sol-145,"Missing Validation of Mint Address. The mint account in the WithdrawFunds struct lacks proper validation of its address. This allows an admin to pass in any mint account with an inflated supply, potentially bypassing withdrawal limits.","rust
pub struct WithdrawFunds<'info> {
    #[account(mut, seeds = [b""token-manager""], bump)]
    pub token_manager: Account<'info, TokenManager>,

    #[account(mut, seeds = [b""mint""], bump)]
    pub mint: Account<'info, Mint>, // Quote Mint

    // The rest of the structure seems to be incomplete.
    // Add the remaining fields here.
}","rust
pub struct WithdrawFunds<'info> {
   #[account(
       mut,
       seeds = [b""token-manager""],
       bump
   )]
   pub token_manager: Account<'info, TokenManager>,

   #[account(
       mut,
       seeds = [b""mint""],
       bump,
       address = token_manager.mint @ ParityIssuanceError::InvalidMintAddress,
       mint::authority = token_manager,
   )]
   pub mint: Account<'info, Mint>,
}",Low,Implement a check to ensure that the mint account's address matches the one associated with the token_manager.,"https://certificate.quantstamp.com/full/parity-finance/02ef0b3b-599c-4c50-8a8b-c085fdfa0db0/index.html#findings-qs2, https://github.com/Parity-Finance/parity-contracts/commit/5df982ba4ce4744d743d0a62f02962a903a45111#diff-10eff0047594d1d4c652e550d382f742aebee948a783b56f2f6dd2c6880f43e5",High
Sol-146,"IOverwriting Pending Withdrawal Amount. If a withdrawal is initiated twice before the first one is processed, the second one would overwrite the first one's pending withdrawal amount.","rust
// Check if there is an existing pending withdrawal 
if token_manager.pending_withdrawal_amount > 0 {
    return err!(ParityIssuanceError::PendingWithdrawalExists);
}","rust
// Check if there is an existing pending withdrawal 
if token_manager.pending_withdrawal_amount > 0 {
    let current_time = Clock::get()?.unix_timestamp;
    let withdraw_window_end = token_manager
        .withdrawal_initiation_time
        .checked_add(token_manager.withdraw_time_lock)
        .ok_or(ParityIssuanceError::CalculationOverflow)?
        .checked_add(token_manager.withdraw_execution_window)
        .ok_or(ParityIssuanceError::CalculationOverflow)?;

    if current_time <= withdraw_window_end {
        return err!(ParityIssuanceError::PendingWithdrawalExists);
    }
}

let quote_amount = quantity;",Low,"Implement a check to ensure there's no existing pending withdrawal before initiating a new one. Alternatively, consider using a queue system for multiple pending withdrawals.","https://github.com/Parity-Finance/parity-contracts/commit/81d727551aa4a827bca8ed5f14f3dcdc76048577#diff-10eff0047594d1d4c652e550d382f742aebee948a783b56f2f6dd2c6880f43e5, https://certificate.quantstamp.com/full/parity-finance/02ef0b3b-599c-4c50-8a8b-c085fdfa0db0/index.html",High
Sol-147,"Insufficient Input Validation Across Multiple Contract Functions. Several functions across the parity-contracts codebase lack comprehensive input validation for critical parameters. This includes missing checks for non-zero values, absence of bounds validation for numerical inputs such as fees, and lack of verification for account authorities and states. The affected areas span various operations such as staking, unstaking, minting, configuration updates, and token management.","rust
pub fn handler(
    ctx: Context<UpdateMintMetadata>, 
    name: String, 
    symbol: String, 
    uri: String, 
) -> Result<()> {
    let token_manager = &ctx.accounts.token_manager;
    let bump = token_manager.bump;
    let signer_seeds: &[&[&[u8]]] = &[&[b""token-manager"", &[bump]]];
}","rust
pub fn handler(
    ctx: Context<UpdateMintMetadata>, 
    name: String, 
    symbol: String, 
    uri: String, 
) -> Result<()> { 
    let token_manager = &ctx.accounts.token_manager; 

    // Check if the name is not empty 
    if name.is_empty() { 
        return err!(ParityIssuanceError::InvalidParam); 
    } 
    
    // Check if the symbol is not empty 
    if symbol.is_empty() { 
        return err!(ParityIssuanceError::InvalidParam); 
    }

    // Check if the URI is not empty 
    if uri.is_empty() { 
        return err!(ParityIssuanceError::InvalidParam); 
    }
    
    let bump = token_manager.bump; 
    
    let signer_seeds: &[&[&[u8]]] = &[&[b""token-manager"", &[bump]]];
}",Low,Implement thorough input validation for all user-supplied parameters and critical values throughout the contract,"https://certificate.quantstamp.com/full/parity-finance/02ef0b3b-599c-4c50-8a8b-c085fdfa0db0/index.html#findings-qs5, https://github.com/Parity-Finance/parity-contracts/commit/26fd1c8857c89f5df53f0211c95331af6672d1e4#diff-310450b79658386d485d11850a1201ad9a22b36916b40b271ca4fae08c2dfeb3",High
Sol-148,"Attacker can front-run multisig creation transaction. A multisig account is derived from an unauthenticated create_key. An attacker can front-run a user’s multisig creation transaction and create the multisig with their own parameters, allowing them to perform transactions from that multisig. The attacker can steal tokens from the multisig vaults if the user is unaware of the front-running and continues to use the multisig.","rust
#[derive(Accounts)]
#[instruction(args: MultisigCreateArgs)]
pub struct MultisigCreate<'info> {
    #[account(
        init,
        payer = creator,
        space = Multisig::size(args.members.len()),
        seeds = [SEED_PREFIX, SEED_MULTISIG, create_key.key().as_ref()],
        bump
    )]
    pub multisig: Account<'info, Multisig>,
    
    /// A random public key that is used as a seed for the Multisig PDA.
    /// CHECK: This can be any random public key.
    pub create_key: AccountInfo<'info>,
    
    /// The creator of the multisig.
    #[account(mut)]
    pub creator: Signer<'info>,
    
    pub system_program: Program<'info, System>,
}","rust
#[derive(Accounts)]
#[instruction(args: MultisigCreateArgs)]
pub struct MultisigCreate<'info> {
    #[account(
        init, 
        payer = creator, 
        space = Multisig::size(args.members.len()), 
        seeds = [SEED_PREFIX, SEED_MULTISIG, create_key.key().as_ref()], 
        bump
    )]
    pub multisig: Account<'info, Multisig>,
    
    /// An ephemeral signer that is used as a seed for the Multisig PDA. 
    /// Must be a signer to prevent front-running attack by someone else but the original creator.
    pub create_key: Signer<'info>,
    
    /// The creator of the multisig.
    #[account(mut)]
    pub creator: Signer<'info>,
    
    pub system_program: Program<'info, System>,
}",High,Change create_key to be a signer to prevent front-running attack by someone else but the original creator.,https://github.com/Squads-Protocol/v4/commit/fe1fc5b8349640e07c1868219e02d2551d08f315,High
Sol-149,Reentrancy,"rust
impl TransactionExecute<'_> {
    /// Execute the multisig transaction. 
    /// The transaction must be `ExecuteReady`.
    pub fn transaction_execute(ctx: Context<Self>) -> Result<()> {
        let multisig = &mut ctx.accounts.multisig;
        let transaction = &mut ctx.accounts.transaction;

        let multisig_key = multisig.key();
        let transaction_key = transaction.key();

        let authority_seeds = &[
            SEED_PREFIX,
            multisig_key.as_ref(),
            &transaction.authority_index.to_le_bytes(),
            SEED_AUTHORITY,
            &[transaction.authority_bump],
        ];

        let authority_pubkey = Pubkey::create_program_address(authority_seeds, ctx.program_id).unwrap();

        let (additional_signer_keys, additional_signer_seeds): (Vec<_>, Vec<_>) =
            transaction.additional_signer_bumps.iter().enumerate().map(|(index, bump)| {
                let seeds = vec![
                    SEED_PREFIX.to_vec(),
                    transaction_key.to_bytes().to_vec(),
                    u8::try_from(index).unwrap().to_le_bytes().to_vec(),
                    SEED_ADDITIONAL_SIGNER.to_vec(),
                    vec![*bump],
                ];

                (
                    Pubkey::create_program_address(
                        seeds.iter().map(Vec::as_slice).collect::<Vec<&[u8]>>().as_slice(), ctx.program_id,
                    ).unwrap(), 
                    seeds,
                ) 
            }).unzip();

        let transaction_message = &transaction.message;
        let num_lookups = transaction_message.address_table_lookups.len();

        let message_account_infos = ctx.remaining_accounts.get(num_lookups..)
            .ok_or(MultisigError::InvalidNumberOfAccounts)?;
        let address_lookup_table_account_infos = ctx.remaining_accounts.get(..num_lookups)
            .ok_or(MultisigError::InvalidNumberOfAccounts)?;

        let executable_message = ExecutableTransactionMessage::new_validated(
            transaction_message, 
            message_account_infos, 
            address_lookup_table_account_infos, 
            &authority_pubkey, 
            &additional_signer_keys,
        )?;

        // Execute the transaction instructions one-by-one.
        for (ix, account_infos) in executable_message.to_instructions_and_accounts().iter() {
            let additional_signer_seeds = &additional_signer_seeds
                .iter()
                .map(|seeds| seeds.iter().map(Vec::as_slice).collect::<Vec<&[u8]>>())
                .collect::<Vec<Vec<&[u8]>>>();

            let mut signer_seeds = additional_signer_seeds.to_vec();
            signer_seeds.push(authority_seeds);

            invoke_signed(ix, account_infos, &signer_seeds)?;
        }
    }
}","rust
impl TransactionExecute<'_> {
    /// Execute the multisig transaction.
    /// The transaction must be `ExecuteReady`.
    pub fn transaction_execute(ctx: Context<Self>) -> Result<()> {
        let multisig = &mut ctx.accounts.multisig;
        let transaction = &mut ctx.accounts.transaction;
        
        let multisig_key = multisig.key();
        let transaction_key = transaction.key();
        
        let authority_seeds = &[
            SEED_PREFIX,
            multisig_key.as_ref(),
            &transaction.authority_index.to_le_bytes(),
            SEED_AUTHORITY,
            &[transaction.authority_bump],
        ];
        let authority_pubkey = Pubkey::create_program_address(authority_seeds, ctx.program_id).unwrap();
        
        let (additional_signer_keys, additional_signer_seeds): (Vec<_>, Vec<_>) = transaction
            .additional_signer_bumps
            .iter()
            .enumerate()
            .map(|(index, bump)| {
                let seeds = vec![
                    SEED_PREFIX.to_vec(),
                    transaction_key.to_bytes().to_vec(),
                    u8::try_from(index).unwrap().to_le_bytes().to_vec(),
                    SEED_ADDITIONAL_SIGNER.to_vec(),
                    vec![*bump],
                ];
                (
                    Pubkey::create_program_address(
                        seeds
                            .iter()
                            .map(Vec::as_slice)
                            .collect::<Vec<&[u8]>>()
                            .as_slice(),
                        ctx.program_id,
                    )
                    .unwrap(),
                    seeds,
                )
            })
            .unzip();
        
        let transaction_message = &transaction.message;
        let num_lookups = transaction_message.address_table_lookups.len();
        let message_account_infos = ctx
            .remaining_accounts
            .get(num_lookups..)
            .ok_or(MultisigError::InvalidNumberOfAccounts)?;
        let address_lookup_table_account_infos = ctx
            .remaining_accounts
            .get(..num_lookups)
            .ok_or(MultisigError::InvalidNumberOfAccounts)?;
       
        let executable_message = ExecutableTransactionMessage::new_validated(
            transaction_message,
            message_account_infos,
            address_lookup_table_account_infos,
            &authority_pubkey,
            &additional_signer_keys,
        )?;
        // Execute the transaction instructions one-by-one.
        for (ix, account_infos) in executable_message.to_instructions_and_accounts().iter() {
            // Make sure we don't allow reentrancy of transaction_execute.
            // TODO: do the same in transaction_create.
            if ix.program_id == id() {
                require!(
                    ix.data[..8] != crate::instruction::TransactionExecute::DISCRIMINATOR,
                    MultisigError::ExecuteReentrancy
                )
            }
            // First round of type conversion; from Vec<Vec<Vec<u8>>> to Vec<Vec<&[u8]>>.
            let additional_signer_seeds = &additional_signer_seeds
                .iter();
            @@ -125,7 +136,6 @@
            // Add the authority seeds.
            signer_seeds.push(authority_seeds);
            invoke_signed(ix, account_infos, &signer_seeds)?;
        }
    }
}",High,,https://github.com/Squads-Protocol/v4/commit/401eb6c3471d25e7ff13415ffc8cf205427c6ea0,High
Sol-150,"this issue stemmed from the system mischaracterising realised collateral and allowing *any* profits to be withdrawn *without* any checks, gates or earmarking of funds **and** without a built-in socialised loss and clawback mechanism. The withdrawal bug is described in more detail in Section 1b and is illustrated in a proof-of-concept with code and visualisations in Section 1d.","rust
use crate::error::ClearingHouseResult;
use crate::math_error;
use anchor_spl::token::TokenAccount;
use solana_program::msg;

/// Calculates how much of withdrawal must come from collateral vault and how much comes from insurance vault 
pub fn calculate_withdrawal_amounts(
    amount: u64,
    collateral_token_account: &TokenAccount,
    insurance_token_account: &TokenAccount,
) -> ClearingHouseResult<(u64, u64)> {
    Ok(
        if collateral_token_account.amount >= amount {
            (amount, 0)
        } else if insurance_token_account.amount > amount.checked_sub(collateral_token_account.amount).ok_or_else(math_error!())? {
            (
                collateral_token_account.amount,
                amount
                    .checked_sub(collateral_token_account.amount)
                    .ok_or_else(math_error!())?,
            )
        } else {
            (
                collateral_token_account.amount,
                insurance_token_account.amount,
            )
        }
    )
}","rust
use crate::error::ClearingHouseResult; 
use crate::math_error; 
use crate::state::market::Markets; 
use anchor_spl::token::TokenAccount; 
use solana_program::msg; 
use std::cell::Ref;

/// Calculates how much of withdrawal must come from collateral vault and how much comes from insurance vault 
pub fn calculate_withdrawal_amounts(
    amount: u64, 
    collateral_token_account: &TokenAccount, 
    insurance_token_account: &TokenAccount, 
    markets: &Ref<Markets>,
) -> ClearingHouseResult<(u64, u64)> { 
    let total_fees_minus_distributions: u128 = markets.markets.iter().fold(0, |sum, market| { 
        sum.checked_add(market.amm.total_fee_minus_distributions)
            .ok_or_else(math_error!())
            .unwrap()
            .checked_sub(market.amm.total_fee_withdrawn)
            .ok_or_else(math_error!())
            .unwrap() 
    });

    let available_collateral_vault_amount = (collateral_token_account.amount as u128)
        .checked_sub(total_fees_minus_distributions)
        .ok_or_else(math_error!())? as u64;

    Ok(if available_collateral_vault_amount >= amount { 
        (amount, 0) 
    } else if insurance_token_account.amount > amount
        .checked_sub(available_collateral_vault_amount)
        .ok_or_else(math_error!())? {
            (
                available_collateral_vault_amount, 
                amount
                    .checked_sub(available_collateral_vault_amount)
                    .ok_or_else(math_error!())? ,
            )
    } else { 
        (
            available_collateral_vault_amount, 
            insurance_token_account.amount,
        ) 
    })
}",Critical,"During periods of market imbalance, to prevent the shortfall in realised collateral (and to block the exploit outlined above), one naive solution is for the protocol to only allow users to withdraw their realised gains if there has been an offsetting realised loss in the same market. A simple example of this change has been implemented here, where realised losses are tracked on the market account and realised gains only credited to a user’s collateral balance when there has been offsetting loss.",https://github.com/drift-labs/protocol-v1/compare/crispheaney/patch-withdraw-bug,High
Sol-151,"Voter weight manipulation by burning after vote Description A voter can influence their vote weight after voting ends and before proposal finalization. The voter relinquishes his/her vote, withdraws their governing tokens, burns to lower the mint supply (and therefore max_voter_weight) and finalizes. Proof of Concept: Deposit 33% of mint supply Create a proposal and vote on it. Between voting time ending and proposal finalization, relinquish vote and withdraw tokens. The vote persists. Burn withdrawn tokens (33%) and finalize. 33/66 = 50%","rust
use solana_program::{
    account_info::{next_account_info, AccountInfo},
    clock::Clock,
    entrypoint::ProgramResult,
    pubkey::Pubkey,
    sysvar::Sysvar,
};
use spl_governance_tools::account::dispose_account;
use crate::{
    error::GovernanceError,
    state::{
        enums::ProposalState,
        governance::get_governance_data_for_realm,
        proposal::get_proposal_data_for_governance,
        realm::get_realm_data_for_governing_token_mint,
        token_owner_record::get_token_owner_record_data_for_realm_and_governing_mint,
        vote_record::{get_vote_record_data_for_proposal_and_token_owner_record, Vote},
    },
};

/// Processes RelinquishVote instruction
pub fn process_relinquish_vote(
    program_id: &Pubkey,
    accounts: &[AccountInfo],
) -> ProgramResult {
    let account_info_iter = &mut accounts.iter();
    let realm_info = next_account_info(account_info_iter)?; // 0
    let governance_info = next_account_info(account_info_iter)?; // 1
    let proposal_info = next_account_info(account_info_iter)?; // 2
    let token_owner_record_info = next_account_info(account_info_iter)?; // 3
    let vote_record_info = next_account_info(account_info_iter)?; // 4
    let vote_governing_token_mint_info = next_account_info(account_info_iter)?; // 5

    let realm_data = get_realm_data_for_governing_token_mint(
        program_id,
        realm_info,
        vote_governing_token_mint_info.key,
    )?;

    let governance_data = get_governance_data_for_realm(
        program_id,
        governance_info,
        realm_info.key
    )?;

    let mut proposal_data = get_proposal_data_for_governance(
        program_id,
        proposal_info,
        governance_info.key
    )?;

    let mut token_owner_record_data = get_token_owner_record_data_for_realm_and_governing_mint(
        program_id,
        token_owner_record_info,
        &governance_data.realm,
        vote_governing_token_mint_info.key,
    )?;

    let mut vote_record_data = get_vote_record_data_for_proposal_and_token_owner_record(
        program_id,
        vote_record_info,
        &realm_data,
        proposal_info.key,
        &proposal_data,
        &token_owner_record_data,
    )?;

    vote_record_data.assert_can_relinquish_vote()?;

    let clock = Clock::get()?;

    // If the Proposal is still being voted on then the token owner vote will be withdrawn and it won't count towards the vote outcome
    // Note: If there is no tipping point the proposal can be still in Voting state but already past the configured max_voting_time
    // It means it awaits manual finalization (FinalizeVote) and it should no longer be possible to withdraw the vote and we only release the tokens
    if proposal_data.state == ProposalState::Voting && !proposal_data.has_vote_time_ended(&governance_data.config, clock.unix_timestamp) {
        let governance_authority_info = next_account_info(account_info_iter)?; // 5
        let beneficiary_info = next_account_info(account_info_iter)?; // 6

        // Note: It's only required to sign by governing_authority if relinquishing the vote results in vote change
        // If the Proposal is already decided then anybody can prune active votes for token owner
        token_owner_record_data.assert_token_owner_or_delegate_is_signer(governance_authority_info)?;

        match vote_record_data.vote {
            Vote::Approve(choices) => {
                for (option, choice) in proposal_data.options.iter_mut().zip(choices) {
                    option.vote_weight = option
                        .vote_weight
                        .checked_sub(choice.get_choice_weight(vote_record_data.voter_weight)?)
                        .unwrap();
                }
            }
            Vote::Deny => {
                proposal_data.deny_vote_weight = Some(
                    proposal_data
                        .deny_vote_weight
                        .unwrap()
                        .checked_sub(vote_record_data.voter_weight)
                        .unwrap(),
                )
            }
            Vote::Veto => {
                proposal_data.veto_vote_weight = proposal_data
                    .veto_vote_weight
                    .checked_sub(vote_record_data.voter_weight)
                    .unwrap();
            }
            Vote::Abstain => {
                return Err(GovernanceError::NotSupportedVoteType.into());
            }
        }

        proposal_data.serialize(&mut *proposal_info.data.borrow_mut())?;

        dispose_account(vote_record_info, beneficiary_info);

        token_owner_record_data.total_votes_count = token_owner_record_data
            .total_votes_count
            .checked_sub(1)
            .unwrap();
    } else {
        vote_record_data.is_relinquished = true;

        vote_record_data.serialize(&mut *vote_record_info.data.borrow_mut())?;
    }

    // If the Proposal has been already voted on then we only have to decrease unrelinquished_votes_count
    token_owner_record_data.unrelinquished_votes_count = token_owner_record_data
        .unrelinquished_votes_count
        .checked_sub(1)
        .unwrap();

    token_owner_record_data.serialize(&mut *token_owner_record_info.data.borrow_mut())?;

    Ok(())
}","rust
//! Program state processor 
use solana_program::{ 
    account_info::{next_account_info, AccountInfo}, 
    clock::Clock, 
    entrypoint::ProgramResult, 
    pubkey::Pubkey, 
    sysvar::Sysvar, 
};

use spl_governance_tools::account::dispose_account; 

use crate::{ 
    error::GovernanceError, 
    state::{ 
        enums::ProposalState, 
        governance::get_governance_data_for_realm, 
        proposal::get_proposal_data_for_governance, 
        realm::get_realm_data_for_governing_token_mint, 
        token_owner_record::get_token_owner_record_data_for_realm_and_governing_mint, 
        vote_record::{get_vote_record_data_for_proposal_and_token_owner_record, Vote}, 
    }
}; 

/// Processes RelinquishVote instruction 
pub fn process_relinquish_vote(program_id: &Pubkey, accounts: &[AccountInfo]) -> ProgramResult { 
    let account_info_iter = &mut accounts.iter(); 

    let realm_info = next_account_info(account_info_iter)?; // 0 
    let governance_info = next_account_info(account_info_iter)?; // 1
    let proposal_info = next_account_info(account_info_iter)?; // 2
    let token_owner_record_info = next_account_info(account_info_iter)?; // 3
    let vote_record_info = next_account_info(account_info_iter)?; // 4
    let vote_governing_token_mint_info = next_account_info(account_info_iter)?; // 5

    let realm_data = get_realm_data_for_governing_token_mint(
        program_id, 
        realm_info, 
        vote_governing_token_mint_info.key,
    )?;

    let governance_data = get_governance_data_for_realm(
        program_id, 
        governance_info, 
        realm_info.key
    )?;

    let mut proposal_data = get_proposal_data_for_governance(
        program_id, 
        proposal_info, 
        governance_info.key
    )?;

    let mut token_owner_record_data = get_token_owner_record_data_for_realm_and_governing_mint( 
        program_id, 
        token_owner_record_info, 
        &governance_data.realm, 
        vote_governing_token_mint_info.key,
    )?;

    // This is continued so on.
}",Medium,Prevent vote relinquishment before the vote is finalized,https://github.com/solana-labs/solana-program-library/pull/3210/files#diff-fea11aeeb42ade34331090ca3048d3bf505f7fe169043b60de2218f3008165bb,High
Sol-152,"Tokens can get locked up indenitely Description Tokens can be staked from any Natix token account a user owns (which can be many). However, only tokens in one specic account per user (the ATA) can be unstaked and therefore retrieved. The unstake and withdraw functions require the token account to be the ATA (associated token account). Staking can be done from any token account the user has. This means that all funds staked from any user token account that is not the ATA will be stuck indenitely.","Rust
control_user_solana_address(user_account, authority_account)?;

let address = get_associated_token_address(user_solana_account.key, &get_natix_token_mint());

if user_account.key != &address {
    return Err(ProgramError::InvalidAccountOwner);
}","rust
// Staking: Only allow staking from the ATA (prevents future issues) 
control_user_solana_address(user_account, authority_account)?;

let staking_address = get_associated_token_address(user_solana_account.key, &get_natix_token_mint());

if user_account.key != &staking_address {
    return Err(ProgramError::InvalidAccountOwner);
}

// Unstaking: Allow unstaking from any valid token account the user owns 
fn unstake_tokens(
    user_solana_account: &AccountInfo, 
    user_token_accounts: &[AccountInfo], // Check all user token accounts 
    natix_token_mint: &Pubkey,
) -> ProgramResult {
    let mut found_valid_account = false;

    for user_token_account in user_token_accounts.iter() {
        let account_data = TokenAccount::unpack(&user_token_account.try_borrow_data()?)?;

        if account_data.owner == *user_solana_account.key && account_data.mint == *natix_token_mint {
            found_valid_account = true;
            msg!(""Unstaking from user-owned token account: {}"", user_token_account.key);
            break;
        }
    }

    if !found_valid_account {
        return Err(ProgramError::InvalidAccountOwner);
    }

    msg!(""Unstaking successful."");

    Ok(())
}",High,"allow staking from the ATA only or also support all accounts for unstaking, withdrawal, etc.",https://hashlock.com/wp-content/uploads/2024/08/Natix-Smart-Contract-Audit-Report-Final-Report-v1-Stake-1-1.pdf,High
Sol-153,Risk of overflows & underflows,"rust
let sum_stakes = amount
    .unwrap_or(0) 
    + give_stakes(staking_pool, address)
        .iter()
        .map(|staker| staker.amount)
        .sum::<u64>();","rust
// Ensure safe summation using checked_add() 
let sum_stakes = amount.unwrap_or(0).checked_add(
    give_stakes(staking_pool, address)
        .iter()
        .map(|staker| staker.amount)
        .sum::<u64>()
).ok_or(ProgramError::InvalidArgument)?;",Medium,Use checked math for calculations involving user inputs or configurable variables.,https://hashlock.com/wp-content/uploads/2024/08/Natix-Smart-Contract-Audit-Report-Final-Report-v1-Stake-1-1.pdf,High
Sol-154,Risk of overflows & underflows,"rust
amount += (unstaker.amount + reward - penalty).max(0); 
forfeit_amount += (penalty - reward).max(0);","rust
// Ensure safe addition/subtraction in staking logic 
amount = amount
    .checked_add(unstaker.amount)
    .and_then(|x| x.checked_add(reward))
    .and_then(|x| x.checked_sub(penalty))
    .ok_or(ProgramError::InvalidArgument)?;

forfeit_amount = penalty
    .checked_sub(reward)
    .unwrap_or(0); 
// Avoid underflow, defaulting to zero",Medium,Use checked math for calculations involving user inputs or configurable variables.,https://hashlock.com/wp-content/uploads/2024/08/Natix-Smart-Contract-Audit-Report-Final-Report-v1-Stake-1-1.pdf,High
Sol-155,"Although secure due to Solana's token program guarantees, some account checks should be added to improve code maintainability by verifying the source and receiver accounts.","rust
pub fn control_user_account(user_account: &AccountInfo) -> ProgramResult { 
    let user_token_account = TokenAccount::unpack(&user_account.data.borrow())?;
    
    msg!(""Checking user token account mint address {:?}"", user_token_account.mint); 
    
    if user_token_account.mint != get_natix_token_mint() { 
        return Err(ProgramError::IncorrectProgramId); 
    } 
    
    Ok(()) 
}","rust
/// Ensures the account is owned by the expected program and belongs to the correct user 
pub fn control_user_account(user_account: &AccountInfo, expected_owner: &Pubkey) -> ProgramResult { 
    if user_account.owner != &TOKEN_PROGRAM_ID { 
        msg!(""Error: Account is not owned by the Solana Token Program.""); 
        return Err(ProgramError::IncorrectProgramId); 
    } 
    let user_token_account = TokenAccount::unpack(&user_account.try_borrow_data()?)?;
     
    if user_token_account.mint != get_natix_token_mint() { 
        msg!(""Error: Token mint mismatch.""); 
        return Err(ProgramError::InvalidAccountData); 
    } 
    if &user_token_account.owner != expected_owner { 
        msg!(""Error: Account owner mismatch.""); 
        return Err(ProgramError::IllegalOwner); 
    } 
    msg!(""Account validation successful.""); 
    Ok(()) 
}",Low,"Future changes could break these checks, leading to serious issues. Properly verify which programs own which accounts.",https://hashlock.com/wp-content/uploads/2024/08/Natix-Smart-Contract-Audit-Report-Final-Report-v1-Stake-1-1.pdf,High
Sol-156,The transfer_token function does not verify if the source and receiver accounts are the same. There are other similar checks that could be improved for better maintainability,"rust
pub fn transfer_token(
    source: &AccountInfo, 
    destination: &AccountInfo, 
    amount: u64,
) -> ProgramResult { 
    msg!(
        ""Token transfer from {:?} to {:?} validated successfully."", 
        source.key, 
        destination.key
    ); 
    
    // Perform token transfer logic here (using CPI to token program)
    
    Ok(()) 
}","rust
pub fn transfer_token(
    source: &AccountInfo, 
    destination: &AccountInfo, 
    amount: u64, 
) -> ProgramResult {
    if source.key == destination.key {
        msg!(""Error: Source and destination accounts cannot be the same."");
        return Err(ProgramError::InvalidAccountData);
    }

    if source.owner != &TOKEN_PROGRAM_ID || destination.owner != &TOKEN_PROGRAM_ID {
        msg!(""Error: One of the accounts is not a valid SPL Token account."");
        return Err(ProgramError::IncorrectProgramId);
    }

    msg!(""Token transfer from {:?} to {:?} validated successfully."", 
         source.key, 
         destination.key
    );

    // Perform token transfer logic here (using CPI to token program)
    Ok(())
}",Low,"Future changes could break these checks, leading to serious issues. Properly verify which programs own which accounts.",https://hashlock.com/wp-content/uploads/2024/08/Natix-Smart-Contract-Audit-Report-Final-Report-v1-Stake-1-1.pdf,High
Sol-157,"The stake account can be supplied with fake PDAs to steal rewards. The StakeAccount account supplied is not validated to be the intended PDA, allowing attackers to create and provide a malicious stake account with arbitrary parameters. Vulnerability Details The Claim, Enter, and Sync instructions do not validate that the provided StakeAccount is the intended PDA account by enforcing the seeds constraint. This validation is important because attackers may pass PDAs with arbitrary parameters to trigger unintended behaviors in the program. In this case, the StakeAccount.xsoar parameter can be set by an attacker to a high value in order to steal rewards from the vault account. This causes a loss of funds when other legitimate users want to claim their rewards.","rust
use crate::*;
use anchor_spl::token::{Token, TokenAccount};
use soarchain_staking::{SoarchainStakingError, StakeAccount};

#[derive(Accounts)]
pub struct Claim<'info> {
    #[account(mut)] 
    pub user: Account<'info, TokenAccount>,

    #[account(mut)] 
    pub vault: Account<'info, TokenAccount>,

    #[account(mut, has_one = vault @ SoarchainError::InvalidVault)] 
    pub reflection: Account<'info, ReflectionAccount>,

    #[account(mut, has_one = authority @ SoarchainError::Unauthorized)] 
    pub reward: Account<'info, RewardAccount>,

    #[account( 
        has_one = authority @ SoarchainError::Unauthorized, 
        constraint = stake.time_unbond == 0 @ SoarchainStakingError::AlreadyUnbonded, 
        constraint = stake.xsoar >= reward.xsoar @ SoarchainStakingError::Decreased, 
    )]
    pub stake: Account<'info, StakeAccount>,

    #[account(mut)] 
    pub authority: Signer<'info>,

    pub token_program: Program<'info, Token>,
}","rust
use crate::*;
use anchor_spl::token::{Token, TokenAccount};
use soarchain_staking::{SoarchainStakingError, StakeAccount};

#[derive(Accounts)]
pub struct Claim<'info> {
    #[account(mut)]
    pub user: Account<'info, TokenAccount>,
    
    #[account(mut)]
    pub vault: Account<'info, TokenAccount>,
    
    #[account(mut, has_one = vault @ SoarchainError::InvalidVault)]
    pub reflection: Account<'info, ReflectionAccount>,
    
    #[account(mut, has_one = authority @ SoarchainError::Unauthorized)]
    pub reward: Account<'info, RewardAccount>,
    
    #[account( 
        has_one = authority @ SoarchainError::Unauthorized, 
        constraint = stake.key() == pda::soarchain_staking(&authority.key()) @ SoarchainError::InvalidAccount, 
        constraint = stake.time_unbond == 0 @ SoarchainStakingError::AlreadyUnbonded, 
        constraint = stake.xsoar >= reward.xsoar @ SoarchainStakingError::Decreased, 
    )]
    pub stake: Account<'info, StakeAccount>,
    
    #[account(mut)]
    pub authority: Signer<'info>,
    
    pub token_program: Program<'info, Token>,
}",High,"Consider enforcing the seeds constraint in StakeAccount to prevent attackers from passing incorrect PDAs. This can be achieved by applying the soarchain_staking function validation from common/src/pda.rs to the Claim, Enter, and Sync instructions.",https://hashlock.com/wp-content/uploads/2025/01/Soarchain-Smart-Contract-Audit-Report-Final-Report-1.pdf,High
Sol-158,"The stake account can be supplied with fake PDAs to steal rewards. The StakeAccount account supplied is not validated to be the intended PDA, allowing attackers to create and provide a malicious stake account with arbitrary parameters. Vulnerability Details The Claim, Enter, and Sync instructions do not validate that the provided StakeAccount is the intended PDA account by enforcing the seeds constraint. This validation is important because attackers may pass PDAs with arbitrary parameters to trigger unintended behaviors in the program. In this case, the StakeAccount.xsoar parameter can be set by an attacker to a high value in order to steal rewards from the vault account. This causes a loss of funds when other legitimate users want to claim their rewards.","rust
use crate::*;
use soarchain_staking::{SoarchainStakingError, StakeAccount};

#[derive(Accounts)]
pub struct Enter<'info> {
    #[account(mut)]
    pub reflection: Account<'info, ReflectionAccount>,

    #[account(
        has_one = authority @ SoarchainError::Unauthorized,
        constraint = stake.time_unbond == 0 @ SoarchainStakingError::AlreadyUnbonded
    )]
    pub stake: Account<'info, StakeAccount>,

    #[account(
        init,
        payer = authority,
        space = RewardAccount::SIZE,
        seeds = [ constants::PREFIX_REWARDS.as_ref(), authority.key().as_ref() ],
        bump,
    )]
    pub reward: Account<'info, RewardAccount>,

    #[account(mut)]
    pub authority: Signer<'info>,

    pub system_program: Program<'info, System>,
}","rust
use crate::*;
use soarchain_staking::{SoarchainStakingError, StakeAccount};

#[derive(Accounts)]
pub struct Enter<'info> {
    #[account(mut)]
    pub reflection: Account<'info, ReflectionAccount>,
    
    #[account(
        has_one = authority @ SoarchainError::Unauthorized,
        constraint = stake.key() == pda::soarchain_staking(&authority.key()) @ SoarchainError::InvalidAccount,
        constraint = stake.time_unbond == 0 @ SoarchainStakingError::AlreadyUnbonded,
    )]
    pub stake: Account<'info, StakeAccount>,
    
    #[account(
        init, 
        payer = authority, 
        space = RewardAccount::SIZE,
        seeds = [ constants::PREFIX_REWARDS.as_ref(), authority.key().as_ref() ], 
        bump,
    )]
    public reward: Account<'info, RewardAccount>,
    
    #[account(mut)]
    public authority: Signer<'info>,
    
    public system_program: Program<'info, System>,
}",High,"Consider enforcing the seeds constraint in StakeAccount to prevent attackers from passing incorrect PDAs. This can be achieved by applying the soarchain_staking function validation from common/src/pda.rs to the Claim, Enter, and Sync instructions.",https://hashlock.com/wp-content/uploads/2025/01/Soarchain-Smart-Contract-Audit-Report-Final-Report-1.pdf,High
Sol-159,"The stake account can be supplied with fake PDAs to steal rewards. The StakeAccount account supplied is not validated to be the intended PDA, allowing attackers to create and provide a malicious stake account with arbitrary parameters. Vulnerability Details The Claim, Enter, and Sync instructions do not validate that the provided StakeAccount is the intended PDA account by enforcing the seeds constraint. This validation is important because attackers may pass PDAs with arbitrary parameters to trigger unintended behaviors in the program. In this case, the StakeAccount.xsoar parameter can be set by an attacker to a high value in order to steal rewards from the vault account. This causes a loss of funds when other legitimate users want to claim their rewards.","rust
use crate::*;
use soarchain_staking::{SoarchainStakingError, StakeAccount};

#[derive(Accounts)]
pub struct Sync<'info> {
    #[account(mut)]
    pub reward: Account<'info, RewardAccount>,
    
    #[account(
        constraint = stake.time_unbond == 0 
            @ SoarchainStakingError::AlreadyUnbonded,
        constraint = stake.authority == reward.authority 
            @ SoarchainError::Unauthorized,
    )]
    pub stake: Account<'info, StakeAccount>,
    
    #[account(mut)]
    pub reflection: Account<'info, ReflectionAccount>,
}","rust
use crate::*;
use soarchain_staking::{SoarchainStakingError, StakeAccount};

#[derive(Accounts)]
pub struct Sync<'info> {
    #[account(mut)]
    pub reward: Account<'info, RewardAccount>,

    #[account(
        constraint = stake.time_unbond == 0 
            @ SoarchainStakingError::AlreadyUnbonded,
        constraint = stake.authority == reward.authority 
            @ SoarchainError::Unauthorized,
        constraint = stake.key() == pda::soarchain_staking(&authority.key())
            @ SoarchainError::InvalidAccount,
    )]
    pub stake: Account<'info, StakeAccount>,

    #[account(mut)]
    pub reflection: Account<'info, ReflectionAccount>,

    pub authority: Signer<'info>,
}",High,"Consider enforcing the seeds constraint in StakeAccount to prevent attackers from passing incorrect PDAs. This can be achieved by applying the soarchain_staking function validation from common/src/pda.rs to the Claim, Enter, and Sync instructions.",https://hashlock.com/wp-content/uploads/2025/01/Soarchain-Smart-Contract-Audit-Report-Final-Report-1.pdf,High
Sol-160,"Missing authentication validation allows attackers to steal referral fees. When claiming referral fees, no validation ensures the caller is the referral state authority, allowing attackers to steal victims’ referral fees. Vulnerability Details The process_claim_referral_fees function in programs/solauto/src/processors/referral_state.rs:172 does not validate that the transaction signer (ctx.accounts.signer.key) equals the referral state authority (referral_state.data.authority). This validation is important because it ensures only the owner of the referral state can withdraw their referral fees.","rust
use jupiter_sdk::JUPITER_ID;
use solana_program::{
    account_info::AccountInfo, 
    entrypoint::ProgramResult, 
    instruction::{get_stack_height, TRANSACTION_LEVEL_STACK_HEIGHT},
    msg, 
    program_error::ProgramError, 
    sysvar::instructions::{load_current_index_checked, load_instruction_at_checked},
};
use spl_associated_token_account::get_associated_token_address;
use spl_token::state::Account as TokenAccount;

use crate::{
    constants::WSOL_MINT,
    instructions::referral_fees,
    state::referral_state::ReferralState,
    types::{
        instruction::{
            accounts::{ ClaimReferralFeesAccounts, ConvertReferralFeesAccounts, UpdateReferralStatesAccounts },
            UpdateReferralStatesArgs,
        }, 
        shared::{DeserializedAccount, SolautoError},
    }, 
    utils::{
        ix_utils::{self, validate_jup_instruction},
        solauto_utils,
        validation_utils,
    },
};


pub fn process_update_referral_states<'a>(
    accounts: &'a [AccountInfo<'a>],
    args: UpdateReferralStatesArgs,
) -> ProgramResult {
    msg!(""Instruction: Update referral states"");

    let ctx = UpdateReferralStatesAccounts::context(accounts)?;

    if !ctx.accounts.signer.is_signer {
        return Err(ProgramError::MissingRequiredSignature.into());
    }
    
    if ctx.accounts.referred_by_authority.is_some() && ctx.accounts.referred_by_authority.unwrap().key == ctx.accounts.signer.key {
        msg!(""Cannot set the referred by as the same as the referral state authority"");
        return Err(SolautoError::IncorrectAccounts.into());
    }

    validation_utils::validate_sysvar_accounts(
        Some(ctx.accounts.system_program), 
        None, None, 
        Some(ctx.accounts.rent), 
        None,
    )?;

    let mut authority_referral_state = solauto_utils::create_or_update_referral_state(
        ctx.accounts.rent,
        ctx.accounts.signer,
        ctx.accounts.signer,
        ctx.accounts.signer_referral_state,
        args.referral_fees_dest_mint,
        ctx.accounts.referred_by_state,
        args.address_lookup_table,
    )?;
    
    ix_utils::update_data(&mut authority_referral_state)?;

    if ctx.accounts.referred_by_state.is_some() {
        let mut referred_by_state = solauto_utils::create_or_update_referral_state(
            ctx.accounts.rent,
            ctx.accounts.signer,
            ctx.accounts.referred_by_authority.unwrap(),
            ctx.accounts.referred_by_state.unwrap(),
            None, None, None,
        )?;

        ix_utils::update_data(&mut referred_by_state)?;
    }
    
    validation_utils::validate_referral_accounts(
        &ctx.accounts.signer.key,
        &authority_referral_state,
        ctx.accounts.referred_by_state,
        None, false,
    )
}

pub fn process_convert_referral_fees<'a>(accounts: &'a [AccountInfo<'a>]) -> ProgramResult {
    msg!(""Instruction: Convert referral fees"");

    let ctx = ConvertReferralFeesAccounts::context(accounts)?;

    let referral_state = DeserializedAccount::<ReferralState>::zerocopy(Some(ctx.accounts.referral_state))?
        .unwrap();

    validation_utils::validate_referral_signer(&referral_state, ctx.accounts.signer, true)?;

    validation_utils::validate_sysvar_accounts(
        Some(ctx.accounts.system_program),
        Some(ctx.accounts.token_program),
        Some(ctx.accounts.ata_program),
        Some(ctx.accounts.rent),
        Some(ctx.accounts.ixs_sysvar),
    )?;

    let token_account = DeserializedAccount::<TokenAccount>::unpack(Some(ctx.accounts.referral_fees_ta))?
        .unwrap();

    if !validation_utils::token_account_owned_by(&token_account, ctx.accounts.referral_state.key) {
        msg!(""Provided incorrect token account for the given referral state account"");
        return Err(SolautoError::IncorrectAccounts.into());
    }
    
    let current_ix_idx = load_current_index_checked(ctx.accounts.ixs_sysvar)?;
    let current_ix = load_instruction_at_checked(current_ix_idx as usize, ctx.accounts.ixs_sysvar)?;

    if current_ix.program_id != crate::ID || get_stack_height() > TRANSACTION_LEVEL_STACK_HEIGHT {
        return Err(SolautoError::InstructionIsCPI.into());
    }

    let mut index = current_ix_idx;
    loop {
        if let Err(_) = load_instruction_at_checked(index as usize, ctx.accounts.ixs_sysvar) {
            break;
        }
        index += 1;
    }

    let jup_swap = ix_utils::InstructionChecker::from_anchor(
        ctx.accounts.ixs_sysvar,
        JUPITER_ID,
        vec![""route"", ""shared_accounts_route""],
        current_ix_idx,
    );

    validate_jup_instruction(
        ctx.accounts.ixs_sysvar,
        (current_ix_idx + 1) as usize,
        &[&get_associated_token_address(
            ctx.accounts.referral_state.key,
            &referral_state.data.dest_fees_mint,
        )],
    )?;
    
    if !jup_swap.matches(1) {
        msg!(""Missing Jup swap as next transaction"");
        return Err(SolautoError::IncorrectInstructions.into());
    }

    referral_fees::convert_referral_fees(ctx, referral_state)
}


pub fn process_claim_referral_fees<'a>(accounts: &'a [AccountInfo<'a>]) -> ProgramResult {
    msg!(""Instruction: Claim referral fees"");

    let ctx = ClaimReferralFeesAccounts::context(accounts)?;

    let referral_state = DeserializedAccount::<ReferralState>::zerocopy(Some(ctx.accounts.referral_state))?
        .unwrap();

    validation_utils::validate_referral_signer(&referral_state, ctx.accounts.signer, false)?;

    validation_utils::validate_sysvar_accounts(
        Some(ctx.accounts.system_program),
        Some(ctx.accounts.token_program),
        None, Some(ctx.accounts.rent),
        None,
    )?;

    if ctx.accounts.referral_fees_dest_ta.key != &get_associated_token_address(
        ctx.accounts.referral_state.key,
        &referral_state.data.dest_fees_mint,
    ) {
        msg!(""Provided incorrect referral_fees_dest_ta account"");
        return Err(SolautoError::IncorrectAccounts.into());
    }

    if referral_state.data.dest_fees_mint != WSOL_MINT && ctx.accounts.fees_destination_ta.is_none() {
        msg!(""Missing fees destination token account when the token mint is not wSOL"");
        return Err(SolautoError::IncorrectAccounts.into());
    }

    referral_fees::claim_referral_fees(ctx, referral_state)
}","rust
use jupiter_sdk::JUPITER_ID;
use solana_program::{
    account_info::AccountInfo, entrypoint::ProgramResult, instruction::{get_stack_height, TRANSACTION_LEVEL_STACK_HEIGHT}, 
    msg,
    program_error::ProgramError, 
    sysvar::instructions::{load_current_index_checked, load_instruction_at_checked},
};

use spl_associated_token_account::get_associated_token_address;
use spl_token::state::Account as TokenAccount;

use crate::{
    constants::WSOL_MINT,
    instructions::referral_fees,
    state::referral_state::ReferralState,
    types::{
        instruction::{
            accounts::{
                ClaimReferralFeesAccounts,
                ConvertReferralFeesAccounts,
                UpdateReferralStatesAccounts,
            },
            UpdateReferralStatesArgs,
        },
        shared::{
            DeserializedAccount,
            SolautoError
        },
    },
    utils::{
        ix_utils::{
            self,
            validate_jup_instruction
        },
        solauto_utils,
        validation_utils,
    },
};

pub fn process_update_referral_states<'a>( 
    accounts: &'a [AccountInfo<'a>], 
    args: UpdateReferralStatesArgs,) 
    -> ProgramResult {

    msg!(""Instruction: Update referral states"");
    let ctx = UpdateReferralStatesAccounts::context(accounts)?;

    if !ctx.accounts.signer.is_signer { 
        return Err(ProgramError::MissingRequiredSignature.into()); 
    }

    if ctx.accounts.referred_by_authority.is_some() && 
        ctx.accounts.referred_by_authority.unwrap().key == ctx.accounts.signer.key {

        msg!(""Cannot set the referred by as the same as the referral state authority"");
        return Err(SolautoError::IncorrectAccounts.into()); 
    }

    validation_utils::validate_sysvar_accounts(
        Some(ctx.accounts.system_program),
        None,
        None,
        Some(ctx.accounts.rent),
        None,
    )?;

    let mut authority_referral_state = solauto_utils::create_or_update_referral_state(
        ctx.accounts.rent, 
        ctx.accounts.signer, 
        ctx.accounts.signer, 
        ctx.accounts.signer_referral_state, 
        args.referral_fees_dest_mint, 
        ctx.accounts.referred_by_state, 
        args.address_lookup_table,
        )?;

    ix_utils::update_data(&mut authority_referral_state)?;

    if ctx.accounts.referred_by_state.is_some() { 
        let mut referred_by_state = solauto_utils::create_or_update_referral_state(
            ctx.accounts.rent, 
            ctx.accounts.signer, 
            ctx.accounts.referred_by_authority.unwrap(), 
            ctx.accounts.referred_by_state.unwrap(), 
            None, None, None,
            )?;

        ix_utils::update_data(&mut referred_by_state)?; 
    }

    validation_utils::validate_referral_accounts(
        &ctx.accounts.signer.key, 
        &authority_referral_state, 
        ctx.accounts.referred_by_state, 
        None, 
        false,
    ) 
}

pub fn process_convert_referral_fees<'a>(accounts: &'a [AccountInfo<'a>]) -> ProgramResult {
    msg!(""Instruction: Convert referral fees"");
    let ctx = ConvertReferralFeesAccounts::context(accounts)?;
    let referral_state = DeserializedAccount::<ReferralState>::zerocopy(Some(ctx.accounts.referral_state))?.unwrap();

    validation_utils::validate_referral_signer(&referral_state, ctx.accounts.signer, true)?;

    validation_utils::validate_sysvar_accounts(
        Some(ctx.accounts.system_program), 
        Some(ctx.accounts.token_program), 
        Some(ctx.accounts.ata_program),
        Some(ctx.accounts.rent), 
        Some(ctx.accounts.ixs_sysvar)
    )?;

    let token_account = DeserializedAccount::<TokenAccount>::unpack(Some(ctx.accounts.referral_fees_ta))?.unwrap();

    if !validation_utils::token_account_owned_by(&token_account, ctx.accounts.referral_state.key) {
        msg!(""Provided incorrect token account for the given referral state account"");
        return Err(SolautoError::IncorrectAccounts.into());
    }

    let current_ix_idx = load_current_index_checked(ctx.accounts.ixs_sysvar)?;
    let current_ix = load_instruction_at_checked(current_ix_idx as usize, ctx.accounts.ixs_sysvar)?;

    if current_ix.program_id != crate::ID || get_stack_height() > TRANSACTION_LEVEL_STACK_HEIGHT {
        return Err(SolautoError::InstructionIsCPI.into());
    }

    let mut index = current_ix_idx;
    loop {
        if let Err(_) = load_instruction_at_checked(index as usize, ctx.accounts.ixs_sysvar) {
            break;
        }
        index += 1;
    }

    let jup_swap = ix_utils::InstructionChecker::from_anchor(
        ctx.accounts.ixs_sysvar,
        JUPITER_ID, 
        vec![""route"", ""shared_accounts_route""], 
        current_ix_idx,
    );

    validate_jup_instruction(
        ctx.accounts.ixs_sysvar, 
        (current_ix_idx + 1) as usize, 
        &[&get_associated_token_address(
            ctx.accounts.referral_state.key, 
            &referral_state.data.dest_fees_mint,
        )],
    )?;
    if !jup_swap.matches(1) {
        msg!(""Missing Jup swap as next transaction"");
        return Err(SolautoError::IncorrectInstructions.into());
    }

    referral_fees::convert_referral_fees(ctx, referral_state)
}

pub fn process_claim_referral_fees<'a>(accounts: &'a [AccountInfo<'a>]) -> ProgramResult {
    msg!(""Instruction: Claim referral fees"");
    let ctx = ClaimReferralFeesAccounts::context(accounts)?;
    let referral_state = DeserializedAccount::<ReferralState>::zerocopy(Some(ctx.accounts.referral_state))?.unwrap();

    validation_utils::validate_referral_signer(
        &referral_state,
        ctx.accounts.signer,
        ctx.accounts.referral_fees_dest_mint.key == &WSOL_MINT,
    )?;

    if ctx.accounts.referral_authority.is_some() && 
        ctx.accounts.referral_authority.unwrap().key != &referral_state.data.authority {

        msg!(""Provided incorrect referral authority"");
        return Err(SolautoError::IncorrectAccounts.into());
    }

    validation_utils::validate_sysvar_accounts(
        Some(ctx.accounts.system_program),
        Some(ctx.accounts.token_program), 
        None,
        Some(ctx.accounts.rent), 
        None
    )?;

    if ctx.accounts.referral_fees_dest_ta.key != &get_associated_token_address(
        ctx.accounts.referral_state.key, 
        &referral_state.data.dest_fees_mint,
    ) {
        msg!(""Provided incorrect referral_fees_dest_ta account"");
        return Err(SolautoError::IncorrectAccounts.into());
    }

    if referral_state.data.dest_fees_mint != WSOL_MINT && ctx.accounts.fees_destination_ta.is_none() {
        msg!(""Missing fees destination token account when the token mint is not wSOL"");
        return Err(SolautoError::IncorrectAccounts.into());
    }

    referral_fees::claim_referral_fees(ctx, referral_state)
}",High,Consider validating that the signer equals the referral state’s authority.,https://github.com/haven-fi/solauto/commit/734f7ee99574603ef24edb332c2a89fda5d402b1#diff-6e22cf5191f8b655489db95dc38ebd8c2ff474ac05cbed75096ffe6d909ff96e,High
Sol-161,"Existing positions will be removed when opening a new position Description If a user calls the MarginfiOpenPosition instruction with an existing position, the position will be removed. Vulnerability Details The create_new_solauto_position function in programs/solauto/src/utils/solauto_utils.rs:85-92 sets the SolautoPosition to a new PositionData and PositionState if the caller specied UpdatePositionData.setting_params as None. If there is any existing position information in solauto_position, it will be overwritten to an empty position in programs/solauto/src/instructions/open_position.rs:112. Impact The user will lose access to their existing position, including any deposited funds","rust
use solana_program::{
    account_info::AccountInfo, entrypoint::ProgramResult, msg, program_error::ProgramError,
    program_pack::Pack, pubkey::Pubkey,
};
use spl_associated_token_account::get_associated_token_address;
use spl_token::state::{Account as TokenAccount, Mint};
use std::ops::{Div, Mul};

use super::solana_utils::{
    account_has_data, init_account, init_ata_if_needed, spl_token_transfer
};
use crate::{
    constants::{SOLAUTO_FEES_WALLET, WSOL_MINT},
    state::{
        referral_state::ReferralState,
        solauto_position::{ 
            DCASettings, PositionData, PositionState, SolautoPosition,
            SolautoSettingsParameters,
        },
    },
    types::{
        instruction::UpdatePositionData,
        shared::{DeserializedAccount, FeeType, LendingPlatform, SolautoError},
    },
};

pub fn get_owner<'a, 'b>(
    solauto_position: &'b DeserializedAccount<'a, SolautoPosition>,
    signer: &'a AccountInfo<'a>,
) -> &'a AccountInfo<'a> {
    if solauto_position.data.self_managed.val {
        signer
    } else {
        solauto_position.account_info
    }
}

pub fn create_new_solauto_position<'a>(
    signer: &AccountInfo<'a>,
    solauto_position: &'a AccountInfo<'a>,
    update_position_data: UpdatePositionData,
    lending_platform: LendingPlatform,
    supply_mint: &'a AccountInfo<'a>,
    debt_mint: &'a AccountInfo<'a>,
    lending_protocol_account: &'a AccountInfo<'a>,
    max_ltv: f64,
    liq_threshold: f64,
) -> Result<DeserializedAccount<'a, SolautoPosition>, ProgramError> {
    let data = if update_position_data.setting_params.is_some() {
        if update_position_data.position_id == 0 {
            msg!(""Position ID 0 is reserved for self-managed positions"");
            return Err(ProgramError::InvalidInstructionData.into());
        }

        let supply = DeserializedAccount::<Mint>::unpack(Some(supply_mint))?.unwrap();
        let debt = DeserializedAccount::<Mint>::unpack(Some(debt_mint))?.unwrap();
        let mut state = PositionState::default();

        state.supply.mint = *supply.account_info.key;
        state.supply.decimals = supply.data.decimals;
        state.debt.mint = *debt.account_info.key;
        state.debt.decimals = debt.data.decimals;
        state.max_ltv_bps = max_ltv.mul(10000.0) as u16;
        state.liq_threshold_bps = liq_threshold.mul(10000.0) as u16;

        let mut position_data = PositionData::default();
        position_data.lending_platform = lending_platform;
        position_data.setting_params = SolautoSettingsParameters::from(*update_position_data.setting_params.as_ref().unwrap());
        position_data.protocol_account = *lending_protocol_account.key;
        position_data.supply_mint = *supply_mint.key;
        position_data.debt_mint = *debt_mint.key;

        if update_position_data.dca.is_some() {
            position_data.dca = DCASettings::from(*update_position_data.dca.as_ref().unwrap());
        }

        Box::new(SolautoPosition::new(
            update_position_data.position_id, *signer.key, position_data, state,
        ))
    } else {
        Box::new(SolautoPosition::new(
            0, *signer.key, PositionData::default(), PositionState::default(),
        ))
    };

    Ok(DeserializedAccount::<SolautoPosition> {
        account_info: solauto_position,
        data,
    })
}","rust
use solana_program::{
    account_info::AccountInfo, 
    entrypoint::ProgramResult, 
    msg, 
    program_error::ProgramError, 
    program_pack::Pack, 
    pubkey::Pubkey,
}; 

use spl_associated_token_account::get_associated_token_address; 
use spl_token::state::{Account as TokenAccount, Mint}; 
use std::ops::Div; 
use super::{
    math_utils::to_bps, 
    solana_utils::{
        account_has_data, 
        init_account, 
        init_ata_if_needed, 
        spl_token_transfer
    }
};

use crate::{ 
    constants::{
        SOLAUTO_FEES_WALLET, 
        WSOL_MINT
    },
    state:{ 
        referral_state::ReferralState, 
        solauto_position::{ 
            DCASettings, 
            PositionData, 
            PositionState, 
            SolautoPosition,
            SolautoSettingsParameters, 
        },
    },
    types:{ 
        instruction::UpdatePositionData, 
        shared::{DeserializedAccount, FeeType, LendingPlatform, SolautoError},
    },
};

pub fn get_owner<'a, 'b>(
    solauto_position: &'b DeserializedAccount<'a, SolautoPosition>, 
    signer: &'a AccountInfo<'a>,
) -> &'a AccountInfo<'a> {
    if solauto_position.data.self_managed.val { 
        signer 
    } else { 
        solauto_position.account_info 
    }
}

pub fn create_new_solauto_position<'a>(
    signer: &AccountInfo<'a>, 
    solauto_position: &'a AccountInfo<'a>, 
    update_position_data: UpdatePositionData, 
    lending_platform: LendingPlatform,
    supply_mint: &'a AccountInfo<'a>, 
    debt_mint: &'a AccountInfo<'a>, 
    lending_protocol_account: &'a AccountInfo<'a>, 
    max_ltv: f64, 
    liq_threshold: f64,
) -> Result<DeserializedAccount<'a, SolautoPosition>, ProgramError> {
    if account_has_data(solauto_position) {
        msg!(""Cannot open new position on an existing Solauto position""); 
        return Err(SolautoError::IncorrectAccounts.into());
    } 

    // Rest of the code.
}",High,Consider checking the position has no existing data with the account_has_data function before overwriting it.,https://github.com/haven-fi/solauto/commit/8745ecea2be6c36c9545493590b89a32335dd773#diff-a6f49a967929ef4294bad0d6ee63494c1d6aa39e7f408ccda492afc4f82939ab,High
Sol-162,"Initialization can be frontrun, leading to ownership takeover Description The initialize instruction in the contract can be invoked by any account. It assigns the caller as the owner of the master account, which is the administrative authority of the program. Vulnerability Details There is no mechanism to restrict access to this instruction, such as validating that only the deployer of the program or an authorised entity can perform the initialization. Impact A malicious actor can take the complete ownership of the master account and hence the program.","pub fn process(ctx: Context<InitializeCtx>, percent_pay_w_sol: u16, percent_pay_w_done_token: u16) -> Result<()> {
    let master = &mut ctx.accounts.master;
    let signer = &ctx.accounts.signer;

    require!(
        percent_pay_w_sol <= 10000,
        CustomErrors::InvalidPercent
    );

    require!(
        percent_pay_w_done_token <= 10000,
        CustomErrors::InvalidPercent
    );

    if master.is_initialized {
        return Err(CustomErrors::MasterAccountAlreadyInitialized.into());
    }

    master.is_initialized = true;
    master.owner = signer.key(); // ❌ Any caller becomes the owner
    master.percent_pay_w_sol = percent_pay_w_sol;
    master.percent_pay_w_done_token = percent_pay_w_done_token;

    emit!(OwnerInitialized {});

    Ok(())
}","rust
use anchor_lang::prelude::*;

#[derive(Accounts)]
pub struct InitializeCtx<'info> {
    #[account(mut)]
    pub master: Account<'info, MasterAccount>,

    #[account(mut, signer)]
    pub signer: Signer<'info>,

    pub system_program: Program<'info, System>,
}

pub fn process(
    ctx: Context<InitializeCtx>,
    percent_pay_w_sol: u16,
    percent_pay_w_done_token: u16,
) -> Result<()> {
    let master = &mut ctx.accounts.master;
    let signer = &ctx.accounts.signer;

    let expected_owner: Pubkey = Pubkey::from_str(""YOUR_HARD_CODED_OWNER_PUBLIC_KEY"").unwrap();

    // ✅ Restrict to expected owner
    require!(percent_pay_w_sol <= 10000, CustomErrors::InvalidPercent);
    require!(percent_pay_w_done_token <= 10000, CustomErrors::InvalidPercent);

    if master.is_initialized {
        return Err(CustomErrors::MasterAccountAlreadyInitialized.into());
    }

    // ✅ Enforce initialization by the correct entity
    if signer.key() != expected_owner {
        return Err(CustomErrors::UnauthorizedInitialization.into());
    }

    master.is_initialized = true;
    master.owner = expected_owner;

    // ✅ Ensure correct ownership
    master.percent_pay_w_sol = percent_pay_w_sol;
    master.percent_pay_w_done_token = percent_pay_w_done_token;

    emit!(OwnerInitialized {});

    Ok(())
}",Critical,Implement access control on the caller of the initialize instruction. A common practice is to use the program’s upgrade_authority as the authorized address to call the initialize function if the program has an upgrade authority. Another solution is to set a hardcoded address of the expected owner’s public key to restrict access to only that specic address.,https://hashlock.com/wp-content/uploads/2024/10/1001_Squares_of_NFT_Smart_Contract_Audit_Report_Final_Report.pdf,High
Sol-163,"Lack of input validation of percent can lead to draining of DONE token vault Description The owner of the program sets and updates the percent in the initialize and set_percent instructions respectively, that is used for DONE token returns in the create_payment instruction, depending on the amount of SOL that users paid. Vulnerability Details The percent parameter is of type u64, allowing values between 0 and 2^64 - 1. Without a validation mechanism to constrain the percent eld, an excessively high value could be set. Impact The vault of the done token can be completely drained even in one payment, if the percent has been set incorrectly to a very high value.","rust
pub fn process(
    ctx: Context<InitializeCtx>, 
    percent_pay_w_sol: u16, 
    percent_pay_w_done_token: u16
) -> Result<()> { 
    let master = &mut ctx.accounts.master; 
    let signer = &ctx.accounts.signer; 

    require!(
        percent_pay_w_sol <= 10000, 
        CustomErrors::InvalidPercent
    ); 

    require!(
        percent_pay_w_done_token <= 10000, 
        CustomErrors::InvalidPercent
    ); 

    if master.is_initialized { 
        return Err(CustomErrors::MasterAccountAlreadyInitialized.into()); 
    } 

    master.is_initialized = true; 
    master.owner = signer.key(); 
    master.percent_pay_w_sol = percent_pay_w_sol; 
    master.percent_pay_w_done_token = percent_pay_w_done_token; 

    emit!(OwnerInitialized {}); 

    Ok(()) 
}","rust
pub fn process( 
    ctx: Context<InitializeCtx>, 
    percent_pay_w_sol: u16, 
    percent_pay_w_done_token: u16 
    ) -> Result<()> { 
    
    let master = &mut ctx.accounts.master; 
    let signer = &ctx.accounts.signer; 

    const MAX_ALLOWED_PERCENT: u16 = 1000; // Example: 1000 = 10% max payout 

    require!(percent_pay_w_sol <= MAX_ALLOWED_PERCENT, CustomErrors::InvalidPercent);
    require!(percent_pay_w_done_token <= MAX_ALLOWED_PERCENT, CustomErrors::InvalidPercent); 

    if master.is_initialized { 
        return Err(CustomErrors::MasterAccountAlreadyInitialized.into()); 
    } 

    master.is_initialized = true; 
    master.owner = signer.key(); 
    master.percent_pay_w_sol = percent_pay_w_sol;
    master.percent_pay_w_done_token = percent_pay_w_done_token;
    
    emit!(OwnerInitialized {}); 
    
    Ok(()) 
}",Medium,"Add an explicit check to ensure the percent value falls within the expected range, that aligns with the project’s requirements.",https://hashlock.com/wp-content/uploads/2024/10/1001_Squares_of_NFT_Smart_Contract_Audit_Report_Final_Report.pdf,High
Sol-164,"One-time limitation of item_id prevents recurring payments Description The create_payment and create_payment_by_done instructions both use item_id to create a corresponding payment record. However, each instruction can only be called once for a specific item_id. Vulnerability Details Each item_payment account is created by using item_id and has the init constraint. Impact Users cannot execute recurring payments for items, since each item_id can only be used once. Furthermore, since there is no check which user creates a payment for a specific item, a malicious actor can create a payment for another user’s item and as a result, the rightful user cannot pay for their specific item.","rust
#[account(
    init, 
    payer = signer, 
    seeds = [ITEM_PAYMENT, item_id.to_le_bytes().as_ref()], 
    bump, 
    space = 8 + ItemPayment::INIT_SPACE, 
)]
item_payment: Account<'info, ItemPayment>, 

...

#[account(
    init, 
    payer = signer, 
    seeds = [ITEM_PAYMENT, item_id.to_le_bytes().as_ref()], 
    bump, 
    space = 8 + ItemPayment::INIT_SPACE, 
)]
item_payment: Account<'info, ItemPayment>,","rust
#[account( 
    init_if_needed, // ✅ Allows multiple payments per item_id 
    payer = signer, 
    seeds = [
        ITEM_PAYMENT, 
        item_id.to_le_bytes().as_ref(), 
        transaction_id.to_le_bytes().as_ref()
    ], // ✅ Unique per payment 
    bump, 
    space = 8 + ItemPayment::INIT_SPACE, 
)]
item_payment: Account<'info, ItemPayment>, 

...

#[account( 
    init_if_needed, // ✅ Allows multiple payments per item_id 
    payer = signer, 
    seeds = [
        ITEM_PAYMENT, 
        item_id.to_le_bytes().as_ref(), 
        transaction_id.to_le_bytes().as_ref()
    ], // ✅ Unique per payment 
    bump, 
    space = 8 + ItemPayment::INIT_SPACE, 
)]
item_payment: Account<'info, ItemPayment>,",Medium,Consider allowing payments for a specic item_id to be made more than once. This can be achieved by changing init constraint to init_if_needed and including additional unique identifiers (e.g. transaction_id) to differentiate between multiple payments for the same item_id.,https://hashlock.com/wp-content/uploads/2024/10/1001_Squares_of_NFT_Smart_Contract_Audit_Report_Final_Report.pdf,High
Sol-165,"Limitation of unique item_id can be bypassed for item payments Description Users can create payments for the same item_id by paying with SOL and DONE tokens as well. Although there is a limitation of each item_id to be used only once, the case of the two different payment methods to take place for the same item is not handled. Vulnerability Details The item_id is an argument that is given to each payment instruction and with that the item_payment is created. By implementing the init constraint, the business logic enforces the usage of the item_id only once. Impact The limitation of the uniqueness of item_id for an item_payment can be bypassed and create scenarios where 2 simultaneous payments for the same item_id take place.","rust
#[account(
    init,
    payer = signer, 
    seeds = [ITEM_PAYMENT, item_id.to_le_bytes().as_ref()], 
    bump, 
    space = 8 + ItemPayment::INIT_SPACE, 
)]
item_payment: Account<'info, ItemPayment>,","rust
#[account( 
    init, 
    payer = signer, 
    seeds = [
        ITEM_PAYMENT, 
        item_id.to_le_bytes().as_ref(), 
        payment_method.as_bytes()
    ], // ✅ Enforce payment type uniqueness 
    bump, 
    space = 8 + ItemPayment::INIT_SPACE, 
)]
item_payment: Account<'info, ItemPayment>,",Medium,Implement a mechanism that ensures each item_id can only be associated with a single payment type by restricting the ability to call both create_payment and create_payment_by_done for the same item_id.,https://hashlock.com/wp-content/uploads/2024/10/1001_Squares_of_NFT_Smart_Contract_Audit_Report_Final_Report.pdf,High
Sol-166,"The token_program that is used for the management of the pool token can be arbitrarily assigned by the pool creator. Therefore, the underlying logic of the critical token_program component cannot be guaranteed, and may lead to unexpected or even malicious behavior when called upon.","rust
pub struct Processor {}

impl Processor {
    /// Issue a stake_deactivate instruction.
    #[allow(clippy::too_many_arguments)]
    fn stake_delegate<'a>(stake_info: AccountInfo<'a>) {
        // omitted code

        stake_pool.check_reserve_stake(reserve_stake_info)?;
        check_stake_program(stake_program_info.key)?;
        check_account_owner(validator_list_info, program_id)?;

        let mut validator_list_data = validator_list_info.data.borrow_mut();
        let (validator_list_header, mut validator_slice); // omitted code

        // omitted code
        let token_program_info = next_account_info(account_info_iter)?;
        let stake_program_info = next_account_info(account_info_iter)?;

        if *stake_program_info.key != stake_program::id() {
            return Err(ProgramError::IncorrectProgramId);
        }
    }
}","rust
pub struct Processor {} 

impl Processor { 
    /// Issue a delegate_stake instruction. 
    #[allow(clippy::too_many_arguments)] 
    fn stake_delegate<'a>( stake_info: AccountInfo<'a>, 

    // code omitted ...
    
    stake_pool.check_reserve_stake(reserve_stake_info)?; 
    check_stake_program(stake_program_info.key)?; 
    
    if validator_stake_accounts.len().checked_rem(2).ok_or(StakePoolError::CalculationFailure)? != 0 {
        msg!(""Odd number of validator stake accounts passed in, should be pairs of validator stake and transient stake accounts""); 
        return Err(StakePoolError::UnexpectedValidatorListAccountSize.into()); 
    } 

    check_account_owner(validator_list_info, program_id)?;

    let mut validator_list_data = validator_list_info.data.borrow_mut(); 

    // code omitted ...

    let token_program_info = next_account_info(account_info_iter)?;
    let stake_program_info = next_account_info(account_info_iter)?;
    check_stake_program(stake_program_info.key)?;
}",Medium,"Recommendation: token_program stake_program_info Restrict the used for pool token management to the one deployed by the Solana Foundation, similar to the validation done for other functions such as process_add_validator_to_pool()",https://github.com/solana-labs/solana-program-library/commit/3b48fa09d38d1b66ffb4fef186b606f1bc4fdb31,High
Sol-167,"AddValidatorToPool instruction allows reclaiming reserve by staker (PR 3714) Description In PR 3714, the AddValidatorToPool now creates the new validator stake account by splitting from the reserve. But there is no check that the reserve has more than zero lamports after this happens. The staker of the pool could thus obtain control of the reserve account: 1. ensure that the reserve contains exactly the amount of lamports required to add a new validator (by increasing/decreasing the stake of some active validators from the reserve) 2. in the same transaction, do both of the following: 1. add a new validator, which splits all lamports from the reserve –> reserve is an unitialized stake account after this instruction 2. initialize a new stake account under the control of the staker at the reserve address Impacts property: Safety, since the staker can now manipulate the lamports balance of the reserve and therefore also the pool token price","rust
// Processes `AddValidatorToPool` instruction. 
#[inline(never)] // needed due to stack size violation
fn process_add_validator_to_pool(
    program_id: &Pubkey,
    accounts: &[AccountInfo], 
    raw_validator_seed: u32,
) -> ProgramResult {
    let account_info_iter = &mut accounts.iter(); 

    let stake_pool_info = next_account_info(account_info_iter)?; 
    let staker_info = next_account_info(account_info_iter)?; 
    let reserve_stake_info = next_account_info(account_info_iter)?; 
    let withdraw_authority_info = next_account_info(account_info_iter)?; 
    let validator_list_info = next_account_info(account_info_iter)?; 
    let stake_info = next_account_info(account_info_iter)?; 
    let validator_vote_info = next_account_info(account_info_iter)?; 
    let rent_info = next_account_info(account_info_iter)?;
    
    let rent = &Rent::from_account_info(rent_info)?; 

    let clock_info = next_account_info(account_info_iter)?; 
    let clock = &Clock::from_account_info(clock_info)?; 

    let stake_history_info = next_account_info(account_info_iter)?; 
    let stake_config_info = next_account_info(account_info_iter)?; 

    let system_program_info = next_account_info(account_info_iter)?; 
    let stake_program_info = next_account_info(account_info_iter)?;

    check_system_program(system_program_info.key)?; 
    check_stake_program(stake_program_info.key)?;
    check_account_owner(stake_pool_info, program_id)?;

    let stake_pool = try_from_slice_unchecked::<StakePool>(&stake_pool_info.data.borrow())?;

    if !stake_pool.is_valid() {
        return Err(StakePoolError::InvalidState.into());
    }

    stake_pool.check_authority_withdraw(
        withdraw_authority_info.key,
        program_id,
        stake_pool_info.key,
    )?;
    
    stake_pool.check_staker(staker_info)?;
    stake_pool.check_reserve_stake(reserve_stake_info)?;
    stake_pool.check_validator_list(validator_list_info)?;

    if stake_pool.last_update_epoch < clock.epoch {
        return Err(StakePoolError::StakeListAndPoolOutOfDate.into());
    }

    check_account_owner(validator_list_info, program_id)?;

    let mut validator_list_data = validator_list_info.data.borrow_mut();
    let (header, mut validator_list) = ValidatorListHeader::deserialize_vec(&mut validator_list_data)?;
    
    if !header.is_valid() {
        return Err(StakePoolError::InvalidState.into());
    }
    
    if header.max_validators == validator_list.len() {
        return Err(ProgramError::AccountDataTooSmall);
    }
    
    let maybe_validator_stake_info = validator_list.find::<ValidatorStakeInfo>(
        validator_vote_info.key.as_ref(),
        ValidatorStakeInfo::memcmp_pubkey,
    );
    
    if maybe_validator_stake_info.is_some() {
        return Err(StakePoolError::ValidatorAlreadyAdded.into());
    }
    
    let validator_seed = NonZeroU32::new(raw_validator_seed);

    let (stake_address, bump_seed) = crate::find_stake_program_address(
        program_id,
        validator_vote_info.key,
        stake_pool_info.key,
        validator_seed,
    );

    if stake_address != *stake_info.key {
        return Err(StakePoolError::InvalidStakeAccountAddress.into());
    }
    
    let validator_seed_bytes = validator_seed.map(|s| s.get().to_le_bytes());
    let stake_account_signer_seeds: &[&[_]] = &[
        validator_vote_info.key.as_ref(),
        stake_pool_info.key.as_ref(),
        validator_seed_bytes
            .as_ref()
            .map(|s| s.as_slice())
            .unwrap_or(&[]),
        &[bump_seed],
    ];

    // Fund the stake account with the minimum + rent-exempt balance
    let space = std::mem::size_of::<stake::state::StakeState>();
    let stake_minimum_delegation = stake::tools::get_minimum_delegation()?;
    let required_lamports = minimum_delegation(stake_minimum_delegation)
        .saturating_add(rent.minimum_balance(space));

    // Create new stake account
    create_stake_account(
        stake_info.clone(), 
        stake_account_signer_seeds, 
        system_program_info.clone(),
    )?;

    // split into validator stake account
    Self::stake_split(
        stake_pool_info.key,
        reserve_stake_info.clone(),
        withdraw_authority_info.clone(),
        AUTHORITY_WITHDRAW,
        stake_pool.stake_withdraw_bump_seed,
        required_lamports,
        stake_info.clone(),
    )?;

    Self::stake_delegate(
        stake_info.clone(),
        validator_vote_info.clone(),
        clock_info.clone(),
        stake_history_info.clone(),
        stake_config_info.clone(),
        withdraw_authority_info.clone(),
        stake_pool_info.key,
        AUTHORITY_WITHDRAW,
        stake_pool.stake_withdraw_bump_seed,
    )?;

    validator_list.push(ValidatorStakeInfo {
        status: StakeStatus::Active,
        vote_account_address: *validator_vote_info.key,
        active_stake_lamports: required_lamports,
        transient_stake_lamports: 0,
        last_update_epoch: clock.epoch,
        transient_seed_suffix_start: 0,
        transient_seed_suffix_end: 0,
        validator_seed_suffix: raw_validator_seed,
    })?;

    Ok(())
}","rust
/// Processes `AddValidatorToPool` instruction. 
#[inline(never)] // needed due to stack size violation
fn process_add_validator_to_pool(
    program_id: &Pubkey,
    accounts: &[AccountInfo],
    raw_validator_seed: u32,
) -> ProgramResult {
    let account_info_iter = &mut accounts.iter();
    let stake_pool_info = next_account_info(account_info_iter)?;
    let staker_info = next_account_info(account_info_iter)?;
    let reserve_stake_info = next_account_info(account_info_iter)?;
    let withdraw_authority_info = next_account_info(account_info_iter)?;
    let validator_list_info = next_account_info(account_info_iter)?;
    let stake_info = next_account_info(account_info_iter)?;
    let validator_vote_info = next_account_info(account_info_iter)?;
    let rent_info = next_account_info(account_info_iter)?;
    let rent = &Rent::from_account_info(rent_info)?;
    let clock_info = next_account_info(account_info_iter)?;
    let clock = &Clock::from_account_info(clock_info)?;
    let stake_history_info = next_account_info(account_info_iter)?;
    let stake_config_info = next_account_info(account_info_iter)?;
    let system_program_info = next_account_info(account_info_iter)?;
    let stake_program_info = next_account_info(account_info_iter)?;
    
    check_system_program(system_program_info.key)?;
    check_stake_program(stake_program_info.key)?;
    check_account_owner(stake_pool_info, program_id)?;
    
    let stake_pool = try_from_slice_unchecked::<StakePool>(&stake_pool_info.data.borrow())?;
    
    if !stake_pool.is_valid() {
        return Err(StakePoolError::InvalidState.into());
    }

    // [...] further code goes here, omitted it for the sake of brevity. 
}",Critical,"Fixed by making sure that after splitting the stake for a new validator, the reserve still has more than the minimium reserve lamports.",https://github.com/solana-labs/solana-program-library/pull/3714/commits/db6293a4aefe3feccfbda8a04d3aef5cab22c28a,High
Sol-168,"Recovery of funds by removing validators not always possible (PR 3714) Description Users can withdraw staked lamports from the reserve or a user-chosen validator via the WithdrawStake instruction. When neither the reserve nor any of the validators have active stake beyond the required minimum amount, i.e., rent-exemption plus minimum delegation, the user is allowed to completely unstake and remove a validator to recover the remaining funds. In order for a user to completely remove a validator, they have to 1. first, bring the validator down to the minimum amount of lamports and 2. then, in a second instruction, withdraw the rest. However, this requires the user to withdraw an exact amount of lamports. Note that the user specifies the amount of tokens and not lamports when withdrawing. Depending on the value of the pool tokens, exactly matching the amount of lamports is not always possible, making the user unable to withdraw. A malicious manager can exploit this to prevent users from withdrawing from the pool at all. As an example, assume that • one token is worth two lamports, • the reserve is empty, i.e. it is at the rent-exemption minimum, • the minimum amount of lamports for a validator’s stake account is 1,000,000 lamports, • all validators have 1,000,001 lamports in their stake accounts. At this point, a user is unable to withdraw. None of the validators are at the minimum amount of lamports, so removing them is impossible. However, to reduce them to the minimum amount, a user would have to withdraw one lamport, which is also impossible because even a single token is worth two lamports. Impacts property: Safety, because users are unable to withdraw funds at all.","rust
let withdraw_lamports = stake_pool
    .calc_lamports_withdraw_amount(pool_tokens_burnt)
    .ok_or(StakePoolError::CalculationFailure)?;

@@ -2442,17 +2436,27 @@
impl Processor {
    let meta = stake_state.meta().ok_or(StakePoolError::WrongStakeState)?;
    let required_lamports = minimum_stake_lamports(&meta, stake_minimum_delegation);

    let has_active_stake = validator_list
        .find::<ValidatorStakeInfo>(
            &required_lamports.to_le_bytes(),
            ValidatorStakeInfo::active_lamports_not_equal,
        )
        .is_some();

    let has_transient_stake = validator_list
        .find::<ValidatorStakeInfo>(
            &0u64.to_le_bytes(),
            ValidatorStakeInfo::transient_lamports_not_equal,
        )
        .is_some();

    let validator_list_item_info = if *stake_split_from.key == stake_pool.reserve_stake {
        if has_transient_stake || has_active_stake {
            msg!(""Error withdrawing from reserve: validator stake accounts have lamports available, please use those first."");
            return Err(StakePoolError::StakeLamportsNotEqualToMinimum.into());
        }
        stake_split_from
            .lamports()
            .checked_sub(minimum_reserve_lamports(&meta))
            .ok_or(StakePoolError::StakeLamportsNotEqualToMinimum)?;

        None
    } else {
        let delegation = stake_state.delegation().ok_or(StakePoolError::WrongStakeState)?;
        let vote_account_address = delegation.voter_pubkey;

        if let Some(preferred_withdraw_validator) = stake_pool.preferred_withdraw_validator_vote_address {
            let preferred_validator_info = validator_list
                .find::<ValidatorStakeInfo>(
                    preferred_withdraw_validator.as_ref(),
                    ValidatorStakeInfo::memcmp_pubkey,
                )
                .ok_or(StakePoolError::ValidatorNotFound)?;

            let available_lamports = preferred_validator_info
                .active_stake_lamports
                .saturating_sub(required_lamports);

            if preferred_withdraw_validator != vote_account_address && available_lamports > 0 {
                msg!(""Validator vote address {} is preferred for withdrawals, it currently has {} lamports available. Please withdraw those before using other validator stake accounts."", preferred_withdraw_validator, preferred_validator_info.active_stake_lamports);
                return Err(StakePoolError::IncorrectWithdrawVoteAddress.into());
            }
        }
    }
}","rust
let mut withdraw_lamports = stake_pool.calc_lamports_withdraw_amount(pool_tokens_burnt)
    .ok_or(StakePoolError::CalculationFailure)?;

@@ -2442,17 +2436,27 @@ impl Processor {

let meta = stake_state.meta().ok_or(StakePoolError::WrongStakeState)?;

let required_lamports = minimum_stake_lamports(&meta, stake_minimum_delegation);

let lamports_per_pool_token = stake_pool.get_lamports_per_pool_token()
    .ok_or(StakePoolError::CalculationFailure)?;

let minimum_lamports_with_tolerance = required_lamports.saturating_add(lamports_per_pool_token);

let has_active_stake = validator_list.find::<ValidatorStakeInfo, _>(|x| {
    ValidatorStakeInfo::active_lamports_greater_than(
        x,
        &minimum_lamports_with_tolerance,
    )
})
.is_some();

let has_transient_stake = validator_list.find::<ValidatorStakeInfo, _>(|x| {
    ValidatorStakeInfo::transient_lamports_greater_than(
        x,
        &minimum_lamports_with_tolerance,
    )
})
.is_some();

let validator_list_item_info = if *stake_split_from.key == stake_pool.reserve_stake {
    // check that the validator stake accounts have no withdrawable stake
    if has_transient_stake || has_active_stake {
        msg!(""Error withdrawing from reserve: validator stake accounts have lamports available, please use those first."");
        return Err(StakePoolError::StakeLamportsNotEqualToMinimum.into());
    }
    
    // check that reserve has enough (should never fail, but who knows?)
    stake_split_from.lamports()
        .checked_sub(minimum_reserve_lamports(&meta))
        .ok_or(StakePoolError::StakeLamportsNotEqualToMinimum)?;

    None
} else {
    let delegation = stake_state.delegation()
        .ok_or(StakePoolError::WrongStakeState)?;

    let vote_account_address = delegation.voter_pubkey;

    if let Some(preferred_withdraw_validator) = stake_pool.preferred_withdraw_validator_vote_address {
        let preferred_validator_info = validator_list.find::<ValidatorStakeInfo, _>(|x| {
            ValidatorStakeInfo::memcmp_pubkey(x, &preferred_withdraw_validator)
        })
        .ok_or(StakePoolError::ValidatorNotFound)?;

        let available_lamports = preferred_validator_info.active_stake_lamports
            .saturating_sub(minimum_lamports_with_tolerance);

        if preferred_withdraw_validator != vote_account_address && available_lamports > 0 {
            msg!(""Validator vote address {} is preferred for withdrawals, it currently has {} lamports available. Please withdraw those before using other validator stake accounts."", preferred_withdraw_validator, preferred_validator_info.active_stake_lamports);
            return Err(StakePoolError::IncorrectWithdrawVoteAddress.into());
        }
    }
}",High,Fixed by adding a small tolerance when withdrawing from validators: A validator can be completely removed if it either has the minimum amount of lamports or has less than one token worth of additional lamports beyond the minimum.,https://github.com/solana-labs/solana-program-library/pull/3839/files#diff-6b2b2ff0d36e80df29c5d299e325622b645a449f82fb42a13c1b9b4d90d64215,High
Sol-169,"Withdrawing stake from the pool requires a transfer of fees to the manager. If this transfer fails, the withdraw also fails. The pool needs to ensure that it is impossible for the transfer to fail, or users may be unable to withdraw their stake. In the previous version of SPL token, the only way for the transfer to fail was if the destination account does not exist or has the wrong mint. However, PR 3714 adds support for SPL token 2022 as the fee account, which is much more complex and supports various extensions with different failure modes. Impacts property: Safety, because users may be unable to withdraw.","rust
/// Check if the manager fee info is a valid token program account
/// capable of receiving tokens from the mint. 
pub(crate) fn check_manager_fee_info(
    &self, 
    manager_fee_info: &AccountInfo, 
) -> Result<(), ProgramError> {
    let account_data = manager_fee_info.try_borrow_data()?;
    let token_account = StateWithExtensions::<Account>::unpack(&account_data)?;
    if manager_fee_info.owner != &self.token_program_id 
        || token_account.base.state != AccountState::Initialized 
        || token_account.base.mint != self.pool_mint {
            msg!(""Manager fee account is not owned by token program, is not initialized, or does not match stake pool's mint"");
            return Err(StakePoolError::InvalidFeeAccount.into());
        }
    Ok(())
}","rust
/// Check if the manager fee info is a valid token program account 
/// capable of receiving tokens from the mint. 
pub(crate) fn check_manager_fee_info( 
    &self, 
    manager_fee_info: &AccountInfo,
) -> Result<(), ProgramError> { 

    let account_data = manager_fee_info.try_borrow_data()?; 
    let token_account = StateWithExtensions::<Account>::unpack(&account_data)?;

    if manager_fee_info.owner != &self.token_program_id || 
       token_account.base.state != AccountState::Initialized ||
       token_account.base.mint != self.pool_mint 
    { 
        msg!(""Manager fee account is not owned by token program, is not initialized, or does not match stake pool's mint""); 
        return Err(StakePoolError::InvalidFeeAccount.into());
    } 

    let extensions = token_account.get_extension_types()?;

    if extensions 
       .iter() 
       .any(|x| !is_extension_supported_for_fee_account(x))
    { 
        return Err(StakePoolError::UnsupportedFeeAccountExtension.into());
    } 

    Ok(())
} 

pub fn is_extension_supported_for_mint(extension_type: &ExtensionType) -> bool { 

    const SUPPORTED_EXTENSIONS: [ExtensionType; 5] = [ 
        ExtensionType::Uninitialized, 
        ExtensionType::TransferFeeConfig, 
        ExtensionType::ConfidentialTransferMint, 
        ExtensionType::DefaultAccountState, 
        ExtensionType::InterestBearingConfig,
    ]; 

    if !SUPPORTED_EXTENSIONS.contains(extension_type) { 
        msg!(""Stake pool mint account cannot have the {:?} extension"", extension_type);
        false 
    } else { 
        true 
    } 
} 

/// Checks if the given extension is supported for the stake pool's fee account 
pub fn is_extension_supported_for_fee_account(extension_type: &ExtensionType) -> bool { 

    const SUPPORTED_EXTENSIONS: [ExtensionType; 4] = [ 
        ExtensionType::Uninitialized, 
        ExtensionType::TransferFeeAmount, 
        ExtensionType::ImmutableOwner, 
        ExtensionType::CpiGuard,
    ]; 

    if !SUPPORTED_EXTENSIONS.contains(extension_type) { 
        msg!(""Fee account cannot have the {:?} extension"", extension_type); 
        false 
    } else { 
        true 
    } 
}",High,"Fixed by adding a whitelist for extensions on both the mint of the pool token and the manager fee token account. If the manager fee account has any extension not in the whitelist, the fee transfer is skipped.",https://github.com/solana-labs/solana-program-library/pull/3714/commits/9c8a2307dea9107e8ed5e3877cb5818b1520c171,High
Sol-170,"When withdrawing tokens from a pool the value in lamports of the tokens is calculated as ceil( tokens * lamports_per_token). Because this rounds up to the next whole lamports amount, the value can be greater than the amount of lamports that were deposited to obtain the tokens. As an example, assume the stake pool is in a state where each token is worth 1.1 lamports. Consider the following actions: • deposit 3 lamports -> get floor(3 / 1.1) = 2 pool tokens • withdraw 1 pool token -> get ceil(1.1) = 2 lamports • withdraw 1 pool token again -> get ceil(1.1) = 2 lamports So in total, 4 lamports received for 3 lamports deposited. The impact of this issue is limited because of transaction costs on Solana and the low amount that can be stolen per transaction. With each withdraw, the gain is at most 1 lamport. However, a single transaction costs at least 5000 lamports. By including the transaction in a block produced by an attacker-controlled validator, 2500 lamports of the fee can be recovered. To exploit this profitably it would be necessary to perform more than 2500 withdraws in a single transaction. This however is much more than the compute limit currently allows. Impacts property: Safety, because stealing from the pool lowers the lamports per token so users may not be able to receive the deposited funds back in full.","rust
/// calculate lamports amount on withdrawal
#[inline]
pub fn calc_lamports_withdraw_amount(&self, pool_tokens: u64) -> Option<u64> {
    // `checked_ceil_div` returns `None` for a 0 quotient result, 
    // but in this case, a return of 0 is valid for small amounts of pool tokens. 
    // So we check for that separately
    let numerator = (pool_tokens as u128).checked_mul(self.total_lamports as u128)?;

    let denominator = self.pool_token_supply as u128;

    if numerator < denominator || denominator == 0 {
        Some(0)
    } else {
        let (quotient, _) = numerator.checked_ceil_div(denominator)?;
        u64::try_from(quotient).ok()
    }
}","rust
#[inline]
pub fn calc_lamports_withdraw_amount(&self, pool_tokens: u64) -> Option<u64> {
    // `checked_div` returns `None` for a 0 quotient result, but in this
    // case, a return of 0 is valid for small amounts of pool tokens. So
    // we check for that separately
    let numerator = (pool_tokens as u128).checked_mul(self.total_lamports as u128)?;
   
    let denominator = self.pool_token_supply as u128;
   
    if numerator < denominator || denominator == 0 {
        Some(0)
    } else {
        u64::try_from(numerator.checked_div(denominator)?).ok()
    }
}",Medium,Fixed by truncating on withdraw instead of rounding up.,https://github.com/solana-labs/solana-program-library/pull/3804/files,High
Sol-171,"Front-Run Deposits To Steal Pool Tokens Description There is no delay mechanism on updating deposit fees and an upper bound of 100%. A user that submits a large deposit could be front-run by a pool manager who sets the fee close to 100% (ensuring that user still receives 1 pool token), receives almost the full value of the deposit, and then reduces the fee afterward.","rust
/// Creates instructions required to deposit into a stake pool, given a stake
/// account owned by the user. 
pub fn deposit_stake(
    program_id: &Pubkey,
    stake_pool: &Pubkey,
    validator_list_storage: &Pubkey,
    stake_pool_withdraw_authority: &Pubkey,
    deposit_stake_address: &Pubkey,
    deposit_stake_withdraw_authority: &Pubkey,
    referrer_pool_tokens_account: &Pubkey,
    pool_mint: &Pubkey,
    token_program_id: &Pubkey,
) -> Vec<Instruction> {

    let stake_pool_deposit_authority = find_deposit_authority_program_address(program_id, stake_pool).0;
    
    let accounts = vec![
        AccountMeta::new(*stake_pool, false),
        AccountMeta::new(*validator_list_storage, false),
        AccountMeta::new_readonly(stake_pool_deposit_authority, false),
        AccountMeta::new_readonly(*stake_pool_withdraw_authority, false),
        AccountMeta::new(*deposit_stake_address, false),
        AccountMeta::new_readonly(sysvar::stake_history::id(), false),
        AccountMeta::new_readonly(*token_program_id, false),
        AccountMeta::new_readonly(stake::program::id(), false),
    ];
      
    vec![
        stake::instruction::authorize(
            deposit_stake_address,
            deposit_stake_withdraw_authority,
            &stake_pool_deposit_authority,
            stake::state::StakeAuthorize::Staker,
            None,
        ),
        stake::instruction::authorize(
            deposit_stake_address,
            deposit_stake_withdraw_authority,
            &stake_pool_deposit_authority,
            stake::state::StakeAuthorize::Withdrawer,
            None,
        ),
        Instruction {
            program_id: *program_id,
            accounts,
            data: StakePoolInstruction::DepositStake.try_to_vec().unwrap(),
       }
    ]
}","fn deposit_stake_internal(
    program_id: &Pubkey,
    stake_pool: &Pubkey,
    validator_list_storage: &Pubkey,
    stake_pool_deposit_authority: Option<&Pubkey>,
    stake_pool_withdraw_authority: &Pubkey,
    deposit_stake_address: &Pubkey,
    deposit_stake_withdraw_authority: &Pubkey,
    validator_stake_account: &Pubkey,
    reserve_stake_account: &Pubkey,
    pool_tokens_to: &Pubkey,
    manager_fee_account: &Pubkey,
    referrer_pool_tokens_account: &Pubkey,
    pool_mint: &Pubkey,
    token_program_id: &Pubkey,
    minimum_pool_tokens_out: Option<u64>,
) -> Vec<Instruction> {
    let mut instructions = vec![];
    let mut accounts = vec![
        AccountMeta::new(*stake_pool, false),
        AccountMeta::new(*validator_list_storage, false),
    ];

    if let Some(stake_pool_deposit_authority) = stake_pool_deposit_authority {
        accounts.push(AccountMeta::new_readonly(
            *stake_pool_deposit_authority,
            true,
        ));
        instructions.extend_from_slice(&[
            stake::instruction::authorize(
                deposit_stake_address,
                deposit_stake_withdraw_authority,
                stake_pool_deposit_authority,
                stake::state::StakeAuthorize::Staker,
                None,
            ),
            stake::instruction::authorize(
                deposit_stake_address,
                deposit_stake_withdraw_authority,
                stake_pool_deposit_authority,
                stake::state::StakeAuthorize::Withdrawer,
                None,
            ),
        ]);
    } else {
        let stake_pool_deposit_authority = find_deposit_authority_program_address(program_id, stake_pool).0;
        accounts.push(AccountMeta::new_readonly(
            stake_pool_deposit_authority,
            false,
        ));
        instructions.extend_from_slice(&[
            stake::instruction::authorize(
                deposit_stake_address,
                deposit_stake_withdraw_authority,
                &stake_pool_deposit_authority,
                stake::state::StakeAuthorize::Staker,
                None,
            ),
            stake::instruction::authorize(
                deposit_stake_address,
                deposit_stake_withdraw_authority,
                &stake_pool_deposit_authority,
                stake::state::StakeAuthorize::Withdrawer,
                None,
            ),
        ]);
    };

    accounts.extend_from_slice(&[
        AccountMeta::new_readonly(*stake_pool_withdraw_authority, false),
        AccountMeta::new(*deposit_stake_address, false),
        AccountMeta::new(*validator_stake_account, false),
        AccountMeta::new(*reserve_stake_account, false),
        AccountMeta::new(*pool_tokens_to, false),
        AccountMeta::new(*manager_fee_account, false),
        AccountMeta::new(*referrer_pool_tokens_account, false),
        AccountMeta::new(*pool_mint, false),
        AccountMeta::new_readonly(sysvar::clock::id(), false),
        AccountMeta::new_readonly(sysvar::stake_history::id(), false),
        AccountMeta::new_readonly(*token_program_id, false),
        AccountMeta::new_readonly(stake::program::id(), false),
    ]);

    instructions.push(
        if let Some(minimum_pool_tokens_out) = minimum_pool_tokens_out {
            Instruction {
                program_id: *program_id,
                accounts,
                data: StakePoolInstruction::DepositStakeWithSlippage {
                    minimum_pool_tokens_out,
                }
                .try_to_vec()
                .unwrap(),
            }
        } else {
            Instruction {
                program_id: *program_id,
                accounts,
                data: StakePoolInstruction::DepositStake
                    .try_to_vec()
                    .unwrap(),
            }
        },
    );

    instructions
}

/// Creates instructions required to deposit into a stake pool, given a stake
/// account owned by the user.
pub fn deposit_stake(
    program_id: &Pubkey,
    stake_pool: &Pubkey,
    validator_list_storage: &Pubkey,
    stake_pool_withdraw_authority: &Pubkey,
    deposit_stake_address: &Pubkey,
    deposit_stake_withdraw_authority: &Pubkey,
    validator_stake_account: &Pubkey,
    reserve_stake_account: &Pubkey,
    pool_tokens_to: &Pubkey,
    manager_fee_account: &Pubkey,
    referrer_pool_tokens_account: &Pubkey,
    pool_mint: &Pubkey,
    token_program_id: &Pubkey,
) -> Vec<Instruction> {
    deposit_stake_internal(
        program_id,
        stake_pool,
        validator_list_storage,
        None,
        stake_pool_withdraw_authority,
        deposit_stake_address,
        deposit_stake_withdraw_authority,
        validator_stake_account,
        reserve_stake_account,
        pool_tokens_to,
        manager_fee_account,
        referrer_pool_tokens_account,
        pool_mint,
        token_program_id,
        None,
    )
}

/// Creates instructions to deposit into a stake pool with slippage
pub fn deposit_stake_with_slippage(
    program_id: &Pubkey,
    stake_pool: &Pubkey,
    validator_list_storage: &Pubkey,
    stake_pool_withdraw_authority: &Pubkey,
    deposit_stake_address: &Pubkey,
    deposit_stake_withdraw_authority: &Pubkey,
    validator_stake_account: &Pubkey,
    reserve_stake_account: &Pubkey,
    pool_tokens_to: &Pubkey,
    manager_fee_account: &Pubkey,
    referrer_pool_tokens_account: &Pubkey,
    pool_mint: &Pubkey,
    token_program_id: &Pubkey,
    minimum_pool_tokens_out: u64,
) -> Vec<Instruction> {
    deposit_stake_internal(
        program_id,
        stake_pool,
        validator_list_storage,
        None,
        stake_pool_withdraw_authority,
        deposit_stake_address,
        deposit_stake_withdraw_authority,
        validator_stake_account,
        reserve_stake_account,
        pool_tokens_to,
        manager_fee_account,
        referrer_pool_tokens_account,
        pool_mint,
        token_program_id,
        Some(minimum_pool_tokens_out),
    )
}

/// Creates instructions required to deposit into a stake pool, given a stake
pub fn deposit_stake_with_authority(
    program_id: &Pubkey,
    stake_pool: &Pubkey,
    validator_list_storage: &Pubkey,
    stake_pool_deposit_authority: &Pubkey,
    stake_pool_withdraw_authority: &Pubkey,
    deposit_stake_address: &Pubkey,
    deposit_stake_withdraw_authority: &Pubkey,
    validator_stake_account: &Pubkey,
    reserve_stake_account: &Pubkey,
    pool_tokens_to: &Pubkey,
    manager_fee_account: &Pubkey,
    referrer_pool_tokens_account: &Pubkey,
    pool_mint: &Pubkey,
    token_program_id: &Pubkey,
) -> Vec<Instruction> {
    deposit_stake_internal(
        program_id,
        stake_pool,
        validator_list_storage,
        Some(stake_pool_deposit_authority),
        stake_pool_withdraw_authority,
        deposit_stake_address,
        deposit_stake_withdraw_authority,
        validator_stake_account,
        reserve_stake_account,
        pool_tokens_to,
        manager_fee_account,
        referrer_pool_tokens_account,
        pool_mint,
        token_program_id,
        None,
    )
}

/// Creates instructions required to deposit into a stake pool with slippage, given
/// a stake account owned by the user. The difference with `deposit()` is that a deposit
/// authority must sign this instruction, which is required for private pools.
pub fn deposit_stake_with_authority_and_slippage(
    program_id: &Pubkey,
    stake_pool: &Pubkey,
    validator_list_storage: &Pubkey,
    stake_pool_deposit_authority: &Pubkey,
    stake_pool_withdraw_authority: &Pubkey,
    deposit_stake_address: &Pubkey,
    deposit_stake_withdraw_authority: &Pubkey,
    validator_stake_account: &Pubkey,
    reserve_stake_account: &Pubkey,
    pool_tokens_to: &Pubkey,
    manager_fee_account: &Pubkey,
    referrer_pool_tokens_account: &Pubkey,
    pool_mint: &Pubkey,
    token_program_id: &Pubkey,
    minimum_pool_tokens_out: u64,
) -> Vec<Instruction> {
    deposit_stake_internal(
        program_id,
        stake_pool,
        validator_list_storage,
        Some(stake_pool_deposit_authority),
        stake_pool_withdraw_authority,
        deposit_stake_address,
        deposit_stake_withdraw_authority,
        validator_stake_account,
        reserve_stake_account,
        pool_tokens_to,
        manager_fee_account,
        referrer_pool_tokens_account,
        pool_mint,
        token_program_id,
        Some(minimum_pool_tokens_out),
    )
}

/// Creates instructions required to deposit SOL directly into a stake pool.
fn deposit_sol_internal(
    program_id: &Pubkey,
    stake_pool: &Pubkey,
    stake_pool_withdraw_authority: &Pubkey,
    reserve_stake_account: &Pubkey,
    lamports_from: &Pubkey,
    pool_tokens_to: &Pubkey,
    manager_fee_account: &Pubkey,
    referrer_pool_tokens_account: &Pubkey,
    pool_mint: &Pubkey,
    token_program_id: &Pubkey,
    sol_deposit_authority: Option<&Pubkey>,
    lamports_in: u64,
    minimum_pool_tokens_out: Option<u64>,
) -> Instruction {
    let mut accounts = vec![
        AccountMeta::new(*stake_pool, false),
        AccountMeta::new_readonly(*stake_pool_withdraw_authority, false),
        AccountMeta::new(*reserve_stake_account, false),
        AccountMeta::new(*lamports_from, false),
        AccountMeta::new(*pool_tokens_to, false),
        AccountMeta::new(*manager_fee_account, false),
        AccountMeta::new(*referrer_pool_tokens_account, false),
        AccountMeta::new(*pool_mint, false),
        AccountMeta::new_readonly(system_program::id(), false),
        AccountMeta::new_readonly(*token_program_id, false),
    ];

    if let Some(sol_deposit_authority) = sol_deposit_authority {
        accounts.push(AccountMeta::new_readonly(*sol_deposit_authority, true));
    }

    if let Some(minimum_pool_tokens_out) = minimum_pool_tokens_out {
        Instruction {
            program_id: *program_id,
            accounts,
            data: StakePoolInstruction::DepositSolWithSlippage {
                lamports_in,
                minimum_pool_tokens_out,
            }
            .try_to_vec()
            .unwrap(),
        }
    } else {
        Instruction {
            program_id: *program_id,
            accounts,
            data: StakePoolInstruction::DepositSol(lamports_in)
                .try_to_vec()
                .unwrap(),
        }
    }
}

/// Creates instruction to deposit SOL directly into a stake pool.
pub fn deposit_sol(
    program_id: &Pubkey,
    stake_pool: &Pubkey,
    stake_pool_withdraw_authority: &Pubkey,
    reserve_stake_account: &Pubkey,
    lamports_from: &Pubkey,
    pool_tokens_to: &Pubkey,
    manager_fee_account: &Pubkey,
    referrer_pool_tokens_account: &Pubkey,
    pool_mint: &Pubkey,
    token_program_id: &Pubkey,
    lamports_in: u64,
) -> Instruction {
    deposit_sol_internal(
        program_id,
        stake_pool,
        stake_pool_withdraw_authority,
        reserve_stake_account,
        lamports_from,
        pool_tokens_to,
        manager_fee_account,
        referrer_pool_tokens_account,
        pool_mint,
        token_program_id,
        None,
        lamports_in,
        None,
    )
}

/// Creates instruction to deposit SOL directly into a stake pool with slippage constraint.
pub fn deposit_sol_with_slippage(
    program_id: &Pubkey,
    stake_pool: &Pubkey,
    stake_pool_withdraw_authority: &Pubkey,
    reserve_stake_account: &Pubkey,
    lamports_from: &Pubkey,
    pool_tokens_to: &Pubkey,
    manager_fee_account: &Pubkey,
    referrer_pool_tokens_account: &Pubkey,
    pool_mint: &Pubkey,
    token_program_id: &Pubkey,
    lamports_in: u64,
    minimum_pool_tokens_out: u64,
) -> Instruction {
    deposit_sol_internal(
        program_id,
        stake_pool,
        stake_pool_withdraw_authority,
        reserve_stake_account,
        lamports_from,
        pool_tokens_to,
        manager_fee_account,
        referrer_pool_tokens_account,
        pool_mint,
        token_program_id,
        None,
        lamports_in,
        Some(minimum_pool_tokens_out),
    )
}",High,"Add instructions that allow the user to specify the minimum amount of tokens they expect to receive. In order to protect against manager fee hikes, a user can use the following instructions and specify a slippage parameter. If the subsequent fee deduction reduces the received amount below this value, the instruction will abort: 1. DepositStakeWithSlippage 2. WithdrawStakeWithSlippage 3. DepositSolWithSlippage 4. WithdrawSolWithSlippage","https://github.com/solana-labs/solana-program-library/pull/3980/files, https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/f5079737-734d-4b73-88a5-4c00eb20015d/Solana_Stake_Pool_audit_final.pdf?table=block&id=353af6fc-8c19-4e59-aefc-3aebc813b926&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743307200000&signature=ga0AQbGGoM7PDHTRtRK5aEOAatzTupp7GT5nQAkWS80&downloadName=Solana+Stake+Pool+Audit+Report.pdf",High
Sol-172,"Front-Run Deposits To Steal Pool Tokens Description There is no delay mechanism on updating deposit fees and an upper bound of 100%. A user that submits a large deposit could be front-run by a pool manager who sets the fee close to 100% (ensuring that user still receives 1 pool token), receives almost the full value of the deposit, and then reduces the fee afterward.","rust
pub fn withdraw_stake(
    program_id: &Pubkey,
    stake_pool: &Pubkey,
    validator_list_storage: &Pubkey,
    // @@ -1480,7 +1822,8 @@ pub fn withdraw_stake(
    manager_fee_account: &Pubkey, 
    pool_mint: &Pubkey, 
    token_program_id: &Pubkey, 
    amount: u64,
) -> Instruction {
    let accounts = vec![
        AccountMeta::new(*stake_pool, false),
        // @@ -1497,17 +1840,98 @@ pub fn withdraw_stake(
        AccountMeta::new_readonly(*token_program_id, false),
        AccountMeta::new_readonly(stake::program::id(), false),
    ];
    Instruction {
        program_id: *program_id, 
        accounts, 
        data: StakePoolInstruction::WithdrawStake(amount)
            .try_to_vec()
            .unwrap(),
    }
}

/// Creates instruction required to withdraw SOL directly from a stake pool.
pub fn withdraw_sol(
    program_id: &Pubkey,
    stake_pool: &Pubkey,
    stake_pool_withdraw_authority: &Pubkey,
    // @@ -1518,9 +1942,11 @@ pub fn withdraw_sol(
    manager_fee_account: &Pubkey, 
    pool_mint: &Pubkey, 
    token_program_id: &Pubkey, 
    pool_tokens: u64,
) -> Instruction {
    let accounts = vec![
        AccountMeta::new(*stake_pool, false),
        AccountMeta::new_readonly(*stake_pool_withdraw_authority, false),
        AccountMeta::new_readonly(*user_transfer_authority, true),
        // @@ -1534,15 +1960,95 @@ pub fn withdraw_sol(
        AccountMeta::new_readonly(stake::program::id(), false),
        AccountMeta::new_readonly(*token_program_id, false),
    ];
    Instruction {
        program_id: *program_id, 
        accounts, 
        data: StakePoolInstruction::WithdrawSol(pool_tokens)
            .try_to_vec()
            .unwrap(),
    }
}","rust
fn withdraw_stake_internal( 
    program_id: &Pubkey, 
    stake_pool: &Pubkey, 
    validator_list_storage: &Pubkey, 
    manager_fee_account: &Pubkey, 
    pool_mint: &Pubkey, 
    token_program_id: &Pubkey, 
    pool_tokens_in: u64, 
    minimum_lamports_out: Option<u64>, 
) -> Instruction { 
    let accounts = vec![
        AccountMeta::new(*stake_pool, false), 
        AccountMeta::new_readonly(*token_program_id, false), 
        AccountMeta::new_readonly(stake::program::id(), false), 
    ]; 
    if let Some(minimum_lamports_out) = minimum_lamports_out { 
        Instruction { 
            program_id: *program_id, 
            accounts, 
            data: StakePoolInstruction::WithdrawStakeWithSlippage { 
                pool_tokens_in, 
                minimum_lamports_out, 
            } 
            .try_to_vec() 
            .unwrap(), 
        } 
    } else { 
        Instruction { 
            program_id: *program_id, 
            accounts, 
            data: StakePoolInstruction::WithdrawStake(pool_tokens_in) 
            .try_to_vec() 
            .unwrap(), 
        } 
    } 
} 

/// Creates a 'WithdrawStake' instruction. 
pub fn withdraw_stake( 
    program_id: &Pubkey, 
    stake_pool: &Pubkey, 
    validator_list_storage: &Pubkey, 
    stake_pool_withdraw: &Pubkey, 
    stake_to_split: &Pubkey, 
    stake_to_receive: &Pubkey, 
    user_stake_authority: &Pubkey, 
    user_transfer_authority: &Pubkey, 
    user_pool_token_account: &Pubkey, 
    manager_fee_account: &Pubkey, 
    pool_mint: &Pubkey, 
    token_program_id: &Pubkey, 
    pool_tokens_in: u64, 
) -> Instruction { 
    withdraw_stake_internal( 
        program_id, 
        stake_pool, 
        validator_list_storage, 
        stake_pool_withdraw, 
        stake_to_split, 
        stake_to_receive, 
        user_stake_authority, 
        user_transfer_authority, 
        user_pool_token_account, 
        manager_fee_account, 
        pool_mint, 
        token_program_id, 
        pool_tokens_in, 
        None, 
    ) 
} 

/// Creates a 'WithdrawStakeWithSlippage' instruction. 
pub fn withdraw_stake_with_slippage( 
    program_id: &Pubkey, 
    stake_pool: &Pubkey, 
    validator_list_storage: &Pubkey, 
    stake_pool_withdraw: &Pubkey, 
    stake_to_split: &Pubkey, 
    stake_to_receive: &Pubkey, 
    user_stake_authority: &Pubkey, 
    user_transfer_authority: &Pubkey, 
    user_pool_token_account: &Pubkey, 
    manager_fee_account: &Pubkey, 
    pool_mint: &Pubkey, 
    token_program_id: &Pubkey, 
    pool_tokens_in: u64, 
    minimum_lamports_out: u64, 
) -> Instruction { 
    withdraw_stake_internal( 
        program_id, 
        stake_pool, 
        validator_list_storage, 
        stake_pool_withdraw, 
        stake_to_split, 
        stake_to_receive, 
        user_stake_authority, 
        user_transfer_authority, 
        user_pool_token_account, 
        manager_fee_account, 
        pool_mint, 
        token_program_id, 
        pool_tokens_in, 
        Some(minimum_lamports_out), 
    ) 
}",High,"Add instructions that allow the user to specify the minimum amount of tokens they expect to receive. In order to protect against manager fee hikes, a user can use the following instructions and specify a slippage parameter. If the subsequent fee deduction reduces the received amount below this value, the instruction will abort: 1. DepositStakeWithSlippage 2. WithdrawStakeWithSlippage 3. DepositSolWithSlippage 4. WithdrawSolWithSlippage","https://github.com/solana-labs/solana-program-library/pull/3980/files, https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/f5079737-734d-4b73-88a5-4c00eb20015d/Solana_Stake_Pool_audit_final.pdf?table=block&id=353af6fc-8c19-4e59-aefc-3aebc813b926&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743307200000&signature=ga0AQbGGoM7PDHTRtRK5aEOAatzTupp7GT5nQAkWS80&downloadName=Solana+Stake+Pool+Audit+Report.pdf",High
Sol-173,"Fee Update Delay Bypass Description Certain fees (StakeWithdrawal, SolWithdrawal, Epoch) can only be updated in the next epoch. In the current implementation, the manager can update the fee at the end of the current epoch and then immediately apply the fee at the start of the next epoch. For example, a pool manager could use this technique to instantaneously apply a withdrawal fee of 0.1% (the baseline fee).","rust
if fee.can_only_change_next_epoch() && stake_pool.last_update_epoch < clock.epoch {
    return Err(StakePoolError::StakeListAndPoolOutOfDate.into());
}","/// Wrapper type that ""counts down"" epochs, which is Borsh-compatible with the
/// native `Option`
#[repr(C)]
#[derive(Clone, Copy, Debug, PartialEq, BorshSerialize, BorshDeserialize, BorshSchema)]
pub enum FutureEpoch<T> {
    /// Nothing is set
    None,
    /// Value is ready after the next epoch boundary
    One(T),
    /// Value is ready after two epoch boundaries
    Two(T),
}

impl<T> Default for FutureEpoch<T> {
    fn default() -> Self {
        Self::None
    }
}

impl<T> FutureEpoch<T> {
    /// Create a new value to be unlocked in a two epochs
    pub fn new(value: T) -> Self {
        Self::Two(value)
    }
}

impl<T: Clone> FutureEpoch<T> {
    /// Update the epoch, to be done after `get`ting the underlying value
    pub fn update_epoch(&mut self) {
        match self {
            Self::None => {},
            Self::One(_) => {
                // The value has waited its last epoch
                *self = Self::None;
            }
            // The value still has to wait one more epoch after this
            Self::Two(v) => {
                *self = Self::One(v.clone());
            }
        }
    }

    /// Get the value if it's ready, which is only at `One` epoch remaining
    pub fn get(&self) -> Option<&T> {
        match self {
            Self::None | Self::Two(_) => None,
            Self::One(v) => Some(v),
        }
    }
}

impl<T> From<FutureEpoch<T>> for Option<T> {
    fn from(v: FutureEpoch<T>) -> Option<T> {
        match v {
            FutureEpoch::None => None,
            FutureEpoch::One(inner) | FutureEpoch::Two(inner) => Some(inner),
        }
    }
}",Medium,"To give users sufficient time to adapt to changing fees, it would likely make sense to ensure the proposed fee is blocked for at least one full epoch.","https://github.com/solana-labs/solana-program-library/pull/3979/files#diff-0d164bba80f160b0f3813ac32c2709f64e62b196cdc2eee8bd54422f73da1e4a, https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/f5079737-734d-4b73-88a5-4c00eb20015d/Solana_Stake_Pool_audit_final.pdf?table=block&id=353af6fc-8c19-4e59-aefc-3aebc813b926&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743307200000&signature=ga0AQbGGoM7PDHTRtRK5aEOAatzTupp7GT5nQAkWS80&downloadName=Solana+Stake+Pool+Audit+Report.pdf",High
Sol-174,"Inaccurate In-Memory Balance Updates. transfer and withdraw in code-vm are vulnerable to incorrect accounting when the source and destination accounts are the same. In scenarios where the source account and the destination account are identical, the program logic may process both operations in memory without distinguishing between the two. This creates a situation where only the final ”greater” destination value (after adding funds) is written back to storage, without accurately subtracting the funds first.","rust
/*
Instruction data:
0. signature: [u8;64] - The opcode to execute.
1. amount: [u64] - The account_indicies of the virtual accounts to use.
*/

pub fn process_transfer(ctx: &ExecContext, data: &ExecIxData) -> ProgramResult {
    let vm = load_vm(ctx.vm_info)?;
    let args = TransferOp::try_from_bytes(&data.data)?.to_struct()?;
    let mem_indicies = &data.mem_indicies;
    let mem_banks = &data.mem_banks;

    check_condition(
        mem_indicies.len() == 3, 
        ""the number of memory indicies must be 3"",
    )?;

    check_condition(
        mem_banks.len() == 3, 
        ""the number of memory banks must be 3"",
    )?;

    let nonce_index = mem_indicies[0];
    let nonce_mem = mem_banks[0];
    let src_index = mem_indicies[1];
    let src_mem = mem_banks[1];
    let dst_index = mem_indicies[2];
    let dst_mem = mem_banks[2];

    let vm_mem = ctx.get_banks();

    check_condition(
        vm_mem[nonce_mem as usize].is_some(), 
        ""the nonce memory account must be provided"",
    )?;

    check_condition(
        vm_mem[src_mem as usize].is_some(), 
        ""the source memory account must be provided"",
    )?;

    check_condition(
        vm_mem[dst_mem as usize].is_some(), 
        ""the destination memory account must be provided"",
    )?;

    let nonce_mem_info = vm_mem[nonce_mem as usize].unwrap();
    let src_mem_info = vm_mem[src_mem as usize].unwrap();
    let dst_mem_info = vm_mem[dst_mem as usize].unwrap();

    let va = try_read(&nonce_mem_info, nonce_index)?;
    let mut vdn = va.into_inner_nonce().unwrap();

    let va = try_read(&src_mem_info, src_index)?;
    let mut src_vta = va.into_inner_timelock().unwrap();

    let va = try_read(&dst_mem_info, dst_index)?;
    let mut dst_vta = va.into_inner_timelock().unwrap();

    let hash = create_transfer_message(
        &vm, 
        &src_vta, 
        &dst_vta, 
        &vdn, 
        args.amount
    );

    sig_verify(
        src_vta.owner.as_ref(), 
        args.signature.as_ref(), 
        hash.as_ref(),
    )?;

    src_vta.balance = src_vta.balance
        .checked_sub(args.amount)
        .ok_or(ProgramError::ArithmeticOverflow)?;

    dst_vta.balance = dst_vta.balance
        .checked_add(args.amount)
        .ok_or(ProgramError::ArithmeticOverflow)?;

    vdn.value = vm.get_current_poh();

    try_write(
        src_mem_info, 
        src_index, 
        &VirtualAccount::Timelock(src_vta)
    )?;

    try_write(
        dst_mem_info, 
        dst_index, 
        &VirtualAccount::Timelock(dst_vta)
    )?;

    try_write(
        nonce_mem_info, 
        nonce_index, 
        &VirtualAccount::Nonce(vdn)
    )?;

    Ok(())
}","rust
/*
Instruction data:
0. signature: [u8;64] - The opcode to execute.
1. amount: [u64] - The account_indicies of the virtual accounts to use.
*/
pub fn process_transfer(
    ctx: &ExecContext,
    data: &ExecIxData,
) -> ProgramResult {
    let vm = load_vm(ctx.vm_info)?;
    let args = TransferOp::try_from_bytes(&data.data)?.to_struct()?;
    let mem_indicies = &data.mem_indicies;
    let mem_banks = &data.mem_banks;
     
    check_condition(
        mem_indicies.len() == 3,
        ""the number of memory indicies must be 3"",
    )?;
    
    check_condition(
        mem_banks.len() == 3,
        ""the number of memory banks must be 3"",
    )?;
    
    let nonce_index = mem_indicies[0];
    let nonce_mem = mem_banks[0];
    let src_index = mem_indicies[1];
    let src_mem = mem_banks[1];
    let dst_index = mem_indicies[2];
    let dst_mem = mem_banks[2];
    
    let vm_mem = ctx.get_banks();
     
    check_condition(
        vm_mem[nonce_mem as usize].is_some(),
        ""the nonce memory account must be provided"",
    )?;
    
    check_condition(
        vm_mem[src_mem as usize].is_some(),
        ""the source memory account must be provided"",
    )?;
    
    check_condition(
        vm_mem[dst_mem as usize].is_some(),
        ""the destination memory account must be provided"",
    )?;
    
    let nonce_mem_info = vm_mem[nonce_mem as usize].unwrap();
    let src_mem_info = vm_mem[src_mem as usize].unwrap();
    let dst_mem_info = vm_mem[dst_mem as usize].unwrap();
    
    let va = try_read(&nonce_mem_info, nonce_index)?;
    let mut vdn = va.into_inner_nonce().unwrap();
    let va = try_read(&src_mem_info, src_index)?;
    let mut src_vta = va.into_inner_timelock().unwrap();
    let va = try_read(&dst_mem_info, dst_index)?;
    let mut dst_vta = va.into_inner_timelock().unwrap();
    
    let hash = create_transfer_message(
        &vm,
        &src_vta,
        &dst_vta,
        &vdn,
        args.amount
    );
    
    sig_verify(
        src_vta.owner.as_ref(),
        args.signature.as_ref(),
        hash.as_ref(),
    )?;
    
    if src_vta.balance < args.amount {
        return Err(ProgramError::InsufficientFunds);
    }
    
    // If the source and destination accounts are the same, then we don't need
    // to do anything.
    let is_same_account = src_mem == dst_mem && src_index == dst_index;
    
    if !is_same_account {
        src_vta.balance = src_vta.balance
            .checked_sub(args.amount)
            .ok_or(ProgramError::ArithmeticOverflow)?;
            
        dst_vta.balance = dst_vta.balance
            .checked_add(args.amount)
            .ok_or(ProgramError::ArithmeticOverflow)?;
    }
    
    vdn.value = vm.get_current_poh();
    try_write(
        src_mem_info,
        src_index,
        &VirtualAccount::Timelock(src_vta)
    )?;
    
    try_write(
        dst_mem_info,
        dst_index,
        &VirtualAccount::Timelock(dst_vta)
    )?;
    
    try_write(
        nonce_mem_info,
        nonce_index,
        &VirtualAccount::Nonce(vdn)
    )?;

    Ok(())
}",Critical,Introduce an explicit check to prevent operations where the source and destination are the same.,https://github.com/code-payments/code-vm/pull/11/files,High
Sol-175,"Inaccurate In-Memory Balance Updates. transfer and withdraw in code-vm are vulnerable to incorrect accounting when the source and destination accounts are the same. In scenarios where the source account and the destination account are identical, the program logic may process both operations in memory without distinguishing between the two. This creates a situation where only the final ”greater” destination value (after adding funds) is written back to storage, without accurately subtracting the funds first.","Rust
/**
 * Instruction data: 0. signature: [u8;64] - The opcode to execute. 
 */
pub fn process_withdraw(
    ctx: &ExecContext, 
    data: &ExecIxData, 
) -> ProgramResult {

    let vm = load_vm(ctx.vm_info)?;
    let args = WithdrawOp::try_from_bytes(&data.data)?;
    
    let mem_indicies = &data.mem_indicies;
    let mem_banks = &data.mem_banks;
    
    check_condition( mem_indicies.len() == 3, ""the number of memory indicies must be 3"", )?;
    check_condition( mem_banks.len() == 3, ""the number of memory banks must be 3"", )?;
    
    let nonce_index = mem_indicies[0]; 
    let nonce_mem = mem_banks[0]; 
    let src_index = mem_indicies[1]; 
    let src_mem = mem_banks[1]; 
    let dst_index = mem_indicies[2]; 
    let dst_mem = mem_banks[2];

    let vm_mem = ctx.get_banks();
    
    check_condition( 
        vm_mem[nonce_mem as usize].is_some(), 
        ""the nonce memory account must be provided"", 
    )?;
    
    check_condition(
        vm_mem[src_mem as usize].is_some(), 
        ""the source memory account must be provided"",
     )?;
     
     
     check_condition(
         vm_mem[dst_mem as usize].is_some(),
          ""the destination memory account must be provided"",
       )?;
       
    let nonce_mem_info = vm_mem[nonce_mem as usize].unwrap(); 
    let src_mem_info = vm_mem[src_mem as usize].unwrap(); 
    let dst_mem_info = vm_mem[dst_mem as usize].unwrap();
    
    let va = try_read(&nonce_mem_info, nonce_index)?;
    let mut vdn = va.into_inner_nonce().unwrap(); 
    let va = try_read(&src_mem_info, src_index)?;
    let mut src_vta = va.into_inner_timelock().unwrap();
    let va = try_read(&dst_mem_info, dst_index)?;
    let mut dst_vta = va.into_inner_timelock().unwrap();
    
    let amount = src_vta.balance; 
    
    let hash = create_withdraw_message(
        &vm,
        &src_vta,
        &dst_vta,
        &vdn,
    );
    
    sig_verify(
        src_vta.owner.as_ref(),
        args.signature.as_ref(),
        hash.as_ref(),
    )?;
    
    src_vta.balance = src_vta.balance
        .checked_sub(amount)
        .ok_or(ProgramError::ArithmeticOverflow)?;
        
    dst_vta.balance = dst_vta.balance
        .checked_add(amount)
        .ok_or(ProgramError::ArithmeticOverflow)?;

    vdn.value = vm.get_current_poh();
    
    try_delete( src_mem_info, src_index )?;
    try_write( dst_mem_info, dst_index, &VirtualAccount::Timelock(dst_vta) )?;
    try_write( nonce_mem_info, nonce_index, &VirtualAccount::Nonce(vdn) )?;
    
    Ok(())
}","rust
pub fn process_withdraw(
    ctx: &ExecContext, 
    data: &ExecIxData,
) -> ProgramResult {
    let vm = load_vm(ctx.vm_info)?;
    let args = WithdrawOp::try_from_bytes(&data.data)?;
    let mem_indicies = &data.mem_indicies;
    let mem_banks = &data.mem_banks;
    
    check_condition(
        mem_indicies.len() == 3,
        ""the number of memory indicies must be 3"",
    )?;
    
    check_condition(
        mem_banks.len() == 3,
        ""the number of memory banks must be 3"",
    )?;
    
    let nonce_index = mem_indicies[0];
    let nonce_mem = mem_banks[0];
    let src_index = mem_indicies[1];
    let src_mem = mem_banks[1];
    let dst_index = mem_indicies[2];
    let dst_mem = mem_banks[2];
    
    let vm_mem = ctx.get_banks();
    
    check_condition(
        vm_mem[nonce_mem as usize].is_some(),
        ""the nonce memory account must be provided"",
    )?;
    
    check_condition(
        vm_mem[src_mem as usize].is_some(),
        ""the source memory account must be provided"",
    )?;
    
    check_condition(
        vm_mem[dst_mem as usize].is_some(),
        ""the destination memory account must be provided"",
    )?;
    
    let nonce_mem_info = vm_mem[nonce_mem as usize].unwrap();
    let src_mem_info = vm_mem[src_mem as usize].unwrap();
    let dst_mem_info = vm_mem[dst_mem as usize].unwrap();
    
    let va = try_read(&nonce_mem_info, nonce_index)?;
    let mut vdn = va.into_inner_nonce().unwrap();
    let va = try_read(&src_mem_info, src_index)?;
    let mut src_vta = va.into_inner_timelock().unwrap();
    let va = try_read(&dst_mem_info, dst_index)?;
    let mut dst_vta = va.into_inner_timelock().unwrap();
    
    let amount = src_vta.balance;
    let hash = create_withdraw_message(
        &vm, 
        &src_vta,
        &dst_vta,
        &vdn,
    );
    
    sig_verify(
        src_vta.owner.as_ref(), 
        args.signature.as_ref(),
        hash.as_ref(),
    )?;
    
    if src_vta.balance < amount {
        return Err(ProgramError::InsufficientFunds);
    }
    
    let is_same_account = src_mem == dst_mem && src_index == dst_index;
    if !is_same_account {
        src_vta.balance = src_vta.balance
            .checked_sub(amount)
            .ok_or(ProgramError::ArithmeticOverflow)?;
        
        dst_vta.balance = dst_vta.balance
            .checked_add(amount)
            .ok_or(ProgramError::ArithmeticOverflow)?;
    }
    
    vdn.value = vm.get_current_poh(); 
    
    try_delete(
        src_mem_info,
        src_index,
    )?;
    
    try_write(
        dst_mem_info,
        dst_index, 
        &VirtualAccount::Timelock(dst_vta),
    )?;
    
    try_write(
        nonce_mem_info, 
        nonce_index, 
        &VirtualAccount::Nonce(vdn),
    )?;
    
    Ok(())
}",Critical,Introduce an explicit check to prevent operations where the source and destination are the same.,https://github.com/code-payments/code-vm/pull/11/files,High
Sol-176,"process_init_timelock does not check that the input bumps are canonical. The bump values are taken directly from the caller without validating whether they match the canonical bumps derived programmatically. A canonical bump corresponds to the first valid seed value that may be used to generate a Program Derived Address (PDA). By not checking for the canonical bump, discrepancies may arise between the addresses expected by the program and those derived in real time, as the address would resolve to a different PDA than what the canonical calculation would yield.","rust
/**
 * Instruction data:
 * 0. account_index: u16 - The location in the VM's paged memory to create the account.
 * 1. virtual_timelock_bump: u8 - The bump seed for the virtual timelock account.
 * 2. virtual_vault_bump: u8 - The bump seed for the virtual token account.
 * 3. unlock_pda_bump: u8 - The bump seed for the unlock PDA address.
 */

pub fn process_init_timelock(accounts: &[AccountInfo<'_>], data: &[u8]) -> ProgramResult {
    let args = InitTimelockIx::try_from_bytes(data)?.to_struct()?;

    let [
        vm_authority_info, 
        vm_info, 
        vm_memory_info, 
        virtual_account_owner_info,
    ] = accounts
    .else {
        return Err(ProgramError::NotEnoughAccountKeys);
    };

    check_signer(vm_authority_info)?;
    check_mut(vm_info)?;
    check_mut(vm_memory_info)?;
    check_readonly(virtual_account_owner_info)?;

    let vm = load_vm_checked(vm_info, vm_authority_info)?;
    check_memory(vm_memory_info, vm_info)?;
    check_is_empty(vm_memory_info, args.account_index)?;

    let owner = virtual_account_owner_info.key.clone();
    let nonce = vm.get_current_poh();

    let timelock_address = pdas::create_virtual_timelock_address(
        &vm.get_mint(),
        &vm.get_authority(),
        &owner,
        vm.get_lock_duration(),
        args.virtual_timelock_bump,
    );

    let unlock_address = pdas::create_unlock_address(
        &owner,
        &timelock_address,
        vm_info.key,
        args.unlock_pda_bump
    );

    // We could technically require the user to provide the withdraw_bump,
    // however, that would make using this instruction more cumbersome since the Expand Down
    // nonce value is determined above.

    let (_, withdraw_bump) = pdas::find_withdraw_receipt_address(
        &unlock_address,
        &nonce,
        vm_info.key
    );

    let vta = VirtualTimelockAccount {
        owner,
        instance: nonce,
        bump: args.virtual_timelock_bump,
        token_bump: args.virtual_vault_bump,
        unlock_bump: args.unlock_pda_bump,
        withdraw_bump,
        balance: 0,
    };

    let va = VirtualAccount::Timelock(vta);
    try_write(vm_memory_info, args.account_index, &va)?;

    vm.advance_poh(CodeInstruction::InitTimelockIx, accounts, data);

    Ok(())
}","rust
// Derived account seeds: 
// 1. vm: [ ""code_vm"", <mint>, <vm_authority>, <lock_duration> ] 
// 2. vm_memory: [ ""code_vm"", ""vm_memory_account"", <self.name>, <vm> ] 

// Instruction data: 
// 0. account_index: u16 - The location in the VM's paged memory to create the account. 
// 1. virtual_timelock_bump: u8 - The bump seed for the virtual timelock account. 
// 2. virtual_vault_bump: u8 - The bump seed for the virtual token account. 
// 3. unlock_pda_bump: u8 - The bump seed for the unlock PDA address. 

pub fn process_init_timelock(accounts: &[AccountInfo<'_>], data: &[u8]) -> ProgramResult { 
    let args = InitTimelockIx::try_from_bytes(data)?.to_struct()?;

    let [ vm_authority_info, vm_info, vm_memory_info, virtual_account_owner_info, ] = accounts
        .else {
            return Err(ProgramError::NotEnoughAccountKeys);
        };

    check_signer(vm_authority_info)?;
    check_mut(vm_info)?;
    check_mut(vm_memory_info)?;
    check_readonly(virtual_account_owner_info)?;

    let vm = load_vm_checked(vm_info, vm_authority_info)?;

    check_memory(vm_memory_info, vm_info)?;
    check_is_empty(vm_memory_info, args.account_index)?;

    let owner = virtual_account_owner_info.key.clone();
    let nonce = vm.get_current_poh();

    let (timelock_address, timelock_bump) = pdas::find_virtual_timelock_address(
        &vm.get_mint(),
        &vm.get_authority(),
        &owner,
        vm.get_lock_duration(),
    );

    if args.virtual_timelock_bump != timelock_bump {
        return Err(ProgramError::InvalidArgument);
    }

    let (unlock_address, unlock_bump) = pdas::find_unlock_address(
        &owner, 
        &timelock_address, 
        vm_info.key
    );

    if args.unlock_pda_bump != unlock_bump {
        return Err(ProgramError::InvalidArgument);
    }

    // We could technically require the user to provide the withdraw_bump
    // however, that would make using this instruction more cumbersome since the nonce value is determined above.
    let (_, withdraw_bump) = pdas::find_withdraw_receipt_address(
        // This call *can* be expensive 
        &unlock_address,
        &nonce, 
        vm_info.key
    );

    let vta = VirtualTimelockAccount {
        owner,
        instance: nonce,
        bump: args.virtual_timelock_bump,
        token_bump: args.virtual_vault_bump,
        unlock_bump: args.unlock_pda_bump,
        withdraw_bump,
        balance: 0,
    };

    let va = VirtualAccount::Timelock(vta);

    try_write(vm_memory_info, args.account_index, &va)?;

    vm.advance_poh(CodeInstruction::InitTimelockIx, accounts, data);

    Ok(())
}",High,Validate that the provided bumps match the canonical bumps.,https://github.com/code-payments/code-vm/pull/13/files,High
Sol-177,"Improper Handling of Empty Items In Circular Buffer. CircularBuffer::contains checks whether a specific item exists within the buffer. However, it does not ignore empty items when checking for a given item. In the context of this CircularBuffer, empty items are represented as arrays filled with default values ( [0; M] ). These empty slots may skew the behavior of contains if they are not properly handled. Without ignoring empty items, the search may incorrectly match these slots and return a false positive. This is especially problematic when an item (such as [0; M] ) is used to represent an empty state in the buffer but is mistakenly treated as a valid entry.","rust
use bytemuck::{Pod, Zeroable}; 

#[repr(C, align(8))] 
#[derive(Clone, Copy, PartialEq, Debug)] 
pub struct CircularBuffer<const N: usize, const M: usize> { 
    pub items: [[u8; M]; N], 
    pub offset: u8, 
    pub num_items: u8, 
    _padding: [u8; 6], 
} 

unsafe impl <const N: usize, const M: usize> Zeroable for CircularBuffer<N, M> {} 
unsafe impl <const N: usize, const M: usize> Pod for CircularBuffer<N, M> {} 

impl<const N: usize, const M: usize> CircularBuffer<N, M> { 
    pub fn new() -> Self { 
        Self { 
            items: [[0; M]; N], 
            offset: 0, 
            num_items: 0, 
            _padding: [0; 6], 
        } 
    } 

    pub const fn capacity(&self) -> usize { N } 

    pub fn is_empty(&self) -> bool { self.num_items == 0 } 

    pub fn find_index(&self, item: &[u8]) -> Option<usize> { 
        self.items.iter().position(|x| x.eq(item)) } 

    pub fn contains(&self, item: &[u8]) -> bool { 
        self.find_index(item).is_some() 
    } 

    pub fn push(&mut self, item: &[u8]) { 
        let mut buffer = [0; M]; 
        buffer[..item.len()].copy_from_slice(item); 

        if self.num_items < N as u8 { 
            self.items[self.num_items as usize] = buffer; 
            self.num_items += 1; 
        } else { 
            self.items[self.offset as usize] = buffer; 
            self.offset = (self.offset + 1) % N as u8; 
        } 
    } 

    pub fn unroll(&self) -> Vec<[u8; M]> { 
        let mut list = Vec::new(); 
        for i in 0..self.num_items { 
            list.push(self.items[(self.offset as usize + i as usize) % N]); 
        } 
        list 
    } 

    pub fn first(&self) -> Option<&[u8; M]> { 
        if self.is_empty() { 
            return None; 
        } 
        Some(&self.items[self.offset as usize]) 
    } 

    pub fn last(&self) -> Option<&[u8; M]> { 
        if self.is_empty() { 
            return None; 
        }
        
        let index = if self.num_items < N as u8 {
            self.num_items as u8 - 1 
        } else { 
            if self.offset == 0 { 
                N as u8 - 1 } 
            else { 
                self.offset - 1 
            }
        }; 

        Some(&self.items[index as usize]) 
    } 

    pub fn get(&self, index: usize) -> Option<&[u8; M]> { 
        if index < self.num_items as usize { 
            let actual_index = (self.offset as usize + index ) % N as usize; 
            Some(&self.items[actual_index]) 
        } else { 
            None 
        } 
    } 
}","use bytemuck::{Pod, Zeroable};

#[repr(C, align(8))]
#[derive(Clone, Copy, PartialEq, Debug)]
pub struct CircularBuffer<const N: usize, const M: usize> {
    pub items: [[u8; M]; N],
    pub offset: u8,
    pub num_items: u8,
    _padding: [u8; 6],
}

unsafe impl<const N: usize, const M: usize> Zeroable for CircularBuffer<N, M> {}
unsafe impl<const N: usize, const M: usize> Pod for CircularBuffer<N, M> {}

impl<const N: usize, const M: usize> CircularBuffer<N, M> {
    pub fn new() -> Self {
        Self {
            items: [[0; M]; N],
            offset: 0,
            num_items: 0,
            _padding: [0; 6],
        }
    }

    pub const fn capacity(&self) -> usize {
        N
    }

    pub fn is_empty(&self) -> bool {
        self.num_items == 0
    }

    pub fn find_index(&self, item: &[u8]) -> Option<usize> {
        for i in 0..self.num_items as usize {
            let idx = (self.offset as usize + i) % N;
            if self.items[idx] == item {
                return Some(i);
            }
        }
        None
    }

    pub fn contains(&self, item: &[u8]) -> bool {
        self.find_index(item).is_some()
    }

    pub fn push(&mut self, item: &[u8]) {
        let mut buffer = [0; M];
        buffer[..item.len()].copy_from_slice(item);

        if self.num_items < N as u8 {
            self.items[self.num_items as usize] = buffer;
            self.num_items += 1;
        } else {
            self.items[self.offset as usize] = buffer;
            self.offset = (self.offset + 1) % N as u8;
        }
    }

    pub fn unroll(&self) -> Vec<[u8; M]> {
        let mut list = Vec::new();
        
        for i in 0..self.num_items {
            list.push(self.items[(self.offset as usize + i as usize) % N]);
        }

        list
    }

    pub fn first(&self) -> Option<&[u8; M]> {
        if self.is_empty() {
            return None;
        }

        Some(&self.items[self.offset as usize])
    }

    pub fn last(&self) -> Option<&[u8; M]> {
        if self.is_empty() {
            return None;
        }

        let index = if self.num_items < N as u8 {
            self.num_items - 1
        } else if self.offset == 0 {
            N as u8 - 1 
        } else {
            self.offset - 1
        };
        
        Some(&self.items[index as usize])
    }

    pub fn get(&self, index: usize) -> Option<&[u8; M]> {
        if index < self.num_items as usize {
            let actual_index = (self.offset as usize + index) % N as usize;
            Some(&self.items[actual_index])
        } else {
            None
        }
    }
}",High,"Modify the the function to exclude empty items when performing the search, ensuring that only non-empty, valid items are considered in the check.",https://github.com/code-payments/code-vm/pull/14/files,High
Sol-178,"Misaligned Memory Access. In the current implementation, function arguments are referenced with their type values without ensuring proper memory alignment, and the structures utilize #[repr(C, packed)] , preventing the compiler from inserting padding for alignment. This creates misaligned references during argument parsing in most functions, resulting in undefined behavior.","rust
#[repr(C, packed)] 
#[derive(Clone, Copy, Debug, Pod, Zeroable)] 
pub struct InitVmIx { 
    pub lock_duration: u8, 
    pub vm_bump: u8, 
    pub vm_omnibus_bump: u8, 
}

#[repr(C, packed)]
#[derive(Clone, Copy, Debug, Pod, Zeroable)]
pub struct InitMemoryIx {
    pub name: [u8; MAX_NAME_LEN],
    pub num_accounts: u32,
    pub account_size: u16,
    pub vm_memory_bump: u8,
}
 
#[repr(C, packed)]
#[derive(Clone, Copy, Debug, Pod, Zeroable)]
pub struct ResizeMemoryIx {
    pub account_size: u32,
}

#[repr(C, packed)]
#[derive(Clone, Copy, Debug, Pod, Zeroable)]
pub struct InitStorageIx {
    pub name: [u8; MAX_NAME_LEN],
    pub vm_storage_bump: u8,
}

#[repr(C, packed)]
#[derive(Clone, Copy, Debug, Pod, Zeroable)]
pub struct ExecIx {
    // Dynamically sized data, not supported by Pod (or steel) @@ -111,29 +160,95 @@
    pub struct ExecIxData {
        pub data: Vec<u8>,
    }
}

...

#[repr(C, packed)]
#[derive(Clone, Copy, Debug, Pod, Zeroable)]
pub struct WithdrawIx {
    _data: PhantomData<WithdrawIxData>,
}","rust
#[repr(C)] #[derive(Clone, Copy, Debug, Pod, Zeroable)] 
pub struct InitVmIx { 
    pub lock_duration: u8, 
    pub vm_bump: u8, 
    pub vm_omnibus_bump: u8, 
}

#[repr(C)] 
#[derive(Clone, Copy, Debug, Pod, Zeroable)] 
pub struct InitMemoryIx { 
    pub name: [u8; MAX_NAME_LEN], 
    pub num_accounts: [u8; 4], // Pack u32 as [u8; 4] 
    pub account_size: [u8; 2], // Pack u16 as [u8; 2] 
    pub vm_memory_bump: u8, 
}

...",Medium,"Store the types as a byte array ( u64 may be stored as [u8; 8] as demonstrated in ore) and manually convert (as done here) when needed, ensuring proper alignment.",https://github.com/code-payments/code-vm/pull/6/files#diff-46924424ca1f5ec8adfa2434f9b95a650e9d3dfe2fc6060c9d7d7470f6528d73,High
Sol-179,"Overflow checks are currently not enabled in release mode. Consequently, there is a possibility for integer overflow in the context of the SliceAllocator , specifically if a MemoryAccount is initialized with account_size=u16::MAX and num_accounts=u32::MAX . When calculating the total memory required for these accounts by multiplying account_size by num_accounts , the subsequent product may be extremely high resulting in an overflow.","rust
pub const MAX_NAME_LEN: usize = 32; 
pub const NUM_ACCOUNTS: usize = 32_000; 
pub const COMPRESSED_STATE_DEPTH: usize = 20; 
pub const RELAY_STATE_DEPTH: usize = 63; 
pub const RELAY_HISTORY_ITEMS: usize = 32;

// Instruction data: 
// 0. name: [u8; 32] - The name of this memory module. 
// 1. num_accounts: u32 - The number of accounts that can be stored in this memory module. 
// 2. account_size: u16 - The size of each account in this memory module. 
// 3. vm_memory_bump: u8 - The bump seed for the this memory account.

pub fn process_init_memory(accounts: &[AccountInfo<'_>], data: &[u8]) -> ProgramResult { 
    let args = InitMemoryIx::try_from_bytes(data)?.to_struct()?;

    let [ vm_authority_info, vm_info, vm_memory_info, system_program_info, rent_sysvar_info ] = accounts.else {
        return Err(ProgramError::NotEnoughAccountKeys); 
    }; 

    check_signer(vm_authority_info)?;
    check_mut(vm_info)?;
    check_mut(vm_memory_info)?;
}

pub fn process_resize(accounts: &[AccountInfo<'_>], data: &[u8]) -> ProgramResult { 
    let args = ResizeMemoryIx::try_from_bytes(data)?.to_struct()?;

    let [ vm_authority_info, vm_info, vm_memory_info, system_program_info, rent_sysvar_info ] = accounts.else {
        return Err(ProgramError::NotEnoughAccountKeys); 
    };

    check_condition( 
        args.account_size as usize > MemoryAccount::get_size(), 
        ""account_size must be greater than the base size of a memory account"", 
    )?;
    
    check_signer(vm_authority_info)?;
    check_mut(vm_info)?;
    check_mut(vm_memory_info)?;
}","rust
pub const MAX_NAME_LEN: usize = 32;
pub const NUM_ACCOUNTS: usize = 32_000;

// Some (reasonable) virtual account limits without being perscriptive
pub const MIN_ACCOUNT_SIZE: usize = 32;
pub const MAX_ACCOUNT_SIZE: usize = 256;
pub const MAX_NUM_ACCOUNTS: usize = 320_000;
pub const COMPRESSED_STATE_DEPTH: usize = 20;
pub const RELAY_STATE_DEPTH: usize = 63;
pub const RELAY_HISTORY_ITEMS: usize = 32;

/*
Instruction data:
0. name: [u8; 32] - The name of this memory module.
1. num_accounts: u32 - The number of accounts that can be stored in this memory module.
2. account_size: u16 - The size of each account in this memory module.
3. vm_memory_bump: u8 - The bump seed for the this memory account. 
*/
pub fn process_init_memory(accounts: &[AccountInfo<'_>], data: &[u8]) -> ProgramResult {
    
    let args = InitMemoryIx::try_from_bytes(data)?.to_struct()?;

    let [vm_authority_info, vm_info, vm_memory_info, system_program_info, rent_sysvar_info] = accounts;
    else {
        return Err(ProgramError::NotEnoughAccountKeys);
    };
    
    check_condition(
        args.account_size as usize >= MIN_ACCOUNT_SIZE
        && args.account_size as usize <= MAX_ACCOUNT_SIZE,
        ""account_size must be between MIN_ACCOUNT_SIZE and MAX_ACCOUNT_SIZE"",
    )?;

    check_condition(
        args.num_accounts as usize <= MAX_NUM_ACCOUNTS,
        ""num_accounts must be less than MAX_NUM_ACCOUNTS"",
    )?;

    check_signer(vm_authority_info)?;
    check_mut(vm_info)?;
    check_mut(vm_memory_info)?;
}

/*
Instruction data:
0. len: u32 - The new size of the vm_memory account. 
*/
pub fn process_resize(accounts: &[AccountInfo<'_>], data: &[u8]) -> ProgramResult {
    
    let args = ResizeMemoryIx::try_from_bytes(data)?.to_struct()?;
    
    let [vm_authority_info, vm_info, vm_memory_info, system_program_info, rent_sysvar_info] = accounts;
    else {
        return Err(ProgramError::NotEnoughAccountKeys);
    };
    
    check_condition(
        args.account_size as usize > MemoryAccount::get_size(),
        ""account_size must be greater than the base size of a memory account"",
    )?;
    
    check_condition(
       args.account_size as usize <= MAX_ACCOUNT_SIZE * MAX_NUM_ACCOUNTS,
       ""account_size must be less than or equal to the maximum size for this type of memory account"",
    )?;
    
    check_signer(vm_authority_info)?;
    check_mut(vm_info)?;
    check_mut(vm_memory_info)?;
}",Medium,Enable overflow checks and properly sanitize parameters such as account_size and num_accounts .,https://github.com/code-payments/code-vm/pull/18/files,High
Sol-180,"Merkle Tree Proof Length Not Verified. When performing a Merkle proof to verify the existence of specific data within the tree, a proof vector (collection of hashes) is provided to the verification function. This proof must correspond to the correct level of the tree. To ensure validity, the verification function should confirm that the proof vector length matches the tree depth. Without this check, invalid proofs may verify intermediate nodes instead of leaves. However, in the current implementation, this issue is mitigated because the compress / decompress methods construct the leaves in a manner that prevents intermediate hashes in the proof from matching the compressed data.","rust
pub fn try_remove(&mut self, proof: &[Hash], val: Hash) -> ProgramResult { 
    self.try_replace_leaf(proof, Self::as_leaf(val), self.get_empty_leaf()) 
} 

pub fn try_replace(&mut self, proof: &[Hash], original_val: Hash, new_val: Hash) -> ProgramResult { 
    let original_leaf = Self::as_leaf(original_val); 
    let new_leaf = Self::as_leaf(new_val); 
    self.try_replace_leaf(proof, original_leaf, new_leaf) 
} 

pub fn try_replace_leaf(&mut self, proof: &[Hash], original_leaf: Hash, new_leaf: Hash) -> ProgramResult { 
    let original_path = MerkleTree::<N>::compute_path(proof, original_leaf); 
    let new_path = MerkleTree::<N>::compute_path(proof, new_leaf); 
    // @@ -128,11 +134,19 @@ 
    impl<const N: usize> MerkleTree<N> { 
    } 

    pub fn contains(&self, proof: &[Hash], val: Hash) -> bool { 
        let leaf = Self::as_leaf(val); 
        self.contains_leaf(proof, leaf) 
    } 

    pub fn contains_leaf(&self, proof: &[Hash], leaf: Hash) -> bool { 
        let root = self.get_root(); 
        Self::is_valid_leaf(proof, root, leaf) 
    } 

    // @@ -233,8 +247,14 @@
    impl<const N: usize> MerkleTree<N> { 
        proof 
    } 
}","rust
pub fn try_remove(&mut self, proof: &[Hash], val: Hash) -> ProgramResult { 
    self.check_length(proof)?;
    self.try_replace_leaf(proof, Self::as_leaf(val), self.get_empty_leaf())
} 

pub fn try_replace(&mut self, proof: &[Hash], original_val: Hash, new_val: Hash) -> ProgramResult { 
    self.check_length(proof)?;
    let original_leaf = Self::as_leaf(original_val); 
    let new_leaf = Self::as_leaf(new_val); 
    self.try_replace_leaf(proof, original_leaf, new_leaf) 
} 

pub fn try_replace_leaf(&mut self, proof: &[Hash], original_leaf: Hash, new_leaf: Hash) -> ProgramResult { 
    self.check_length(proof)?;
    let original_path = MerkleTree::<N>::compute_path(proof, original_leaf); 
    let new_path = MerkleTree::<N>::compute_path(proof, new_leaf); 
    @@ -128,11 +134,19 @@ impl<const N: usize> MerkleTree<N> { } 
}

pub fn contains(&self, proof: &[Hash], val: Hash) -> bool { 
    if let Err(_) = self.check_length(proof) { 
        return false; 
    } 
    let leaf = Self::as_leaf(val); 
    self.contains_leaf(proof, leaf) 
} 

pub fn contains_leaf(&self, proof: &[Hash], leaf: Hash) -> bool { 
    if let Err(_) = self.check_length(proof) { 
        return false; 
    } 
    let root = self.get_root(); 
    Self::is_valid_leaf(proof, root, leaf) 
} 

@@ -233,8 +247,14 @@ impl<const N: usize> MerkleTree<N> { 
    proof 
}

fn check_length(&self, proof: &[Hash]) -> Result<(), ProgramError> { 
    check_condition( 
        proof.len() == N, 
        ""merkle proof length does not match tree depth"", 
    ) 
}",Low,Verify the proof length against the tree depth to ensure correctness.,https://github.com/code-payments/code-vm/pull/7/files,High
Sol-181,"Sequence Misalignment in Allocations Array . There is a sequence mismatch between the vault_allocation_strategy and invested.allocations arrays in amounts_invested . vault_allocation_strategy represents the vault’s target allocation strategy and contains all allocations, including active and inactive ones (inactive entries have Pubkey::default as the reserve key). invested.allocations , on the other hand, reflects the current state of investments in the vault. Since amounts_invested filters out inactive entries from vault_allocation_strategy while building invested.allocations , it includes only active entries, without placeholders for inactive ones. As a result, the indices of the reserves in invested.allocations no longer align with their corresponding indices in vault_allocation_strategy . However, in invest , when refresh_target_allocations is invoked, it relies on accurate alignment between vault_allocation_strategy and invested.allocations to determine which reserves are part of the allocation strategy and calculate the actual from target allocations for each reserve. Consequently, due to the mismatch in index sequences between vault_allocation_strategy and invested.allocations , the operations in refresh_target_allocations will not succeed, causing invest to fail.","rust
pub fn amounts_invested<'info, T>(
    vault: &VaultState, 
    mut reserves_iter: impl Iterator<Item = T>, 
    slot: Slot, 
) -> Result<Invested> 
where 
    T: AnyAccountLoader<'info, Reserve>,
{
    let mut invested = Invested::default();
    let mut total = Fraction::ZERO;
    
    for (index, allocation) in vault
        .vault_allocation_strategy
        .iter()
        .filter(|a| a.reserve != Pubkey::default())
        .enumerate() 
    { 
        // [...]
    } 

    invested.total = total;
    
    Ok(invested)
}","rust
pub fn amounts_invested<'info, T>(
    vault: &VaultState, 
    mut reserves_iter: impl Iterator<Item = T>, 
    slot: Slot, 
) -> Result<Invested> where T: AnyAccountLoader<'info, Reserve>, {
    let mut invested = Invested::default();
    let mut total = Fraction::ZERO;
    
    for allocation in vault.vault_allocation_strategy.iter() {
        if allocation.reserve == Pubkey::default() {
            // Include placeholders for inactive entries
            invested.allocations.push(None);
        } else {
            // Process active allocations
            let reserve = reserves_iter.next().ok_or(ProgramError::InvalidArgument)?;
            let amount = compute_invested_amount(reserve, slot)?;
            total += amount;
            invested.allocations.push(Some(amount));
        }
    }
    
    invested.total = total;
    
    Ok(invested)
}",High,Preserve the original sequence of vault_allocation_strategy in invested.allocations by including placeholders in invested.allocations for inactive entries.,https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/2e0c3c98-3ba4-45a5-9c04-8c6d4dbbb51a/kamino_kvault_audit_final.pdf?table=block&id=1ad84d4e-4146-80d3-9227-c07e16b89009&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742522400000&signature=60z2ZURdyP9KSn9A3_OuVX-NAqTi3QaCkJtXHai05i0&downloadName=kamino_kvault_audit_final.pdf,High
Sol-182,"Improper Enforcement of Allocation Cap. In the current implementation of state::refresh_target_allocations , there is a potential issue where the token_target_allocation of a reserve may exceed its token_allocation_cap . This occurs because the allocation logic does not account for the existing allocation token_target_allocation when determining whether the ideal allocation reserve_target_ideal exceeds the cap. The reserve_target_ideal >= Fraction::from(allocation.token_allocation_cap) comparison checks only if the current iteration’s ideal allocation exceeds the cap, ignoring any previously accumulated allocation ( token_target_allocation ). If the token_target_allocation from previous iterations already brings the total close to the cap, the function may allocate additional tokens beyond the cap.","rust
pub fn refresh_target_allocations(&mut self, invested: &Invested) -> Result<()> { 
    
    // ...
    
    let reserve_target_capped = if reserve_target_ideal >= Fraction::from(allocation.token_allocation_cap) {
        a_cap_was_reached = true;

        // Remove the weight from the total
        remaining_weight_to_allocate -= reserve_weight; 
        
        Fraction::from(allocation.token_allocation_cap) 
    } else { 
        reserve_target_ideal 
    }; 
    
    remaining_tokens_to_allocate -= reserve_target_capped;
    *token_target_allocation += reserve_target_capped; 
    
    // ...
}","rust
pub fn refresh_target_allocations(&mut self, invested: &Invested) -> Result<()> {

    // ... previous code

    let current_allocated = *token_target_allocation;
    let reserve_target_capped = 
        if current_allocated + reserve_target_ideal >= Fraction::from(allocation.token_allocation_cap) {
            a_cap_was_reached = true;

            // Adjust the remaining weight since this reserve hits its cap
            remaining_weight_to_allocate -= reserve_weight;

            // Only allocate the remaining available tokens
            Fraction::from(allocation.token_allocation_cap) - current_allocated 
        } 
        else {
            reserve_target_ideal
        };
        
    remaining_tokens_to_allocate -= reserve_target_capped;
    *token_target_allocation += reserve_target_capped;

    // ... subsequent code

}",Medium,"Check that the sum of token_target_allocation + reserve_target_ideal is greater than or equal to token_allocation_cap , and then set reserve_target_capped to token_allocation_cap - token_target_allocation .",https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/2e0c3c98-3ba4-45a5-9c04-8c6d4dbbb51a/kamino_kvault_audit_final.pdf?table=block&id=1ad84d4e-4146-80d3-9227-c07e16b89009&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742522400000&signature=60z2ZURdyP9KSn9A3_OuVX-NAqTi3QaCkJtXHai05i0&downloadName=kamino_kvault_audit_final.pdf,High
Sol-183,"There is a lack of validation for the Switchboard price in refresh_oracle_price::load_switchboard . While it retrieves and parses data from the feed_account to extract the price, it does not verify the associated timestamp. This omission may result in the system accepting outdated prices if the oracle feed has not been updated for an extended period. There is no guarantee that the price corresponds to the current market state or a recent update. A recency check ensures that the price data fetched from the oracle is current and reflects the latest market conditions. A stale oracle price may result in inaccurate calculations of asset values, allowing the possibility of exploiting the system by utilizing old prices for arbitrage attacks.","rust
fn load_switchboard<'a>(oracle_switchboard: &AccountInfo<'a>) -> Result<Decimal> { 
    let feed_account = oracle_switchboard.data.borrow(); 
    let feed = PullFeedAccountData::parse(feed_account).unwrap(); 
    msg!(""Switchboard unpack start""); 
    let price = feed.value().unwrap(); 
    Ok(price) 
}","rust
fn load_switchboard<'a>(oracle_switchboard: &AccountInfo<'a>, current_timestamp: u64) -> Result<Decimal> {
    let feed_account = oracle_switchboard.data.borrow();
    let feed = PullFeedAccountData::parse(feed_account).unwrap();

    msg!(""Switchboard unpack start""); 

    // Example: Extract timestamp from feed (assuming feed.timestamp() returns u64)
    let price_timestamp = feed.timestamp().unwrap();

    // Define an acceptable threshold for staleness (e.g., 60 seconds)
    let allowed_threshold: u64 = 60;

    if current_timestamp.saturating_sub(price_timestamp) > allowed_threshold {
        msg!(""Error: Oracle price is stale."");
        return Err(ErrorCode::StaleOraclePrice.into());
    }

    let price = feed.value().unwrap();

    Ok(price)
}",High,"Modify load_switchboard to verify that the price fetched from the oracle is recent. If the price is outdated, the function should fail gracefully with a specific error, preventing the protocol from using invalid data.",https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/5ba78692-e48a-491f-8d84-30321e9b55d4/neptune_audit_final.pdf?table=block&id=17484d4e-4146-80ed-b006-cb827d75f945&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742522400000&signature=fxN15QlEXvjbatfhVS9myZ8svNOOcKswaC1y3_qS2Dc&downloadName=neptune_audit_final.pdf,High
Sol-184,"Flawed Logic in case of Shared Escrow. The vulnerability in pool::try_autoclose_pool lies in the logic for handling PoolType::Token . Specifically, the function checks the pool.amount field to decide whether the pool has enough SOL to purchase another NFT, but it does not account for the case where a shared_escrow is configured. The logic assumes if pool.currency == Pubkey::default , it indicates the pool utilizes SOL (not a token). pool.amount represents the SOL available in the pool. The pool should be closed if pool.amount is less than the price needed to purchase another NFT.","rust
/// A utitilty function that tries to autoclose a pool if it is possible.
pub fn try_autoclose_pool<'info>(
    pool: &Account<'info, Pool>, 
    rent_payer: AccountInfo<'info>, 
    owner: AccountInfo<'info>,
) -> Result<()> {
    match pool.config.pool_type {
        PoolType::Trade => {
            // Cannot be auto-closed
            ()
        },
        PoolType::Token => {
            // Not enough SOL to purchase another NFT, so we can close the pool.
            if pool.currency == Pubkey::default() && pool.amount < pool.current_price(TakerSide::Sell)? {
                close_pool(pool, rent_payer, owner)?;
            }
        },
        PoolType::NFT => {
            // No more NFTs to sell, so we can close the pool.
            if pool.nfts_held == 0 {
                close_pool(pool, rent_payer, owner)?;
            }
        },
    }
    Ok(())
}","rust
/// A utility function that tries to autoclose a pool if it is possible. 
pub fn try_autoclose_pool<'info>(
    pool: &Account<'info, Pool>,
    rent_payer: AccountInfo<'info>,
    owner: AccountInfo<'info>,
    shared_escrow: Option<&AccountInfo<'info>>,
) -> Result<()> { 
    match pool.config.pool_type {
        PoolType::Trade => (), // Cannot be auto-closed
        PoolType::Token => {
            let amount = if pool.shared_escrow == Pubkey::default() {
                pool.amount
            } else { 
                shared_escrow.unwrap().lamports() 
            }; 
            
            // Not enough SOL to purchase another NFT, so we can close the pool.
            if pool.currency == Pubkey::default() && amount < pool.current_price(TakerSide::Sell)? {
                close_pool(pool, rent_payer, owner)?;
            }
        }
        PoolType::NFT => {
            // No more NFTs to sell, so we can close the pool.
            if pool.nfts_held == 0 {
                close_pool(pool, rent_payer, owner)?;
            }
        }
    }
    Ok(())
}",High,Check if shared_escrow == pubkey::default and in that case utilize the pool.amount directly.,https://github.com/tensor-foundation/amm/pull/94/files,High
Sol-185,"Ineffective Shared Escrow Validation . In CreatePool , the shared_escrow field is constrained with the following check: pool.config.pool_type != NFT . This constraint is intended to ensure that a pool using shared escrow cannot have a PoolType::NFT configuration. However, the pool account is not yet initialized when this constraint is checked and pool.config.pool_type does not contain any meaningful data. Thus, any constraint referencing pool.config.pool_type before initialization is ineffective.","rust
/// Instruction accounts. 
#[derive(Accounts)]
#[instruction(args: CreatePoolArgs)]
pub struct CreatePool<'info> {
    /// The account that pays for the rent to open the pool. 
    /// This will be stored on the pool
    /// so it can be refunded when the pool is closed. 
    #[account(mut)] 
    pub rent_payer: Signer<'info>, 

    /// The owner of the pool will be stored and used to control 
    /// permissioned pool instructions. 
    pub owner: Signer<'info>, 

    /// The pool state account. 
    #[account(
       init, 
       payer = rent_payer, 
       space = Pool::SIZE, 
       seeds = [ 
           b""pool"", 
           owner.key().as_ref(), 
           args.pool_id.as_ref(), 
       ], 
       bump,
    )]
    pub pool: Box<Account<'info, Pool>>, 

    /// The whitelist that gatekeeps which NFTs can be bought or sold with this pool. 
    #[account( 
        seeds = [
            b""whitelist"", 
            &whitelist.namespace.as_ref(), 
            &whitelist.uuid
        ], 
        bump, 
        seeds::program = whitelist_program::ID 
    )]
    pub whitelist: Box<Account<'info, WhitelistV2>>, 

    #[account( 
        has_one = owner @ ErrorCode::WrongOwner, 
        constraint = pool.config.pool_type != PoolType::NFT @ ErrorCode::CannotUseSharedEscrow,
    )]
    pub shared_escrow: Option<Account<'info, MarginAccount>>, 

    /// The Solana system program. 
    pub system_program: Program<'info, System>, 
}","/// Instruction accounts.
#[derive(Accounts)]
#[instruction(args: CreatePoolArgs)]
pub struct CreatePool<'info> {
    /// The account that pays for the rent to open the pool. This will be stored on the pool
    /// so it can be refunded when the pool is closed.
    #[account(mut)]
    pub rent_payer: Signer<'info>,

    /// The owner of the pool will be stored and used to control permissioned pool instructions.
    pub owner: Signer<'info>,

    /// The pool state account.
    #[account(
        init,
        payer = rent_payer,
        space = Pool::SIZE,
        seeds = [
            b""pool"",
            owner.key().as_ref(),
            args.pool_id.as_ref(),
        ],
        bump,
    )]
    pub pool: Box<Account<'info, Pool>>,

    /// The whitelist that gatekeeps which NFTs can be bought or sold with this pool.
    #[account(
        seeds = [
            b""whitelist"",
            &whitelist.namespace.as_ref(),
            &whitelist.uuid
        ],
        bump,
        seeds::program = whitelist_program::ID
    )]
    pub whitelist: Box<Account<'info, WhitelistV2>>,

    #[account(
        has_one = owner @ ErrorCode::WrongOwner,
        constraint = args.config.pool_type != PoolType::NFT @ ErrorCode::CannotUseSharedEscrow,
    )]
    pub shared_escrow: Option<Account<'info, MarginAccount>>,

    /// The Solana system program.
    pub system_program: Program<'info, System>,
}",Medium,Apply this constraint to the incoming arguments ( args.config.pool_type ) instead of the uninitialized pool.config.pool_type .,https://github.com/tensor-foundation/amm/commit/87ad4a70bcbcbec2ea0443ec5bbe2fb680aa9574#diff-94e6998cd6c2e0f422b4f57f96da650b1ac8527f5b036f3e8d50c3c00c96633d,High
Sol-186,"Missing Account Authenticity Checks. In shared_accounts within the MplxShared structure, the metadata and edition accounts are essential to validate an NFT’s properties, such as its uniqueness and associated data. The vulnerability concerns the lack of seed checks to verify the existence of the metadata and edition for the provided mint. Additionally, in the transfer functionality, only the metadata is verified, and the master_edition is not utilized for the non-pNFT case. Thus, the master_edition account is not utilized or checked in the non-pNFT case. This is crucial because without verifying the existence of the master edition, there is no confirmation that the mint is truly non-fungible.","rust
#[derive(Accounts)]
pub struct MplxShared<'info> {
    /// The mint account of the NFT.
    pub mint: Box<InterfaceAccount<'info, Mint>>,
    
    /// The Token Metadata metadata account of the NFT.
    /// CHECK: ownership, structure and mint are checked in assert_decode_metadata.
    #[account(mut)] 
    pub metadata: UncheckedAccount<'info>,

    /// The Token Metadata edition account of the NFT.
    /// CHECK: seeds checked on Token Metadata CPI
    //note that MASTER EDITION and EDITION share the same seeds, and so it's valid to check them here
    pub edition: UncheckedAccount<'info>,

    /// The Token Metadata source token record account of the NFT.
    /// CHECK: seeds checked on Token Metadata CPI 
    #[account(mut)] 
    pub user_token_record: Option<UncheckedAccount<'info>>,

    /// The Token Metadata token record for the destination.
    /// CHECK: seeds checked on Token Metadata CPI 
    #[account(mut)]
    pub pool_token_record: Option<UncheckedAccount<'info>>,

    /// The Token Metadata program account.
    /// CHECK: address constraint is checked here 
    #[account(address = mpl_token_metadata::ID)] 
    pub token_metadata_program: Option<UncheckedAccount<'info>>,

    /// The sysvar instructions account.
    /// CHECK: address constraint is checked here 
    #[account(address = anchor_lang::solana_program::sysvar::instructions::ID)] 
    pub sysvar_instructions: Option<UncheckedAccount<'info>>,

    /// The Metaplex Token Authority Rules account that stores royalty enforcement rules.
    /// CHECK: validated by mplex's pnft code 
    pub authorization_rules: Option<UncheckedAccount<'info>>,

    /// The Metaplex Token Authority Rules program account.
    /// CHECK: address constraint is checked here
    #[account(address = MPL_TOKEN_AUTH_RULES_ID)] 
    pub authorization_rules_program: Option<UncheckedAccount<'info>>,
}","rust
/* Shared account structs for different standards */

/// Shared accounts for interacting with Metaplex legacy and pNFTs.
#[derive(Accounts)]
pub struct MplxShared<'info> {
    /// The mint account of the NFT.
    pub mint: Box<InterfaceAccount<'info, Mint>>,

    /// The Token Metadata metadata account of the NFT.
    /// CHECK: ownership, structure and mint are checked in assert_decode_metadata, seeds checked here.
    #[account(mut, seeds = [
        Metadata::PREFIX, 
        mpl_token_metadata::ID.as_ref(), 
        mint.key().as_ref(), 
    ], 
    bump, seeds::program = mpl_token_metadata::ID)]
    pub metadata: UncheckedAccount<'info>,

    /// The Token Metadata edition account of the NFT.
    /// CHECK: seeds checked here
    #[account( seeds = [
        MasterEdition::PREFIX.0, 
        mpl_token_metadata::ID.as_ref(), 
        mint.key().as_ref(), 
        MasterEdition::PREFIX.1, 
    ], 
    bump, seeds::program = mpl_token_metadata::ID)]
    pub edition: UncheckedAccount<'info>,

    // --------------------------------------- pNft

    /// The Token Metadata source token record account of the NFT.
    /// CHECK: seeds checked on Token Metadata CPI
    #[account(mut)]
    pub user_token_record: Option<UncheckedAccount<'info>>,

    /// The Token Metadata token record for the destination.
    /// CHECK: seeds checked on Token Metadata CPI
    #[account(mut)]
    pub pool_token_record: Option<UncheckedAccount<'info>>,

    /// The Token Metadata program account.
    /// CHECK: address constraint is checked here
    #[account(address = mpl_token_metadata::ID)]
    pub token_metadata_program: Option<UncheckedAccount<'info>>,

    /// The sysvar instructions account.
    /// CHECK: address constraint is checked here
    #[account(address = anchor_lang::solana_program::sysvar::instructions::ID)]
    pub sysvar_instructions: Option<UncheckedAccount<'info>>,

    /// The Metaplex Token Authority Rules account that stores royalty enforcement rules.
    /// CHECK: validated by mplex's pnft code
    pub authorization_rules: Option<UncheckedAccount<'info>>,

    /// The Metaplex Token Authority Rules program account.
    /// CHECK: address constraint is checked here
    #[account(address = MPL_TOKEN_AUTH_RULES_ID)]
    pub authorization_rules_program: Option<UncheckedAccount<'info>>,
}",Medium,"implement PDA (Program Derived Address) and initialization checks to ensure that the metadata , edition , and master_edition accounts are properly validated.",https://github.com/tensor-foundation/amm/pull/94/files#diff-1c09b7e45cff20e6a63576cdc1ce45da7cad5a7dc9a86aed18a1046dad831dea,High
Sol-187,"Improper Rent Calculation. price-lock utilizes token_account.get_lamports to determine the rent instead of calculating the proper rent-exemption reserve. If an attacker ( maker ) deposits a large amount of SOL (more than the rent-exemption reserve) into an account, it may prevent trades from executing. Since the program only expects a minimal amount for rent and does not handle large balances, the excess SOL will block the processing of the trade, rendering the option worthless. For example, the TAmmSellNftTokenPool , get_lamports is utilized to determine the amount of SOL held in order_ta account. If a very large amount of SOL is deposited into the order_ta account, the program will assume this large balance represents the necessary rent to perform operations. The program will fail to execute trades because the logic incorrectly assumes that the large SOL deposit represents the required rent. The return_rent logic tries to return any excess rent from order_ta back to the order_vault . It assumes that all SOL in the order_ta account should be returned. Since the program does not calculate the actual rent exemption correctly, it transfers a large portion of SOL , which includes both the genuine rent and the attacker’s deposit, into the order_vault , resulting in improper SOL transfers and an imbalance in the vault’s holdings. Thus, the option becomes worthless, as no trades may be executed, locking up trade executions.","rust
fn return_rent(&self, order_seeds: [&[&[u8]]; 1]) -> Result<()> {
    let token_account_rent = self.token.order_ta.get_lamports();
    let record_rent = Rent::get()?.minimum_balance(TokenRecord::LEN); 
    // For the token pool, the seller receives everything back. 
    let excess_rent = 2 * token_account_rent + record_rent; 
    self.trade.return_rent_for_sell(excess_rent, order_seeds)
}","rust
fn return_rent(&self, order_seeds: [&[&[u8]]; 1]) -> Result<()> {
    // Calculate the proper rent exemption based on the account's size
    let order_ta_size = self.token.order_ta.data_len();
    let required_rent = Rent::get()?.minimum_balance(order_ta_size);

    // Get the current balance
    let current_balance = self.token.order_ta.get_lamports();

    // Only consider the excess SOL above the required rent as ""excess""
    // Ensure that the account holds at least the minimum required balance
    if current_balance < required_rent {
        return Err(ErrorCode::InsufficientRentBalance.into());
    }

    // Calculate the excess rent that should be returned,
    // without including any funds deposited by an attacker.
    let excess_rent = current_balance - required_rent;

    self.trade.return_rent_for_sell(excess_rent, order_seeds)
}",Medium,Ensure that the rent exemption reserve is properly calculated utilizing the size of the account instead of its lamports.,https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/8cad4a72-5d69-4c26-9f6c-a296efd8f011/tensor_foundation_audit_final.pdf?table=block&id=19784d4e-4146-80f1-81d5-f7094dea2280&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742522400000&signature=EJjVlegyav7Jm5YuqzTTQ6ubaOxqvVbDchfA4y5K4CQ&downloadName=tensor_foundation_audit_final.pdf,High
Sol-188,"Absence of Royalty Enforcement. In buy_spl::process_buy_legacy_spl the optional_royalty_pct parameter is currently utilized without verifying whether the royalties are actually enforced based on the metadata.token_standard . optional_royalty_pct is a user-provided parameter specifying the percentage of royalties to be paid to the creators. metadata.token_standard indicates the standard of the token. Some token standards enforce royalties at a protocol level. By directly utilizing optional_royalty_pct , the token standard that requires a specific amount of royalties may receive the incorrect amount if the user-supplied amount is inappropriate.","rust
#[access_control(ctx.accounts.validate())]
#[inline(never)]
pub fn process_buy_legacy_spl<'info, 'b>(
    ctx: Context<'_, 'b, '_, 'info, BuyLegacySpl<'info>>,
    max_amount: u64,
    optional_royalty_pct: Option<u16>,
    authorization_data: Option<AuthorizationDataLocal>,
) -> Result<()> {
    // validate the mint
    let mint = ctx.accounts.mint.key();
    let metadata = assert_decode_metadata(&mint, &ctx.accounts.metadata)?;
    let list_state = &ctx.accounts.list_state;
    let remaining_accounts = ctx.remaining_accounts;

    // Parse remaining accounts.
    let num_creators = metadata.creators.as_ref().map(Vec::len).unwrap_or(0);
    let (creator_accounts, remaining) = remaining_accounts.split_at(num_creators);
    let (creator_ta_accounts, remaining) = remaining.split_at(num_creators);

    // If broker acounts are present, we need the currency token accounts from them.
    let (maker_broker_currency_ta, remaining) = if let Some(maker_broker) = &ctx.accounts.maker_broker {
        let (account, remaining) = remaining
            .split_first()
            .ok_or(TcompError::InsufficientRemainingAccounts)?;
        assert_decode_token_account(&mint, &maker_broker.key(), account)?;
        (Some(account), remaining)
    } else {
        (None, remaining)
    };
    
    let (taker_broker_currency_ta, _remaining) = if let Some(taker_broker) = &ctx.accounts.taker_broker {
        let (account, remaining) = remaining
            .split_first()
            .ok_or(TcompError::InsufficientRemainingAccounts)?;
        assert_decode_token_account(&mint, &taker_broker.key(), account)?;
        (Some(account), remaining)
    } else {
        (None, remaining)
    };

    let creator_accounts_with_ta = creator_accounts
        .iter()
        .zip(creator_ta_accounts.iter())
        .flat_map(|(creator, ata)| vec![creator.to_account_info(), ata.to_account_info()])
        .collect::<Vec<_>>();

    let amount = list_state.amount;
    let currency = list_state.currency;
    
    require!(amount <= max_amount, TcompError::PriceMismatch);
    require!(currency.is_some(), TcompError::CurrencyMismatch);

    let tnsr_discount = matches!(currency, Some(c) if c.to_string() == TNSR_CURRENCY);

    let Fees {
        protocol_fee: tcomp_fee,
        maker_broker_fee,
        taker_broker_fee,
        ..
    } = calc_fees(CalcFeesArgs {
        amount,
        tnsr_discount,
        total_fee_bps: TAKER_FEE_BPS,
        broker_fee_pct: BROKER_FEE_PCT,
        maker_broker_pct: MAKER_BROKER_PCT,
    })?;

    let creator_fee = calc_creators_fee(
        metadata.seller_fee_basis_points,
        amount,
        optional_royalty_pct,
    )?;

    ...

    return Ok(());
}","rust
#[access_control(ctx.accounts.validate())]
#[inline(never)]
pub fn process_buy_legacy_spl<'info, 'b>(
    ctx: Context<'_, 'b, '_, 'info, BuyLegacySpl<'info>>,
    max_amount: u64,
    optional_royalty_pct: Option<u16>,
    authorization_data: Option<AuthorizationDataLocal>,
) -> Result<()> {
    // validate mint and currency
    let mint = ctx.accounts.mint.key();
    let currency = ctx.accounts.currency.key();
    let metadata = assert_decode_metadata(&mint, &ctx.accounts.metadata)?;
    let list_state = &ctx.accounts.list_state;
    let remaining_accounts = ctx.remaining_accounts;

    // Parse remaining accounts.
    let num_creators = metadata.creators.as_ref().map(Vec::len).unwrap_or(0);
    let (creator_accounts, remaining) = remaining_accounts.split_at(num_creators);
    let (creator_ta_accounts, remaining) = remaining.split_at(num_creators);

    // If broker acounts are present, we need the currency token accounts from them.
    let (maker_broker_currency_ta, remaining) = if let Some(maker_broker) = &ctx.accounts.maker_broker {
        let (account, remaining) = remaining
            .split_first()
            .ok_or(TcompError::InsufficientRemainingAccounts)?;

        // Create ATA if it doesn't exist
        if account.data_is_empty() {
            anchor_spl::associated_token::create(CpiContext::new(
                ctx.accounts.associated_token_program.to_account_info(),
                anchor_spl::associated_token::Create {
                    payer: ctx.accounts.payer.to_account_info(),
                    associated_token: account.to_account_info(),
                    authority: maker_broker.to_account_info(),
                    mint: ctx.accounts.currency.to_account_info(),
                    system_program: ctx.accounts.system_program.to_account_info(),
                    token_program: ctx.accounts.currency_token_program.to_account_info(),
                },
            ))?;
        }

        assert_decode_token_account(&currency, &maker_broker.key(), account)?;

        (Some(account), remaining)
    } else {
        (None, remaining)
    };

    // More code...
}",Medium,"Ensure that if royalty is enforced for a certain token standard, the system overrides any user-provided optional_royalty_pct and applies a predefined percentage.",https://github.com/tensor-foundation/marketplace/commit/9eab87ed9ab2fd83cbe7285f4feaad060af98173#diff-c674fd03e612b14b066eccb76cbb0ba30797c548f59219b0e46344e7ab538da7,High
Sol-189,"Utilization of Improper Payer Account. In close_expired_listing::process_close_expired_listing_core , the list_state account is currently utilized as the payer for the TransferV1CpiBuilder CPI (Cross-Program Invocation). The list_state account is a program-owned account that holds metadata and operational data for the listing. Such accounts are generally funded only with enough lamports to cover rent. If the list_state account lacks sufficient lamports to cover the cost of the CPI invocation, the transaction will fail, resulting in the cleanup of the expired listing to revert. Similarly, in delist::process_delist_core the rent_destination account is utilized as the payer in the TransferV1CpiBuilder . This enforces an unnecessary requirement that the rent_destination account should be a signer. The rent_destination account is not supposed to be responsible for paying transaction fees. Its role is to receive any refunded rent when the list_state account is closed, not to pay for the transfer itself. As a result of the constraint, the delisting may fail if the rent_destination is not a signer.","rust
pub fn process_delist_core<'info>(
    ctx: Context<'_, '_, '_, 'info, DelistCore<'info>>,
) -> Result<()> {
    
    validate_core_asset(
        &ctx.accounts.asset, 
        ctx.accounts.collection.as_ref().map(|c| c.as_ref()),
    )?;

    TransferV1CpiBuilder::new(&ctx.accounts.mpl_core_program)
        .asset(&ctx.accounts.asset)
        .authority(Some(&ctx.accounts.list_state.to_account_info()))
        .new_owner(&ctx.accounts.owner.to_account_info())
        .payer(&ctx.accounts.rent_destination) 
        .collection(ctx.accounts.collection.as_ref().map(|c| c.as_ref()))
        .invoke_signed(&[&ctx.accounts.list_state.seeds()])?;

    let list_state = &ctx.accounts.list_state;

    record_event(
        &TcompEvent::Maker(MakeEvent {
            maker: *ctx.accounts.owner.key,
            bid_id: None,
            target: Target::AssetId,
            target_id: list_state.asset_id,
            field: None,
            field_id: None,
            amount: list_state.amount,
            quantity: 1, 
            currency: list_state.currency,
            expiry: list_state.expiry,
            private_taker: list_state.private_taker,
            asset_id: Some(list_state.asset_id),
        }),
        &ctx.accounts.marketplace_program,
        TcompSigner::List(&ctx.accounts.list_state),
    )?;
    
    Ok(())
}","rust
pub fn process_delist_core<'info>(
    ctx: Context<'_, '_, '_, 'info, DelistCore<'info>>,
) -> Result<()> {
    validate_core_asset(
        &ctx.accounts.asset,
        ctx.accounts.collection.as_ref().map(|c| c.as_ref()),
    )?;

    TransferV1CpiBuilder::new(&ctx.accounts.mpl_core_program)
        .asset(&ctx.accounts.asset)
        .authority(Some(&ctx.accounts.list_state.to_account_info()))
        .new_owner(&ctx.accounts.owner.to_account_info())
        .payer(&ctx.accounts.owner)
        .collection(ctx.accounts.collection.as_ref().map(|c| c.as_ref()))
        .invoke_signed(&[&ctx.accounts.list_state.seeds()])?;

    let list_state = &ctx.accounts.list_state;
    record_event(
        &TcompEvent::Maker(MakeEvent {
            maker: *ctx.accounts.owner.key,
            bid_id: None,
            target: Target::AssetId,
            target_id: list_state.asset_id,
            field: None,
            field_id: None,
            amount: list_state.amount,
            quantity: 1, // <-- represents how many NFTs got delisted
            currency: list_state.currency,
            expiry: list_state.expiry,
            private_taker: list_state.private_taker,
            asset_id: Some(list_state.asset_id),
        }),
        &ctx.accounts.marketplace_program,
        TcompSigner::List(&ctx.accounts.list_state),
    )?;

    Ok(())
}",Medium,utilize the DelistCore.owner account in process_delist_core .,https://github.com/tensor-foundation/marketplace/commit/cbda695d0e2600ff2968e8e5d90a925010c7f555#diff-baf1cdca1649a8b58d07cb5cf7c5f3eb41d3fe76237f04f6a27f360f774e6cf3,High
Sol-190,"Utilization of Improper Payer Account. In close_expired_listing::process_close_expired_listing_core , the list_state account is currently utilized as the payer for the TransferV1CpiBuilder CPI (Cross-Program Invocation). The list_state account is a program-owned account that holds metadata and operational data for the listing. Such accounts are generally funded only with enough lamports to cover rent. If the list_state account lacks sufficient lamports to cover the cost of the CPI invocation, the transaction will fail, resulting in the cleanup of the expired listing to revert. Similarly, in delist::process_delist_core the rent_destination account is utilized as the payer in the TransferV1CpiBuilder . This enforces an unnecessary requirement that the rent_destination account should be a signer. The rent_destination account is not supposed to be responsible for paying transaction fees. Its role is to receive any refunded rent when the list_state account is closed, not to pay for the transfer itself. As a result of the constraint, the delisting may fail if the rent_destination is not a signer.","rust
pub fn process_close_expired_listing_core<'info>(
    ctx: Context<'_, '_, '_, 'info, CloseExpiredListingCore<'info>>,
) -> Result<()> {
    let list_state = &ctx.accounts.list_state;
    
    validate_core_asset(
        &ctx.accounts.asset,
        ctx.accounts.collection.as_ref().map(|c| c.as_ref()),
    )?;
    
    TransferV1CpiBuilder::new(&ctx.accounts.mpl_core_program)
        .asset(&ctx.accounts.asset)
        .authority(Some(&ctx.accounts.list_state.to_account_info()))
        .new_owner(&ctx.accounts.owner.to_account_info())
        .payer(&ctx.accounts.list_state.to_account_info()) // pay for what?
        .collection(ctx.accounts.collection.as_ref().map(|c| c.as_ref()))
        .invoke_signed(&[&ctx.accounts.list_state.seeds()])?;
        
    record_event(
        &TcompEvent::Maker(MakeEvent {
            maker: *ctx.accounts.owner.key,
            bid_id: None,
            target: Target::AssetId,
            target_id: list_state.asset_id,
            field: None,
            field_id: None,
            amount: list_state.amount,
            quantity: 1, // <-- represents how many NFTs got delisted
            currency: list_state.currency,
            expiry: list_state.expiry,
            private_taker: list_state.private_taker,
            asset_id: Some(list_state.asset_id),
        }),
        &ctx.accounts.marketplace_program,
        TcompSigner::List(&ctx.accounts.list_state),
    )?;
    
    Ok(())
}","rust
pub fn process_close_expired_listing_core<'info>(
    ctx: Context<'_, '_, '_, 'info, CloseExpiredListingCore<'info>>,
) -> Result<()> {
    let list_state = &ctx.accounts.list_state;
    
    validate_core_asset(
        &ctx.accounts.asset,
        ctx.accounts.collection.as_ref().map(|c| c.as_ref()),
    )?;

    TransferV1CpiBuilder::new(&ctx.accounts.mpl_core_program)
        .asset(&ctx.accounts.asset)
        .authority(Some(&ctx.accounts.list_state.to_account_info()))
        .new_owner(&ctx.accounts.owner.to_account_info())
        // This will break if Metaplex ever adds tx fees as it will take list state below minimum balance
        .payer(&ctx.accounts.list_state.to_account_info())
        .collection(ctx.accounts.collection.as_ref().map(|c| c.as_ref()))
        .invoke_signed(&[&ctx.accounts.list_state.seeds()])?;

    record_event(
        &TcompEvent::Maker(MakeEvent {
            maker: *ctx.accounts.owner.key,
            bid_id: None,
            target: Target::AssetId,
            target_id: list_state.asset_id,
            field: None,
            field_id: None,
            amount: list_state.amount,
            quantity: 1, // <-- represents how many NFTs got delisted
            currency: list_state.currency,
            expiry: list_state.expiry,
            private_taker: list_state.private_taker,
            asset_id: Some(list_state.asset_id),
        }),
        &ctx.accounts.marketplace_program,
        TcompSigner::List(&ctx.accounts.list_state),
    )?;
    
    Ok(())
}",Medium,Replace list_state with a user-provided payer account in process_close_expired_listing_core,https://github.com/tensor-foundation/marketplace/commit/cbda695d0e2600ff2968e8e5d90a925010c7f555#diff-baf1cdca1649a8b58d07cb5cf7c5f3eb41d3fe76237f04f6a27f360f774e6cf3,High
Sol-191,"Legacy NFT Validation Gaps. The vulnerability relates to verification gaps in TakeBidLegacy and the handling of legacy standards for NFTs (non-programmable NFTs). The master_edition account ensures the non-fungibility of an NFT. However, the PDA validation (Program-Derived Address) for master_edition is missing for non-pNFTs. Additionally, the metadata account’s seed checks are missing in the TakeBidLegacy context.","Rust
#[derive(Accounts)] 
pub struct TakeBidLegacy<'info> {
    /// CHECK: checked in assert_fee_account() 
    #[account(mut)] 
    pub fee_vault: UncheckedAccount<'info>,
    
    #[account(mut)] 
    pub seller: Signer<'info>, 
    
    /// CHECK: this ensures that specific asset_id belongs to specific owner 
    #[account( mut, seeds=[b""bid_state"".as_ref(), owner.key().as_ref(), bid_state.bid_id.as_ref()], bump = bid_state.bump[0], has_one = owner )]
    pub bid_state: Box<Account<'info, BidState>>, 

    // Owner needs to be passed in as mutable account, so we can reassign lamports back to them 
    /// CHECK: has_one = owner on bid_state 
    #[account(mut)] 
    pub owner: UncheckedAccount<'info>, 

    /// CHECK: none, can be anything 
    #[account(mut)] 
    pub taker_broker: Option<UncheckedAccount<'info>>, 

    /// CHECK: checked in validate() 
    #[account(mut)] 
    pub maker_broker: Option<UncheckedAccount<'info>>, 

    /// CHECK: optional, manually handled in handler: 1)seeds, 2)program owner, 3)normal owner, 4)margin acc stored on pool 
    #[account(mut)] 
    pub shared_escrow: UncheckedAccount<'info>, 

    /// CHECK: manually below, since this account is optional 
    pub whitelist: Option<UncheckedAccount<'info>>, 

    // --------------------------------------- nft 
    #[account(mut, token::mint = mint, token::authority = seller)] 
    pub seller_ta: Box<InterfaceAccount<'info, TokenAccount>>, 

    /// CHECK: whitelist, token::mint in seller_token, associated_token::mint in owner_ata_acc 
    pub mint: Box<InterfaceAccount<'info, Mint>>, 

    //can't deserialize directly coz Anchor traits not implemented 
    /// CHECK: assert_decode_metadata check seeds 
    #[account(mut)] 
    pub metadata: UncheckedAccount<'info>, 

    #[account( init_if_needed, payer = seller, associated_token::mint = mint, associated_token::authority = owner, )]
    pub owner_ta: Box<InterfaceAccount<'info, TokenAccount>>, 

    // --------------------------------------- pNft 
    //note that MASTER EDITION and EDITION share the same seeds, and so it's valid to check them here 
    /// CHECK: seeds checked on Token Metadata CPI 
    pub edition: UncheckedAccount<'info>, 

    /// CHECK: seeds checked on Token Metadata CPI 
    #[account(mut)] 
    pub seller_token_record: Option<UncheckedAccount<'info>>, 

    /// CHECK: seeds checked on Token Metadata CPI 
    #[account(mut)] 
    pub owner_token_record: Option<UncheckedAccount<'info>>, 

    pub pnft_shared: ProgNftShared<'info>, 

    //using this as temporary escrow to avoid having to rely on delegate 
    /// Implicitly checked via transfer. Will fail if wrong account 
    #[account( init_if_needed, payer = seller, seeds=[ b""nft_escrow"".as_ref(), mint.key().as_ref(), ], bump, token::mint = mint, // NB: super important this is a PDA w/ data, o/w ProgramOwnedList rulesets break. token::authority = bid_state, )]
    pub bid_ta: Box<InterfaceAccount<'info, TokenAccount>>, 

    /// CHECK: seeds checked on Token Metadata CPI 
    #[account(mut)] 
    pub bid_token_record: Option<UncheckedAccount<'info>>, 

    /// CHECK: validated by mplex's pnft code 
    pub authorization_rules: Option<UncheckedAccount<'info>>, 

    pub token_program: Interface<'info, TokenInterface>, 
    pub associated_token_program: Program<'info, AssociatedToken>, 
    pub system_program: Program<'info, System>, 
    pub marketplace_program: Program<'info, crate::program::MarketplaceProgram>, 
    pub escrow_program: Program<'info, EscrowProgram>, 

    // cosigner is checked in validate() 
    pub cosigner: Option<Signer<'info>>, 

    /// intentionally not deserializing, it would be dummy in the case of VOC/FVC based verification 
    /// CHECK: assert_decode_mint_proof 
    pub mint_proof: Option<UncheckedAccount<'info>>, 

    /// CHECK: bid_state.get_rent_payer() 
    #[account(mut, constraint = rent_destination.key() == bid_state.get_rent_payer() @ TcompError::BadRentDest )]
    pub rent_destination: UncheckedAccount<'info>, 

    // Remaining accounts: 
    // 1. creators (1-5) 
}","rust
#[derive(Accounts)] 
pub struct TakeBidLegacy<'info> {
    pub struct TakeBidLegacy<'info> {
         /// CHECK: checked in assert_fee_account() 
         #[account(mut)] 
         pub fee_vault: UncheckedAccount<'info>, 
          #[account(mut)] 
         pub seller: Signer<'info>, 
         /// CHECK: this ensures that specific asset_id belongs to specific owner 
         #[account(
              mut, 
              seeds=[b""bid_state"".as_ref(), 
                     owner.key().as_ref(), 
                     bid_state.bid_id.as_ref()],
              bump = bid_state.bump[0], 
              has_one = owner 
         )]
         pub bid_state: Box<Account<'info, BidState>>, 
         // Owner needs to be passed in as mutable account, so we can reassign lamports back to them 
         /// CHECK: has_one = owner on bid_state
         #[account(mut)]
         pub owner: UncheckedAccount<'info>, 
         /// CHECK: none, can be anything
         #[account(mut)]
         pub taker_broker: Option<UncheckedAccount<'info>>, 
         /// CHECK: checked in validate()
         #[account(mut)] 
         pub maker_broker: Option<UncheckedAccount<'info>>,
         /// CHECK: optional, manually handled in handler: 1)seeds, 2)program owner, 3)normal owner, 4)margin acc stored on pool 
         #[account(mut)] 
         pub shared_escrow: UncheckedAccount<'info>, 
         /// CHECK: manually below, since this account is optional 
         pub whitelist: Option<UncheckedAccount<'info>>,
         // --------------------------------------- nft 
         #[account(
              mut, 
              token::mint = mint, 
              token::authority = seller
         )]
         pub seller_ta: Box<InterfaceAccount<'info, TokenAccount>>,
         /// CHECK: whitelist, token::mint in seller_token, associated_token::mint in owner_ata_acc 
         #[account(
              mint::token_program = token_program, 
         )]
         pub mint: Box<InterfaceAccount<'info, Mint>>, 
... // end of the code is cut-off, but the approach would be the same beyond this point.",Medium,"Add PDA, initialized checks on master_edition in all legacy standard instructions and metadata account checks in TakeBidLegacy .",https://github.com/tensor-foundation/marketplace/commit/cbda695d0e2600ff2968e8e5d90a925010c7f555#diff-baf1cdca1649a8b58d07cb5cf7c5f3eb41d3fe76237f04f6a27f360f774e6cf3,High
Sol-192,"Denial of Service Due to ATA Ownership Change. As a result of the WithdrawCollateral token account checks in WithdrawCollateralShared within validate , there is a possibility that a Denial of Service (DoS) attack may occur if the maker (the original creator of the lock) intentionally changes their Associated Token Account (ATA) ownership to prevent the taker (the buyer) from claiming their collateral. Proof of Concept 1. The maker creates an NFT lock and deposits their NFT into the lock, which is held as collateral. 2. The taker buys the locked NFT from the maker, sending yield to the maker. As a result, the value of the NFT increases, which implies that the taker stands to benefit if they sell it. 3. The taker sells the NFT at a higher price. As a result, the price of the NFT drops, implying it is possible to buy back the NFT at a lower price. © 2024 Otter Audits LLC. All Rights Reserved. 18 / 37 Tensor Foundation Audit 04 — Vulnerabilities 4. The taker buys the NFT again at a lower price. Consequently, the NFT ’s value drops drastically. 5. At this point, the maker changes the owner of their ATA (which holds the SOL collateral). 6. If the taker, now in possession of the NFT again, wishes to return the NFT to the maker and withdraw the SOL collateral, they will be unable to do so due to the change in the maker’s ATA ownership.","pub fn validate(&mut self, collateral_type: CollateralType, to_maker: bool) -> Result<()> { 
    [...] 
    // If returning to maker: cannot 
    if to_maker { 
        require!( 
            !order_state.collateral_returned, 
            TLockError::CollateralAlreadyReturned 
        ); 
    } else { 
        require!( 
            order_state.collateral_returned, 
            TLockError::CollateralNotReturned 
        ); 
    } 
    if order_state.is_lock_closeable_by_anyone()? { 
        // NB: anyone can permissionlessly return the collateral back to the maker. 
    } else { 
        require!( 
            order_state.taker.unwrap() == self.signer.key(), 
            TLockError::InvalidSigner 
        ); 
    } 
    [...] 
    Ok(()) 
}","rust
use spl_token::state::Account as TokenAccount;

pub fn validate(&mut self, collateral_type: CollateralType, to_maker: bool) -> Result<()> {

    // Retrieve the order state (assumed to be available as self.order_state)
    let order_state = &self.order_state;

    // Verify that the maker's ATA ownership has not changed.
    // Assume that order_state.maker holds the expected maker's public key.
    let expected_maker = order_state.maker;
    let token_account_data = TokenAccount::unpack(&self.token.order_ta.data.borrow())
        .map_err(|_| TLockError::InvalidATAData)?;

    require!(
        token_account_data.owner == expected_maker,
        TLockError::InvalidATAOwnership
    );

    // Proceed with the existing collateral validation logic.
    // If returning to maker, ensure collateral has not already been returned.
    if to_maker {
        require!(
            !order_state.collateral_returned, 
            TLockError::CollateralAlreadyReturned
        );
    } else {
        require!(
            order_state.collateral_returned, 
            TLockError::CollateralNotReturned
        );
    }

    // Check if the lock is closeable by anyone.
    if order_state.is_lock_closeable_by_anyone()? {
        // Anyone can permissionlessly return the collateral back to the maker.
    } else {
        // Ensure that the signer is the expected taker.
        require!(
            order_state.taker.unwrap() == self.signer.key(),
            TLockError::InvalidSigner
        );
    }

    Ok(())
}",Medium,Create the ATA only if it does not already exist.,https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/8cad4a72-5d69-4c26-9f6c-a296efd8f011/tensor_foundation_audit_final.pdf?table=block&id=19784d4e-4146-80f1-81d5-f7094dea2280&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742522400000&signature=EJjVlegyav7Jm5YuqzTTQ6ubaOxqvVbDchfA4y5K4CQ&downloadName=tensor_foundation_audit_final.pdf,High
Sol-193,Missing Timestamp Update. Description The updated_at field in the BidState structure is not updated during the execution of take_bid_shared and stakeholders will not have an accurate record of when the bid was last modified.,"rust
pub fn take_bid_shared(args: TakeBidArgs) -> Result<()> { 
    let TakeBidArgs { 
        bid_state, 
        seller, 
        escrow, 
        owner, 
        rent_destination, 
        maker_broker, 
        taker_broker, 
        fee_vault, 
        asset_id, 
        token_standard, 
        creators, 
        min_amount, 
        optional_royalty_pct, 
        seller_fee_basis_points, 
        creator_accounts, 
        marketplace_prog, 
        escrow_prog, 
        system_prog, 
    } = args;
    
    // Verify & increment quantity
    require!(bid_state.can_buy_more(), TcompError::BidFullyFilled); 
    bid_state.incr_filled_quantity()?;
}","rust
pub fn take_bid_shared(args: TakeBidArgs) -> Result<()> { 
    let TakeBidArgs { 
        bid_state, 
        seller, 
        escrow, 
        owner, 
        rent_destination, 
        maker_broker, 
        taker_broker, 
        fee_vault, 
        asset_id, 
        token_standard, 
        creators, 
        min_amount, 
        optional_royalty_pct, 
        seller_fee_basis_points, 
        creator_accounts, 
        marketplace_prog, 
        escrow_prog, 
        system_prog, 
    } = args; 

    // Verify & increment quantity 
    require!(bid_state.can_buy_more(), TcompError::BidFullyFilled);

    bid_state.incr_filled_quantity()?;
    
    bid_state.updated_at = Clock::get()?.unix_timestamp;
    bid_state.updated_at = Clock::get()?.unix_timestamp;
}",Low,Ensure updated_at field is updated whenever any modification is made to the BidState .,"https://github.com/tensor-foundation/marketplace/commit/cbda695d0e2600ff2968e8e5d90a925010c7f555, https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/4f0e5931-8de0-4ba1-971b-76011285a661/jito_restaking_audit_final.pdf?table=block&id=15184d4e-4146-80e3-9209-fddf9c04d92e&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742544000000&signature=_QID0SDuvb0JE34X1SKY6Z7BEA8n9HQjSdY6qjIWqKc&downloadName=jito_restaking_audit_final.pdf",High
Sol-194,"Inconsistent Validation of Starting Price. In the current code, there is a check for the starting_price field in create_pool::process_create_pool . This check ensures that the starting price of the pool is not less than 1 when a new pool is created. However, this validation is missing in the edit_pool instruction in validate_pool_config . The edit_pool instruction allows an existing pool to be modified, and the starting_price field may be updated. If the starting_price is not validated in edit_pool , an invalid value may be set for an existing pool.","rust
impl<'info> EditPool<'info> {
    fn validate_pool_config(&self, new_config: Option<PoolConfig>) -> Result<()> {
        let new_config = match new_config {
            Some(config) => config,
            None => return Ok(()),
        };
        //cannot change pool type
        if self.pool.config.pool_type != new_config.pool_type {
            throw_err!(ErrorCode::WrongPoolType);
        }
        new_config.validate()
    }
}","Rust
impl<'info> EditPool<'info> { 
    fn validate_pool_config(&self, edit_config: Option<EditPoolConfig>) -> Result<Option<PoolConfig>> { 
        let new_config = match edit_config { 
            Some(config) => config.into_pool_config(self.pool.config.pool_type), 
            None => return Ok(None), 
        };
        
        //cannot change pool type
        if self.pool.config.pool_type != new_config.pool_type { 
            throw_err!(ErrorCode::WrongPoolType); 
        } 
        
        new_config.validate()?; 
        Ok(Some(new_config)) 
    } 
} 

//! This code was AUTOGENERATED using the kinobi library. 
//! Please DO NOT EDIT THIS FILE, instead use visitors 
//! to add features, then rerun kinobi to update it. 
//! 
//! <https://github.com/kinobi-so/kinobi> 

use crate::generated::types::CurveType; 
use crate::hooked::NullableU16; 
use borsh::BorshDeserialize; 
use borsh::BorshSerialize; 

// clients/rust/src/generated/types/edit_pool_config.rs 

#[derive(BorshSerialize, BorshDeserialize, Clone, Debug, Eq, PartialEq)] 
#[cfg_attr(feature = ""serde"", derive(serde::Serialize, serde::Deserialize))] 
pub struct EditPoolConfig { 
    pub curve_type: CurveType, 
    pub starting_price: u64, 
    pub delta: u64, 
    pub mm_compound_fees: bool, 
    pub mm_fee_bps: NullableU16, 
}",Low,"Move the validation logic for starting_price into PoolConfig::validate . This will ensure it is applied consistently in both the create_pool and edit_pool instructions. This way, the validation is centralized and reusable, which improves code maintainability.",https://github.com/tensor-foundation/amm/commit/06e11ea9321474167a0bf6327c1007ba577ce63d#diff-375a4ee7b3c7f41ab6294c9e23ed08320e047ec6cfaa06a26ffb15b34aa848d9,High
Sol-195,"Unauthorized Withdrawal of Unstaked Amount. The burn instruction may be utilized to withdraw the unstaked amounts intended for withdrawal tickets. In the current implementation, since the function only validates that the amount_in is less than the VRT supply, any user with VRT tokens may call the burn instruction to initiate a withdrawal, regardless of whether they have a legitimate withdrawal ticket. This allows a user to bypass the standard withdrawal process by directly burning tokens and accessing funds","rust
use jito_bytemuck::AccountDeserialize; 
use jito_jsm_core::loader::{ 
    load_associated_token_account, 
    load_signer, 
    load_system_program, 
    load_token_mint, 
    load_token_program, 
}; 
use jito_vault_core::{ 
    config::Config, 
    vault::{
        BurnSummary, Vault
    }, 
}; 
use solana_program::{ 
    account_info::AccountInfo, 
    clock::Clock,
    entrypoint::ProgramResult, 
    program::{
        invoke, 
        invoke_signed
    }, 
    program_error::ProgramError, 
    pubkey::Pubkey, 
    sysvar::Sysvar, 
}; 
use spl_token::instruction::{
    burn, 
    transfer
}; 

pub fn process_burn( 
    program_id: &Pubkey, 
    accounts: &[AccountInfo], 
    amount_in: u64, 
    min_amount_out: u64, 
) -> ProgramResult { 
    let (required_accounts, optional_accounts) = accounts.split_at(11); 

    let [config, vault_info, vault_token_account, vrt_mint, staker, staker_token_account, staker_vrt_token_account, vault_fee_token_account, program_fee_token_account, token_program, system_program] = required_accounts
        else { return Err(ProgramError::NotEnoughAccountKeys); }; 
        
    let clock = Clock::get()?; 
    Config::load(program_id, config, false)?; 

    let config_data = config.data.borrow(); 
    let config = Config::try_from_slice_unchecked(&config_data)?; 

    Vault::load(program_id, vault_info, true)?; 
    let mut vault_data = vault_info.data.borrow_mut(); 
    let vault = Vault::try_from_slice_unchecked_mut(&mut vault_data)?; 

    load_associated_token_account(vault_token_account, vault_info.key, &vault.supported_mint)?; 
    load_token_mint(vrt_mint)?; 
    load_signer(staker, false)?; 
    
    load_associated_token_account(staker_token_account, staker.key, &vault.supported_mint)?; 
    load_associated_token_account(staker_vrt_token_account, staker.key, &vault.vrt_mint)?; 
    load_associated_token_account( program_fee_token_account, &config.program_fee_wallet, &vault.vrt_mint, )?; 
    load_associated_token_account(vault_fee_token_account, &vault.fee_wallet, &vault.vrt_mint)?; 

    load_token_program(token_program)?; 
    load_system_program(system_program)?; 

    vault.check_vrt_mint(vrt_mint.key)?; 
    vault.check_update_state_ok(clock.slot, config.epoch_length())?; 
    vault.check_mint_burn_admin(optional_accounts.first())?; 
    vault.check_is_paused()?; 

    let BurnSummary { vault_fee_amount, program_fee_amount, burn_amount, out_amount, } = vault.burn_with_fee(config.program_fee_bps(), amount_in, min_amount_out)?; 

    invoke( 
        &burn( 
            &spl_token::id(), 
            staker_vrt_token_account.key, 
            vrt_mint.key, 
            staker.key, 
            &[], 
            burn_amount, 
        )?, 
        &[ 
            staker_vrt_token_account.clone(), 
            vrt_mint.clone(), 
            staker.clone(), 
        ], 
    )?;
    
    invoke( 
        &transfer( 
            &spl_token::id(), 
            staker_vrt_token_account.key, 
            vault_fee_token_account.key, 
            staker.key, 
            &[], 
            vault_fee_amount, 
        )?, 
        &[ 
            staker_vrt_token_account.clone(), 
            vault_fee_token_account.clone(), 
            staker.clone(), 
        ], 
    )?;

    invoke( 
        &transfer( 
            &spl_token::id(), 
            staker_vrt_token_account.key, 
            program_fee_token_account.key, 
            staker.key, 
            &[], 
            program_fee_amount, 
        )?, 
        &[ 
            staker_vrt_token_account.clone(), 
            program_fee_token_account.clone(), 
            staker.clone(), 
        ], 
    )?;
    
    let (_, vault_bump, mut vault_seeds) = Vault::find_program_address(program_id, &vault.base); 
    vault_seeds.push(vec![vault_bump]); 
    let seed_slices: Vec<&[u8]> = vault_seeds.iter().map(|seed| seed.as_slice()).collect(); 

    drop(vault_data); 

    invoke_signed( 
        &transfer( 
            &spl_token::id(), 
            vault_token_account.key, 
            staker_token_account.key, 
            vault_info.key, 
            &[], 
            out_amount, 
        )?, 
        &[ 
            vault_token_account.clone(), 
            staker_token_account.clone(), 
            vault_info.clone(), 
        ], 
        &[seed_slices.as_slice()], 
    )?;
    
    Ok(()) 
}",Remove Entire Code,Critical,Remove the burn instruction from the withdrawal process.,https://github.com/jito-foundation/restaking/pull/137/files,High
Sol-196,"Slashing-Induced Share Dilution. The vulnerability arises when the vault’s underlying tokens have been completely slashed, resulting in a balance of zero deposited tokens but still having outstanding VRT tokens in circulation. In such a scenario, the current implementation of calculate_vrt_mint_amount may result in an unfair outcome for new depositors. If tokens_deposited is zero due to slashing, but there are still outstanding VRT tokens, any new depositor will encounter the initial check: if self.tokens_deposited() == 0 . This check then returns the amount deposited as the minted VRT without considering the existing VRT supply. In effect, this first depositor is assigned an amount of VRT equal to their deposited tokens, but the minted VRT does not accurately reflect their share of ownership because of the outstanding VRT tokens that others still hold. Thus, the first depositor effectively donates their deposited tokens to prior VRT holders without receiving a fair share of VRT . Instead of gaining proportional ownership, their assets unfairly inflate the value of pre-existing VRT tokens. If the vault undergoes multiple slashes, it will progressively reduce tokens_deposited while outstanding VRT tokens remain the same, deflating the value of the VRT token. Consequently, there may be a risk of overflow in the share calculations due to needing to mint too many shares.","rust
restaking/vault_core/src/vault.rs 

/// Calculate the amount of VRT tokens to mint based on the amount of tokens deposited in
/// the vault. 
/// If no tokens have been deposited, the amount is equal to the amount passed in.
/// Otherwise, the amount is calculated as the pro-rata share of the total VRT supply.
pub fn calculate_vrt_mint_amount(&self, amount: u64) -> Result<u64, VaultError> {
    if self.tokens_deposited() == 0 {
        return Ok(amount);
    }

    amount
    .checked_mul(self.vrt_supply())
    .and_then(|x| x.checked_div(self.tokens_deposited()))
    .ok_or(VaultError::VaultOverflow)
}

vault_program/src/slash.rs

use jito_bytemuck::AccountDeserialize;
use jito_jsm_core::loader::{
    load_associated_token_account,
    load_signer,
    load_token_program,
};
use jito_restaking_core::{
    ncn::Ncn,
    ncn_operator_state::NcnOperatorState,
    ncn_vault_slasher_ticket::NcnVaultSlasherTicket,
    ncn_vault_ticket::NcnVaultTicket,
    operator::Operator,
    operator_vault_ticket::OperatorVaultTicket,
};
use jito_vault_core::{
    config::Config,
    vault::Vault,
    vault_ncn_slasher_operator_ticket::VaultNcnSlasherOperatorTicket,
    vault_ncn_slasher_ticket::VaultNcnSlasherTicket,
    vault_ncn_ticket::VaultNcnTicket,
    vault_operator_delegation::VaultOperatorDelegation,
};
use jito_vault_sdk::error::VaultError;
use solana_program::{
    account_info::AccountInfo,
    clock::Clock,
    entrypoint::ProgramResult,
    msg,
    program::invoke_signed,
    program_error::ProgramError,
    pubkey::Pubkey,
    sysvar::Sysvar,
};
use spl_token::instruction::transfer;

/// Processes the vault slash instruction: [`crate::VaultInstruction::Slash`]
pub fn process_slash(
    program_id: &Pubkey, 
    accounts: &[AccountInfo], 
    slash_amount: u64,
) -> ProgramResult {
    /*...*/
}

#[allow(clippy::too_many_arguments)]
fn check_states_active_or_cooling_down(
    vault_ncn_slasher_ticket: &VaultNcnSlasherTicket,
    ncn_vault_slasher_ticket: &NcnVaultSlasherTicket,
    ncn_operator_state: &NcnOperatorState,
    operator_vault_ticket: &OperatorVaultTicket,
    vault_ncn_ticket: &VaultNcnTicket,
    ncn_vault_ticket: &NcnVaultTicket,
    slot: u64,
    epoch_length: u64,
) -> ProgramResult {
    /*...*/
}

/// Slashes the vault and updates the vault amounts based on the slashing amount.
fn slash_and_update_vault(
    vault: &mut Vault, 
    vault_operator_delegation: &mut VaultOperatorDelegation, 
    vault_ncn_slasher_operator_ticket: &mut VaultNcnSlasherOperatorTicket, 
    slash_amount: u64,
) -> ProgramResult {
    /*...*/
}",Remove Entire Code (vault_program/src/slash.rs),High,Remove the slashing instruction.,https://github.com/jito-foundation/restaking/pull/141/files#diff-4200ef7af2b6c1734be1438ea2ea643497061bf91824dfd16519556440b81b3e,High
Sol-197,"DOS Due to Withdrawal Ticket Desynchronization. There is a potential Denial of Service (DoS) attack in vault_program::process_burn_withdrawal_ticket that may occur if an attacker manipulates the state of the system by directly sending VRT tokens to the vault_staker_withdrawal_ticket_token_account . This will result in inconsistencies between the amount of VRT tokens recorded in the token account and the amount recorded in the VaultStakerWithdrawalTicket account. The direct transfer will increase the balance of tokens in the token account without updating VaultStakerWithdrawalTicket , creating a desynchronization between these two values since vault_staker_withdrawal_ticket.vrt_amount() would still reflect the original amount of tokens expected by the withdrawal process. close_account checks that the amount stored in the token account is zero before allowing the account to be closed. If the amounts are out of sync, close_account operation may fail, as it verifies that the account’s balance is zero. This effectively prevents the staker from closing their withdrawal ticket and claiming tokens, resulting in a denial-of-service scenario.","rust
/// Burns the withdrawal ticket, transferring the assets to the staker and closing the withdrawal ticket. 

/// Expand Down Expand Up @@ -58,6 +60,11 @@ pub fn process_burn_withdrawal_ticket( 
/// One should call the [`crate::VaultInstruction::CrankVaultUpdateStateTracker`] instruction before running this instruction 
/// to ensure that any rewards that were accrued are accounted for. 
pub fn process_burn_withdrawal_ticket(
    program_id: &Pubkey,
    accounts: &[AccountInfo],
) -> ProgramResult {
    let (required_accounts, optional_accounts) = accounts.split_at(12);
    let [config, vault_info, vault_token_account, vrt_mint, staker, staker_token_account, vault_staker_withdrawal_ticket_info, vault_staker_withdrawal_ticket_token_account, vault_fee_token_account, program_fee_token_account, token_program, system_program] = required_accounts else {
        return Err(ProgramError::NotEnoughAccountKeys);
    };
    // ....
}","rust
use spl_token_2022::state::Account;

pub fn process_burn_withdrawal_ticket(
    program_id: &Pubkey,
    accounts: &[AccountInfo],
) -> ProgramResult {
    let (required_accounts, optional_accounts) = accounts.split_at(12);
    let [config, vault_info, vault_token_account, vrt_mint, staker, staker_token_account, vault_staker_withdrawal_ticket_info, vault_staker_withdrawal_ticket_token_account, vault_fee_token_account, program_fee_token_account, token_program, system_program] = required_accounts else {
    return Err(ProgramError::NotEnoughAccountKeys);
    };

    Config::load(program_id, config, false)?;
    let config_data = config.data.borrow();
    let config = Config::try_from_slice_unchecked(&config_data)?;
    
    // Rest of your function code...

    Ok(())
}",High,Ensure the program always verifies the actual balance of the token account directly via SPL Token Program methods before allowing operations that rely on the amount of tokens.,https://github.com/jito-foundation/restaking/pull/140/files,High
Sol-198,"Incorrect Parameter Encoding. In marginfi_cpi::withdraw_from_lending_account , there is an incorrect encoding of the withdraw_all parameter in the instruction data. withdraw_from_lending_account allows a user to withdraw funds from their lending account. It constructs and sends a cross-program invocation (CPI) to the Marginfi program with the appropriate parameters to perform this withdrawal. One of these parameters, withdraw_all , is a boolean flag indicating whether to withdraw the entire balance from the lending account. However, the withdraw_all field in the instruction is incorrectly assigned as a single byte (1), while the Marginfi program expects the withdraw_all parameter to be an Option<bool> , which is a two-byte representation. Thus, the Marginfi program expects an Option<bool> , but it receives a single byte.","rust
pub fn withdraw_from_lending_account<'info>(
    ctx: CpiContext<'_, '_, '_, 'info, LendingAccountWithdraw<'info>>,
    amount: u64, 
    withdraw_all: bool,
) -> Result<()> { 
    // ... 
}","rust
pub fn withdraw_from_lending_account<'info>(
    ctx: CpiContext<'_, '_, '_, 'info, LendingAccountWithdraw<'info>>,
    amount: u64,
    withdraw_all: Option<bool>,  // Updated to Option<bool>
) -> Result<()> 
{
    // Function implementation
}",Medium,Encode the withdraw_all parameter as Option .,https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/6d83ab5f-c00a-4ddf-bc68-d408deb91d5f/marginfi_integration_audit_final.pdf?table=block&id=13c84d4e-4146-80c2-a1fc-ec6e95ee4aa7&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742702400000&signature=MZUOOqCmah8oqBzft5jJhH3USzWXxdSfZzvJW9e3CIY&downloadName=marginfi_integration_audit_final.pdf,High
Sol-199,"Discrepancy in Conversion of Synthetic Yield Tokens. In the RedeemSy instruction, there is a potential discrepancy in the conversion of synthetic yield ( SY ) tokens (shares) to their corresponding base asset amounts. This discrepancy arises due to the way the share-to-asset conversion rate may change after the SY tokens are burned but before the base assets are redeemed. When a user initiates the RedeemSy instruction, the first step is to burn the specified amount of SY tokens ( amount ). Between the time the SY tokens are burned and the base assets are redeemed through the FakeRewards program, the asset share value may be updated. As a result, the calculation utilized to determine the number of base assets corresponding to the burned SY tokens ( shares ) may no longer be accurate, as the base amount to be redeemed is calculated via the asset share value at the time the SY tokens are burned. If this value changes before the redemption is complete, the resulting base amount will not accurately reflect the user’s intended redemption value. Consequently, the invariant check that ensures that the total supply of SY tokens ( mint_sy.supply ) and the corresponding base assets remain in balance will fail.","rust
pub fn handler(ctx: Context<RedeemSy>, amount: u64) -> Result<()> {
    let bump = ctx.bumps.authority; 
    
    // Burn SY tokens 
    token_2022::burn(
        CpiContext::new(
            ctx.accounts.token_2022_program.to_account_info(),
            anchor_spl::token_2022::Burn {
                mint: ctx.accounts.mint_sy.to_account_info(),
                from: ctx.accounts.sy_account.to_account_info(),
                authority: ctx.accounts.owner.to_account_info(),
            },
        ),
        amount,
    )?;
    
    // Redeem shares from FakeRewards and transfer the base asset 
    let seeds: [&[u8]; 2] = [
        crate::GLOBAL_AUTH_SEED, 
        &[bump]
    ]; 
    
    // the rest of your code
    // [...]
}","rust
pub fn handler(ctx: Context<RedeemSy>, amount: u64) -> Result<()> { 

    let bump = ctx.bumps.authority; 

    // Start a transaction to ensure atomicity 
    let mut transaction = Transaction::new(); 

    // Burn SY tokens 
    transaction.add_instruction(
        token_2022::burn( 
            CpiContext::new( 
                ctx.accounts.token_2022_program.to_account_info(), 
                anchor_spl::token_2022::Burn { 
                    mint: ctx.accounts.mint_sy.to_account_info(), 
                    from: ctx.accounts.sy_account.to_account_info(), 
                    authority: ctx.accounts.owner.to_account_info(), 
                },
            ), 
            amount,
        )?
    ); 

    // Redeem shares from FakeRewards and transfer the base asset 
    let seeds: [&[u8]; 2] = [crate::GLOBAL_AUTH_SEED, &[bump]]; 
    transaction.add_instruction(
        redeem_shares_instruction( 
            ctx.accounts.fake_rewards_program.to_account_info(), 
            ctx.accounts.base_asset_account.to_account_info(), 
            amount, 
            seeds, 
        )?
    ); 

    // Execute the transaction atomically 
    transaction.execute()?; 
    
    Ok(())
}",Medium,"Ensure that the burning of SY tokens and the redemption of base assets occur atomically within a single transaction, minimizing the window during which the asset share value may change.",https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/6d83ab5f-c00a-4ddf-bc68-d408deb91d5f/marginfi_integration_audit_final.pdf?table=block&id=13c84d4e-4146-80c2-a1fc-ec6e95ee4aa7&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742702400000&signature=MZUOOqCmah8oqBzft5jJhH3USzWXxdSfZzvJW9e3CIY&downloadName=marginfi_integration_audit_final.pdf,High
Sol-200,"Inconsistencies in the AMM Fee Logic. amm::get_limit_order_size_in_base_and_quote incorrectly applies the fee to the base asset amount rather than the quote asset. The fee is applied after converting the quote asset to the base asset. This results in an incorrect post-fee calculation. The function first converts the quote amount to base via the exchange rate ( base_snapshot / quote_snapshot ), and then applies the fee on the converted base amount. However, fees should only be applied to the quote amount before it is converted to the base asset. This is because the fee should be calculated on the traded amount (in this case, the quote asset) rather than the converted result (base asset). Furthermore, there are inconsistencies in the way the limit order mechanism within the AMM accounts for fees and handles the price snapshot. Currently, the limit order is stopped early to account for fees. This implies that when a user places a trade, the system prematurely adjusts the amount based on fees before fully consuming the limit order. By prematurely adjusting for fees, the order is not fully executed at the actual limit price. The issue arises because, after the limit order is consumed, the price in the pool may improve due to the natural mechanics of the AMM. The user will not benefit from this potential price improvement because the limit order stops early due to fee deductions. Additionally, after a swap that fully consumes the limit order, if a new swap is executed in the same direction, the limit order may be hit again due to the pricing mechanism not resetting properly.","rust
/// This function solves the closed-form solution for the size of the virtual limit order 
/// in the pool. 
pub fn get_limit_order_size_in_base_and_quote(&self, side: Side) -> LimitOrderConfiguration {
    let quote_snapshot = self.quote_reserves_snapshot.upcast();
    let base_snapshot = self.base_reserves_snapshot.upcast();
    let quote_reserves = self.quote_reserves.upcast();
    let base_reserves = self.base_reserves.upcast();
    match side {
        Side::Buy => {
            let ask = if quote_snapshot * base_reserves > base_snapshot * quote_reserves {
                let size_in_quote = (quote_snapshot * base_reserves - base_snapshot * quote_reserves) 
                                    / (base_snapshot + self.post_fee_adjust_rounded_down(base_snapshot));
                let size_in_base = self.post_fee_adjust_rounded_down(
                                    size_in_quote * base_snapshot / quote_snapshot, 
                                  );
                let fee_in_quote = self.fee_rounded_down(size_in_quote);
                LimitOrderConfiguration {
                    size_in_base, 
                    size_in_quote: size_in_quote - fee_in_quote, 
                    fee_in_quote,
                }
            } else {
                LimitOrderConfiguration::new_default()
            };
            ask 
        }
        Side::Sell => {
            let bid = if base_snapshot * quote_reserves > quote_snapshot * base_reserves {
                let size_in_base = (base_snapshot * quote_reserves - quote_snapshot * base_reserves) 
                                   / (2 * quote_snapshot);
                let size_in_quote = size_in_base * quote_snapshot / base_snapshot;
                let fee_in_quote = self.fee_rounded_down(size_in_quote);
                LimitOrderConfiguration {
                    size_in_base, 
                    size_in_quote: size_in_quote - fee_in_quote, 
                    fee_in_quote,
                }
            } else {
                LimitOrderConfiguration::new_default()
            };
            bid 
        }
    }
}","rust
/// This function solves the closed-form solution for the size of the virtual limit order
/// in the pool. 
pub fn get_limit_order_size_in_base_and_quote(&self, side: Side) -> LimitOrderConfiguration {
    let quote_snapshot = self.quote_reserves_snapshot.upcast();
    let base_snapshot = self.base_reserves_snapshot.upcast();
    let quote_reserves = self.quote_reserves.upcast();
    let base_reserves = self.base_reserves.upcast();

    match side {
        Side::Buy => {
            let ask = if quote_snapshot * base_reserves > base_snapshot * quote_reserves {
                let size_in_quote = (quote_snapshot * base_reserves - base_snapshot * quote_reserves) 
                                    / (2 * base_snapshot);
                let size_in_base = size_in_quote * base_snapshot / quote_snapshot;

                LimitOrderConfiguration { 
                    size_in_base,
                    size_in_quote,
                }
            } 
            else { 
                LimitOrderConfiguration::new_default() 
            };

            ask
        },
        
        Side::Sell => {
            let bid = if base_snapshot * quote_reserves > quote_snapshot * base_reserves {
                let size_in_base = (base_snapshot * quote_reserves - quote_snapshot * base_reserves) 
                                   / (2 * quote_snapshot);
                let size_in_quote = size_in_base * quote_snapshot / base_snapshot;

                LimitOrderConfiguration { 
                    size_in_base,
                    size_in_quote, 
                }
            } 
            else { 
                LimitOrderConfiguration::new_default() 
            };

            bid
        },
    }
}",High,"Apply the fee to the quoted amount first, and then convert the post-fee quote into the base currency. This ensures that the fee is deducted from the traded amount (quote) rather than the converted result (base). Additionally, the fee should only be deducted after the limit order is fully executed. This ensures the order is executed at the correct price and allows traders to benefit from any potential price improvements that may arise.",https://github.com/Ellipsis-Labs/plasma/commit/46b9aa9e6a1ba83ab00c43a7deea05e0169232a7#diff-fd37b892d53929555a7af19738b17b18cf4bcc11fde54385d8b780f0fda9597d,High
Sol-201,"Lack of PDA Validation. In both MintToInstruction and TransferInstruction, the token_pool_pda account is included as a mutable account but does not undergo any seed validation or authority checks. This implies that there are no checks to ensure that token_pool_pda was generated using the expected seeds and bump values. An attacker may provide their own token account as token_pool_pda instead of the intended token pool Program Derived Address (PDA). Since there are no checks to validate that this account is derived from the expected seeds, the program will treat the attacker's account as if it were the legitimate token pool PDA. The attacker may utilize this manipulated token_pool_pda to compress tokens, which involves sending tokens to this account. Since the program does not validate the seeds, the tokens would be added to the attacker's account. Consequently, when decompressing tokens, the attacker will utilize the same token_pool_pda account to withdraw the tokens that were originally in the legitimate token pool. This would allow the attacker to steal tokens from the genuine token pool account and move them to their own account.","rust
use crate::POOL_SEED;
#[derive(Accounts)]
pub struct TransferInstruction<'info> {
    /// UNCHECKED: only pays fees. @@ -34,28 +33,28 @@
    /// (different program) checked in light system program to derive
    /// cpi_authority_pda and check that this program is the signer of the cpi.
    pub self_program: Program<'info, crate::program::LightCompressedToken>,
    
    #[account(
        mut, 
        seeds = [POOL_SEED, &token_pool_pda.mint.key().to_bytes()],
        bump
    )]
    pub token_pool_pda: Option<Account<'info, TokenAccount>>, 

    #[account(
        mut, 
        constraint= if token_pool_pda.is_some() {
                Ok(token_pool_pda.as_ref().unwrap().key() != compress_or_decompress_token_account.key())
            } else { 
                err!(crate::ErrorCode::TokenPoolPdaUndefined)
            }? 
        @crate::ErrorCode::IsTokenPoolPda
    )]
    pub compress_or_decompress_token_account: Option<Account<'info, TokenAccount>>,
    
    pub token_program: Option<Program<'info, Token>>,
    pub system_program: Program<'info, System>,
}","rust
programs/compressed-token/src/instructions/transfer.rs
    
#[derive(Accounts)]
pub struct TransferInstruction<'info> {
    /// UNCHECKED: only pays fees. 
    @@ -34,28 +33,28 @@
    /// (different program) checked in light system program to derive
    /// cpi_authority_pda and check that this program is the signer of the cpi.
    pub self_program: Program<'info, crate::program::LightCompressedToken>,
    
    #[account(mut)]
    pub token_pool_pda: Option<Account<'info, TokenAccount>>,
    
    #[account(mut, constraint= if token_pool_pda.is_some() {
        Ok(token_pool_pda.as_ref().unwrap().key() != compress_or_decompress_token_account.key())
    } else {
        err!(crate::ErrorCode::TokenPoolPdaUndefined)
    }? @crate::ErrorCode::IsTokenPoolPda)]
    pub compress_or_decompress_token_account: Option<Account<'info, TokenAccount>>,
    
    pub token_program: Option<Program<'info, Token>>,
    
    pub system_program: Program<'info, System>,
}

programs/compressed-token/src/spl_compression.rs 

use crate::{
    process_transfer::get_cpi_signer_seeds,
    CompressedTokenInstructionDataTransfer,
    TransferInstruction,
    POOL_SEED,
};

pub fn process_compression_or_decompression<'info>( @@ -17,6 +17,20 @@ ) {}

pub fn spl_token_pool_derivation(
    mint: &Pubkey,
    program_id: &Pubkey,
    token_pool_pubkey: &Pubkey,
) -> Result<()> {
    let seeds = &[POOL_SEED, &mint.to_bytes()[..]];
    let (pda, _bump_seed) = Pubkey::find_program_address(seeds, program_id);

    if pda == *token_pool_pubkey {
        Ok(())
    } else {
        err!(crate::ErrorCode::InvalidTokenPoolPda)
    }
}

pub fn decompress_spl_tokens<'info>(
    inputs: &CompressedTokenInstructionDataTransfer,
    ctx: &Context<'_, '_, '_, 'info, TransferInstruction<'info>>,
    @@ -29,6 +43,8 @@ 
    Some(token_pool_pda) => token_pool_pda.to_account_info(),
    None => return err!(crate::ErrorCode::CompressedPdaUndefinedForDecompress),
};

spl_token_pool_derivation(&inputs.mint, &crate::ID, &token_pool_pda.key())?;

let amount = match inputs.compress_or_decompress_amount {
    Some(amount) => amount,
    None => return err!(crate::ErrorCode::DeCompressAmountUndefinedForDecompress),
    @@ -50,10 +66,11 @@ 
    inputs: &CompressedTokenInstructionDataTransfer,
    ctx: &Context<'_, '_, '_, 'info, TransferInstruction<'info>>,
) -> Result<()> {
    let recipient_token_pool = match ctx.accounts.token_pool_pda.as_ref() {
        Some(token_pool_pda) => token_pool_pda.to_account_info(),
        None => return err!(crate::ErrorCode::CompressedPdaUndefinedForCompress),
    };

    spl_token_pool_derivation(&inputs.mint, &crate::ID, &recipient_token_pool.key())?;

    let amount = match inputs.compress_or_decompress_amount {
        Some(amount) => amount,
        None => return err!(crate::ErrorCode::DeCompressAmountUndefinedForCompress),
        @@ -65,28 +82,28 @@
        .as_ref()
        .unwrap()
        .to_account_info(),
    &recipient_token_pool,
    &ctx.accounts.authority.to_account_info(),
    &ctx.accounts
        .token_program
        .as_ref()
        .unwrap()
        .to_account_info(),
    amount,
    )
}",Critical,Ensure that the token_pool_pda account is validated against the expected seeds and bump values to confirm that it is derived correctly.,https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/162f0926-b84f-4d4a-8966-139fc610a524/light_protocol_audit_final.pdf?table=block&id=0a8bcc85-0c10-495b-92a7-701e5f90053a&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742702400000&signature=NcxekgBOO8I0tPeMN5PuHHA9Np-04BAcxUx1KdjBIso&downloadName=light_protocol_audit_final.pdf,High
Sol-202,"Utilization of Incorrect Authority for Token Transfers spl_compression::compress_spl_tokens is intended to transfer SPL tokens from a specified token account (compress_or_decompress_token_account) to a token pool account (token_pool_pda) to compress tokens.  In the function, transfer is called with cpi_authority_pda as the authority for the token transfer. This implies that cpi_authority_pda is utilized to authorize the transfer instead of ctx.accounts.authority, which is typically expected to be the signer or authority responsible for the action.  The attacker may set up both the token_pool_pda and the compress_or_decompress_token_account to point to the same token account by creating a token account and utilizing it as both the source and destination for the transfer. Since cpi_authority_pda is utilized as the authority, the attacker may authorize the transfer even if it is a self-transfer.  With tokens effectively self-transferred to a pool account, the attacker may then decompress the tokens. Since the attacker controls both accounts involved in the transfer, they may effectively steal tokens from the pool.","rust
use account_compression::utils::constants::CPI_AUTHORITY_PDA_SEED;
use anchor_lang::{prelude::*, solana_program::account_info::AccountInfo};
use anchor_spl::token::Transfer;
use crate::{CompressedTokenInstructionDataTransfer, TransferInstruction};

pub fn compress_spl_tokens<'info>(
    inputs: &CompressedTokenInstructionDataTransfer,
    ctx: &Context<'_, '_, '_, 'info, TransferInstruction<'info>>,
) -> Result<()> 
{
    [...]
    transfer(
        &ctx.accounts
            .compress_or_decompress_token_account
            .as_ref()
            .unwrap()
            .to_account_info(),
        &recipient,
        &ctx.accounts.cpi_authority_pda.to_account_info(),
        [...]
    )
}

pub fn process_compression_or_decompression<'info>(
    inputs: &CompressedTokenInstructionDataTransfer,
    ctx: &Context<'_, '_, '_, 'info, TransferInstruction<'info>>,
) -> Result<()> 
{
    if inputs.is_compress {
        compress_spl_tokens(inputs, ctx)
    } else if inputs.compress_or_decompress_amount.is_some() {
        decompress_spl_tokens(inputs, ctx)
    } else {
        Ok(())
    }
}

pub fn transfer<'info>(
    from: &AccountInfo<'info>,
    to: &AccountInfo<'info>,
    authority: &AccountInfo<'info>,
    token_program: &AccountInfo<'info>,
    amount: u64,
) -> Result<()> 
{
    let (_, bump) = anchor_lang::prelude::Pubkey::find_program_address(
        &[CPI_AUTHORITY_PDA_SEED], 
        &crate::ID
    );
    let bump = &[bump];
    let seeds = &[&[CPI_AUTHORITY_PDA_SEED, bump][..]];
    let accounts = Transfer {
        from: from.to_account_info(),
        to: to.to_account_info(),
        authority: authority.to_account_info(),
    };
    let cpi_ctx = CpiContext::new_with_signer(
        token_program.to_account_info(), 
        accounts, 
        seeds
    );
    
    anchor_spl::token::transfer(cpi_ctx, amount)
}","rust
use anchor_lang::{prelude::*, solana_program::account_info::AccountInfo}; 
use anchor_spl::token::Transfer; 
use crate:: { 
    process_transfer::get_cpi_signer_seeds, 
    CompressedTokenInstructionDataTransfer, 
    TransferInstruction, 
}; 

pub fn process_compression_or_decompression<'info>(
    inputs: &CompressedTokenInstructionDataTransfer, 
    ctx: &Context<'_, '_, '_, 'info, TransferInstruction<'info>>,
) -> Result<()> { 
    if inputs.is_compress { 
        compress_spl_tokens(inputs, ctx) 
    } else { 
        decompress_spl_tokens(inputs, ctx) 
    } 
}

@@ -59,39 +59,54 @@ None => return err!(crate::ErrorCode::DeCompressAmountUndefinedForCompress), };

pub fn transfer_compress<'info>(
    from: &AccountInfo<'info>,
    to: &AccountInfo<'info>,
    authority: &AccountInfo<'info>,
    token_program: &AccountInfo<'info>,
    amount: u64,
) -> Result<()> { 
    let accounts = Transfer { 
        from: from.to_account_info(),
        to: to.to_account_info(),
        authority: authority.to_account_info(),
    }; 

    let cpi_ctx = CpiContext::new(token_program.to_account_info(), accounts); 
    
    anchor_spl::token::transfer(cpi_ctx, amount) 
}

pub fn transfer<'info>(
    from: &AccountInfo<'info>,
    to: &AccountInfo<'info>,
    authority: &AccountInfo<'info>,
    token_program: &AccountInfo<'info>,
    amount: u64,
) -> Result<()> { 
    let signer_seeds = get_cpi_signer_seeds(); 
    let signer_seeds_ref = &[&signer_seeds[..]]; 

    let accounts = Transfer { 
        from: from.to_account_info(),
        to: to.to_account_info(),
        authority: authority.to_account_info(),
    };
    
    let cpi_ctx = CpiContext::new_with_signer(token_program.to_account_info(), accounts, signer_seeds_ref); 
    anchor_spl::token::transfer(cpi_ctx, amount) 
}",Critical,ensure that ctx.accounts.authority is used as the authority for token transfers rather than cpi_authority_pda. This ensures that only authorized signers may approve transfers.,https://github.com/Lightprotocol/light-protocol/commit/043e22ad788c9e4b7ac03f07bb2613d081830a39#diff-98099715f41e2c848d7f1498327a3d8b6a3e94e413430c8dd5dde402bf518f65,High
Sol-203,"Changelog Path Update Error. In the original implementation of append_batch, the fillup_index is calculated to determine the upper limit for computing the Merkle path. It includes the condition self.next_index.trailing_ones() as usize + 1, which consists of the last node in the Merkle path computation.  However, during the loop that updates the changelog paths, there is a check if i < self.height - 1 to update the paths. This implies it attempts to update the path even for the last node.  The issue arises because the fillup_index calculation considers the last node (leaf) to be part of the Merkle path computation. Therefore, when updating the changelog paths, it incorrectly attempts to update the path for the last node, which should not be updated.  This inconsistency may result in incorrect Merkle proofs or paths stored in the changelog.","rust
pub fn append_batch(
    &mut self,
    leaves: &[&[u8; 32]],
) -> Result<(usize, usize), ConcurrentMerkleTreeError> {
    // ...
    for (leaf_i, leaf) in leaves.iter().enumerate() {
        // Limit until which we fill up the current Merkle path.
        let fillup_index = if leaf_i < (leaves.len() - 1) {
            self.next_index.trailing_ones() as usize + 1
        } // ...
        for i in 0..fillup_index {
            let is_left = current_index % 2 == 0;
            current_node = if is_left {
                // ...
            } else {
                H::hashv(&[&self.filled_subtrees[i], &current_node])?
            };
            if i < self.height - 1 {
                self.changelog[self.current_changelog_index].path[i + 1] = current_node;
                for leaf_j in 0..leaf_i {
                    let changelog_index = (first_changelog_index + leaf_j) % self.changelog_capacity;
                    if self.changelog[changelog_index].path[i + 1] == [0u8; 32] {
                        self.changelog[changelog_index].path[i + 1] = current_node;
                    }
                }
            }
            current_index /= 2;
        }
        // ...
    }
    // ...
} 

// ...

fn append_batch_common<
    const WITH_PROOFS: bool,
>(
    &mut self,
    leaves: &[&[u8; 32]],
    mut proofs: Option<&mut [&mut BoundedVec<[u8; 32]>]>,
) -> Result<(usize, usize), ConcurrentMerkleTreeError> {
    // ...
}
// ...","Rust
/// Appends a batch of new leaves to the tree.     
///     
/// This method contains the common logic and is not intended for external     
/// use. Callers should choose between [`append_batch`](ConcurrentMerkleTree::append_batch)     
/// and [`append_batch_with_proofs`](ConcurrentMerkleTree::append_batch_with_proofs).     
fn append_batch_common<
    // The only purpose of this const generic is to force compiler to         
    // produce separate functions, with and without proof.         
    //
    // Unfortunately, using `Option` is not enough:         
    //
    // https://godbolt.org/z/fEMMfMdPc  
    // https://godbolt.org/z/T3dxnjMzz  
    //
    // Using the const generic helps and ends up generating two separate 
    // functions:  
    //
    // https://godbolt.org/z/zGnM7Ycn1         
    const WITH_PROOFS: bool,
>(
    &mut self,
    leaves: &[&[u8; 32]],
    // Slice for saving Merkle proofs.         
    //         
    // Currently it's used only for indexed Merkle trees.
    mut proofs: Option<&mut [&mut BoundedVec<[u8; 32]>]>,
) -> Result<(usize, usize), ConcurrentMerkleTreeError> {
    if leaves.is_empty() {
        return Err(ConcurrentMerkleTreeError::EmptyLeaves);
    }
    if (self.next_index() + leaves.len() - 1) >= 1 << self.height {
        return Err(ConcurrentMerkleTreeError::TreeFull);
    }
    if leaves.len() > self.changelog.capacity() {
        return Err(ConcurrentMerkleTreeError::BatchGreaterThanChangelog(
            leaves.len(),
            self.changelog.capacity(),
        ));
    }
    let first_leaf_index = self.next_index();
    let first_changelog_index = (self.changelog.last_index() + 1) % self.changelog.capacity();
    let first_sequence_number = self.sequence_number() + 1;
    
    for (leaf_i, leaf) in leaves.iter().enumerate() {
        self.changelog
        .push(ChangelogEntry::<HEIGHT>::default_with_index(
            first_leaf_index + leaf_i,
        ));
        let changelog_index = self.changelog_index();
        let mut current_index = self.next_index();
        let mut current_node = **leaf;
        self.changelog[changelog_index].path[0] = **leaf;
        
        // omitted: very long loop block

        self.changelog[changelog_index].root = current_node;
        self.roots.push(current_node);
        self.inc_next_index()?;
        self.inc_sequence_number()?;
        self.set_rightmost_leaf(leaf);
    }
    
    if self.canopy_depth > 0 {
        self.update_canopy(first_changelog_index, leaves.len());
    }

    Ok((first_changelog_index, first_sequence_number))
}",High,Update the loop to exclude the last iteration (fillup_index - 1) during the changelog update. The fillup_index - 1 condition should be incorporated into the i < self.height - 1 check.,https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/162f0926-b84f-4d4a-8966-139fc610a524/light_protocol_audit_final.pdf?table=block&id=0a8bcc85-0c10-495b-92a7-701e5f90053a&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742702400000&signature=NcxekgBOO8I0tPeMN5PuHHA9Np-04BAcxUx1KdjBIso&downloadName=light_protocol_audit_final.pdf,High
Sol-204,"Absence of Index Validation and Initialization. The IndexedMerkleTree::update function lacks checks to ensure that the new element (new_element) is inserted at its designated index (new_element.index). This validation is critical because the leaf_index in the Merkle tree is derived from new_element.index.  The Merkle tree relies on the correct placement of elements at their respective indices. If an element is inserted at an incorrect index, or if the index does not match the expected value, it will lead to inconsistencies in the Merkle tree structure.","rust
pub fn update(
    &mut self, 
    mut changelog_index: usize, 
    indexed_changelog_index: usize, 
    mut new_element: IndexedElement<I>, 
    mut low_element: IndexedElement<I>, 
    mut low_element_next_value: BigUint, 
    low_leaf_proof: &mut BoundedVec<[u8; 32]>,
) -> Result<IndexedMerkleTreeUpdate<I>, IndexedMerkleTreeError> {
    self.patch_elements_and_proof(
        indexed_changelog_index, 
        &mut changelog_index, 
        &mut new_element, 
        &mut low_element, 
        &mut low_element_next_value, 
        low_leaf_proof,
    )?;
    
    // Check that the value of `new_element` belongs to the range of `old_low_element`.
    if low_element.next_index == I::zero() {
        // In this case, the `old_low_element` is the greatest element. The value of `new_element` needs to be greater than the value
        // of `old_low_element` (and therefore, be the greatest).
        if new_element.value <= low_element.value {
            return Err(IndexedMerkleTreeError::LowElementGreaterOrEqualToNewElement);
        }
    } else {
        // The value of `new_element` needs to be greater than the value of `old_low_element` (and therefore, be the greatest).
        if new_element.value <= low_element.value {
            return Err(IndexedMerkleTreeError::LowElementGreaterOrEqualToNewElement);
        }
        // The value of `new_element` needs to be lower than the value of next element pointed by `old_low_element`.
        if new_element.value >= low_element_next_value {
            return Err(IndexedMerkleTreeError::NewElementGreaterOrEqualToNextElement);
        }
    }
    
    if new_element.next_index != low_element.next_index {
        return Err(IndexedMerkleTreeError::NewElementNextIndexMismatch);
    }
    
    // Instantiate `new_low_element` - the low element with updated values.
    let new_low_element = IndexedElement {
        index: low_element.index,
        value: low_element.value.clone(),
        next_index: new_element.index,
    };
    
    // Update low element. If the `old_low_element` does not belong to the tree, validating the proof is going to fail.
    let old_low_leaf = low_element.hash::<H>(&low_element_next_value)?;
    let new_low_leaf = new_low_element.hash::<H>(&new_element.value)?;
    let (new_changelog_index, _) = self.merkle_tree.update(
        changelog_index, 
        &old_low_leaf,
        &new_low_leaf, 
        low_element.index.into(), 
        low_leaf_proof,
    )?;
    
    // Emit changelog entry for low element.
    let new_low_element = RawIndexedElement { 
        value: bigint_to_be_bytes_array::<32>(&new_low_element.value).unwrap(),
        next_index: new_low_element.next_index, 
        next_value: bigint_to_be_bytes_array::<32>(&new_element.value)?,
        index: new_low_element.index,
    };
    
    let low_element_changelog_entry = IndexedChangelogEntry { 
        element: new_low_element,
        proof: low_leaf_proof.as_slice()[..NET_HEIGHT].try_into().unwrap(), 
        changelog_index: new_changelog_index,
    };

    self.indexed_changelog.push(low_element_changelog_entry);
    
    // New element is always the newest one in the tree. Since we support concurrent updates, the index provided by the caller might be outdated.
    // Let's just use the latest index indicated by the tree.
    new_element.index = I::try_from(self.next_index()).map_err(|_| IndexedMerkleTreeError::IntegerOverflow)?;
    
    // Append new element.
    let mut proof = BoundedVec::with_capacity(self.height);
    let new_leaf = new_element.hash::<H>(&low_element_next_value)?;
    let (new_changelog_index, _) = self.merkle_tree.append_with_proof(&new_leaf, &mut proof)?;
    
    // Prepare raw new element to save in changelog.
    let raw_new_element = RawIndexedElement {
        value: bigint_to_be_bytes_array::<32>(&new_element.value).unwrap(),
        next_index: new_element.next_index,
        next_value: bigint_to_be_bytes_array::<32>(&low_element_next_value)?,
        index: new_element.index,
    };
    
    // Emit changelog entry for new element.
    let new_element_changelog_entry = IndexedChangelogEntry {
        element: raw_new_element,
        proof: proof.as_slice()[..NET_HEIGHT].try_into().unwrap(),
        changelog_index: new_changelog_index,
    };
    
    self.indexed_changelog.push(new_element_changelog_entry);
    
    let output = IndexedMerkleTreeUpdate {
        new_low_element,
        new_low_element_hash: new_low_leaf,
        new_high_element: raw_new_element,
        new_high_element_hash: new_leaf,
    };
    
    Ok(output)  
}","rust
pub fn update(
    &mut self,
    mut changelog_index: usize,
    indexed_changelog_index: usize,
    new_element_value: BigUint,
    mut low_element: IndexedElement<I>,
    mut low_element_next_value: BigUint,
    low_leaf_proof: &mut BoundedVec<[u8; 32]>,
) -> Result<IndexedMerkleTreeUpdate<I>, IndexedMerkleTreeError> {

    let mut new_element = IndexedElement {
        index: I::try_from(self.merkle_tree.next_index())
            .map_err(|_| IndexedMerkleTreeError::IntegerOverflow)?,
        value: new_element_value,
        next_index: low_element.next_index,
    };
    
    self.patch_elements_and_proof(
        indexed_changelog_index,
        &mut changelog_index,
        &mut new_element,
        &mut low_element,
        &mut low_element_next_value,
        low_leaf_proof,
    )?;
    
    if low_element.next_index == I::zero() {
        if new_element.value <= low_element.value {
            return Err(IndexedMerkleTreeError::LowElementGreaterOrEqualToNewElement);
        }
    } else {
        if new_element.value <= low_element.value {
            return Err(IndexedMerkleTreeError::LowElementGreaterOrEqualToNewElement);
        }
        if new_element.value >= low_element_next_value {
            return Err(IndexedMerkleTreeError::NewElementGreaterOrEqualToNextElement);
        }
    }
    
    let new_low_element = IndexedElement {
        index: low_element.index,
        value: low_element.value.clone(),
        next_index: new_element.index,
    };
    
    let old_low_leaf = low_element.hash::<H>(&low_element_next_value)?;
    let new_low_leaf = new_low_element.hash::<H>(&new_element.value)?;

    let (new_changelog_index, _) = self.merkle_tree.update(
        changelog_index,
        &old_low_leaf,
        &new_low_leaf,
        low_element.index.into(),
        low_leaf_proof,
    )?;
    
    let new_low_element = RawIndexedElement {
        value: bigint_to_be_bytes_array::<32>(&new_low_element.value).unwrap(),
        next_index: new_low_element.next_index,
        next_value: bigint_to_be_bytes_array::<32>(&new_element.value)?,
        index: new_low_element.index,
    };

    let low_element_changelog_entry = IndexedChangelogEntry {
        element: new_low_element,
        proof: low_leaf_proof.as_slice()[..NET_HEIGHT].try_into().unwrap(),
        changelog_index: new_changelog_index,
    };
    
    self.indexed_changelog.push(low_element_changelog_entry);
    
    new_element.index =
        I::try_from(self.next_index()).map_err(|_| IndexedMerkleTreeError::IntegerOverflow)?;
    
    let mut proof = BoundedVec::with_capacity(self.height);

    let new_leaf = new_element.hash::<H>(&low_element_next_value)?;

    let (new_changelog_index, _) = self.merkle_tree.append_with_proof(&new_leaf, &mut proof)?;

    let raw_new_element = RawIndexedElement {
        value: bigint_to_be_bytes_array::<32>(&new_element.value).unwrap(),
        next_index: new_element.next_index,
        next_value: bigint_to_be_bytes_array::<32>(&low_element_next_value)?,
        index: new_element.index,
    };
    
    let new_element_changelog_entry = IndexedChangelogEntry {
        element: raw_new_element,
        proof: proof.as_slice()[..NET_HEIGHT].try_into().unwrap(),
        changelog_index: new_changelog_index,
    };

    self.indexed_changelog.push(new_element_changelog_entry);
    
    let output = IndexedMerkleTreeUpdate {
        new_low_element,
        new_low_element_hash: new_low_leaf,
        new_high_element: raw_new_element,
        new_high_element_hash: new_leaf,
    };
    
    Ok(output)
}",High,"Verify that new_element is inserted at new_element.index within the update function. Additionally, since init_value is inserted at index one, ensure that add_highest_element is invoked as part of the tree initialization process.",https://github.com/Lightprotocol/light-protocol/commit/0210a9ac96bff063b3c40d1a50d8724e7d274d85#diff-438f5150c0c85e9cf699a09779704ff2c8d9bd76e77a4cf6b510db11268c6ec8,High
Sol-205,"Inclusion of Lamports as Rent in Rollover Fee Calculation. In the current implementation of the account-compression program, the lamports in the tree and queue are considered as rent for rollover fee calculations. This gives rise to several issues:  During the rollover process, the rent lamports are considered for withdrawal from the old Merkle tree. compute_rollover_fee utilizes ceiling division to calculate the fee based on the rent. Due to ceiling division, the protocol may charge slightly more in fees than required to cover the rent.  For instance, if 10 lamports are the rent and the tree supports 3 node insertions, the ideal fee would be 10 / 3 ≈ 3.33 lamports per insertion. However, with ceiling division, the fee is rounded up to 4 lamports per insertion. Thus, for 3 insertions, the protocol will collect 4 × 3 = 12 lamports in fees instead of 10. These extra lamports collected (2 lamports in this case) are not extracted and remain locked in the tree/queue accounts, effectively becoming inaccessible or unusable funds.  Moreover, the rollover process considers the lamports in the new accounts as rent, allowing that amount to be fetched from the old tree/queue accounts to the fee account. Normally, the program is designed to avoid closing old tree accounts by default (as close_threshold is set to None), but by passing extra lamports to new accounts, the owner may withdraw the total lamports from the old account, resulting in the deletion of the old account.  This manipulation allows the authority owner to bypass the program’s default behavior, prematurely closing and deleting old tree accounts.  ","Rust
pub fn compute_rollover_fee(rollover_threshold: u64, tree_height: u32, rent: u64,) -> Result<u64, UtilsError> {
    let number_of_transactions = 1 << tree_height;
    if rollover_threshold > 100 {
        return Err(UtilsError::InvalidRolloverThreshold);
    }
    // rent / (total_number_of_leaves * (rollover_threshold / 100))
    // (with ceil division)
    Ok((rent * 100).div_ceil(number_of_transactions * rollover_threshold))
}

programs/account-compression/src/instructions/rollover_state_merkle_tree_and_queue.rs

use crate::{
    assert_size_equal,
    processor::{
        initialize_concurrent_merkle_tree::process_initialize_state_merkle_tree,
        initialize_nullifier_queue::process_initialize_nullifier_queue,
    },
    state::{
        queue::{queue_from_bytes_zero_copy_mut, QueueAccount},
        StateMerkleTreeAccount,
    },
    state_merkle_tree_from_bytes_zero_copy,
    utils::{
        check_signer_is_registered_or_authority::{
            check_signer_is_registered_or_authority, GroupAccounts,
        },
    },
};

pub fn process_rollover_state_merkle_tree_nullifier_queue_pair<'a, 'b, 'c: 'info, 'info>(
    ctx: Context<'a, 'b, 'c, 'info, RolloverStateMerkleTreeAndNullifierQueue<'info>>,
) -> Result<()> {
    assert_size_equal(
        &ctx.accounts.old_nullifier_queue.to_account_info(),
        &ctx.accounts.new_nullifier_queue.to_account_info(),
        ""Queue size mismatch"",
    )?;
    assert_size_equal(
        &ctx.accounts.old_state_merkle_tree.to_account_info(),
        &ctx.accounts.new_state_merkle_tree.to_account_info(),
        ""Merkle tree size mismatch"",
    )?;

    let queue_metadata = {
        //...
    };

    let lamports = ctx.accounts.new_nullifier_queue.get_lamports()
        + ctx.accounts.new_state_merkle_tree.get_lamports();

    transfer_lamports(
        &ctx.accounts.old_state_merkle_tree.to_account_info(),
        &ctx.accounts.fee_payer.to_account_info(),
        lamports,
    )?;
    Ok(())
}","rust
// file: programs/account-compression/src/utils/check_account.rs
use anchor_lang::prelude::*;
use anchor_lang::solana_program::{account_info::AccountInfo, msg, rent::Rent};
use crate::errors::AccountCompressionErrorCode;

/// Checks that the account balance is equal to rent exemption.
pub fn check_account_balance_is_rent_exempt(account_info: &AccountInfo) -> Result<u64> {
    let lamports = account_info.lamports();
    let rent_exemption = (Rent::get()?).minimum_balance(account_info.data_len());
    if lamports != rent_exemption {
        msg!(
            ""Account {:?} lamports is not equal to rent exemption: {} != {}"",
            account_info.key(),
            lamports,
            rent_exemption
        );
        return err!(AccountCompressionErrorCode::InvalidAccountBalance);
    }
    Ok(lamports)
}

// file: programs/account-compression/src/instructions/rollover_state_merkle_tree_and_queue.rs
use crate::{
    assert_size_equal,
    processor::{
        initialize_concurrent_merkle_tree::process_initialize_state_merkle_tree,
        initialize_nullifier_queue::process_initialize_nullifier_queue,
    },
    state::{
        queue::{queue_from_bytes_zero_copy_mut, QueueAccount},
        StateMerkleTreeAccount,
    },
    state_merkle_tree_from_bytes_zero_copy,
    utils::{
        check_account::check_account_balance_is_rent_exempt,
        check_signer_is_registered_or_authority::{
            check_signer_is_registered_or_authority, GroupAccounts,
        },
    },
};

pub fn process_rollover_state_merkle_tree_nullifier_queue_pair<'a, 'b, 'c: 'info, 'info/**
    // rest of the code ...
});",High,"These issues may be mitigated by transferring total_lamports - minimum_rent to the fee account, ensuring that all lamports except the required rent are collected as a fee.  However, this approach introduces a rug pull risk: the tree authority could initialize the tree with excess lamports to artificially inflate the rollover fee, eventually reclaiming both the intended fees and the extra lamports.  To prevent this, it would be more secure to calculate rent explicitly using: let minimum_rent = (Rent::get()?).minimum_balance(size); This ensures that only the required rent is excluded from the fee calculation, reducing the risk of manipulation.",https://github.com/Lightprotocol/light-protocol/commit/afafb283710ec2c2b67ecbc9a0a38dd633fa9b2,High
Sol-206,"Failure to Update Canopy Nodes. The update function in ConcurrentMerkleTree is responsible for updating a leaf node and ensuring that the associated proof remains valid. However, it does not include functionality to update the canopy nodes when a leaf node is updated.  In Merkle trees, a canopy is a subset of nodes that are used in proof generation but are not part of the main tree structure. When generating Merkle proofs, canopy nodes are utilized to compute intermediate hashes.  If canopy nodes are not updated along with the main tree structure, the generated proofs will include outdated or incorrect canopy node hashes. This inconsistency will cause subsequent proof validation to fail.","rust
pub fn update(
    &mut self, 
    changelog_index: usize, 
    old_leaf: &[u8; 32],
    new_leaf: &[u8; 32], 
    leaf_index: usize,
    proof: &mut BoundedVec<[u8; 32]>,
) -> Result<(usize, usize), ConcurrentMerkleTreeError> {
    let expected_proof_len = self.height - self.canopy_depth;

    if proof.len() != expected_proof_len {
        return Err(ConcurrentMerkleTreeError::InvalidProofLength(
            expected_proof_len,
            proof.len(),
        ));
    }

    if leaf_index >= self.next_index() {
        return Err(ConcurrentMerkleTreeError::CannotUpdateEmpty);
    }

    if self.canopy_depth > 0 {
        self.update_proof_from_canopy(leaf_index, proof)?;
    }

    if self.changelog_capacity > 0 && changelog_index != self.changelog_index() {
        self.update_proof_from_changelog(changelog_index, leaf_index, proof)?;
    }

    self.validate_proof(old_leaf, leaf_index, proof)?;
    self.update_leaf_in_tree(new_leaf, leaf_index, proof);

    /// ...
    /// other part of code
    /// ...
}","merkle-tree/concurrent/src/lib.rs
:/// Updates the leaf under `leaf_index` with the `new_leaf` value.
/// 1. Computes the new path and root from `new_leaf` and Merkle proof (`proof`).
/// 2. Stores the new path as the latest changelog entry and increments the latest changelog index.
/// 3. Stores the latest root and increments the latest root index.
/// 4. If new leaf is at the rightmost index, stores it as the new rightmost leaf and stores
///    the Merkle proof as the new rightmost proof.
///
/// # Validation
///
/// This method doesn't validate the proof. Caller is responsible for doing that before.
fn update_leaf_in_tree(
    &mut self,
    new_leaf: &[u8; 32],
    leaf_index: usize,
    proof: &BoundedVec<[u8; 32]>,
) -> Result<(usize, usize), ConcurrentMerkleTreeError> {
    let mut current_node = *new_leaf;
    let mut changelog_path = [[0u8; 32]; HEIGHT];

    for (level, sibling) in proof.iter().enumerate() {
        changelog_path[level] = current_node;
        current_node = compute_parent_node::<H>(&current_node, sibling, leaf_index, level)?;
    }

    self.inc_sequence_number()?;

    let changelog_entry = ChangelogEntry::new(current_node, changelog_path, leaf_index);

    self.roots.push(current_node);

    // Check if the leaf is the last leaf in the tree.
    if self.next_index() < (1 << self.height) {
        changelog_entry.update_proof(self.next_index(), &mut self.filled_subtrees)?;
        // Check if we updated the rightmost leaf.
        if leaf_index >= self.current_index() {
            self.set_rightmost_leaf(new_leaf);
        }
    }

    self.changelog.push(changelog_entry);

    if self.canopy_depth > 0 {
        self.update_canopy(self.changelog.last_index(), 1);
    }

    Ok((self.changelog.last_index(), self.sequence_number()))
}

/// Replaces the `old_leaf` under the `leaf_index` with a `new_leaf`, using
/// the given `proof` and `changelog_index` (pointing to the changelog entry
/// which was the newest at the time of preparing the proof).
#[inline(never)]
pub fn update(
    &mut self,
    changelog_index: usize,
    old_leaf: &[u8; 32],
    new_leaf: &[u8; 32],
    leaf_index: usize,
    proof: &mut BoundedVec<[u8; 32]>,
) -> Result<(usize, usize), ConcurrentMerkleTreeError> {
    let expected_proof_len = self.height - self.canopy_depth;

    if proof.len() != expected_proof_len {
        return Err(ConcurrentMerkleTreeError::InvalidProofLength(
            expected_proof_len,
            proof.len(),
        ));
    }

    if leaf_index >= self.next_index() {
        return Err(ConcurrentMerkleTreeError::CannotUpdateEmpty);
    }

    if self.canopy_depth > 0 {
        self.update_proof_from_canopy(leaf_index, proof)?;
    }

    if changelog_index != self.changelog_index() {
        self.update_proof_from_changelog(changelog_index, leaf_index, proof)?;
    }

    self.validate_proof(old_leaf, leaf_index, proof)?;
    self.update_leaf_in_tree(new_leaf, leaf_index, proof)
}merkle-tree/reference/src/lib.rs:/// Number of nodes to include in canopy, based on `canopy_depth`.
pub fn canopy_size(&self) -> usize {
    (1 << (self.canopy_depth + 1)) - 2
}

fn update_upper_layers(&mut self, mut i: usize) -> Result<(), HasherError> {
    for level in 1..self.height {
        i /= 2;
        // ... (rest of the function implementation assumed to be unchanged)
    }
    Ok(())
}

pub fn get_canopy(&self) -> Result<BoundedVec<[u8; 32]>, BoundedVecError> {
    if self.canopy_depth == 0 {
        return Ok(BoundedVec::with_capacity(0));
    }

    let mut canopy = BoundedVec::with_capacity(self.canopy_size());
    let mut num_nodes_in_level = 2;

    for i in 0..self.canopy_depth {
        let level = self.height - 1 - i;
        for j in 0..num_nodes_in_level {
            let node = self.layers[level]
                .get(j)
                .cloned()
                .unwrap_or(H::zero_bytes()[level]);
            canopy.push(node)?;
        }
        num_nodes_in_level *= 2;
    }

    Ok(canopy)
}",High,Include logic in the update function to update the canopy nodes alongside the main tree structure whenever a leaf node is modified.,https://github.com/Lightprotocol/light-protocol/commit/587ca5f39203cfca1591fde6de02eb2911a5c258#diff-557b7f9d167847113d9dbe17a08803a31d9139ea1f7420cedfa19f8b360f1ee4,High
Sol-207,"Hash Collision in Merkle Tree. This vulnerability arises from an assumption in create_cpi_accounts_and_instruction_data that all remaining accounts in the ctx.remaining_accounts vector are unique. Specifically, it assumes that different Merkle tree accounts should appear only once in the vector.  However, if an attacker manipulates ctx.remaining_accounts to include the same Merkle tree account multiple times (e.g., remaining_accounts[0] = tree_key and remaining_accounts[1] = tree_key), then different output_compressed_accounts may reference the same tree but at different indices.  Each time merkle_tree_index changes between iterations, the value of num_leaves_in_tree is reset to zero. As a result, output_compressed_account_indices[j] for both compressed accounts will be identical, causing multiple compressed accounts to share the same leaf index in the same tree.  This leads to identical leaf hashes being inserted into the tree at the same index for different accounts—resulting in a hash collision in the Merkle tree.","rust
/// Creates CPI accounts, instruction data, and performs checks.
/// - Merkle tree indices must be in order.
/// - Hashes output accounts for insertion and event.
/// - Collects sequence numbers for event.
///
/// Checks:
/// 1. Checks whether a Merkle tree is program owned, if so checks write
///    eligibility.
/// 2. Checks ordering of Merkle tree indices.
/// 3. Checks that addresses in output compressed accounts have been created or
///    exist in input compressed accounts. An address may not be used in an
///    output compressed accounts. This will close the account.
/// 
#[allow(clippy::too_many_arguments)]
pub fn create_cpi_accounts_and_instruction_data<'a>(
    output_compressed_accounts: &[OutputCompressedAccountWithPackedContext],
    output_compressed_account_indices: &mut [u32],
    output_compressed_account_hashes: &mut [[u8; 32]],
    compressed_account_addresses: &mut Vec<Option<[u8; 32]>>,
    invoking_program: &Option<Pubkey>,
    hashed_pubkeys: &mut Vec<(Pubkey, [u8; 32])>,
    sequence_numbers: &mut Vec<MerkleTreeSequenceNumber>,
    remaining_accounts: &'a [AccountInfo<'a>],
    account_infos: &mut Vec<AccountInfo<'a>>,
    accounts: &mut Vec<AccountMeta>,
) -> Result<Vec<u8>> {
    // Initialization
    let mut current_index: i16 = -1;
    let mut num_leaves_in_tree: u32 = 0;
    let mut mt_next_index = 0;
    let num_leaves = output_compressed_account_hashes.len();
    let mut instruction_data = Vec::<u8>::with_capacity(12 + 33 * num_leaves);
    let mut hashed_merkle_tree = [0u8; 32];
    let mut index_merkle_tree_account = 0;

    // Anchor instruction signature.
    instruction_data.extend_from_slice(&[199, 144, 10, 82, 247, 142, 143, 7]);
    
    // Leaves vector length (for borsh compat)
    instruction_data.extend_from_slice(&(num_leaves as u32).to_le_bytes());

    // Main loop
    for (j, account) in output_compressed_accounts.iter().enumerate() {
        ...
    }

    Ok(instruction_data)
}","rust
/// Creates CPI accounts, instruction data, and performs checks. 
/// - Merkle tree indices must be in order. 
/// - Hashes output accounts for insertion and event. 
/// - Collects sequence numbers for event. 
/// 
/// Checks: 
/// 1. Checks whether a Merkle tree is program owned, if so checks write
///    eligibility. 
/// 2. Checks ordering of Merkle tree indices. 
/// 3. Checks that addresses in output compressed accounts have been created or 
///    exist in input compressed accounts. An address may not be used in an 
///    output compressed accounts. This will close the account. 

#[allow(clippy::too_many_arguments)] 
pub fn create_cpi_accounts_and_instruction_data<'a>(
     output_compressed_accounts: &[OutputCompressedAccountWithPackedContext],
     output_compressed_account_indices: &mut [u32],
     output_compressed_account_hashes: &mut [[u8; 32]],
     compressed_account_addresses: &mut Vec<Option<[u8; 32]>>,
     invoking_program: &Option<Pubkey>,
     hashed_pubkeys: &mut Vec<(Pubkey, [u8; 32])>,
     sequence_numbers: &mut Vec<MerkleTreeSequenceNumber>,
     remaining_accounts: &'a [AccountInfo<'a>],
     account_infos: &mut Vec<AccountInfo<'a>>,
     accounts: &mut Vec<AccountMeta>,
 ) -> Result<Vec<u8>> {
     let mut current_index: i16 = -1;
     let mut num_leaves_in_tree: u32 = 0;
     let mut mt_next_index = 0;
     let num_leaves = output_compressed_account_hashes.len();
     let mut instruction_data = Vec::<u8>::with_capacity(12 + 33 * num_leaves);
     let mut hashed_merkle_tree = [0u8; 32];
     let mut index_merkle_tree_account = 0;
     let number_of_merkle_trees = output_compressed_accounts.last().unwrap().merkle_tree_index as usize + 1;
     let mut merkle_tree_pubkeys = Vec::<Pubkey>::with_capacity(number_of_merkle_trees);
 
 // Anchor instruction signature.
 instruction_data.extend_from_slice(&[199, 144, 10, 82, 247, 142, 143, 7]);

 // leaves vector length (for borsh compat)
 instruction_data.extend_from_slice(&(num_leaves as u32).to_le_bytes());

 for (j, account) in output_compressed_accounts.iter().enumerate() {
     if account.merkle_tree_index as i16 == current_index {}
     else if account.merkle_tree_index as i16 > current_index {
         current_index = account.merkle_tree_index.into();
         let seq;
         (mt_next_index, _, seq) = check_program_owner_state_merkle_tree(
             &remaining_accounts[account.merkle_tree_index as usize],
             invoking_program,
         )?;

         let account_info =
             remaining_accounts[account.merkle_tree_index as usize].to_account_info();

         sequence_numbers.push(MerkleTreeSequenceNumber {
             pubkey: account_info.key(),
             seq,
         });

         hashed_merkle_tree = match hashed_pubkeys.iter().find(|x| x.0 == account_info.key()) {
             Some(hashed_merkle_tree) => hashed_merkle_tree.1,
             None => {
                 hash_to_bn254_field_size_be(&account_info.key().to_bytes())
                     .unwrap()
                     .0
             }
         };

         if merkle_tree_pubkeys.contains(&account_info.key()) {
             return err!(SystemProgramError::OutputMerkleTreeNotUnique);
         } else {
             merkle_tree_pubkeys.push(account_info.key());
         }

         accounts.push(AccountMeta {
             pubkey: account_info.key(),
             is_signer: false,
             is_writable: true,
         });

         account_infos.push(account_info);

         num_leaves_in_tree = 0;
         index_merkle_tree_account += 1;
     } else {
         return err!(SystemProgramError::OutputMerkleTreeIndicesNotInOrder);
     }

     if let Some(address) = account.compressed_account.address {
         if let Some(position) = compressed_account_addresses
             .iter()
             .filter(|x| x.is_some())
             .position(|&x| x.unwrap() == address)
         {
             compressed_account_addresses.remove(position);
         } else {
             msg!(""Remaining compressed_account_addresses: {:?}"", compressed_account_addresses);
             return Err(SystemProgramError::InvalidAddress.into());
         }
     }

     output_compressed_account_indices[j] = mt_next_index + num_leaves_in_tree;
     num_leaves_in_tree += 1;

     if account.compressed_account.data.is_some() && invoking_program.is_none() {
         msg!(""Only program owned compressed accounts can have data."");
         return err!(SystemProgramError::InvokingProgramNotProvided);
     }

     output_compressed_account_hashes[j] = account
         .compressed_account
         .hash_with_hashed_values::<Poseidon>(
             &hashed_owner,
             &hashed_merkle_tree,
             &output_compressed_account_indices[j],
         )?;

     instruction_data.extend_from_slice(&[index_merkle_tree_account - 1]);
     instruction_data.extend_from_slice(&output_compressed_account_hashes[j]);
 }

 Ok(instruction_data)
 }",High,Introduce a validation step to ensure that each Merkle tree in ctx.remaining_accounts is unique before processing. This prevents duplicate references to the same tree and mitigates the risk of hash collisions caused by repeated use of the same account.,https://github.com/Lightprotocol/light-protocol/commit/bb222d4961938607e50d5b209c84f1acceb7fca7#diff-2768b720228fc9c7fa739661abf355f30c56e018b539edf7030a39337305ea28,High
Sol-208,"Inadequate Verification of Non-executable Programs In the emit_indexer_event function, the purpose of verifying the public key and executability of the noop_program is to ensure that events are emitted through a legitimate and intended no-operation (noop) program.  However, the current validation logic for the noop_program contains a flaw. It checks whether the public key is correct and whether the program is executable simultaneously, but the logic may allow non-executable programs to pass this check.  As a result, there is a risk that a non-executable program could be incorrectly treated as valid, leading to a failed invocation when attempting to emit the event.","rust
#[inline(never)]
pub fn emit_indexer_event(data: Vec<u8>, noop_program: &AccountInfo) -> Result<()> {
    if noop_program.key() != Pubkey::new_from_array(NOOP_PUBKEY) && noop_program.executable {
        return err!(AccountCompressionErrorCode::InvalidNoopPubkey);
    } 

    let instruction = Instruction {
        program_id: noop_program.key(),
        accounts: vec![],
        data,
    };
    
    invoke(&instruction, &[noop_program.to_account_info()])?;

    Ok(())
}","rust
#[inline(never)]
pub fn emit_indexer_event(
    data: Vec<u8>, 
    noop_program: &AccountInfo
) -> Result<()> { 
    if noop_program.key() != Pubkey::new_from_array(NOOP_PUBKEY) && !noop_program.executable {
        return err!(AccountCompressionErrorCode::InvalidNoopPubkey);
    } 
    
    let instruction = Instruction {
        program_id: noop_program.key(), 
        accounts: vec![], 
        data,
    }; 
    
    invoke(&instruction, &[noop_program.to_account_info()])?;
    
    Ok(())
}",Medium,"Update the condition in emit_indexer_event to reject the noop_program if it is either not the correct noop program or if it is not executable. Specifically, ensure the condition checks:  if noop_program.key() != Pubkey::new_from_array(NOOP_PUBKEY) || !noop_program.executable {     return Err(ProgramError::InvalidArgument); }  This guarantees that the event is only emitted through a valid, executable noop program, preventing invocation errors and maintaining program integrity.  ",https://github.com/Lightprotocol/light-protocol/commit/fea5e3a60b4c23d1b1f094dab19f701dd2b038cc,High
Sol-209,"Lack of Merkle Tree Association Check. In invoke_cpi::process_cpi_context, there is no validation to ensure that all input and output compressed accounts belong to the same Merkle tree as specified by CpiContextAccount.associated_merkle_tree. This introduces a significant vulnerability.  The CpiContextAccount is expected to maintain a reference to a specific Merkle tree, which is used to validate compressed accounts via Merkle proofs. Without verifying that the input and output compressed accounts are associated with the same Merkle tree, it becomes possible to pass in accounts from different Merkle trees.  This can result in incorrect or invalid proof verifications, as the proofs and the associated Merkle tree hashes may not match, potentially compromising the integrity of the system.","rust
pub fn process_cpi_context<'info>(
    mut inputs: InstructionDataInvokeCpi,
    ctx: &mut Context<'_, '_, '_, 'info, InvokeCpiInstruction<'info>>,
) -> Result<Option<InstructionDataInvokeCpi>> {

    let cpi_context = &inputs.cpi_context;

    if ctx.accounts.get_cpi_context_account().is_some() && cpi_context.is_none() {
        msg!(""cpi context account is some but cpi context is none"");
        return err!(SystemProgramError::CpiContextMissing);
    }

    if ctx.accounts.get_cpi_context_account().is_none() && cpi_context.is_some() {
        msg!(""cpi context account is none but cpi context is some"");
        return err!(SystemProgramError::CpiContextAccountUndefined);
    }  

    if let Some(cpi_context) = cpi_context {
        let fee_payer = ctx.accounts.fee_payer.key();
        let cpi_context_account = match ctx.accounts.get_cpi_context_account() {
            Some(cpi_context_account) => cpi_context_account,
            None => return err!(SystemProgramError::CpiContextMissing),
        };                          

        if cpi_context.set_context {
            set_cpi_context(fee_payer, cpi_context_account, inputs)?;
            return Ok(None);
        } else {
            if cpi_context_account.context.is_empty() {
                msg!(""cpi context account : {:?}"", cpi_context_account);
                msg!(""fee payer : {:?}"", fee_payer);
                msg!(""cpi context  : {:?}"", cpi_context);
                return err!(SystemProgramError::CpiContextEmpty);
            } else if cpi_context_account.fee_payer != fee_payer || cpi_context.first_set_context {
                msg!(""cpi context account : {:?}"", cpi_context_account);
                msg!(""fee payer : {:?}"", fee_payer);
                msg!(""cpi context  : {:?}"", cpi_context);
                return err!(SystemProgramError::CpiContextFeePayerMismatch);
            }
            inputs.combine(&cpi_context_account.context);
            cpi_context_account.context = Vec::new();
            cpi_context_account.fee_payer = Pubkey::default();
        }
    }

    Ok(Some(inputs))
}","rust
/// Cpi context enables the use of input compressed accounts owned by different programs.
///
/// Example:
/// - a transaction calling a pda program needs to transfer tokens and modify a
///   compressed pda
/// - the pda is owned by pda program while the tokens are owned by the compressed
///   token program
///
/// Without cpi context:
/// - naively invoking each compressed token via cpi and modifying the pda
///   requires two proofs 128 bytes and ~100,000 CU each
///
/// With cpi context:
/// - only one proof is required -> less instruction data and CU cost
/// 1. first invocation (token program) performs signer checks of the compressed
///    token accounts, caches these in the cpi context and returns. The state
///    transition is not executed yet.
/// 2. second invocation (pda program) performs signer checks of the pda
///    compressed account, reads cpi context and combines the instruction inputs
///    with verified inputs from the cpi context. The proof is verified and
///    other state transition is executed with the combined inputs.
pub fn process_cpi_context<'info>(
    mut inputs: InstructionDataInvokeCpi,
    cpi_context_account: &mut Option<Account<'info, CpiContextAccount>>,
    fee_payer: Pubkey,
    remaining_accounts: &[AccountInfo<'info>],
) -> Result<Option<InstructionDataInvokeCpi>> {
    let cpi_context = &inputs.cpi_context;
    
    if cpi_context_account.is_some() && cpi_context.is_none() {
        msg!(""cpi context account is some but cpi context is none"");
        return err!(SystemProgramError::CpiContextMissing);
    }
    
    if let Some(cpi_context) = cpi_context {
        let cpi_context_account = match cpi_context_account {
            Some(cpi_context_account) => cpi_context_account,
            None => return err!(SystemProgramError::CpiContextAccountUndefined),
        };
        
        let index = if !inputs
            .input_compressed_accounts_with_merkle_context
            .is_empty()
        {
            inputs.input_compressed_accounts_with_merkle_context[0]
                .merkle_context
                .merkle_tree_pubkey_index
        } else if !inputs.output_compressed_accounts.is_empty() {
            inputs.output_compressed_accounts[0].merkle_tree_index
        } else {
            return err!(SystemProgramError::NoInputs);
        };
        
        let first_merkle_tree_pubkey = remaining_accounts[index as usize].key();
        
        if first_merkle_tree_pubkey != cpi_context_account.associated_merkle_tree {
            msg!(
                ""first_merkle_tree_pubkey {:?} != associated_merkle_tree {:?}"",
                first_merkle_tree_pubkey,
                cpi_context_account.associated_merkle_tree
            );
            return err!(SystemProgramError::CpiContextAssociatedMerkleTreeMismatch);
        }
        
        if cpi_context.set_context {
            set_cpi_context(fee_payer, cpi_context_account, inputs)?;
            return Ok(None);
        } else {
            if cpi_context_account.context.is_empty() {
                msg!(""cpi context account : {:?}"", cpi_context_account);
                msg!(""fee payer : {:?}"", fee_payer);
                msg!(""cpi context  : {:?}"", cpi_context);
                return err!(SystemProgramError::CpiContextEmpty);
            } else if cpi_context_account.fee_payer != fee_payer || cpi_context.first_set_context {
                msg!(""cpi context account : {:?}"", cpi_context_account);
                msg!(""fee payer : {:?}"", fee_payer);
                msg!(""cpi context  : {:?}"", cpi_context);
                return err!(SystemProgramError::CpiContextFeePayerMismatch);
            }
            
            inputs.combine(&cpi_context_account.context);
            cpi_context_account.context = Vec::new();
            cpi_context_account.fee_payer = Pubkey::default();
        }
    }
    
    Ok(Some(inputs))
}",Medium,"Verify that the Merkle tree associated with each compressed account matches the associated_merkle_tree in CpiContextAccount. This ensures that all accounts involved are validated against the same Merkle tree, maintaining consistency and preventing invalid or mismatched proof verifications.  ",https://github.com/Lightprotocol/light-protocol/commit/0e0fec6de1936eff454c0c498a3a703670c65e10#diff-e9d5d26d4d2ef5207c312ac8f3e41800ef55272874b3642d5312fbc7944e32f0,High
Sol-210,"Insecure Context Management  The vulnerability stems from the lack of explicit access control when utilizing CpiContextAccount in invoke_cpi. In InvokeCpiInstruction, the CpiContextAccount is meant to hold or manage context information required for cross-program invocation (CPI).  However, there are no specific checks or restrictions on who may modify or access this CpiContextAccount. This lack of control may be exploited by injecting a different proof during the utilization of CpiContextAccount—especially when the context spans multiple transactions instead of a single transaction—allowing an attacker to reset the context account and remove unused invoke inputs.","rust
programs/system/src/invoke_cpi/instruction.rs

#[derive(Accounts)]
pub struct InvokeCpiInstruction<'info> {
      #[account(mut)]
      pub fee_payer: Signer<'info>,
      pub authority: Signer<'info>,
      
      /// CHECK:
      #[account(
          seeds = [&crate::ID.to_bytes()], bump, seeds::program = &account_compression::ID,
      )]
      pub registered_program_pda:
          Account<'info, account_compression::instructions::register_program::RegisteredProgram>,
          
      /// CHECK: checked in emit_event.rs.
      pub noop_program: UncheckedAccount<'info>,
      
      /// CHECK:
      #[account(seeds = [CPI_AUTHORITY_PDA_SEED], bump)]
      pub account_compression_authority: UncheckedAccount<'info>,
      
      /// CHECK:
      pub account_compression_program: Program<'info, AccountCompression>,
      
      /// CHECK: checked in cpi_signer_check.
      pub invoking_program: UncheckedAccount<'info>,
      
      #[account(
          mut,
          seeds = [SOL_POOL_PDA_SEED], bump
      )]
      pub sol_pool_pda: Option<UncheckedAccount<'info>>,
      
      #[account(mut)]
      pub decompression_recipient: Option<UncheckedAccount<'info>>,
      
      pub system_program: Program<'info, System>,
      
      #[account(mut)]
      pub cpi_context_account: Option<Account<'info, CpiContextAccount>>,
}

... rest of your code ...","rust
#[derive(Accounts)]
pub struct InvokeCpiInstruction<'info> {
    /// Fee payer needs to be mutable to pay rollover and protocol fees.
    #[account(mut)]
    pub fee_payer: Signer<'info>,
    pub authority: Signer<'info>,
    /// CHECK:
    #[account(
        seeds = [&crate::ID.to_bytes()], bump, seeds::program = &account_compression::ID,
    )]
    pub registered_program_pda: AccountInfo<'info>,
    /// CHECK: checked in emit_event.rs.
    pub noop_program: UncheckedAccount<'info>,
    /// CHECK:
    #[account(seeds = [CPI_AUTHORITY_PDA_SEED], bump)]
    pub account_compression_authority: UncheckedAccount<'info>,
    /// CHECK:
    pub account_compression_program: Program<'info, AccountCompression>,
    /// CHECK: checked in cpi_signer_check.
    pub invoking_program: UncheckedAccount<'info>,
    #[account(mut, seeds = [SOL_POOL_PDA_SEED], bump)]
    pub sol_pool_pda: Option<UncheckedAccount<'info>>,
    #[account(mut)]
    pub decompression_recipient: Option<UncheckedAccount<'info>>,
    pub system_program: Program<'info, System>,
    #[account(mut)]
    pub cpi_context_account: Option<Account<'info, CpiContextAccount>>,
}

impl<'info> SignerAccounts<'info> for InvokeCpiInstruction<'info> {
    fn get_fee_payer(&self) -> &Signer<'info> {
        &self.fee_payer
    }

    fn get_authority(&self) -> &Signer<'info> {
        &self.authority
    }
}

impl<'info> InvokeAccounts<'info> for InvokeCpiInstruction<'info> {
    fn get_registered_program_pda(&self) -> &AccountInfo<'info> {
        &self.registered_program_pda
    }

    fn get_noop_program(&self) -> &UncheckedAccount<'info> {
        &self.noop_program
    }

    fn get_account_compression_authority(&self) -> &UncheckedAccount<'info> {
        &self.account_compression_authority
    }

    fn get_account_compression_program(&self) -> &Program<'info, AccountCompression> {
        &self.account_compression_program
    }

    fn get_sol_pool_pda(&self) -> Option<&UncheckedAccount<'info>> {
        self.sol_pool_pda.as_ref()
    }

    fn get_decompression_recipient(&self) -> Option<&UncheckedAccount<'info>> {
        self.decompression_recipient.as_ref()
    }

    fn get_system_program(&self) -> &Program<'info, System> {
        &self.system_program
    }
}

programs/system/src/invoke_cpi/process_cpi_context.rs 

pub fn process_cpi_context<'info>(
    mut inputs: InstructionDataInvokeCpi, 
    cpi_context_account: &mut Option<Account<'info, CpiContextAccount>>, 
    fee_payer: Pubkey, 
    remaining_accounts: &[AccountInfo<'info>],
) -> Result<Option<InstructionDataInvokeCpi>> {
// and so on. I had to cut here because the text exceeds my character limit. Please split your code into smaller pieces.",Medium,Implement strict access control mechanisms to ensure that only authorized entities may modify or interact with CpiContextAccount.,https://github.com/Lightprotocol/light-protocol/commit/0e0fec6de1936eff454c0c498a3a703670c65e10#diff-1c724800521b3ca80925fc753bee5554059048d10c175cda80c1d831c36c5306,High
Sol-211,"Incorrect Element Dequeuing. The dequeue_at_with_low_element_index function in the IndexedArray module is designed to remove an element from the array at a given index and update references accordingly.  However, the function is missing a check to ensure that elements[low_element_index].next_index == index. Without this check, the function may update the next_index of elements[low_element_index] to point to an incorrect element.  If the next_index of the element at low_element_index does not actually point to the element at index, the function may end up removing an element that should not be removed. This can result in unintended dequeuing and corruption of the internal structure of the IndexedArray.","rust
// TODO: remove since it's not used (hashset replaces this)     
/// Returns and removes the element from the given index.     
///     
/// It also performs necessary updated of the remaning elements, to     
/// preserve the integrity of the array.     
///     
/// The low element under `low_element_index` is updated, to point to a new     
/// next element instead of the one which is removed.     
pub fn dequeue_at_with_low_element_index(
    &mut self,
    low_element_index: I,
    index: I,
) -> Result<Option<IndexedElement<I>>, IndexedMerkleTreeError> {
    if index > self.current_node_index {
        // Index out of bounds.
        return Ok(None);
    }
    // Save the element to be removed.
    let removed_element = self.elements[usize::from(index)].clone();
    // Update the lower element - point to the node which the currently     
    // removed element is pointing to.   
    self.elements[usize::from(low_element_index)].next_index = removed_element.next_index;
    let mut new_highest_element_index = I::zero();
    for i in 0..usize::from(self.current_node_index) {
        // Shift elements, which are on the right from the removed element,
        // to the left.
        if i >= usize::from(index) {
            self.elements[i] = self.elements[i
                .checked_add(1_usize)
                .ok_or(IndexedMerkleTreeError::IntegerOverflow)?
            ].clone();
            self.elements[i].index = self.elements[i]
                .index
                .checked_sub(&I::one())
                .ok_or(IndexedMerkleTreeError::IntegerOverflow)?;
        }
        // If the `next_index` is greater than the index of the removed
        // element, decrement it. Elements on the right from the removed
        // element are going to be shifted left.
        if self.elements[i].next_index >= index {
            self.elements[i].next_index = self.elements[i]
                .next_index
                .checked_sub(&I::one())
                .ok_or(IndexedMerkleTreeError::IntegerOverflow)?;
        }
        if self.elements[i].value > self.elements[usize::from(new_highest_element_index)].value {
            new_highest_element_index = i
                .try_into()
                .map_err(|_| IndexedMerkleTreeError::IntegerOverflow)?;
        }
    }
    // Update current_node_index
    self.current_node_index = self
        .current_node_index
        .checked_sub(&I::one())
        .ok_or(IndexedMerkleTreeError::IntegerOverflow)?;
    // Update highest_element_index
    self.highest_element_index = new_highest_element_index;

    Ok(Some(removed_element))
}    

/// Returns and removes the element from the given index.     
///     
/// It also performs necessary updates of the remaning elements, to     
/// preserve the integrity of the array. It searches for the low element     
/// and updates it, to point to a new next element instead of the one     
pub fn dequeue_at(
    &mut self,
    index: I,
) -> Result<Option<IndexedElement<I>>, IndexedMerkleTreeError> {
    match self.elements.get(usize::from(index)) {
        Some(node) => {
            let low_element_index = self.find_low_element_index_for_existent(&node.value)?;
            self.dequeue_at_with_low_element_index(low_element_index, index)
        }
        None => Ok(None),
    }
}",Remove this code,Medium,Add a check to ensure that the next_index of the element at low_element_index actually points to the element at index before proceeding with the removal.,https://github.com/Lightprotocol/light-protocol/commit/92930cd7b5c3f8c3caede873856b26cef6b69197,High
Sol-212,"Improper Equality Comparison. The CyclicBoundedVec::eq function compares the underlying data of two vectors without accounting for the cyclic nature of the vector, which may result in incorrect outcomes.  This occurs because the data in a CyclicBoundedVec may be stored in a non-contiguous manner due to cyclic indexing. As a result, the order of elements in the underlying data array may not match the logical order of elements in the vector.  The function creates a slice from the start of self.data up to self.length and iterates over its elements. It then compares these elements with those from other.data. However, this approach assumes that self.data and other.data are in the same order, which is not necessarily the case in a cyclic vector.  Due to cyclic indexing, and particularly the positions of first_index and last_index, the logical order of the elements may differ from their physical layout in memory, making direct comparison unreliable.",Error fetching AI explanation: list index out of range,"rust
/// `CyclicBoundedVec` is a wrapper around [`Vec`](std::vec::Vec) which:
///
/// * Forbids post-initialization reallocations.
/// * Starts overwriting elements from the beginning once it reaches its
///   capacity.
#[derive(Debug)]
pub struct CyclicBoundedVec<T> 
where
    T: Clone, 
{
    metadata: *mut CyclicBoundedVecMetadata,
    data: NonNull<T>,   
}  

impl<T> CyclicBoundedVec<T> 
where
    T: Clone, 
{
    #[inline] 
    pub fn with_capacity(capacity: usize) -> Self {
        let layout = Layout::new::<CyclicBoundedVecMetadata>();
        let metadata = unsafe { alloc::alloc(layout) as *mut CyclicBoundedVecMetadata };
        
        if metadata.is_null() {
              handle_alloc_error(layout);
        } 
        
        unsafe {
            *metadata = CyclicBoundedVecMetadata {
                capacity, 
                length: 0,
                first_index: 0,
                last_index: 0,
            };
        } 
        
        let layout = Layout::array::<T>(capacity).unwrap();
        let data_ptr = unsafe { alloc::alloc(layout) as *mut T };
        
        if data_ptr.is_null() {
            handle_alloc_error(layout); 
        }
        
        let data = NonNull::new(data_ptr).unwrap(); 
        
        Self { metadata, data } 
    }
}

impl<T> PartialEq for CyclicBoundedVec<T> 
where
    T: Clone + PartialEq, 
{
    fn eq(&self, other: &Self) -> bool {
        self.iter().eq(other.iter()) 
    } 
}",Medium,Ensure the comparison accounts for the cyclic ordering by iterating through the elements in their logical order to properly compare two CyclicBoundedVec instances.,https://github.com/Lightprotocol/light-protocol/commit/534d90f1da5aa6ad5e7fe6eebb69f6fe1b552f5d#diff-baafeefaa4cdaeb001c2048f2bbddcde242bb9dde546c332ca9015f9a03e54c5,High
Sol-213,"Program Account Misuse. The authority field is a Signer<'info>. This implies it is expected to be an account that has signed the transaction and, therefore, is responsible for authorizing the action.  If the authority signer is a program, the program admin may misuse their authority. Since the admin possesses the corresponding private key for the program’s public key, they can generate the Signer for the program’s public key and use the invoke instruction to delete program-owned accounts or transfer lamports.","rust
#[derive(Accounts)]
pub struct InvokeInstruction<'info> {
    #[account(mut)]
    pub fee_payer: Signer<'info>,
    pub authority: Signer<'info>,
    // ...
}

pub fn input_compressed_accounts_signer_check(
    input_compressed_accounts_with_merkle_context: &[PackedCompressedAccountWithMerkleContext],
    authority: &Pubkey,
) -> Result<()> {
    input_compressed_accounts_with_merkle_context
        .iter()
        .try_for_each(
            |compressed_account_with_context: &PackedCompressedAccountWithMerkleContext| {
                if compressed_account_with_context.compressed_account.owner == *authority {
                    Ok(())
                } else {
                    msg!(
                        ""signer check failed compressed account owner {} != authority {}"",
                        compressed_account_with_context.compressed_account.owner,
                        authority
                    );
                    err!(SystemProgramError::SignerCheckFailed)
                }
            },
        )
}","rust
#[derive(Accounts)]
pub struct InvokeInstruction<'info> {
    #[account(mut)]
    pub fee_payer: Signer<'info>,
    pub authority: Signer<'info>,
    // [...]
}

pub fn input_compressed_accounts_signer_check(
    input_compressed_accounts_with_merkle_context: &[PackedCompressedAccountWithMerkleContext],
    authority: &Pubkey,
) -> Result<()> {
    input_compressed_accounts_with_merkle_context
        .iter()
        .try_for_each(
            |compressed_account_with_context: &PackedCompressedAccountWithMerkleContext| {
                if compressed_account_with_context.compressed_account.owner == *authority
                    && compressed_account_with_context
                        .compressed_account
                        .data
                        .is_none()
                {
                    Ok(())
                } else {
                    msg!(
                        ""signer check failed compressed account owner {} != authority {} or data is not none {} (only programs can own compressed accounts with data)"",
                        compressed_account_with_context.compressed_account.owner,
                        authority,
                        compressed_account_with_context.compressed_account.data.is_none()
                    );
                    err!(SystemProgramError::SignerCheckFailed)
                }
            },
        )
}",Medium,Implement checks to ensure that the authority signer is not a program account.,https://github.com/Lightprotocol/light-protocol/commit/203296b6510679e7ca8e477759f8347c9ea496fb,High
Sol-214,"Inaccurate Reconstruction of Cyclic Bounded Vector The vulnerability in ConcurrentMerkleTree::copy_from_bytes is related to the reconstruction of CyclicBoundedVec structures from byte slices.  A CyclicBoundedVec maintains its elements in a circular buffer, using specific indices to track the start (first_index) and end (last_index) of valid elements. When reconstructing a CyclicBoundedVec from a byte slice, it is crucial to consider these indices in order to preserve the correct logical ordering of elements.  However, in the current implementation of copy_from_bytes, the reconstruction process does not account for these indices. It simply copies elements based on their positions in the byte slice, leading to potential misordering of the logical sequence of elements.  This issue affects various parts of the codebase, including both concurrent and indexed Merkle trees.","rust
/// # Safety     
/// This is highly unsafe. Ensuring the alignment and that the slice   
/// provides actual data of the hash set is the caller's responsibility.    
/// Calling it in async context (or anyhwere where the underlying data can   
/// be moved in the memory) is certainly going to cause undefined behavior. 
pub unsafe fn copy_from_bytes(
       bytes_struct: &[u8],
       bytes_filled_subtrees: &[u8],
       bytes_changelog: &[u8],
       bytes_roots: &[u8],
       bytes_canopy: &[u8],
       bytes_indexed_changelog: &'a [u8],
   ) -> Result<Self, IndexedMerkleTreeError> {
       
       let expected_bytes_struct_size = mem::size_of::<IndexedMerkleTree<'a, H, I, HEIGHT>>();
       
       if bytes_struct.len() != expected_bytes_struct_size {
           return Err(IndexedMerkleTreeError::ConcurrentMerkleTree(
               ConcurrentMerkleTreeError::StructBufferSize(
                   expected_bytes_struct_size,
                   bytes_struct.len(),
               ),
           ));
       }
       
       let struct_ref: *mut IndexedMerkleTree<'a, H, I, HEIGHT> = bytes_struct.as_ptr() as _; 
       
       let mut merkle_tree = unsafe {
           ConcurrentMerkleTree {
               height: (*struct_ref).merkle_tree.height,
               changelog_capacity: (*struct_ref).merkle_tree.changelog_capacity,
               changelog_length: (*struct_ref).merkle_tree.changelog_length,
               current_changelog_index: (*struct_ref).merkle_tree.current_changelog_index,
               roots_capacity: (*struct_ref).merkle_tree.roots_capacity,
               roots_length: (*struct_ref).merkle_tree.roots_length,
               current_root_index: (*struct_ref).merkle_tree.current_root_index,
               canopy_depth: (*struct_ref).merkle_tree.canopy_depth,
               next_index: (*struct_ref).merkle_tree.next_index,
               sequence_number: (*struct_ref).merkle_tree.sequence_number,
               rightmost_leaf: (*struct_ref).merkle_tree.rightmost_leaf, 
               filled_subtrees: BoundedVec::with_capacity((*struct_ref).merkle_tree.height),
               changelog: CyclicBoundedVec::with_capacity(
                   (*struct_ref).merkle_tree.changelog_capacity,
               ),
               roots: CyclicBoundedVec::with_capacity((*struct_ref).merkle_tree.roots_capacity),
               canopy: BoundedVec::with_capacity(ConcurrentMerkleTree::<H, HEIGHT>::canopy_size(
                   (*struct_ref).merkle_tree.canopy_depth,
               )),
               _hasher: PhantomData,
           }
       }; 
       
       // The remaining body of the function
       // ...
}","/// This method is meant to be used mostly in Solana programs, where memory
/// constraints are tight and we want to make sure no data is copied.
pub fn from_bytes_copy(bytes: &[u8]) -> Result<Self, IndexedMerkleTreeError> {
    let (merkle_tree, mut offset) =
        ConcurrentMerkleTreeCopy::<H, HEIGHT>::struct_from_bytes_copy(bytes)?;

    let indexed_changelog_metadata: CyclicBoundedVecMetadata =
        unsafe { read_value_at(bytes, &mut offset) };

    let expected_size = IndexedMerkleTree::<H, I, HEIGHT>::size_in_account(
        merkle_tree.height,
        merkle_tree.changelog.capacity(),
        merkle_tree.roots.capacity(),
        merkle_tree.canopy_depth,
        indexed_changelog_metadata.capacity(),
    );

    if bytes.len() < expected_size {
        return Err(IndexedMerkleTreeError::ConcurrentMerkleTree(
            ConcurrentMerkleTreeError::BufferSize(expected_size, bytes.len()),
        ));
    }

    let indexed_changelog =
        unsafe { read_cyclic_bounded_vec_at(bytes, &mut offset, &indexed_changelog_metadata) };

    Ok(Self(IndexedMerkleTree {
        merkle_tree,
        indexed_changelog,
        _index: PhantomData,
    }))
}utils/src/offset.rs:use std::{mem, ptr};

use light_bounded_vec::{
    BoundedVec,
    BoundedVecMetadata,
    CyclicBoundedVec,
    CyclicBoundedVecMetadata,
};

/// Casts a part of provided `bytes` buffer with the given `offset` to a
/// mutable pointer to `T`.
///
/// Should be used for single values.
///
/// # Safety
///
/// This is highly unsafe. This function doesn't ensure alignment and
/// correctness of provided buffer. The responsibility of such checks is on
/// the caller.
pub unsafe fn read_ptr_at<T>(bytes: &[u8], offset: &mut usize) -> *mut T {
    let size = mem::size_of::<T>();
    let ptr = bytes[*offset..*offset + size].as_ptr() as *mut T;
    *offset += size;
    ptr
}

/// Casts a part of provided `bytes` buffer with the given `offset` to a
/// mutable pointer to `T`.
///
/// Should be used for array-type sequences.
///
/// # Safety
///
/// This is highly unsafe. This function doesn't ensure alignment and
/// correctness of provided buffer. The responsibility of such checks is on
/// the caller.
pub unsafe fn read_array_like_ptr_at<T>(
    bytes: &[u8],
    offset: &mut usize,
    len: usize,
) -> *mut T {
    let size = mem::size_of::<T>() * len;
    let ptr = bytes[*offset..*offset + size].as_ptr() as *mut T;
    *offset += size;
    ptr
}

/// Creates a copy of value of type `T` based on the provided `bytes` buffer.
///
/// # Safety
///
/// This is highly unsafe. This function doesn't ensure alignment and
/// correctness of provided buffer. The responsibility of such checks is on
/// the caller.
pub unsafe fn read_value_at<T>(bytes: &[u8], offset: &mut usize) -> T
where
    T: Clone,
{
    let size = mem::size_of::<T>();
    let ptr = bytes[*offset..*offset + size].as_ptr() as *const T;
    *offset += size;
    // (*ptr).clone()
    ptr::read(ptr)
}

/// Creates a `BoundedVec` from the sequence of values provided in `bytes` buffer.
///
/// # Safety
///
/// This is highly unsafe. This function doesn't ensure alignment and
/// correctness of provided buffer. The responsibility of such checks is on
/// the caller.
pub unsafe fn read_bounded_vec_at<T>(
    bytes: &[u8],
    offset: &mut usize,
    metadata: &BoundedVecMetadata,
) -> BoundedVec<T>
where
    T: Clone,
{
    let size = mem::size_of::<T>() * metadata.capacity();
    let ptr = bytes[*offset..*offset + size].as_ptr() as *const T;

    let mut vec = BoundedVec::with_capacity(metadata.capacity());
    for i in 0..metadata.length() {
        let val = ptr::read(ptr.add(i));
        // PANICS: We ensured the bounds.
        vec.push(val).unwrap();
    }

    *offset += size;
    vec
}

/// Creates a `CyclicBoundedVec` from the sequence of values provided in
/// `bytes` buffer.
///
/// # Safety
///
/// This is highly unsafe. This function doesn't ensure alignment and
/// correctness of provided buffer. The responsibility of such checks is on
/// the caller.
pub unsafe fn read_cyclic_bounded_vec_at<T>(
    bytes: &[u8],
    offset: &mut usize,
    metadata: &CyclicBoundedVecMetadata,
) -> CyclicBoundedVec<T>
where
    T: Clone,
{
    let size = mem::size_of::<T>() * metadata.capacity();
    let ptr = bytes[*offset..*offset + size].as_ptr() as *const T;

    let mut vec = CyclicBoundedVec::with_capacity(metadata.capacity());
    for i in 0..metadata.length() {
        let val = ptr::read(ptr.add(i));
        vec.push(val);
    }

    *offset += size;
    vec
}

/// Writes provided `data` into provided `bytes` buffer with the given
/// `offset`.
pub fn write_at<T>(bytes: &mut [u8], data: &[u8], offset: &mut usize) {
    let size = mem::size_of::<T>();
    bytes[*offset..*offset + size].copy_from_slice(data);
    *offset += size;
}",Medium,Ensure there construction processre stores the first_index and last_index of the CyclicBoundedVec .,https://github.com/Lightprotocol/light-protocol/commit/203296b6510679e7ca8e477759f8347c9ea496fb,High
Sol-215,"Inconsistency in Prime Number Calculation The vulnerability arises from how the find_next_prime function adjusts n to find the next prime number greater than n.  All prime numbers greater than three are either of the form 6k + 1 or 6k + 5. When (remainder != 0.0), the function currently adjusts n by setting it to n + 6.0 - remainder, which ensures that n becomes the nearest number of the form 6k + 5.  However, the function does not explicitly check for a prime of the form 6k + 1. As a result, it may skip valid primes by jumping ahead to the next number of the form 6k + 5, even when the given number is already a prime in the form 6k + 1.  This leads to incorrect identification of the next prime number in some cases.  ","rust
/// Finds the lowest prime number which is greater than the provided number `n`.
pub fn find_next_prime(mut n: f64) -> f64 {
    n = n.round();

    // Handle small numbers separately
    if n <= 2.0 {
        return 2.0;
    } else if n <= 3.0 {
        return 3.0;
    }

    // All prime numbers greater than 3 are of the form 6k + 1 or 6k + 5
    // This leaves only 6k + 1 and 6k + 5 as candidates.

    // Ensure the candidate is of the form 6k - 1 or 6k + 1.
    let remainder = n % 6.0;
    if remainder != 0.0 {
        n = n + 6.0 - remainder;
        let candidate = n - 1.0;
        if is_prime(candidate) {
            return candidate;
        }
    }

    loop {
        let candidate = n + 1.0;
        if is_prime(candidate) {
            return candidate;
        }
        let candidate = n + 5.0;
        if is_prime(candidate) {
            return candidate;
        }

        n += 6.0;
    }
}

pub fn find_next_prime_with_load_factor(n: f64, load_factor: f64) -> f64 {
    let minimum = n / load_factor;
    find_next_prime(minimum)
}

/// Checks whether the provided number `n` is a prime number.
pub fn is_prime(n: f64) -> bool {
    if n <= 1.0 {
        return false;
    }
    if n <= 3.0 {
        return true;
    }
    if n % 2.0 == 0.0 || n % 3.0 == 0.0 {
        return false;
    }
    let mut i = 5.0;
    while i * i <= n {
        if n % i == 0.0 || n % (i + 2.0) == 0.0 {
            return false;
        }
        i += 6.0;
    }
    true
}","rust
/// Finds the lowest prime number which is greater than the provided number `n`.
pub fn find_next_prime(mut n: u32) -> u32 {
    // Handle small numbers separately
    if n <= 2 {
        return 2;
    } else if n <= 3 {
        return 3;
    }  
    
    // All prime numbers greater than 3 are of the form 6k + 1 or 6k + 5 (or @@ -22,52 +20,68 @@ pub fn find_next_prime(mut n: f64) -> f64 {
    // This leaves only 6k + 1 and 6k + 5 as candidates.  
    
    // Ensure the candidate is of the form 6k - 1 or 6k + 1.
    let remainder = n % 6;
    if remainder != 0 {
        // Check if `n` already satisfies the pattern and is prime.
        if remainder == 5 && is_prime(n) {
            return n;
        }
        if remainder == 1 && is_prime(n) {
            return n;
        }  

        // Add `6 - remainder` to `n`, to it satisfies the `6k` pattern.
        n = n + 6 - remainder;
        
        // Check if `6k - 1` candidate is prime.
        let candidate = n - 1;
        if is_prime(candidate) {
            return candidate;
        }
    }  
    
    // Consequently add `6`, keep checking `6k + 1` and `6k + 5` candidates.
    loop {
        let candidate = n + 1;
        if is_prime(candidate) {
            return candidate;
        }
        let candidate = n + 5;
        if is_prime(candidate) {
            return candidate;
        }  

        n += 6;
    }
}  

pub fn find_next_prime_with_load_factor(n: u32, load_factor: f64) -> u32 {
    // SAFETY: These type coercions should not cause any issues.
    
    // * `f64` can precisely represent all integer values up to 2^53, which is
    //   more than `u32::MAX`. `u64` and `usize` would be too large though.
    // * We want to return and find an integer (prime number), so coercing `f64`
    //   back to `u32` is intentional here.
    
    let minimum = n as f64 / load_factor;
    find_next_prime(minimum as u32)
}  

/// Checks whether the provided number `n` is a prime number.
pub fn is_prime(n: u32) -> bool {
    if n <= 1 {
        return false;
    }
    if n <= 3 {
        return true;
    }
    if n % 2 == 0 || n % 3 == 0 {
        return false;
    }
    let mut i = 5;
    while i * i <= n {
        if n % i == 0 || n % (i + 2) == 0 {
            return false;
        }
        i += 6;
    }
    true
}",Medium,Explicitly check both n - 1.0 and n + 5.0 after adjusting n to the form 6k + 5.,https://github.com/Lightprotocol/light-protocol/commit/f0a7b5b87b0cded5f7e0e08483ffda7287e8228f#diff-c6ffbb012bdf358efd6e1a69d2c74388ac2200cc115b4ed6ea6588d073ebc0c3,High
Sol-216,"Removing validators immediately after a successful EpochMaintenance may result in the desynchronization of the internal state of the Steward Program with the external state of the stake pool validator list, particularly when handling delinquent validators. A validator may be removed from the list in the same epoch if there is no transient stake. The issue arises because the validator is marked for deactivation in one epoch but is not removed until the next. If the internal state of the Steward program does not update synchronously with the stake pool’s external state, the Steward may think it still has the validator in its active pool while the stake pool has already removed it, creating a discrepancy between the two systems. Proof of Concept 1. deactivate_delinquent is called on a validator’s stake account during epoch 1, marking it as delinquent but not immediately removing it from the validator list. 2. epoch_maintenance is executed during epoch 2, which performs necessary checks and updates the internal state of the Steward Program. 3. auto_remove_validator_from_pool is called during the maintenance process, which attempts to remove the delinquent validator from the pool. 4. The stake pool operations may subsequently execute, which will remove the validator from the validator list, resulting in state desynchronization","rust
pub fn remove_validator(&mut self, index: usize) -> Result<()> {
    require!(
        self.validators_to_remove.get(index)?, 
        StewardError::ValidatorNotMarkedForRemoval
    );

    self.num_pool_validators = self
        .num_pool_validators
        .checked_sub(1)
        .ok_or(StewardError::ArithmeticError)?;

    let num_pool_validators = self.num_pool_validators as usize;

    // Shift all validator state to the left
    for i in index..num_pool_validators {
        let next_i = i + 1;

        self.progress.set(i, self.progress.get(next_i)?)?;

        self.validators_to_remove
            .set(i, self.validators_to_remove.get(next_i)?)?;
    }
    //other code here if any
}","rust
programs/steward/src/instructions/instant_remove_validator.rs

use crate::{
    errors::StewardError,
    utils::{
        check_validator_list_has_stake_status_other_than, deserialize_stake_pool, 
        get_stake_pool_address, get_validator_list, get_validator_list_length,
    },
    Config, StewardStateAccount,
};

use anchor_lang::prelude::*;
use spl_stake_pool::state::StakeStatus;

#[derive(Accounts)]
pub struct InstantRemoveValidator<'info> {
    pub config: AccountLoader<'info, Config>,
    #[account(
        mut,
        seeds = [StewardStateAccount::SEED, config.key().as_ref()],
        bump
    )]
    pub state_account: AccountLoader<'info, StewardStateAccount>,
    #[account(address = get_validator_list(&config)?)]
    pub validator_list: AccountInfo<'info>,
    #[account(
        address = get_stake_pool_address(&config)?
    )]
    pub stake_pool: AccountInfo<'info>,
}

pub fn handler(
    ctx: Context<InstantRemoveValidator>,
    validator_index_to_remove: usize,
) -> Result<()> {
    let stake_pool = deserialize_stake_pool(&ctx.accounts.stake_pool)?;
    let mut state_account = ctx.accounts.state_account.load_mut()?;

    let clock = Clock::get()?;
    let validators_to_remove = state_account.state.validators_for_immediate_removal.count();
    let validators_in_list = get_validator_list_length(&ctx.accounts.validator_list)?;

    require!(
        clock.epoch == stake_pool.last_update_epoch,
        StewardError::StakePoolNotUpdated
    );

    require!(
        state_account
            .state
            .validators_for_immediate_removal
            .get(validator_index_to_remove)?,
        StewardError::ValidatorNotInList
    );

    require!(
        state_account.state.num_pool_validators as usize
            + state_account.state.validators_added as usize
            - validators_to_remove
            == validators_in_list,
        StewardError::ListStateMismatch
    );

    require!(
        !check_validator_list_has_stake_status_other_than(
            &ctx.accounts.validator_list,
            StakeStatus::Active
        )?,
        StewardError::ValidatorsHaveNotBeenRemoved
    );

    state_account
        .state
        .remove_validator(validator_index_to_remove)?;

    Ok(())
}

programs/steward/src/state/steward_state.rs

pub fn remove_validator(&mut self, index: usize) -> Result<()> {
    let marked_for_regular_removal = self.validators_to_remove.get(index)?;
    let marked_for_immediate_removal = self.validators_for_immediate_removal.get(index)?;

    require!(
        marked_for_regular_removal || marked_for_immediate_removal,
        StewardError::ValidatorNotMarkedForRemoval
    );

    if index >= self.num_pool_validators as usize {
        self.validators_added = self
            .validators_added
            .checked_sub(1)
            .ok_or(StewardError::ArithmeticError)?;
    } else {
        self.num_pool_validators = self
            .num_pool_validators
            .checked_sub(1)
            .ok_or(StewardError::ArithmeticError)?;
    }

    let num_pool_validators = self.num_pool_validators as usize;

    self.progress.set(i, self.progress.get(next_i)?)?;
    self.validators_to_remove
        .set(i, self.validators_to_remove.get(next_i)?)?;
    self.validators_for_immediate_removal
        .set(i, self.validators_for_immediate_removal.get(next_i)?)?;

    self.sorted_yield_score_indices[num_pool_validators] = SORTED_INDEX_DEFAULT;
    self.delegations[num_pool_validators] = Delegation::default();
    self.instant_unstake.set(num_pool_validators, false)?;

    self.progress.set(num_pool_validators, false)?;

    if marked_for_regular_removal {
        self.validators_to_remove.set(index, false)?;
    } else {
        self.validators_for_immediate_removal.set(index, false)?;
    }

    Ok(())
}

pub fn mark_validator_for_removal(&mut self, index: usize) -> Result<()> {
    self.validators_to_remove.set(index, true)
}

pub fn mark_validator_for_immediate_removal(&mut self, index: usize) -> Result<()> {
    self.validators_for_immediate_removal.set(index, true)
}",High,"Implement a mechanism to flag delinquent validators for immediate removal, ensuring that the state machine halts further progress until these validators are removed within the same epoch.",https://github.com/jito-foundation/stakenet/commit/0425db0396f433dc2c26fd7a5d2c29b094950ae7,High
Sol-217,"Missing Associated Token Account Check  stake::process_stake loads various accounts, including the treasury_tokens_info account, which is intended to be the associated token account (ATA) of the treasury.  However, without a strict equality check, there is no assurance that the provided treasury_tokens_info account is actually the correct associated token account.  As a result, an attacker may provide a different token account for treasury_tokens_info, thereby redirecting the staked tokens to an account they control, instead of the intended treasury account.","rust
pub fn process_stake<'a, 'info>(
    _program_id: &Pubkey, 
    accounts: &'a [AccountInfo<'info>], 
    data: &[u8], 
) -> ProgramResult {
    // Parse args
    let args = StakeArgs::try_from_bytes(data)?;
    let amount = u64::from_le_bytes(args.amount);

    // Load accounts
    let [signer, proof_info, sender_info, treasury_tokens_info, token_program] = accounts else {
        return Err(ProgramError::NotEnoughAccountKeys);
    };

    load_signer(signer)?;
    load_proof(proof_info, signer.key, true)?;
    load_token_account(sender_info, Some(signer.key), &MINT_ADDRESS, true)?;
    load_token_account(sender_info, Some(signer.key), &MINT_ADDRESS, true)?;

    load_token_account(    
        treasury_tokens_info,
        Some(&TREASURY_ADDRESS),
        &MINT_ADDRESS,
        true,
    )?;
}","rust
pub fn load_treasury_tokens<'a, 'info>(     
    info: &'a AccountInfo<'info>,     
    is_writable: bool, 
) -> Result<(), ProgramError> {     
    if info.key.ne(&TREASURY_TOKENS_ADDRESS) {         
        return Err(ProgramError::InvalidSeeds);     
    }      
    load_token_account(info, Some(&TREASURY_ADDRESS), &MINT_ADDRESS, is_writable) 
}

pub fn process_stake<'a, 'info>(
    _program_id: &Pubkey,     
    accounts: &'a [AccountInfo<'info>],     
    data: &[u8], 
) -> ProgramResult {     
    // Parse args     
    let args = StakeArgs::try_from_bytes(data)?;     
    let amount = u64::from_le_bytes(args.amount);

    // Load accounts     
    let [signer, proof_info, sender_info, treasury_tokens_info, token_program] = accounts else {         
        return Err(ProgramError::NotEnoughAccountKeys);     
    };     
    load_signer(signer)?;     
    load_proof(proof_info, signer.key, true)?;     
    load_token_account(sender_info, Some(signer.key), &MINT_ADDRESS, true)?;     
    load_treasury_tokens(treasury_tokens_info, true)?;
}",High,"Implement a strict equality check to ensure that treasury_tokens_info matches the expected associated token account (ATA) for the treasury.  Similarly, apply this check in the claim and rest instructions.","https://github.com/regolith-labs/ore/commit/3b1039b46908647df42dbd66c7967b7ef3dbe27e#diff-0215af55b6e37a0cf2c673e231f8f423472f690a82dc8e3c17ac55c1d5f30f6f, https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/a5efbbe3-b801-46f5-a1ae-28319e2a67e2/audit_ore_final.pdf?table=block&id=54dde62d-7915-48ae-b407-08094a5a7dcd&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742896800000&signature=_nV9M1D2C5iusWj8FCLEHzuDAiKXhrcMjC6lfH61kNU&downloadName=audit_ore_final.pdf",High
Sol-218,"Enhancing Mining Activity Tracking  TOLERANCE is the threshold for what the system considers acceptable levels of spam or delays. Adjusting this tolerance may inadvertently decrease the effective spam duration, which could potentially lower the system’s overall reliability against spam attacks.  Instead of directly manipulating TOLERANCE, consider updating the last_hash_at with logic that ensures a minimum interval between hash submissions or other critical actions. This approach will mitigate spamming or rapid submissions by making sure last_hash_at only reflects significant changes in miner activity, rather than every single hash submission.  ","rust
/// Mine is the primary workhorse instruction of the Ore program. Its responsibilities include: 
/// 1. Calculate the hash from the provided nonce. 
/// 2. Payout rewards based on difficulty, staking multiplier, and liveness penalty. 
/// 3. Generate a new challenge for the miner. 
/// 4. Update the miner's lifetime stats. 
///
/// Safety requirements: 
/// - Mine is a permissionless instruction and can be called by any signer. 
/// - Can only succeed if mining is not paused. 
/// - Can only succeed if the last reset was less than 60 seconds ago. 
/// - Can only succeed if the provided hash satisfies the minimum difficulty requirement. 
/// - The the provided proof account must be associated with the signer. 
/// - The provided bus, config, noise, stake, and slot hash sysvar must be valid. 
pub fn process_mine<'a, 'info>(
    _program_id: &Pubkey, 
    accounts: &'a [AccountInfo<'info>],
    data: &[u8], 
) -> ProgramResult {    
    // Parse args
    let args = MineArgs::try_from_bytes(data)?;
    
    // Load accounts
    let [signer, bus_info, config_info, proof_info, instructions_sysvar, slot_hashes_sysvar] = 
        accounts;
    else {
        return Err(ProgramError::NotEnoughAccountKeys);
    };
    load_signer(signer)?;
    load_any_bus(bus_info, true)?;
    load_config(config_info, false)?;
    load_proof_with_miner(proof_info, signer.key, true)?;
    load_sysvar(instructions_sysvar, sysvar::instructions::id())?;
    load_sysvar(slot_hashes_sysvar, sysvar::slot_hashes::id())?;
    
    // Validate this is the only mine ix in the transaction.
    if !validate_transaction(&instructions_sysvar.data.borrow()).unwrap_or(false) {
        return Err(OreError::TransactionInvalid.into());
    }
    
    // other computations ...

    Ok(())
}","rust
/// Mine is the primary workhorse instruction of the Ore program. Its responsibilities include: 
/// 1. Calculate the hash from the provided nonce. 
/// 2. Payout rewards based on difficulty, staking multiplier, and liveness penalty. 
/// 3. Generate a new challenge for the miner. 
/// 4. Update the miner's lifetime stats.

/// Safety requirements: 
/// - Mine is a permissionless instruction and can be called by any signer. 
/// - Can only succeed if mining is not paused. 
/// - Can only succeed if the last reset was less than 60 seconds ago. 
/// - Can only succeed if the provided hash satisfies the minimum difficulty requirement. 
/// - The the provided proof account must be associated with the signer. 
/// - The provided bus, config, noise, stake, and slot hash sysvar must be valid.
pub fn process_mine<'a, 'info>(
    _program_id: &Pubkey,
    accounts: &'a [AccountInfo<'info>],
    data: &[u8],
) -> ProgramResult {
    // Parse args
    let args = MineArgs::try_from_bytes(data)?;
    
    // Load accounts
    let [signer, bus_info, config_info, proof_info, instructions_sysvar, slot_hashes_sysvar] = accounts
    else {
        return Err(ProgramError::NotEnoughAccountKeys);
    };
    
    load_signer(signer)?;
    load_any_bus(bus_info, true)?;
    load_config(config_info, false)?;
    load_proof_with_miner(proof_info, signer.key, true)?;
    load_sysvar(instructions_sysvar, sysvar::instructions::id())?;
    load_sysvar(slot_hashes_sysvar, sysvar::slot_hashes::id())?;

    // Validate this is the only mine ix in the transaction. 
    if !validate_transaction(&instructions_sysvar.data.borrow()).unwrap_or(false) {
        return Err(OreError::TransactionInvalid.into());
    }

    // Validate epoch is active. 
    let config_data = config_info.data.borrow();
    let config = Config::try_from_bytes(&config_data)?;
    let clock = Clock::get().or(Err(ProgramError::InvalidAccountData))?;
    if config
        .last_reset_at
        .saturating_add(EPOCH_DURATION)
        .le(&clock.unix_timestamp)
    {
        return Err(OreError::NeedsReset.into());
    }
    
    // Validate the hash digest. 
    let mut proof_data = proof_info.data.borrow_mut();
    let proof = Proof::try_from_bytes_mut(&mut proof_data)?;
    let solution = Solution::new(args.digest, args.nonce);
    if !solution.is_valid(&proof.challenge) {
        return Err(OreError::HashInvalid.into());
    }

    // Validate hash satisfies the minimnum difficulty.
    let hash = solution.to_hash();
    let difficulty = hash.difficulty();
    sol_log(&format!(""Diff {}"", difficulty));
    if difficulty.lt(&MIN_DIFFICULTY) {
        return Err(OreError::HashTooEasy.into());
    }

    // Calculate base reward rate. 
    let difficulty = difficulty.saturating_sub(MIN_DIFFICULTY);
    let mut reward = config
        .base_reward_rate
        .checked_mul(2u64.checked_pow(difficulty).unwrap())
        .unwrap();
    
    // Apply staking multiplier. 
    let t = clock.unix_timestamp;
    if config.max_stake.gt(&0) && proof.last_stake_at.saturating_add(ONE_MINUTE).le(&t) {
        let staking_reward = proof
            .balance
            .min(config.max_stake)
            .checked_mul(reward)
            .unwrap()
            .checked_div(config.max_stake)
            .unwrap();
        reward = reward.checked_add(staking_reward).unwrap();
    }
    
    // Reject spam transactions. 
    let t_target = proof.last_hash_at.saturating_add(ONE_MINUTE);
    let t_spam = t_target.saturating_sub(TOLERANCE);
    if t.lt(&t_spam) {
        return Err(OreError::Spam.into());
    }
     
    // Apply liveness penalty.
    let t_liveness = t_target.saturating_add(TOLERANCE);
    if t.gt(&t_liveness) {
        reward = reward
            .checked_sub(
                reward
                    .checked_mul(t.checked_sub(t_liveness).unwrap() as u64)
                    .unwrap()
                    .checked_div(ONE_MINUTE as u64)
                    .unwrap(),
            )
            .unwrap();
    }
    
    // Limit payout amount to whatever is left in the bus
    let mut bus_data = bus_info.data.borrow_mut();
    let bus = Bus::try_from_bytes_mut(&mut bus_data)?;
    let reward_actual = reward.min(bus.rewards);
     
    // Update balances
    bus.theoretical_rewards = bus.theoretical_rewards.checked_add(reward).unwrap();
    bus.rewards = bus.rewards.checked_sub(reward_actual).unwrap();
    proof.balance = proof.balance.checked_add(reward_actual).unwrap();
     
    // Hash recent slot hash into the next challenge to prevent pre-mining attacks
    proof.last_hash = hash.h;
    proof.challenge = hashv(&[
        hash.h.as_slice(),
        &slot_hashes_sysvar.data.borrow()[0..size_of::<SlotHash>()],
    ])
    .0;
     
    // Update time trackers
    proof.last_hash_at = t.max(t_target);
    
    // Update lifetime stats
    proof.total_hashes = proof.total_hashes.saturating_add(1);
    proof.total_rewards = proof.total_rewards.saturating_add(reward);
     
    // Log the mined rewards
    set_return_data(
        MineEvent {
            difficulty: difficulty as u64,
            reward: reward_actual,
            timing: t.saturating_sub(t_liveness),
        }
        .to_bytes(),
    );
     
    Ok(())
}",Medium,"Modify the logic that updates last_hash_at. Instead of setting it directly to the current Unix timestamp (clock.unix_timestamp), update it to the maximum value between prev_last_hash_at + ONE_MINUTE and clock.unix_timestamp.  This introduces a minimum interval (ONE_MINUTE) between consecutive hash submissions that are allowed to update last_hash_at.  ",https://github.com/regolith-labs/ore/commit/3e9150503c3febb8eb96821862fea5e268e9b8bd,High
Sol-219,"Incorrect Follows Fee Calculation  In the buy_token::handler function, the Follows fees (follows_fees_lamports) are calculated based on the price after the wrapper program’s fees have been added (follows_price_after_wrapper_fees).  This causes the Follows program to receive a higher effective price for the transaction, which can lead to the collection of higher fees than originally intended.  As a result, users end up paying more for their wrapped token purchases due to these inflated Follows fees.","rust
// Simulation will return price after all fees 
pub fn handler(ctx: Context<BuyToken>, amount: u64, max_price: u64) -> Result<u64> { 
    // [...]
    
    // Take fees for wrapper 
    let follows_price = ctx.accounts.token_info.get_token_buy_price(amount)?;
    let wrapper_fees_lamports = ctx.accounts.platform_info.get_fees_lamports(follows_price);
    let follows_price_after_wrapper_fees = follows_price.try_add(wrapper_fees_lamports.total());

    // Get expected final price 
    let follows_fees_lamports = ctx.accounts.follows_platform_info.get_fees_lamports(follows_price_after_wrapper_fees);
    let follows_token_price_after_all_fees = follows_price_after_wrapper_fees.try_add(follows_fees_lamports.total());
    
    // [...]
}","// Simulation will return price after all fees
pub fn handler(
    ctx: Context<BuyToken>,
    amount: u64,
    max_price: u64,
) -> Result<u64> {
    // [...] (other code assumed to be here)

    let follows_price = ctx.accounts.token_info.get_token_buy_price(amount)?;
    let follows_fees_lamports = ctx.accounts
        .follows_platform_info
        .get_fees_lamports(follows_price);
    let wrapper_fees_lamports = ctx.accounts
        .platform_info
        .get_fees_lamports(follows_price);
    let follows_price_after_all_fees = follows_price
        .try_add(wrapper_fees_lamports.total())?
        .try_add(follows_fees_lamports.total())?;

    // [...] (other code assumed to be here)

    Ok(follows_price_after_all_fees)  // Assumed return based on context
}",High,Ensure the Follows fees are calculated based on the original buy price (follows_price) before any fees are added.,https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/e85d7b3e-dc47-4a17-b41e-53cf39227528/follows_audit_final.pdf?table=block&id=fecda538-7053-41b1-8ccf-67334c1f5932&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742954400000&signature=lqLyDrQKe9VQNYLnkievdea6Kk8SB570z546v8GVUwI&downloadName=follows_audit_final.pdf,High
Sol-220,"Improper Calculation of Fees  The function quote::get_pre_fee_amount_ld invokes calculate_pre_fee_amount to compute amount_sent_ld. However, there is an issue within calculate_pre_fee_amount when transfer_fee_basis_points is equal to MAX_FEE_BASIS_POINTS, which represents a 100% fee.  In such a case, the function consistently returns zero as the pre-fee amount. This is problematic because, under a 100% fee rate, the correct pre-fee amount should account for the fact that the entire post-fee amount would be consumed by the fee.","rust
pub fn calculate_pre_fee_amount(&self, post_fee_amount: u64) -> Option<u64> { 
    let maximum_fee = u64::from(self.maximum_fee);         
    let transfer_fee_basis_points = u16::from(self.transfer_fee_basis_points) as u128;         
    
    if transfer_fee_basis_points == 0 {             
        Some(post_fee_amount)         
    } else if transfer_fee_basis_points == ONE_IN_BASIS_POINTS || post_fee_amount == 0 {             
        Some(0)         
    } else {             
        let numerator = (post_fee_amount as u128).checked_mul(ONE_IN_BASIS_POINTS)?;             
        let denominator = ONE_IN_BASIS_POINTS.checked_sub(transfer_fee_basis_points)?;             
        let raw_pre_fee_amount = Self::ceil_div(numerator, denominator)?;   
        
        if raw_pre_fee_amount.checked_sub(post_fee_amount as u128)? >= maximum_fee as u128 {                 
            post_fee_amount.checked_add(maximum_fee)             
        } else {                 
            // should return `None` if `pre_fee_amount` overflows                 
            u64::try_from(raw_pre_fee_amount).ok()             
        }         
    }     
}","rust
pub fn calculate_pre_fee_amount(&self, post_fee_amount: u64) -> Option<u64> {         
    let maximum_fee = u64::from(self.maximum_fee);         
    let transfer_fee_basis_points = u16::from(self.transfer_fee_basis_points) as u128;         
    
    match (transfer_fee_basis_points, post_fee_amount) {             
        // no fee, same amount             
        (0, _) => Some(post_fee_amount),             
        
        // 0 zero out, 0 in             
        (_, 0) => Some(0),             
        
        // 100%, cap at max fee             
        (ONE_IN_BASIS_POINTS, _) => maximum_fee.checked_add(post_fee_amount),             
        
        _ => {                 
            let numerator = (post_fee_amount as u128).checked_mul(ONE_IN_BASIS_POINTS)?;                 
            let denominator = ONE_IN_BASIS_POINTS.checked_sub(transfer_fee_basis_points)?;                 
            let raw_pre_fee_amount = Self::ceil_div(numerator, denominator)?;                  
            
            if raw_pre_fee_amount.checked_sub(post_fee_amount as u128)? >= maximum_fee as u128 {                     
                post_fee_amount.checked_add(maximum_fee)                 
            } else {                     
                // should return `None` if `pre_fee_amount` overflows                     
                u64::try_from(raw_pre_fee_amount).ok()                 
            }             
        }         
    }     
}",High,Return the pre-fee amount as post_fee_amount + maximum_fee when transfer_fee_basis_points == MAX_FEE_BASIS_POINTS.,https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/e8652209-92b3-4c46-bcd5-c1bba5a6d709/layerzero_v2_solana_audit_final.pdf?table=block&id=6b7e3fe1-4ed0-45bf-b211-19dc4cc86207&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742954400000&signature=SlBpjvPVTGlfmIi49vQC_G1ZWooFVs6YddLZsLQZ6Jo&downloadName=layerzero_v2_solana_audit_final.pdf,High
Sol-221,"Incorrect Account Ordering. transfer_with_split_proofs assembles a list of seven AccountMeta objects, which provide metadata about accounts involved in the transaction. process_transfer iterates through these accounts; however, these accounts are structured incorrectly. In verify_transfer_proof, account_info_iter iterates through the first three accounts out of the seven accounts listed in transfer_with_split_proofs.In the instance, no_op_on_split_proof_context_state is false, and close_split_context_state_on_execution is true, execution enters into the if condition and account_info_iter loads the next account into lamport_destination_account_info to load lamport_destination, however, due to the incorrect ordering of accounts, source_account_authority is loaded instead, which is a signer account. Therefore, during the closure of each split context state account, it employs lamport_destination_account_info as the destination for lamport transfers, which currently references source_account_authority. This, in essence, results in the transfer of lamports to the signing authority of the source account, a behavior that was not the intended outcome. Note that a similar issue is present when transferring with fees. Furthermore, if no_op_on_split_proof_context_state is set to true and a necessary context state account has not been initialized, the invocation of verify_transfer_proof results in a return of None as demonstrated below. Consequently, in the event that close_split_context_state_on_execution is true, process_transfer clears lamport_destination, context_accounts.authority, and zk_token_proof_program to load source_account_authority into authority_info. However, due to the incorrect ordering of accounts, source_account_authority, lamport_destination and context_accounts.authority accounts are flushed out and authority_info is assigned zk_token_proof_program account. Thus, the incorrect authority may fail to verify the zero-knowledge proof, which is a critical part of ensuring the correctness of the transfer. If the proof fails or the verification process does not execute as intended, the transaction may result in an error and failure of the transfer.","rust
/// Create a `TransferWithSplitProof` instruction without fee 
#[allow(clippy::too_many_arguments)] 
#[cfg(not(target_os = ""solana""))] 
pub fn transfer_with_split_proofs( 
    token_program_id: &Pubkey, 
    source_token_account: &Pubkey, 
    mint: &Pubkey, 
    destination_token_account: &Pubkey, 
    new_source_decryptable_available_balance: DecryptableBalance, 
    source_account_authority: &Pubkey, 
    context_accounts: TransferSplitContextStateAccounts, 
    source_decrypt_handles: &SourceDecryptHandles, 
) -> Result<Instruction, ProgramError> { 
    check_program_account(token_program_id)?; 
    let mut accounts = vec![ 
        AccountMeta::new(*source_token_account, false), 
        AccountMeta::new_readonly(*mint, false), 
        AccountMeta::new(*destination_token_account, false), 
    ]; 
    let close_split_context_state_on_execution = 
        if let Some(close_split_context_state_on_execution_accounts) =
            context_accounts.close_split_context_state_accounts 
        { 
            // If `close_split_context_state_accounts` is set, then all context-state
            // accounts must be `writable`. 
            accounts.push(AccountMeta::new(*context_accounts.equality_proof, false)); 
            accounts.push(AccountMeta::new(
                *context_accounts.ciphertext_validity_proof,
                false,
            )); 
            accounts.push(AccountMeta::new(*context_accounts.range_proof, false));
            accounts.push(AccountMeta::new_readonly(*source_account_authority, true)); 
            accounts.push(AccountMeta::new(
                *close_split_context_state_on_execution_accounts.lamport_destination,
                false,
            )); 
            accounts.push(AccountMeta::new_readonly(*context_accounts.authority, true)); 
            accounts.push(AccountMeta::new_readonly(
                *close_split_context_state_on_execution_accounts.zk_token_proof_program,
                false,
            )); 
            true 
        } else { 
            // If `close_split_context_state_accounts` is not set, then context state accounts can be read-only. 
            accounts.push(AccountMeta::new_readonly(
                *context_accounts.equality_proof,
                false,
            ));
            accounts.push(AccountMeta::new_readonly(
                *context_accounts.ciphertext_validity_proof,
                false,
            )); 
            accounts.push(AccountMeta::new_readonly(
                *context_accounts.range_proof,
                false,
            )); 
            accounts.push(AccountMeta::new_readonly(*source_account_authority, true)); 
            false 
        }; 
   //There seems to be a missing ending bracket here for the function 

 pub fn verify_transfer_proof( [...] ) -> Result<Option<TransferProofContextInfo>, ProgramError> { 
    // The first three accounts are loaded here [...] 
    if close_split_context_state_on_execution { 
        let lamport_destination_account_info = ,→ next_account_info(account_info_iter)?; 
        let context_state_account_authority_info = ,→ next_account_info(account_info_iter)?; 
        msg!(""Closing equality proof context state account""); 
        invoke(&zk_token_proof_instruction::close_context_state(ContextStateInfo {
            context_state_account: ,→ equality_proof_context_state_account_info.key, 
            context_state_authority: ,→ context_state_account_authority_info.key, }, 
            lamport_destination_account_info.key,
        ), 
        &[ equality_proof_context_state_account_info.clone(),
            lamport_destination_account_info.clone(),
            context_state_account_authority_info.clone(),
        ],)?; 
    //Similarly, cipher text validity proof and range proof context state ,→ accounts are also closed [...] 
}","/// Create a `TransferWithSplitProof` instruction without fee
#[allow(clippy::too_many_arguments)]
#[cfg(not(target_os = ""solana""))]
pub fn transfer_with_split_proofs(
    token_program_id: &Pubkey,
    source_token_account: &Pubkey,
    mint: &Pubkey,
    destination_token_account: &Pubkey,
    new_source_decryptable_available_balance: DecryptableBalance,
    source_account_authority: &Pubkey,
    context_accounts: TransferSplitContextStateAccounts,
    source_decrypt_handles: &SourceDecryptHandles,
) -> Result<Instruction, ProgramError> {
    check_program_account(token_program_id)?;

    let mut accounts = vec![
        AccountMeta::new(*source_token_account, false),
        AccountMeta::new_readonly(*mint, false),
        AccountMeta::new(*destination_token_account, false),
    ];

    let close_split_context_state_on_execution =
        if let Some(close_split_context_state_on_execution_accounts) =
            context_accounts.close_split_context_state_accounts
        {
            // If `close_split_context_state_accounts` is set, then all context state
            // accounts must be `writable`.
            accounts.push(AccountMeta::new(*context_accounts.equality_proof, false));
            accounts.push(AccountMeta::new(
                *context_accounts.ciphertext_validity_proof,
                false,
            ));
            accounts.push(AccountMeta::new(*context_accounts.range_proof, false));
            accounts.push(AccountMeta::new(
                *close_split_context_state_on_execution_accounts.lamport_destination,
                false,
            ));
            accounts.push(AccountMeta::new_readonly(*context_accounts.authority, true));
            accounts.push(AccountMeta::new_readonly(
                *close_split_context_state_on_execution_accounts.zk_token_proof_program,
                false,
            ));
            accounts.push(AccountMeta::new_readonly(*source_account_authority, true));
            true
        } else {
            // If `close_split_context_state_accounts` is not set, then context state
            // accounts can be read-only.
            accounts.push(AccountMeta::new_readonly(
                *context_accounts.equality_proof,
                false,
            ));
            accounts.push(AccountMeta::new_readonly(
                *context_accounts.ciphertext_validity_proof,
                false,
            ));
            accounts.push(AccountMeta::new_readonly(
                *context_accounts.range_proof,
                false,
            ));
            accounts.push(AccountMeta::new_readonly(*source_account_authority, true));
            false
        };

    // Note: Function appears incomplete in the provided snippet.
    // Typically, this would return an Instruction wrapped in Ok()
    // Ok(Instruction { ... })
}",Medium,"Modify the conditions in process_transfer, verify_transfer_with_fee_proof, verify_transfer_proof and the structuring of accounts in transfer_with_split_proofs, such that the new conditions accurately reflect the order of accounts as listed in transfer_with_split_proofs.","https://github.com/solana-labs/solana-program-library/pull/5931/files#diff-2595d3cfe17c6e4ddac286e86b3fadfcdda4a44dbd1259890b94ba105fac63e3L1396, https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/e21cbb09-5ce7-48c8-954e-5077c486a579/solana_token22_audit_final.pdf?table=block&id=88fc9b14-b183-49ee-aa0a-29c29c1eaf89&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742961600000&signature=H_I1MmWaBTT1ZTabCmBV6FDaHowAV7WGiNbDzY0_3Yc&downloadName=solana_token22_audit_final.pdf",High
Sol-222,"Missing Side Check On Market Vault Account. The vulnerability is related to a potential mismatch between the side of an order and the market vault utilized for depositing assets in place_order. place_order is responsible for validating and placing a new order in a trading market, ensuring the calculation of the required deposit amount, and transferring assets between the trader’s account and the market’s vault. It is crucial to ensure that the deposit and withdrawal of assets into and from a market vault are consistent with the side of the order, i.e., a bid or an ask order. The issue arises since there is no check to ensure that the market vault account utilized for depositing assets (ctx.accounts.market_vault) matches the side of the order, as seen in the attached code snippet. As a result, an attacker may place a bid order but use an ask-side market vault for depositing assets (or vice versa). This mismatch may result in the attacker draining funds from the market vault without providing the expected assets in return. This imbalance in the market vault disrupts the fairness and integrity of the trading system, resulting in financial losses for legitimate traders. Proof of Concept 1. Trader A places a legitimate bid order to buy one BTC and deposits 10,000 USD into the market vault (as expected for a bid order). 2. Trader B exploits the vulnerability by placing a bid order to buy one BTC but intentionally uses an ask-side market vault (containing BTC) for depositing assets. 3. The attacker’s bid order is accepted due to the lack of a check to ensure that the market vault matches the side of the order. 4. The attacker’s order executes, and they receive one BTC from Trader A’s legitimate order. However, the attacker never deposited the expected USD into the market vault. 5. As a result, Trader A is left with 10,000 USD less in the market vault (as expected), but Trader B never provided the expected USD. This imbalance leaves the market vault with less USD and more BTC.","rust
pub fn place_order(
    ctx: Context<PlaceOrder>, 
    order: Order, 
    limit: u8
) -> Result<Option<u128>> { 
    require_gte!(order.max_base_lots, 0, OpenBookError::InvalidInputLots); 
    require_gte!( order.max_quote_lots_including_fees, 0, OpenBookError::InvalidInputLots ); 
    // [...] 
    let mut market = ctx.accounts.market.load_mut()?; 
    // abscence of checks regarding side of the order. 
    require!( !market.is_expired(clock.unix_timestamp), OpenBookError::MarketHasExpired ); 
    // [...] 
}","rust
pub fn place_order(ctx: Context<PlaceOrder>, order: Order, limit: u8) -> Result<Option<u128>> {
    require_gte!(
        order.max_base_lots, 
        0, 
        OpenBookError::InvalidInputLots
    );
    
    require_gte!(
        order.max_quote_lots_including_fees, 
        0, 
        OpenBookError::InvalidInputLots
    ); 

    let mut market = ctx.accounts.market.load_mut()?;

    require_keys_eq!(
        market.get_vault_by_side(order.side), 
        ctx.accounts.market_vault.key(), 
        OpenBookError::InvalidMarketVault
    ); 

    require!(
        !market.is_expired(clock.unix_timestamp), 
        OpenBookError::MarketHasExpired
    ); 

    [...]
}",Critical,"Include checks that ensure the market vault utilized for depositing assets matches the side of the order. If the sides do not match, the order should not be executed, and appropriate error handling should occur.","https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/9b7206a8-60c4-4e96-a6d6-66a864dd1d21/openbook_audit_final.pdf?table=block&id=527e1c3e-b913-4a2a-9d82-88757467e4a0&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742961600000&signature=Cj4h-LnuGst0dqwThVB6AUD7YRx0Z4Z8LQTn1bywiKw&downloadName=openbook_audit_final.pdf, https://github.com/openbook-dex/openbook-v2/commit/1b40b6898f7fca130d47f74c66c8f3017d17753#diff-25d3fff0e41784465ae972be88540e901aac18c4d84ca3541c8e3b06b75538d8",High
Sol-223,"Incorrect Check On Variance Value. In market::oracle_price_from_a_and_b, the target_var value indicates the target variance, which is the upper bound for the permissible range of values for the variance. An issue arises when comparing target_var and var in oracle_price_from_a_and_b. In the existing code, the condition target_var > var implies that if the calculated variance (var) is less than the target variance (target_var), the function returns None. This means that if the actual variance is less than the target variance, the function will not return an oracle price, even though it should. Thus, the only scenario in which it will function without issues is when the variance value is incorrect. In such a situation, users will receive an inaccurate price with a significant error, causing the resulting price to deviate either above or below the actual asset price.","rust
fn oracle_price_from_a_and_b(
    &self, 
    oracle_a_acc: &impl KeyedAccountReader, 
    oracle_b_acc: &impl KeyedAccountReader, 
    now_slot: u64, 
) -> Result<Option<I80F48>> {
    //... rest of the code

    let (price, var) = oracle_a.combine_div_with_var(&oracle_b);
    let target_var = self.oracle_config.conf_filter.powi(2);
    
    if target_var > var {
        msg!(""Combined variance too high; value {}, target {}"", var, target_var);
        Ok(None)
    } else {
        //... rest of the code
    }
}","rust
fn oracle_price_from_a_and_b( 
    &self, 
    oracle_a_acc: &impl KeyedAccountReader, 
    oracle_b_acc: &impl KeyedAccountReader, 
    now_slot: u64, 
) -> Result<Option<I80F48>> { 
    [...] 
    let (price, var) = oracle_a.combine_div_with_var(&oracle_b); 
    let target_var = self.oracle_config.conf_filter.powi(2); 
    if var > target_var { 
        msg!( 
            ""Combined variance too high; value {}, target {}"", 
            var, target_var 
        ); 
        Ok(None) 
    } else { 
        [...] 
    } 
}",High,"Ensure that the calculated variance does not exceed the desired variance by modifying the condition to: target_var <= var. This change will allow the function to return an oracle price when the actual variance is less than or equal to the target variance, which is the correct behavior.",https://github.com/openbook-dex/openbook-v2/commit/dad37aaf02cd668b92b68d022982de41c5a34a16,High
Sol-224,"Proper Access Control Implementation. The issue relates to the security and access control of market-related accounts, specifically market_base_vault and market_quote_vault. These vault accounts store and manage tokens associated with the market and are expected to be controlled by certain authorities. Currently, create_market does not explicitly check if the close_market_admin is set as an authority on the market_base_vault and market_quote_vault accounts. If a malicious actor sets the close_market_admin as an authority on these vaults, they may manipulate or drain the funds held in those vaults, even if the market should be closed. ","rust
use crate::state::*;
use anchor_lang::prelude::*;
use anchor_spl::token::{Mint, TokenAccount};

#[event_cpi]
#[derive(Accounts)]
pub struct CreateMarket<'info> {
    #[account(
        init,
        payer = payer,
        space = 8 + std::mem::size_of::<Market>(),
    )]
    pub market: AccountLoader<'info, Market>,

    #[account(
        seeds = [b""Market"".as_ref(), market.key().to_bytes().as_ref()],
        bump
    )]
    pub market_authority: UncheckedAccount<'info>,
    
    #[account(zero)]
    pub bids: AccountLoader<'info, BookSide>,
    
    #[account(zero)]
    pub asks: AccountLoader<'info, BookSide>,
    
    #[account(zero)]
    pub event_heap: AccountLoader<'info, EventHeap>,
    
    #[account(mut)]
    pub payer: Signer<'info>,
    
    #[account(token::mint = base_mint, token::authority = market_authority)]
    pub market_base_vault: Account<'info, TokenAccount>,
    
    #[account(token::mint = quote_mint, token::authority = market_authority)]
    pub market_quote_vault: Account<'info, TokenAccount>,
    
    pub base_mint: Box<Account<'info, Mint>>,
    
    pub quote_mint: Box<Account<'info, Mint>>,
    
    pub system_program: Program<'info, System>,
    
    pub oracle_a: Option<UncheckedAccount<'info>>,
    
    public oracle_b: Option<UncheckedAccount<'info>>,
    
    pub collect_fee_admin: UncheckedAccount<'info>,
    
    pub open_orders_admin: Option<UncheckedAccount<'info>>,
    
    pub consume_events_admin: Option<UncheckedAccount<'info>>,
    
    pub close_market_admin: Option<UncheckedAccount<'info>>,
}","rust
use crate::state::*;
use anchor_lang::prelude::*;
use anchor_spl::{
    associated_token::AssociatedToken,
    token::{Mint, Token, TokenAccount},
};

#[event_cpi]
#[derive(Accounts)]
pub struct CreateMarket<'info> {
    #[account(
        init,
        payer = payer,
        space = 8 + std::mem::size_of::<Market>(),
    )]
    pub market: AccountLoader<'info, Market>,
    
    #[account(
        seeds = [b""Market"".as_ref(), market.key().to_bytes().as_ref()],
        bump,
    )]
    /// CHECK:
    pub market_authority: UncheckedAccount<'info>,
    
    /// Accounts are initialized by client,
    /// anchor discriminator is set first when ix exits,
    #[account(zero)]
    pub bids: AccountLoader<'info, BookSide>,
    
    #[account(zero)]
    pub asks: AccountLoader<'info, BookSide>,
    
    #[account(zero)]
    pub event_heap: AccountLoader<'info, EventHeap>,
    
    #[account(mut)]
    pub payer: Signer<'info>,
    
    #[account(
        init,
        payer = payer,
        associated_token::mint = base_mint,
        associated_token::authority = market_authority,
    )]
    pub market_base_vault: Account<'info, TokenAccount>,
    
    #[account(
        init,
        payer = payer,
        associated_token::mint = quote_mint,
        associated_token::authority = market_authority,
    )]
    pub market_quote_vault: Account<'info, TokenAccount>,
    
    pub base_mint: Box<Account<'info, Mint>>,
    pub quote_mint: Box<Account<'info, Mint>>,
    pub system_program: Program<'info, System>,
    pub token_program: Program<'info, Token>,
    pub associated_token_program: Program<'info, AssociatedToken>,
    
    /// CHECK: The oracle can be one of several different account types
    pub oracle_a: Option<UncheckedAccount<'info>>,
    
    /// CHECK: The oracle can be one of several different account types
    pub oracle_b: Option<UncheckedAccount<'info>>,
    
    /// CHECK:
    pub collect_fee_admin: UncheckedAccount<'info>,
    
    /// CHECK:
    pub open_orders_admin: Option<UncheckedAccount<'info>>,
    
    /// CHECK:
    pub consume_events_admin: Option<UncheckedAccount<'info>>,
    
    /// CHECK:
    pub close_market_admin: Option<UncheckedAccount<'info>>,
}",Medium,"Implement proper checks and make use of program-derived addresses as detailed below for better security: • Utilize Program Derived Addresses(PDAs) for vaults instead of creating vault accounts directly within create_market, ensuring that the vault accounts are controlled solely by the program and cannot have external authorities. • When creating the market, the program may initialize the vaults with the appropriate data and permissions. This includes setting the program itself as the authority and specifying other necessary parameters. • After creating the market and initializing the vaults, the program should explicitly check and ensure that only authorized entities have the necessary authority over these vaults.","https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/9b7206a8-60c4-4e96-a6d6-66a864dd1d21/openbook_audit_final.pdf?table=block&id=527e1c3e-b913-4a2a-9d82-88757467e4a0&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742961600000&signature=Cj4h-LnuGst0dqwThVB6AUD7YRx0Z4Z8LQTn1bywiKw&downloadName=openbook_audit_final.pdf, https://github.com/openbook-dex/openbook-v2/commit/851eca88af0d52c1818254b0973b0d54acc5cb85#diff-f6f0fd2c552f11dda866417172f286b03edf12c18cd7daa68d176343eb580749",High
Sol-225,"Incorrect Reallocation Size. When adding a member to a multi-signature account, if the pre-allocated memory becomes fully utilized, it is necessary to reallocate. realloc_if_needed assesses the requirement for reallocation and performs reallocation for the account, providing additional space for ten members. The number of members is expanded in two instances: • multisig_add_member. • config_transaction_execute. While the former only increases the member count by one, the latter may increase the member count by more than one due to the possibility of executing multiple actions. Therefore, if the size of members to add exceeds the sum of the remaining space and the size of ten members, the fixed increment of ten members may result in a shortage of space.","rust
/// Check if the multisig account space needs to be reallocated to accommodate `members_length`.
/// Returns `true` if the account was reallocated.
pub fn realloc_if_needed<'a>(
    multisig: AccountInfo<'a>,
    members_length: usize,
    rent_payer: AccountInfo<'a>,
    system_program: AccountInfo<'a>,
) -> Result<bool> {
    let current_account_size = multisig.data.borrow().len();

    // Check if we need to reallocate space.
    if current_account_size >= Multisig::size(members_length) { 
        return Ok(false); 
    }

    // We need to allocate more space. To avoid doing this operation too often, 
    // we increment it by 10 members.
    let new_size = current_account_size + (10 * Member::INIT_SPACE);

    // Reallocate more space.
    AccountInfo::realloc(&multisig, new_size, false)?;

    // If more lamports are needed, transfer them to the account.
    let rent_exempt_lamports = Rent::get().unwrap().minimum_balance(new_size).max(1);
    let top_up_lamports = rent_exempt_lamports.saturating_sub(multisig.to_account_info().lamports());

    if top_up_lamports > 0 {
        system_program::transfer(
            CpiContext::new(
                system_program, 
                system_program::Transfer {
                    from: rent_payer,
                    to: multisig,
                },
            ), 
            top_up_lamports,
        )?;
    }
    Ok(true)
}","rust
/// Check if the multisig account space needs to be reallocated to accommodate `members_length`. 
/// Returns `true` if the account was reallocated. 
pub fn realloc_if_needed<'a>(
    multisig: AccountInfo<'a>,
    members_length: usize,
    rent_payer: AccountInfo<'a>,
    system_program: AccountInfo<'a>,
) -> Result<bool> {
    let current_account_size = multisig.data.borrow().len();
    let account_size_to_fit_members = Multisig::size(members_length);

    // Check if we need to reallocate space.
    if current_account_size >= account_size_to_fit_members {
        return Ok(false);
    }

    let new_size = max(
        current_account_size + (10 * Member::INIT_SPACE), // We need to allocate more space. To avoid doing this operation too often, we increment it by 10 members.
        account_size_to_fit_members,
    );

    // Reallocate more space.
    AccountInfo::realloc(&multisig, new_size, false)?;

    // If more lamports are needed, transfer them to the account.
    let rent_exempt_lamports = Rent::get().unwrap().minimum_balance(new_size).max(1);
    let top_up_lamports = rent_exempt_lamports.saturating_sub(multisig.to_account_info().lamports());

    if top_up_lamports > 0 {
        system_program::transfer(
            CpiContext::new(
                system_program,
                system_program::Transfer {
                    from: rent_payer,
                    to: multisig,
                },
            ),
            top_up_lamports,
        )?;
    }
    
    Ok(true)
}",Low,Select the larger value between the size increased by ten members and the size increased as needed.,"https://github.com/Squads-Protocol/v4/commit/5640af0cd681148a435c68549b338eb219be0021, https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/568d9d7a-ac1f-4996-94ed-7c8506e47b38/squads_v4_audit_final.pdf?table=block&id=4d707018-e849-40d7-99b2-bbec51b7eeb2&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1742968800000&signature=_i9qmF_3wPp_RRZ_P4KE1AZG0agLVLZHKy8y1cRVI9o&downloadName=squads_v4_audit_final.pdf",High
Sol-226,"Blocked Transaction Addition. After creating a batch, adding transactions necessitates a proposal generated by proposal_create. The program-derived address of the proposal uses the transaction index utilized in batch_create as a seed. When initializing the proposal, the caller may select between the Draft and Active states. In BatchAddTransaction::validate, safeguards permit the addition of transactions to the batch only when the proposal is in a Draft state. However, a malicious attacker may set the proposal to Active, preventing the utilization of transactions created for the batch.","rust
use anchor_lang::prelude::*;
use crate::errors::*;
use crate::state::*;

#[derive(AnchorSerialize, AnchorDeserialize)]
pub struct ProposalCreateArgs {
    /// Index of the multisig transaction this proposal is associated with.
    pub transaction_index: u64,
    /// Whether the proposal should be initialized with status `Draft`.
    pub draft: bool,
}

#[derive(Accounts)]
#[instruction(args: ProposalCreateArgs)]
pub struct ProposalCreate<'info> {
    #[account( 
        seeds = [SEED_PREFIX, SEED_MULTISIG, multisig.create_key.as_ref()],
        bump = multisig.bump,
    )]
    pub multisig: Account<'info, Multisig>,

    #[account( 
        init, 
        payer = rent_payer, 
        space = Proposal::size(multisig.members.len()), 
        seeds = [ 
            SEED_PREFIX, 
            multisig.key().as_ref(), 
            SEED_TRANSACTION, 
            &args.transaction_index.to_le_bytes(), 
            SEED_PROPOSAL, 
        ], 
        bump 
    )]
    pub proposal: Account<'info, Proposal>,
    #[account(mut)]
    pub rent_payer: Signer<'info>,
    pub system_program: Program<'info, System>,
}

impl ProposalCreate<'_> {
    fn validate(&self, args: &ProposalCreateArgs) -> Result<()> {
        let Self { multisig, .. } = self;
        
        require!( 
            args.transaction_index <= multisig.transaction_index, 
            MultisigError::InvalidTransactionIndex 
        );
        
        require!( 
            args.transaction_index > multisig.stale_transaction_index, 
            MultisigError::StaleProposal 
        );
        
        Ok(())
    }

    #[access_control(ctx.accounts.validate(&args))]
    pub fn proposal_create(
        ctx: Context<Self>, 
        args: ProposalCreateArgs
    ) -> Result<()> {
        let proposal = &mut ctx.accounts.proposal;
        proposal.multisig = ctx.accounts.multisig.key();
        proposal.transaction_index = args.transaction_index;
        proposal.status = if args.draft {
            ProposalStatus::Draft {
                timestamp: Clock::get()?.unix_timestamp,
            }
        } else {
            ProposalStatus::Active {
                timestamp: Clock::get()?.unix_timestamp,
            }
        };
        proposal.bump = *ctx.bumps.get(""proposal"").unwrap();
        proposal.approved = vec![];
        proposal.rejected = vec![];
        proposal.cancelled = vec![];

        Ok(())
    }
}","rust
use anchor_lang::prelude::*;
use crate::errors::*;
use crate::state::*;

#[derive(AnchorSerialize, AnchorDeserialize)]
pub struct ProposalCreateArgs {
    /// Index of the multisig transaction this proposal is associated with.
    pub transaction_index: u64,

    /// Whether the proposal should be initialized with status `Draft`.
    pub draft: bool,
}

#[derive(Accounts)]
#[instruction(args: ProposalCreateArgs)]
pub struct ProposalCreate<'info> {
    #[account(
        seeds = [SEED_PREFIX, SEED_MULTISIG, multisig.create_key.as_ref()],
        bump = multisig.bump,
    )]
    pub multisig: Account<'info, Multisig>,

    #[account(
        init,
        payer = creator,
        space = Proposal::size(multisig.members.len()),
        seeds = [
            SEED_PREFIX,
            multisig.key().as_ref(),
            SEED_TRANSACTION,
            &args.transaction_index.to_le_bytes(),
            SEED_PROPOSAL,
        ],
        bump
    )]
    pub proposal: Account<'info, Proposal>,

    #[account(mut)]
    pub creator: Signer<'info>,

    pub system_program: Program<'info, System>,
}

impl ProposalCreate<'_> {
    fn validate(&self, args: &ProposalCreateArgs) -> Result<()> {
        let Self { multisig, creator, .. } = self;
        let creator_key = creator.key();

        // args
        // We can only create a proposal for an existing transaction.
        require!(
            args.transaction_index <= multisig.transaction_index,
            MultisigError::InvalidTransactionIndex
        );

        // We can't create a proposal for a stale transaction.
        require!(
            args.transaction_index > multisig.stale_transaction_index,
            MultisigError::StaleProposal
        );

        // creator
        // Has to be a member.
        require!(
            self.multisig.is_member(self.creator.key()).is_some(),
            MultisigError::NotAMember
        );

        // Must have at least one of the following permissions: Initiate or Vote.
        require!(
            self.multisig.member_has_permission(creator_key, Permission::Initiate)
                || self.multisig.member_has_permission(creator_key, Permission::Vote),
            MultisigError::Unauthorized
        );

        Ok(())
    }

    /// Create a new multisig proposal.
    #[access_control(ctx.accounts.validate(&args))]
    pub fn proposal_create(ctx: Context<Self>, args: ProposalCreateArgs) -> Result<()> {
        let proposal = &mut ctx.accounts.proposal;
        proposal.multisig = ctx.accounts.multisig.key();
        proposal.transaction_index = args.transaction_index;
        proposal.status = if args.draft {
            ProposalStatus::Draft {
                timestamp: Clock::get()?.unix_timestamp,
            }
        } else {
            ProposalStatus::Active {
                timestamp: Clock::get()?.unix_timestamp,
            }
        };

        proposal.bump = *ctx.bumps.get(""proposal"").unwrap();
        proposal.approved = vec![];
        proposal.rejected = vec![];
        proposal.cancelled = vec![];

        Ok(())
    }
}",Low,Add a cross-program invocation for proposal_create at the end of batch_create to ensure the creation of a proposal in the Draft state for the batch. Fixed by restricting the proposal creation for multi-signature members with the initiate or vote role.,https://github.com/Squads-Protocol/v4/commit/3906ce916a36aa26ebfdc984bd0ea3f055080d0c#diff-851f5d927f0e623bd2a6ddc11f0b6ca55eb4072f93c87c3a3d6da9a799d75345,High
Sol-227,"Incorrect Account And Bump. Withdraw_v2 checks the withdraw_from_burner_ta variable to determine whether the withdrawal will occur from burn_ta or vault_ta. However, if withdraw_from_burner_ta is set to true, it utilizes vault_ta and vault_bump instead of burn_ta and burn_bump. This may result in a runtime error and a denial of service.","rust
pub fn withdraw_v2<'a, 'b, 'c, 'info>(
    ctx: Context<'a, 'b, 'c, 'info, WithdrawV2>,
    vault_bump: u8,
    burn_bump: u8,
    withdraw_amount: u64, 
    before_amount: u64, 
    final_amount: u64,
) -> Result<()> {
    let locker = &mut ctx.accounts.locker;
    let mk = ctx.accounts.mint.key();
    let mint_position_option = locker.mints.iter().position(|&lm| lm == mk);

    if let None = mint_position_option {
        return Err(error!(ErrorCode::WithdrawForMintNotInLocker));
    }
    
    let withdraw_from_burner_ta = ctx.accounts.vault_ta.key() == ctx.accounts.burn_ta.key();
    let mut sourceTa = match withdraw_from_burner_ta {
        true => Account::<'_, anchor_spl::token::TokenAccount>::try_from(
            &ctx.accounts.burn_ta.to_account_info(),
        )?,
        false => Account::<'_, anchor_spl::token::TokenAccount>::try_from(
            &ctx.accounts.vault_ta.to_account_info(),
        )?,
    };
    
    if sourceTa.amount < withdraw_amount {
        return Err(error!(ErrorCode::InsufficientFunds));
    }
    
    let mint_position = mint_position_option.unwrap();
    let withdraw_type = get_withdraw_type (
        locker,
        ctx.accounts.user_ta_owner.key(),
        final_amount,
        sourceTa.amount,
        withdraw_amount,
    );
    
    if locker.amounts[mint_position] != before_amount {
        return Err(error!(ErrorCode::InvalidBeforeState));
    }
    
    if final_amount > 0 {
        locker.amounts[mint_position] = final_amount;
    }
    else {
        locker.mints.remove(mint_position);
        locker.amounts.remove(mint_position);
    }

    if *ctx.accounts.user_ta.to_account_info().owner != ctx.accounts.token_program.key() {
        let cpi_program = ctx.accounts.associated_token_program.to_account_info();
        let cpi_accounts = anchor_spl::associated_token::Create {
            payer: ctx.accounts.user_ta_owner.to_account_info(),
            associated_token: ctx.accounts.user_ta.to_account_info(),
            authority: ctx.accounts.user_ta_owner.to_account_info(),
            mint: ctx.accounts.mint.to_account_info(),
            system_program: ctx.accounts.system_program.to_account_info(),
            token_program: ctx.accounts.token_program.to_account_info(),
            rent: ctx.accounts.rent.to_account_info(),
        };
        let cpi_ctx = anchor_lang::context::CpiContext::new(cpi_program, cpi_accounts);
        anchor_spl::associated_token::create(cpi_ctx)?;
    }
    
    if withdraw_from_burner_ta {
        anchor_spl::token::transfer(
            CpiContext::new_with_signer(
                ctx.accounts.token_program.to_account_info(),
                anchor_spl::token::Transfer {
                    from: ctx.accounts.vault_ta.to_account_info(),
                    to: ctx.accounts.user_ta.to_account_info(),
                    authority: ctx.accounts.vault_ta.to_account_info(),
                },
                &[&[ctx.accounts.mint.key().as_ref(), &[vault_bump]]],
            ),
            withdraw_amount.into(),
        )?;
    }
}","rust
pub fn withdraw_v2<'a, 'b, 'c, 'info>(
    ctx: Context<'a, 'b, 'c, 'info, WithdrawV2>,
    vault_bump: u8,
    burn_bump: u8,
    withdraw_amount: u64,
    before_amount: u64,
    final_amount: u64,
) -> Result<()> {

    let locker = &mut ctx.accounts.locker;
    let mk = ctx.accounts.mint.key();
    let mint_position_option = locker.mints.iter().position(|&lm| lm == mk);

    if let None = mint_position_option {
        return Err(error!(ErrorCode::WithdrawForMintNotInLocker));
    }

    let withdraw_from_burner_ta = ctx.accounts.vault_ta.key() == ctx.accounts.burn_ta.key();
    let mut sourceTa = match withdraw_from_burner_ta {
        true => Account::<'_, anchor_spl::token::TokenAccount>::try_from(&ctx.accounts.burn_ta.to_account_info())?,
        false => Account::<'_, anchor_spl::token::TokenAccount>::try_from(&ctx.accounts.vault_ta.to_account_info())?,
    };

    if sourceTa.amount < withdraw_amount {
        return Err(error!(ErrorCode::InsufficientFunds));
    }

    let mint_position = mint_position_option.unwrap();
    let withdraw_type = get_withdraw_type(
        locker,
        ctx.accounts.user_ta_owner.key(),
        final_amount,
        sourceTa.amount,
        withdraw_amount,
    );

    // Check if locker.amounts[i] is equal to before_amount to avoid duplicates
    if locker.amounts[mint_position] != before_amount {
        return Err(error!(ErrorCode::InvalidBeforeState));
    }

    if final_amount > 0 {
        locker.amounts[mint_position] = final_amount;
    } else {
        locker.mints.remove(mint_position);
        locker.amounts.remove(mint_position);
    }

    if *ctx.accounts.user_ta.to_account_info().owner != ctx.accounts.token_program.key() {
        let cpi_program = ctx.accounts.associated_token_program.to_account_info();
        let cpi_accounts = anchor_spl::associated_token::Create {
            payer: ctx.accounts.user_ta_owner.to_account_info(),
            associated_token: ctx.accounts.user_ta.to_account_info(),
            authority: ctx.accounts.user_ta_owner.to_account_info(),
            mint: ctx.accounts.mint.to_account_info(),
            system_program: ctx.accounts.system_program.to_account_info(),
            token_program: ctx.accounts.token_program.to_account_info(),
            rent: ctx.accounts.rent.to_account_info(),
        };

        let cpi_ctx = anchor_lang::context::CpiContext::new(cpi_program, cpi_accounts);
        anchor_spl::associated_token::create(cpi_ctx)?;
    }

    if withdraw_from_burner_ta {
        anchor_spl::token::transfer(
            CpiContext::new_with_signer(
                ctx.accounts.token_program.to_account_info(),
                anchor_spl::token::Transfer {
                    from: ctx.accounts.burn_ta.to_account_info(),
                    to: ctx.accounts.user_ta.to_account_info(),
                    authority: ctx.accounts.burn_ta.to_account_info(),
                },
                &[&[ctx.accounts.mint.key().as_ref(), &[burn_bump]]],
            ),
            withdraw_amount.into(),
        )?;
    }
}",Medium,Replace vault_ta and vault_bump with burn_ta and burn_bump respectively.,https://github.com/Aurory-Game/ocil/commit/91217b35cd3005a2a7ef056cd3a1bddf4b7a3e67#diff-00f6d20af88536a2ed89ff4b04ae4735c78c26ae4bf724b37bf8bd688596dbfc,High
Sol-228,"Incorrect Calculation For Linear Curves. While setting prices of pools, owners have three curves to choose from: Linear, Exponential and ConstantProduct. Additionally, for Trade pools, dealers can buy and sell NFTs to the pool. get_buy_quote and get_sell_quote are used to calculate the price where pools buy and sell NFTs. Since all pricing curves support dynamic prices and Trade pools essentially allow the price to move in both directions, it is crucial for infinity to ensure that pools will not suffer a loss from a sequence of buy and sell actions. To simplify, if a pool buys an NFT and then sells it immediately, the number of tokens spent on buying the NFT should not exceed the number of tokens collected from selling the NFT. This rule is enforced by the following logic • When a pool buys an NFT, the price is calculated with respect to the pool state after the swap has finished. • When a pool sells an NFT, the price is calculated with respect to the current pool state. These rules ensure that the pool state will always be restored if N sells + N buys occur. However, an error in calculating the NFT buy price causes pools using Linear curves to buy at a higher price than it should. This potentially leads to a loss of funds for pool owners","rust
pub fn get_buy_quote(&self, min_quote: Uint128) -> Result<Option<Uint128>, ContractError> {
    // Calculate the buy price with respect to pool types and bonding curves
    let buy_price = match self.pool_type {
        PoolType::Token => Ok(self.spot_price),
        PoolType::Nft => Err(ContractError::InvalidPool(""pool cannot buy nfts"".to_string())),
        PoolType::Trade => match self.bonding_curve {
            BondingCurve::Linear => {
                self.spot_price
                    .checked_add(self.delta)
                    .map_err(|e| ContractError::Std(StdError::overflow(e)))
            },
            //checks for other types of curves can go here
            //...
        },
    }?;
    
    // If the pool has insufficient tokens to buy the NFT, return None
    if self.total_tokens < buy_price || buy_price < min_quote {
        return Ok(None);
    } 

    Ok(Some(buy_price))
}","rust
pub fn get_buy_quote(&self, min_quote: Uint128) -> Result<Option<Uint128>, ContractError> {
    // Calculate the buy price with respect to pool types and bonding curves
    let buy_price = match self.pool_type {
        PoolType::Trade => match self.bonding_curve {
            BondingCurve::Linear => {
                self.spot_price
                    .checked_add(self.delta)
                    .and_then(|result| result.checked_sub(self.delta))
                    .map_err(|e| ContractError::Std(StdError::overflow(e)))
            },
            // other curves ...
        },
       // other types ...
    }?;
    // other code ...
}",Critical,Calculate the correct price when acquiring NFTs.,https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/e54a133f-cd3f-4295-b875-ffc2ff17ac6d/infinity_swap_audit_final.pdf?table=block&id=cff181d8-2ba4-4c02-8c00-5ce9cff84551&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743048000000&signature=cNln5anlnzJiPXvu9G74jUHgOuHnFrExaakLjUbDF3w&downloadName=infinity_swap_audit_final.pdf,High
Sol-229,"Incorrect Calculation For Exponential Curves. The inverse operation of V ∗(1+delta)isV /(1+delta). TheExponentialcurves incorrectly implement the price decrement step as V ∗ (1 − delta). Since V ∗ (1 + delta) ∗ (1 − delta) < V , this exposes the Exponential pool to risks of price manipulation and may lead to loss of pool owner funds.","pub fn get_buy_quote(&self, min_quote: Uint128) -> Result<Option<Uint128>, ContractError> { 
    let buy_price = match self.pool_type { 
        ... 
        PoolType::Trade => match self.bonding_curve { 
            ... 
            BondingCurve::Exponential => { 
                let product = self
                    .spot_price
                    .checked_mul(self.delta)
                    .map_err(|e| StdError::Overflow { source: e })?
                    .checked_div(Uint128::from(MAX_BASIS_POINTS))
                    .map_err(|e| ContractError::Std(StdError::divide_by_zero(e)))?;

                self.spot_price 
                    .checked_add(product)
                    .map_err(|e| ContractError::Std(StdError::overflow(e))) 
            }
            ... 
        }, 
    }?; 
    ... 
} 

pub fn update_spot_price(&mut self, tx_type: &TransactionType) -> Result<(), StdError> { 
    let result = match tx_type { 
        ... 
        TransactionType::NftsForTokens => match self.bonding_curve { 
            ... 
            BondingCurve::Exponential => { 
                let product = self 
                    .spot_price
                    .checked_mul(self.delta)
                    .map_err(|e| StdError::Overflow { source: e })?
                    .checked_div(Uint128::from(MAX_BASIS_POINTS))
                    .map_err(|e| StdError::DivideByZero { source: e })?;

                self.spot_price
                    .checked_sub(product)
                    .map_err(|e| StdError::Overflow { source: e }) 
            }
            ...
        }, 
    }; 
    ... 
}","rust
pub fn get_buy_quote(&self, min_quote: Uint128) -> Result<Option<Uint128>, ContractError> 
{
    match PoolType {
        BondingCurve::Exponential => {
            let mut calculated_value = self.spot_price.checked_mul(Uint128::from(MAX_BASIS_POINTS))
                .map_err(|e| StdError::Overflow { source: e })?
                .checked_div( 
                    self.delta.checked_add(
                        Uint128::from(MAX_BASIS_POINTS)
                    )
                    .map_err(|e| ContractError::Std(StdError::overflow(e)))?
                )
                .map_err(|e| ContractError::Std(StdError::divide_by_zero(e)));

                //continue your code here...
        }
    }    
}

pub fn update_spot_price(&mut self, tx_type: &TransactionType) -> Result<(), StdError>  
{
    let result = match tx_type {
        TransactionType::NftsForTokens => 
            match self.bonding_curve {
                BondingCurve::Exponential => {
                    let mut calculated_value = self.spot_price.checked_mul(Uint128::from(MAX_BASIS_POINTS))
                        .map_err(|e| StdError::Overflow { source: e })?
                        .checked_div( 
                            self.delta.checked_add(
                                Uint128::from(MAX_BASIS_POINTS)
                            )
                            .map_err(|e| ContractError::Std(StdError::overflow(e)))?
                        )
                        .map_err(|e| ContractError::Std(StdError::divide_by_zero(e)))
                        .checked_add(Uint128::one())
                        .map_err(|e| StdError::Overflow { source: e});
                        
                    //continue your code here...
                }
        },
    };
}",Critical,Use V /(1 + delta) instead of V ∗ (1 − delta).,https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/e54a133f-cd3f-4295-b875-ffc2ff17ac6d/infinity_swap_audit_final.pdf?table=block&id=cff181d8-2ba4-4c02-8c00-5ce9cff84551&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743048000000&signature=cNln5anlnzJiPXvu9G74jUHgOuHnFrExaakLjUbDF3w&downloadName=infinity_swap_audit_final.pdf,High
Sol-230,"Lack Of Check Between Collection And Swap Pool. The execute_swap_tokens_for_specific_nfts action takes a user-provided collection and nfts_to_swap_for. Each entry of nfts_to_swap_for includes a pool_id pointing to the target pool for a swap to occur. Unfortunately, while performing swaps, the collection contract address included in the pool configuration is not checked against the user-supplied collection. This potential mismatch between the user-provided and pool collection causes issues since the pools are used in processing the majority of the swap logic, except the final NFT transfer, which is performed on collection instead. The following illustrates how an attacker may abuse this mismatch to steal NFTs from infinity. 1. Attacker aims to steal collectionV::nftX, currently held by poolV on infinity. 2. Attacker deploys mock an NFT contract collectionM. 3. Attacker mints collectionM::nftX from the mock NFT contract. 4. Attacker creates poolM on infinity and assigns collectionM to the pool. 5. Attacker lists collectionM::nftX on poolM for sale. 6. Attacker callsexecute_swap_tokens_for_specific_nftswithnfts_to_swap_for = poolM::nftX and collection = collectionV. 7. Swap logic is processed for poolM::nftX, the attacker pays poolM for collectionM::nftX. Then, the NFT transfer is completed on collectionV::nftX, and the attacker successfully steals the target NFT from infinity.","rust
fn commit_messages(&self, response: &mut Response) -> Result<(), ContractError> {
    // Iterate over swaps and reduce token payments that need to be made
    for swap in self.swaps.iter() {
        // Push transfer NFT messages
        transfer_nft(
            &swap.nft_payment.nft_token_id,
            &swap.nft_payment.address,
            self.collection.as_ref(),
            response,
        )?;
    }
}","rust
pub fn swap_tokens_for_specific_nfts(
    &mut self, 
    storage: &'a dyn Storage, 
    nfts_to_swap_for: Vec<PoolNftSwap>, 
    swap_params: SwapParams, 
) -> Result<(), ContractError> {
    
    for pool_nfts in nfts_to_swap_for {
        // If pool is not in pool_map, load it from storage
        if !pool_queue_item_map.contains_key(&pool_nfts.pool_id) {
            let pool_option = pools().may_load(storage, pool_nfts.pool_id)?;

            // If pool is not found, return error
            if pool_option.is_none() {
                return Err(ContractError::PoolNotFound(format!(
                    ""pool {} not found"", pool_nfts.pool_id
                )));
            }

            // Create PoolQueueItem and insert into pool_queue_item_map
            let pool = pool_option.unwrap();
            if pool.collection != self.collection {
                return Err(ContractError::InvalidPool(
                    ""pool does not belong to this collection"".to_string(),
                ));
            }

            let quote_price = pool.get_sell_quote(self.min_quote)?;
        }
    }
}",Critical,Check that each selected pool handles the same collection provided by the user.,https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/e54a133f-cd3f-4295-b875-ffc2ff17ac6d/infinity_swap_audit_final.pdf?table=block&id=cff181d8-2ba4-4c02-8c00-5ce9cff84551&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743048000000&signature=cNln5anlnzJiPXvu9G74jUHgOuHnFrExaakLjUbDF3w&downloadName=infinity_swap_audit_final.pdf,High
Sol-231,"NFTs Treated As Fungible Tokens During Withdrawal. During NFT withdrawals, no checks against the owner pool are performed. Combined with remove_nft_deposit succeeding regardless of whether the removed pool_id and nft_token_id storage entry exists, attackers will be able to deposit an NFT (nftX) and withdraw another one with a different id (nftY) from infinity.","rust
pub fn remove_nft_deposit(
    storage: &mut dyn Storage, 
    pool_id: u64, 
    nft_token_id: &str
) {
    NFT_DEPOSITS.remove(
        storage, 
        (pool_id, nft_token_id.to_string())
    );
}","rust
pub fn execute_withdraw_nfts( ... ) -> Result<Response, ContractError> {
    ... 
    // Withdraw NFTs to the asset recipient if specified, otherwise to the sender 
    let recipient = asset_recipient.unwrap_or(info.sender); 
    
    for nft_token_id in &nft_token_ids { 
        transfer_nft( nft_token_id, recipient.as_ref(), pool.collection.as_ref(), &mut response, )?;
        verify_nft_deposit(deps.storage, pool_id, nft_token_id);
        remove_nft_deposit(deps.storage, pool_id, nft_token_id); 
    } 
    
    // Track the NFTs that have been withdrawn from the pool 
    pool.withdraw_nfts(&nft_token_ids)?;

    ... 
}",Critical,Check that each NFT withdrawn belongs to the provided pool.,https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/e54a133f-cd3f-4295-b875-ffc2ff17ac6d/infinity_swap_audit_final.pdf?table=block&id=cff181d8-2ba4-4c02-8c00-5ce9cff84551&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743048000000&signature=cNln5anlnzJiPXvu9G74jUHgOuHnFrExaakLjUbDF3w&downloadName=infinity_swap_audit_final.pdf,High
Sol-232,"Rounding Errors In Quote Calculation. Quote calculation for ConstantProduct curves contain division, leading to potential rounding errors. pools may suffer a marginal loss due to prices rounding down when selling NFTs.","rust
pub fn get_sell_quote(&self, min_quote: Uint128) -> Result<Option<Uint128>, ContractError> {
    ...
    let sell_price = match self.bonding_curve {
        BondingCurve::Linear | BondingCurve::Exponential => self.spot_price,
        BondingCurve::ConstantProduct => {
            if self.total_nfts < 2 {
                return Ok(None);
            }
            self.total_tokens
                .checked_div(Uint128::from(self.total_nfts - 1))
                .unwrap()
        }
    };
    ...
}","rust
pub fn get_sell_quote(&self, min_quote: Uint128) -> Result<Option<Uint128>, ContractError> {
    ...
    let quotient = self.total_tokens.checked_div(Uint128::from(self.total_nfts - 1)).unwrap();
    let result = quotient.checked_add(Uint128::one()).unwrap();
    ...
    Ok(Some(result))
}",Low,Ensure that pool always sells NFTs with rounded-up prices.,https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/e54a133f-cd3f-4295-b875-ffc2ff17ac6d/infinity_swap_audit_final.pdf?table=block&id=cff181d8-2ba4-4c02-8c00-5ce9cff84551&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743048000000&signature=cNln5anlnzJiPXvu9G74jUHgOuHnFrExaakLjUbDF3w&downloadName=infinity_swap_audit_final.pdf,High
Sol-233,"Robust Flag Not Respected When Buying Specific NFTs. When the robust flag is enabled, a single swap failure should not revert successfully processed swaps. However, in swap_tokens_for_specifc_nfts, when a pool_queue_item becomes unusable and inserted intopools_to_save, the loop around it continues to run. Hence, unwrappingpool_queue_item fetched from pool_queue_item_map in the next iteration will panic.","rust
pub fn swap_tokens_for_specific_nfts(
    &mut self,
    storage: &'a dyn Storage,
    nfts_to_swap_for: Vec<PoolNftSwap>,
    swap_params: SwapParams,
) -> Result<(), ContractError> {
    // Create a pool_queue_item map for tracking swap pools
    let mut pool_queue_item_map: BTreeMap<u64, PoolQueueItem> = BTreeMap::new();
    
    for pool_nfts in nfts_to_swap_for {
        // Iterate over all NFTs selected for the given pool 
        for nft_swap in pool_nfts.nft_swaps {
            let pool_queue_item = pool_queue_item_map.remove(&pool_nfts.pool_id).unwrap();
            
            if pool_queue_item.usable {
                // If the swap was a success, and the quote price was updated, save into pool_queue
                pool_queue_item_map.insert(pool_queue_item.pool.id, pool_queue_item);
            } 
            else {
                // If the swap was a success, but the quote price was not updated, withdraw from circulation by inserting into pools_to_save
                self.pools_to_save.insert(pool_queue_item.pool.id, pool_queue_item.pool);
            }
        }
    }
    ...
}","rust
if pool_queue_item.usable {
    // code to be executed if `pool_queue_item` is usable goes here, denoted by `...`
} else {
    // If the swap was a success, but the quote price was not updated,
    // withdraw from circulation by inserting into pools_to_save
    self.pools_to_save
        .insert(pool_queue_item.pool.id, pool_queue_item.pool);
    
    // break from enclosing loop (if it exists)
    break; 
}",Low,Break out of the loop if pool_queue_item is flagged as unusable.,https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/e54a133f-cd3f-4295-b875-ffc2ff17ac6d/infinity_swap_audit_final.pdf?table=block&id=cff181d8-2ba4-4c02-8c00-5ce9cff84551&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743048000000&signature=cNln5anlnzJiPXvu9G74jUHgOuHnFrExaakLjUbDF3w&downloadName=infinity_swap_audit_final.pdf,High
Sol-234,"Inadequate Access Control Inside HealthRegions. HealthRegion allows multiple instructions to be executed without performing health checks, thereby reducing gas costs, as long as the account remains in a healthy position at the end. However, this feature also introduces new attack surfaces. For instance, an attacker may bypass the limitations of the FlashLoan implementation, which prevents users from calling Mango after receiving a flash loan. To execute a flash loan without using FlashLoanBegin/Start, an attacker can: 1. Borrow any quantity of tokens within a HealthRegion, which would render their account in an unchecked and unhealthy state. 2. Conduct certain operations using the borrowed tokens. 3. Deposit the tokens back to restore their account to a healthy state. Furthermore, rather than returning the borrowed tokens to restore the health of the account, an attacker may exploit the TokenLiqBankruptcy instruction to liquidate the bad debt. This enables the attacker to force the protocol to cover the cost of the liquidation, resulting in the unauthorized appropriation of funds. Proof of Concept To demonstrate how this attack can be carried out, let us consider a scenario where the attacker has two accounts: A and B. Account A will serve as the liquidatee, while Account B will be the liquidator. The attacker may execute a transaction with the following instructions: 1. HealthRegionBegin(A) - pre_init_health is zero. 2. A.TokenWithdraw(amt) - A where amt is the amount of tokens to be borrowed from the liab_bank. As A is within the HealthRegion, it can proceed into a liquidable stage without restriction. 3. B.TokenLiqBankruptcy(A) - B liquidates A through the token_liq_bankruptcy instruction. The protocol repays A’s liabilities, and post_init_health becomes zero. 4. HealthRegionEnd(A). This results in the attacker stealing amt tokens from the bank.","rs
use crate::accounts_ix::*;
use crate::error::*;
use crate::health::*;
use crate::state::*;
use anchor_lang::prelude::*;
use anchor_lang::solana_program::sysvar::instructions as tx_instructions;
use anchor_lang::Discriminator;
use fixed::types::I80F48;

pub fn health_region_begin<'key, 'accounts, 'remaining, 'info>(
    ctx: Context<'key, 'accounts, 'remaining, 'info, HealthRegionBegin<'info>>,
) -> Result<()> {
    // Check if the other instructions in the transactions are compatible
    {
        let ixs = ctx.accounts.instructions.as_ref();
        let current_index = tx_instructions::load_current_index_checked(ixs)? as usize;
        // There must be a matching HealthRegionEnd instruction
        let mut index = current_index + 1;
        let mut found_end = false;
        loop {
            let ix = match tx_instructions::load_instruction_at_checked(index, ixs) {
                Ok(ix) => ix,
                Err(ProgramError::InvalidArgument) => break, // past the last instruction
                Err(e) => return Err(e.into()),
            };
            index += 1;
            if ix.program_id != crate::id() { continue; }
            if ix.data[0..8] != crate::instruction::HealthRegionEnd::discriminator() { continue; }
            // check that it's for the same account
            require_keys_eq!(ix.accounts[0].pubkey, ctx.accounts.account.key());
            found_end = true;
            index += 1;
        }
        require_msg!(
            found_end,
            ""found no HealthRegionEnd instruction in transaction""
        );
    }

    let mut account = ctx.accounts.account.load_full_mut()?;
    require_msg!(
        !account.fixed.is_in_health_region(),
        ""account must not already be health wrapped""
    );

    account.fixed.set_in_health_region(true);
    let group = account.fixed.group;
    let account_retriever = ScanningAccountRetriever::new(ctx.remaining_accounts, &group)
        .context(""create account retriever"")?;

    // Compute pre-health and store it on the account
    let health_cache = new_health_cache(&account.borrow(), &account_retriever)?;
    let pre_init_health = account.check_health_pre(&health_cache)?;
    account.fixed.health_region_begin_init_health = pre_init_health.ceil().to_num();

    Ok(())
}

pub fn health_region_end<'key, 'accounts, 'remaining, 'info>(
    ctx: Context<'key, 'accounts, 'remaining, 'info, HealthRegionEnd<'info>>,
) -> Result<()> {
    let mut account = ctx.accounts.account.load_full_mut()?;
    require_msg!(
        account.fixed.is_in_health_region(),
        ""account must be health wrapped""
    );
    account.fixed.set_in_health_region(false);
    let group = account.fixed.group;
    let account_retriever = ScanningAccountRetriever::new(ctx.remaining_accounts, &group)
        .context(""create account retriever"")?;

    let health_cache = new_health_cache(&account.borrow(), &account_retriever)?;
    let pre_init_health = I80F48::from(account.fixed.health_region_begin_init_health);
    account.check_health_post(&health_cache, pre_init_health)?;
    account.fixed.health_region_begin_init_health = 0;

    Ok(())
}","Rust

use crate::accounts_ix::*;
use crate::error::*;
use crate::health::*;
use crate::state::*;

use anchor_lang::prelude::*;
use anchor_lang::solana_program::sysvar::instructions as tx_instructions;
use anchor_lang::Discriminator;

use fixed::types::I80F48;

pub fn health_region_begin<'key, 'accounts, 'remaining, 'info>(
    ctx: Context<'key, 'accounts, 'remaining, 'info, HealthRegionBegin<'info>>,
) -> Result<()> {
    // The instructions that may be called inside a HealthRegion
    let allowed_inner_ix = [
        crate::instruction::PerpCancelAllOrders::discriminator(),
        ...
        crate::instruction::Serum3SettleFundsV2::discriminator(),
    ];

    // Check if the other instructions in the transaction are compatible
    check_allowed_instructions(ctx, &allowed_inner_ix)?;

    let mut account = ctx.accounts.account.load_full_mut()?;
    ...
    account.fixed.health_region_begin_init_health = pre_init_health.ceil().to_num();
    Ok(())
}

...

pub fn check_allowed_instructions<'key, 'accounts, 'remaining, 'info>(ctx: Context<'key, 'accounts, 'remaining, 'info, HealthRegionBegin<'info>>, allowed_inner_ix: &[Discriminator]) -> Result<()> {
    let ixs = ctx.accounts.instructions.as_ref();
    let current_index = tx_instructions::load_current_index_checked(ixs)? as usize;
    ...
    // There must be a matching HealthRegionEnd instruction
    let mut index = current_index + 1;
    let mut found_end = false;
    loop {
        ...
        if discriminator == crate::instruction::HealthRegionEnd::discriminator() {
            ...
            found_end = true;
            break;
        } else {
            require!(
                allowed_inner_ix.contains(&discriminator),
                MangoError::HealthRegionBadInnerInstruction
            );
        }
    }
    require_msg!(
        found_end,
        ""found no HealthRegionEnd instruction in transaction""
    );
    
    Ok(())
}",Critical,Harden the current HealthRegion implementation to prevent liquidations and withdrawals from being executed inside it. This can be executed by leveraging the existing instruction introspection logic. Resolved in b22a1e7 by explicitly allowing only the instructions necessary to interact with the perp and spot markets inside HealthRegions.,https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/5ce2fca2-1481-4d9c-8b45-7cb241bff7b6/mango_v4_audit_final.pdf?table=block&id=41f58737-a349-4eec-901a-3762d66e27eb&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743048000000&signature=TMEwwf9j4zyMkOPh7MNZ7K1cfmnHgxZcib_TmrY9Bnw&downloadName=mango_v4_audit_final.pdf,High
Sol-235,"Inadequate Sanitization Of Token Indexes. When registering a token, the protocol does not adequately check the provided token_index. While the value TokenIndex::MAX is reserved to represent a disabled TokenPosition, it is not explicitly disallowed from being registered. As a result, if a token is registered with TokenIndex::MAX, all user token accounts for that token will be interpreted as deactivated, and using them will result in an error. This may lead to all user token accounts for this token being interpreted as deactivated, and the attempt to trade them will result in an error. Moreover, there is inconsistent behaviour between is_active_for_token and is_active in this context. Specifically, when token_index == TokenIndex::MAX, then is_active_for_token returns true, while is_active returns false. Similar behaviour occurs for the Serum3MarketIndex and PerpMarketIndex indices which also have a reserved MAX value that is reserved for deactivated entries.","rust
use anchor_lang::prelude::*;
use fixed::types::I80F48;
use crate::accounts_zerocopy::AccountInfoRef;
use crate::error::*;
use crate::state::*;
use crate::util::fill_from_str;
use crate::logs::TokenMetaDataLog;

pub const INDEX_START: I80F48 = I80F48::from_bits(1_000_000 * I80F48::ONE.to_bits());

use crate::accounts_ix::*;

impl Default for TokenPosition {
    // Some code here
    TokenPosition {
        token_index: TokenIndex::MAX,
        // Some code here
    }
    // Some code here
}

impl TokenPosition {
    // Some code here
    pub fn is_active(&self) -> bool {
        self.token_index != TokenIndex::MAX
    }

    pub fn is_active_for_token(&self, token_index: TokenIndex) -> bool {
        self.token_index == token_index 
    }
    // Some code here
}

#[allow(clippy::too_many_arguments)]
pub fn token_register(
    ctx: Context<TokenRegister>,
    token_index: TokenIndex,
    name: String,
    oracle_config: OracleConfigParams,
    interest_rate_params: InterestRateParams,
    loan_fee_rate: f32,
    loan_origination_fee_rate: f32,
    maint_asset_weight: f32,
    init_asset_weight: f32,
    maint_liab_weight: f32,
    init_liab_weight: f32,
    liquidation_fee: f32,
    min_vault_to_deposits_ratio: f64,
    net_borrow_limit_window_size_ts: u64,
    net_borrow_limit_per_window_quote: i64,
) -> Result<()> {
    // Rest of the code here
}

#[allow(clippy::too_many_arguments)]
pub fn token_register_trustless(
    ctx: Context<TokenRegisterTrustless>,
    token_index: TokenIndex,
    name: String,
) -> Result<()> {
    // Rest of the code here
}","Rust
impl Default for TokenPosition {
    ... 
    TokenPosition {
        ... 
        token_index: TokenIndex::MAX,
         ... 
    } 
    ... 
}
    
impl TokenPosition { 
    ... 
    pub fn is_active(&self) -> bool { 
        self.token_index != TokenIndex::MAX 
    } 
    
    pub fn is_active_for_token(&self, token_index: TokenIndex) -> bool { 
        self.token_index == token_index 
    } 

    ... 
}

use anchor_lang::prelude::*;
use fixed::types::I80F48;
use crate::accounts_zerocopy::AccountInfoRef;
use crate::error::*;
use crate::state::*;
use crate::util::fill_from_str;
use crate::logs::TokenMetaDataLog;

pub const INDEX_START: I80F48 = I80F48::from_bits(1_000_000 * I80F48::ONE.to_bits());

use crate::accounts_ix::*;

#[allow(clippy::too_many_arguments)]
pub fn token_register(
    ctx: Context<TokenRegister>,
    token_index: TokenIndex,
    name: String,
    oracle_config: OracleConfigParams,
    interest_rate_params: InterestRateParams,
    loan_fee_rate: f32,
    loan_origination_fee_rate: f32,
    maint_asset_weight: f32,
    init_asset_weight: f32,
    maint_liab_weight: f32,
    init_liab_weight: f32,
    liquidation_fee: f32,
    min_vault_to_deposits_ratio: f64,
    net_borrow_limit_window_size_ts: u64,
    net_borrow_limit_per_window_quote: i64,
) -> Result<()> {
    // body of the function
    ...
}

#[allow(clippy::too_many_arguments)]
pub fn token_register_trustless(
    ctx: Context<TokenRegisterTrustless>,
    token_index: TokenIndex,
    name: String,
 ) -> Result<()> {
    // body of the function
    ...
}",Low,"Disallow the reserved value TokenIndex::MAX for token registration. Additionally, modify the inconsistent behaviour between is_active_for_token and is_active.",https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/5ce2fca2-1481-4d9c-8b45-7cb241bff7b6/mango_v4_audit_final.pdf?table=block&id=41f58737-a349-4eec-901a-3762d66e27eb&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743048000000&signature=TMEwwf9j4zyMkOPh7MNZ7K1cfmnHgxZcib_TmrY9Bnw&downloadName=mango_v4_audit_final.pdf,High
Sol-236,"Invalid DoubleEndedIterator Trait Implementations. The critbit, AVL tree, and red-black tree do not correctly implement Rust’s DoubleEndedIterator trait, which is described here. For instance, the red-black tree iterator’s next and next_back method will cross each other, “doublecounting” each element. This does not follow the spec, and can even be unsafe: when using iter_mut, one can obtain multiple mutable references to the same value.","rust
pub struct AVLTreeIterator<
    'a,
    K: PartialOrd + Copy + Clone + Default + Pod + Zeroable,
    V: Default + Copy + Clone + Pod + Zeroable,
    const MAX_SIZE: usize,
> {
    tree: &'a AVLTree<K, V, MAX_SIZE>,
    stack: Vec<u32>,
    rev_stack: Vec<u32>,
    node: u32,
}

impl<
    'a,
    K: PartialOrd + Copy + Clone + Default + Pod + Zeroable,
    V: Default + Copy + Clone + Pod + Zeroable,
    const MAX_SIZE: usize,
> Iterator for AVLTreeIterator<'a, K, V, MAX_SIZE> {
    type Item = (&'a K, &'a V);

    fn next(&mut self) -> Option<Self::Item> {
        while !self.stack.is_empty() || self.node != SENTINEL {
            if self.node != SENTINEL {
                self.stack.push(self.node);
                self.node = self.tree.get_field(self.node, Field::Left);
            } else {
                self.node = self.stack.pop().unwrap();
                let node = self.tree.get_node(self.node);
                self.node = self.tree.get_field(self.node, Field::Right);
                return Some((&node.key, &node.value));
            }
        }
        None
    }
}

impl<
    'a,
    K: PartialOrd + Copy + Clone + Default + Pod + Zeroable,
    V: Default + Copy + Clone + Pod + Zeroable,
    const MAX_SIZE: usize,
> DoubleEndedIterator for AVLTreeIterator<'a, K, V, MAX_SIZE> {
    fn next_back(&mut self) -> Option<Self::Item> {
        while !self.rev_stack.is_empty() || self.node != SENTINEL {
            if self.node != SENTINEL {
                self.rev_stack.push(self.node);
                self.node = self.tree.get_field(self.node, Field::Right);
            } else {
                self.node = self.rev_stack.pop().unwrap();
                let node = self.tree.get_node(self.node);
                self.node = self.tree.get_field(self.node, Field::Left);
                return Some((&node.key, &node.value));
            }
        }
        None
    }
}

pub struct AVLTreeIteratorMut<
    'a,
    K: PartialOrd + Copy + Clone + Default + Pod + Zeroable,
    V: Default + Copy + Clone + Pod + Zeroable,
    const MAX_SIZE: usize,
> {
    tree: &'a mut AVLTree<K, V, MAX_SIZE>,
    stack: Vec<u32>,
    rev_stack: Vec<u32>,
    node: u32,
}

impl<
    'a,
    K: PartialOrd + Copy + Clone + Default + Pod + Zeroable,
    V: Default + Copy + Clone + Pod + Zeroable,
    const MAX_SIZE: usize,
> Iterator for AVLTreeIteratorMut<'a, K, V, MAX_SIZE> {
    type Item = (&'a K, &'a mut V);

    fn next(&mut self) -> Option<Self::Item> {
        while !self.stack.is_empty() || self.node != SENTINEL {
            if self.node != SENTINEL {
                self.stack.push(self.node);
                self.node = self.tree.get_field(self.node, Field::Left);
            } else {
                self.node = self.stack.pop().unwrap();
                let ptr = self.node;
                self.node = self.tree.get_field(ptr, Field::Right);
                // TODO: How does one remove this unsafe?
                unsafe {
                    let node = (*self.tree.allocator.nodes.as_mut_ptr().add((ptr - 1) as usize)).get_value_mut();
                    return Some((&node.key, &mut node.value));
                }
            }
        }
        None
    }
}

impl<
    'a,
    K: PartialOrd + Copy + Clone + Default + Pod + Zeroable,
    V: Default + Copy + Clone + Pod + Zeroable,
    const MAX_SIZE: usize,
> DoubleEndedIterator for AVLTreeIteratorMut<'a, K, V, MAX_SIZE> {
    fn next_back(&mut self) -> Option<Self::Item> {
        while !self.rev_stack.is_empty() || self.node != SENTINEL {
            if self.node != SENTINEL {
                self.rev_stack.push(self.node);
                self.node = self.tree.get_field(self.node, Field::Right);
            } else {
                self.node = self.rev_stack.pop().unwrap();
                let ptr = self.node;
                self.node = self.tree.get_field(ptr, Field::Left);
                // TODO: How does one remove this unsafe?
                unsafe {
                    let node = (*self.tree.allocator.nodes.as_mut_ptr().add((ptr - 1) as usize)).get_value_mut();
                    return Some((&node.key, &mut node.value));
                }
            }
        }
        None
    }
}","rust
pub struct AVLTreeIterator<
    'a,
    K: PartialOrd + Copy + Clone + Default + Pod + Zeroable,
    V: Default + Copy + Clone + Pod + Zeroable,
    const MAX_SIZE: usize,
> {
    tree: &'a AVLTree<K, V, MAX_SIZE>,
    fwd_stack: Vec<u32>,
    fwd_ptr: u32,
    fwd_node: Option<u32>,
    rev_stack: Vec<u32>,
    rev_ptr: u32,
    rev_node: Option<u32>,
    terminated: bool,
}

impl<
    'a,
    K: PartialOrd + Copy + Clone + Default + Pod + Zeroable,
    V: Default + Copy + Clone + Pod + Zeroable,
    const MAX_SIZE: usize,
> Iterator for AVLTreeIterator<'a, K, V, MAX_SIZE> {
    type Item = (&'a K, &'a V);

    fn next(&mut self) -> Option<Self::Item> {
        while !self.terminated && (!self.fwd_stack.is_empty() || self.fwd_ptr != SENTINEL) {
            if self.fwd_ptr != SENTINEL {
                self.fwd_stack.push(self.fwd_ptr);
                self.fwd_ptr = self.tree.get_field(self.fwd_ptr, Field::Left);
            } else {
                let current_node = self.fwd_stack.pop();
                if current_node == self.rev_node {
                    self.terminated = true;
                    return None;
                }
                self.fwd_node = current_node;
                let node = self.tree.get_node(current_node.unwrap());
                self.fwd_ptr = self.tree.get_field(current_node.unwrap(), Field::Right);
                return Some((&node.key, &node.value));
            }
        }
        None
    }
}

impl<
    'a,
    K: PartialOrd + Copy + Clone + Default + Pod + Zeroable,
    V: Default + Copy + Clone + Pod + Zeroable,
    const MAX_SIZE: usize,
> DoubleEndedIterator for AVLTreeIterator<'a, K, V, MAX_SIZE> {
    fn next_back(&mut self) -> Option<Self::Item> {
        while !self.terminated && (!self.rev_stack.is_empty() || self.rev_ptr != SENTINEL) {
            if self.rev_ptr != SENTINEL {
                self.rev_stack.push(self.rev_ptr);
                self.rev_ptr = self.tree.get_field(self.rev_ptr, Field::Right);
            } else {
                let current_node = self.rev_stack.pop();
                if current_node == self.fwd_node {
                    self.terminated = true;
                    return None;
                }
                self.rev_node = current_node;
                let node = self.tree.get_node(current_node.unwrap());
                self.rev_ptr = self.tree.get_field(current_node.unwrap(), Field::Left);
                return Some((&node.key, &node.value));
            }
        }
        None
    }
}",High,"Rewrite next and next_back so that they do not cross each other, or remove the implementations of DoubleEndedIterator altogether.","https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/d490abb1-acff-4638-973f-203664bccf1c/ellipsis_phoenix_audit_final.pdf?table=block&id=9888c291-939f-4def-bbb3-77a165bd9230&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743048000000&signature=Q30qii9Z1NRF6BOaqE6ZgfVAvxgDTNp91YjhzAWfRFs&downloadName=ellipsis_phoenix_audit_final.pdf, https://github.com/Ellipsis-Labs/sokoban/pull/11/files#diff-ec08f3ee9629cf28c530930cfdd8b0fafed2fde1367f9dea17cc64803a5d3d5d",High
Sol-237,"When parsing events from transactions, the Phoenix SDK iterates over all the inner instructions to try and parse out PhoenixInstruction::Log instructions. Unfortunately, this loop fails to return when the transaction has errored, as specified in the is_err field. If a malicious user were to manually invoke the Phoenix program from a separate onchain program, inaccurate log events could be subsequently processed in parse_phoenix_events. In conjunction with OS-EPS-SUG-02, this could lead to a denial of service condition for users of the SDK.","rust
pub async fn parse_events_from_transaction(&self, sig: &Signature) -> Option<Vec<PhoenixEvent>> {
    let tx = self.client.get_transaction(sig).await.ok()?;

    let mut event_list = vec![];

    for inner_ixs in tx.inner_instructions.iter() {
        for inner_ix in inner_ixs.iter() {
            let current_program_id = inner_ix.instruction.program_id.clone();

            if current_program_id != phoenix::id().to_string() {
                continue;
            }

            if inner_ix.instruction.data.is_empty() {
                continue;
            }

            let (tag, data) = match inner_ix.instruction.data.split_first() {
                Some((tag, data)) => (*tag, data),
                None => continue,
            };

            let ix_enum = match PhoenixInstruction::try_from(tag).ok() {
                Some(ix) => ix,
                None => continue,
            };

            if matches!(ix_enum, PhoenixInstruction::Log) {
                event_list.push(data.to_vec());
            }
        }
    }

    self.parse_phoenix_events(sig, event_list)
}","rust
pub async fn parse_events_from_transaction(&self, sig: &Signature,) -> Option<Vec<PhoenixEvent>> {
    let tx = self.client.get_transaction(sig).await.ok()?;
    
    if tx.is_err {
        return None;
    }
    
    let mut event_list = vec![];
    for inner_ixs in tx.inner_instructions.iter() {
        for inner_ix in inner_ixs.iter() {
            let current_program_id = inner_ix.instruction.program_id.clone();
            
            if current_program_id != phoenix::id().to_string() {
                continue;
            }
            
            if inner_ix.instruction.data.is_empty() {
                continue;
            }
            
            let (tag, data) = match inner_ix.instruction.data.split_first() {
                Some((tag, data)) => (*tag, data),
                None => continue,
            };
            
            let ix_enum = match PhoenixInstruction::try_from(tag).ok() {
                Some(ix) => ix,
                None => continue,
            };
            
            if matches!(ix_enum, PhoenixInstruction::Log) {
                event_list.push(data.to_vec());
            }
        }
    }
    
    self.parse_phoenix_events(sig, event_list)
}",High,"Check if the transaction was successfully completed, and if not, skip processing of the transaction.","https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/d490abb1-acff-4638-973f-203664bccf1c/ellipsis_phoenix_audit_final.pdf?table=block&id=9888c291-939f-4def-bbb3-77a165bd9230&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743048000000&signature=Q30qii9Z1NRF6BOaqE6ZgfVAvxgDTNp91YjhzAWfRFs&downloadName=ellipsis_phoenix_audit_final.pdf, https://github.com/Ellipsis-Labs/phoenix-sdk/pull/50/files#diff-46eeb1f8fcfbf2818e8a7a6d1bb4111208f298f8e6e9ca2a18264521c1ab8482",High
Sol-238,"Account Creation DOS. Account creation primitives in phoenix will error if the account already has lamports. This could, for example, allow an attacker to deny seat creation. let space = size_of::<Seat>(); invoke_signed( &system_instruction::create_account( payer.key, seat.key, Rent::get()?.minimum_balance(space), space.try_into().unwrap(), &crate::ID, ), &[payer.clone(), seat.clone(), system_program.clone()], &[&[b""seat"", market_key.as_ref(), trader.as_ref(), &[bump]]],","program/src/program/processor/initialize.rs 

// A trade of 1 base lot at the minimum tick price of 1 must result in an integer number of quote lots 
// Suppose there are T quote lots per tick and there are B base lots per base unit. 
// At a price of 1 tick per base unit, for a trade of size 1 base lot, the resulting quote lots N must be an integer 
// T (quote lots/tick) * 1 (tick/base unit) * 1/B (base units/base lots) * 1 (base lots) = N (quote lots) 
// T/B = N => B | T (B divides T) 

assert_with_msg( 
    tick_size_in_quote_lots_per_base_unit % num_base_lots_per_base_unit == 0, 
    ProgramError::InvalidInstructionData, 
    ""The number of quote lots per tick be a multiple of the number of base lots per base unit"", 
)?; 

// Create the base and quote vaults of this market 
let rent = Rent::get()?; 
let mut bumps = vec![];

for (token_account, mint) in [ 
    (base_vault.as_ref(), base_mint.as_ref()), 
    (quote_vault.as_ref(), quote_mint.as_ref()), 
] { 
    let (vault_key, bump) = get_vault_address(market_info.key, mint.key); 
    
    assert_with_msg( 
        vault_key == *token_account.key, 
        PhoenixError::InvalidMarketSigner, 
        &format!(
            ""Supplied vault ({}) does not match computed key ({})"", 
            token_account.key, 
            vault_key 
        ), 
    )?; 

    let space = spl_token::state::Account::LEN; 

    invoke_signed( 
        &system_instruction::create_account( 
            market_creator.key, 
            token_account.key, 
            rent.minimum_balance(space), 
            space.try_into().unwrap(), 
            &spl_token::id(), 
        ), 
        &[ 
            market_creator.as_ref().clone(), 
            token_account.clone(), 
            system_program.as_ref().clone(), 
        ], 
        &[&[ 
            b""vault"", 
            market_info.key.as_ref(), 
            mint.key.as_ref(), 
            &[bump], 
        ]], 
    )?; 
}","pub async fn parse_events_from_transaction(
    &self,
    sig: &Signature,
) -> Option<Vec<PhoenixEvent>> {
    let tx = self.client.get_transaction(sig).await.ok()?;

    if tx.is_err {
        return None;
    }

    let mut event_list = vec![];

    for inner_ixs in tx.inner_instructions.iter() {
        for inner_ix in inner_ixs.iter() {
            let current_program_id = inner_ix.instruction.program_id.clone();

            if current_program_id != phoenix::id().to_string() {
                continue;
            }

            if inner_ix.instruction.data.is_empty() {
                continue;
            }

            let (tag, data) = match inner_ix.instruction.data.split_first() {
                Some((tag, data)) => (*tag, data),
                None => continue,
            };

            let ix_enum = match PhoenixInstruction::try_from(tag).ok() {
                Some(ix) => ix,
                None => continue,
            };

            if matches!(ix_enum, PhoenixInstruction::Log) {
                event_list.push(data.to_vec());
            }
        }
    }

    self.parse_phoenix_events(sig, event_list)
}",Medium,Use transfer and allocate instead of create_account similar to what Anchor does.,"https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/d490abb1-acff-4638-973f-203664bccf1c/ellipsis_phoenix_audit_final.pdf?table=block&id=9888c291-939f-4def-bbb3-77a165bd9230&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743048000000&signature=Q30qii9Z1NRF6BOaqE6ZgfVAvxgDTNp91YjhzAWfRFs&downloadName=ellipsis_phoenix_audit_final.pdf, https://github.com/Ellipsis-Labs/phoenix-v1/pull/1/files",High
Sol-239,"Unchecked Type Casting. In the get_delta_amount_0_signed function, there are unchecked conversions from u64 (which get_delta_amount_0_unsigned returns) to i64. The issue is that the value of the u64 returned by get_delta_amount_0_unsigned might be larger than what i64 can represent, which would result in a faulty conversion. The same applies for get_delta_amount_1_signed. We prepared a simple proof of concept test case demonstrating that this could be exploited against the burn liquidity instruction.",Error fetching AI explanation: list index out of range,"rust
/// Helper function to get signed delta amount_0 for given liquidity and price range 
pub fn get_delta_amount_0_signed( 
    sqrt_ratio_a_x64: u128,
    sqrt_ratio_b_x64: u128, 
    liquidity: i128
) -> i64 { 
    if liquidity < 0 { 
        -(i64::try_from(get_delta_amount_0_unsigned(
            sqrt_ratio_a_x64, 
            sqrt_ratio_b_x64, 
            u128::try_from(-liquidity).unwrap(), false)
        ).unwrap())
    } else { 
        i64::try_from(get_delta_amount_0_unsigned(
            sqrt_ratio_a_x64, 
            sqrt_ratio_b_x64, 
            u128::try_from(liquidity).unwrap(), 
            true
        )).unwrap() 
    } 
}",High,A possible method of remediation is using i64::try_from instead of an unchecked cast.,"https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/8464f93a-f2c8-49b8-afb1-5056f4782dfc/Raydium_AMM_V3_Audit_Report.pdf?table=block&id=88f0ad30-c74b-4311-82bb-e6062bf12169&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743307200000&signature=AsG6ddNcRmbP3N5kADqbWt0rxS4L2XD4jBIhoabbCvM&downloadName=Raydium+AMM+V3+Audit+Report.pdf, https://github.com/raydium-io/raydium-clmm/pull/27/files",High
Sol-240,"Closing Personal Positions Is Not Gated. When a personal position is created, the program mints an NFT to the user’s wallet. Subsequent instructions which require authorization of the position, such as increasing and decreasing liquidity, use the is_authorized_for_token function to check that the signer holds the NFT. The ClosePosition instruction should also be privileged, but it does not check NFT ownership. An attacker can create their own empty NFT account, thus spoofing NFT ownership. This allows them to harvest the lamports used for rent.","rust
use crate::error::ErrorCode;
use crate::states::*;
use crate::util::{burn, close_account, close_spl_account};
use anchor_lang::prelude::*;
use anchor_spl::token::{Mint, Token, TokenAccount};

Expand Down
Expand Up
@@ -31,6 +31,12 @@ pub struct ClosePosition<'info> {

#[derive(Accounts)]
pub struct ClosePosition<'info> {
    /// The position nft owner
    #[account(mut)]
    pub nft_owner: Signer<'info>,

    /// Unique token mint address
    #[account(mut, address = personal_position.nft_mint)]
    pub position_nft_mint: Box<Account<'info, Mint>>,

    /// Token account where position NFT will be minted
    #[account(mut, associated_token::mint = position_nft_mint, associated_token::authority = nft_owner, )]
    pub position_nft_account: Box<Account<'info, TokenAccount>>,

    /// To store metaplex metadata
    /// CHECK: Safety check performed inside function body
    // #[account(mut)]
    // pub metadata_account: UncheckedAccount<'info>,

    /// Metadata for the tokenized position
    pub personal_position: Box<Account<'info, PersonalPositionState>>,

    /// Program to create the position manager state account
    Expand Down
    Expand Up
    @@ -84,11 +90,6 @@ pub fn close_position<'a, 'b, 'c, 'info>(
    pub system_program: Program<'info, System>,
    
    /// Program to create mint account and mint tokens
    pub token_program: Program<'info, Token>,
}

pub fn close_position<'a, 'b, 'c, 'info>(
    ctx: Context<'a, 'b, 'c, 'info, ClosePosition<'info>>
) -> Result<()> {
    if ctx.accounts.personal_position.liquidity != 0 || 
    ctx.accounts.personal_position.token_fees_owed_0 != 0 || 
    ctx.accounts.personal_position.token_fees_owed_1 != 0 {
        msg!(
            ""remaing liquidity:{},token_fees_owed_0:{},token_fees_owed_1:{}"",
            ctx.accounts.personal_position.liquidity, 
            ctx.accounts.personal_position.token_fees_owed_0, 
            ctx.accounts.personal_position.token_fees_owed_1
        );
        return err!(ErrorCode::ClosePositionErr);
    }

    for i in 0..ctx.accounts.personal_position.reward_infos.len() {
        if ctx.accounts.personal_position.reward_infos[i].reward_amount_owed != 0 {
            msg!(
                ""remaing reward index:{},amount:{}"",
                i, 
                ctx.accounts.personal_position.reward_infos[i].reward_amount_owed,
            );
            return err!(ErrorCode::ClosePositionErr);
        }
    }

    if ctx.accounts.position_nft_account.amount == 1 {
        burn( 
            &ctx.accounts.nft_owner, 
            &ctx.accounts.position_nft_mint, 
            &ctx.accounts.position_nft_account, 
            &ctx.accounts.token_program, 
            &[],
            1,
        )?;
    }
    close_spl_account(
        &ctx.accounts.nft_owner,
        &ctx.accounts.nft_owner.to_account_info(),
        &ctx.accounts.position_nft_account.to_account_info(),
        &ctx.accounts.token_program,
        &[],
    )?;
    close_account( 
        &ctx.accounts.personal_position.to_account_info(), 
        &ctx.accounts.nft_owner.to_account_info(),
    )?;

    Ok(())
}","rust
use crate::error::ErrorCode;
use crate::states::*;
use crate::util::{burn, close_spl_account};
use anchor_lang::prelude::*;
use anchor_spl::token::{Mint, Token, TokenAccount};

@@ -31,6 +31,12 @@ pub struct ClosePosition<'info> {
#[derive(Accounts)]
pub struct ClosePosition<'info> {
    // The position nft owner
    #[account(mut)]
    pub nft_owner: Signer<'info>,
    
    // Unique token mint address
    #[account(mut, address = personal_position.nft_mint)]
    pub position_nft_mint: Box<Account<'info, Mint>>,
    
    // Token account where position NFT will be minted
    #[account(mut, associated_token::mint = position_nft_mint, associated_token::authority = nft_owner)]
    pub position_nft_account: Box<Account<'info, TokenAccount>>,
    
    // Metadata for the tokenized position
    #[account(mut, seeds = [POSITION_SEED.as_bytes(), position_nft_mint.key().as_ref()], bump, close = nft_owner)]
    pub personal_position: Box<Account<'info, PersonalPositionState>>,
}

@@ -84,11 +90,6 @@ pub fn close_position<'a, 'b, 'c, 'info>(
pub system_program: Program<'info, System>,
pub token_program: Program<'info, Token>,
}

pub fn close_position<'a, 'b, 'c, 'info>(
    ctx: Context<'a, 'b, 'c, 'info, ClosePosition<'info>>,
) -> Result<()> {
    if ctx.accounts.personal_position.liquidity != 0 
       || ctx.accounts.personal_position.token_fees_owed_0 != 0 
       || ctx.accounts.personal_position.token_fees_owed_1 != 0 {
        
        msg!(""remaing liquidity:{},token_fees_owed_0:{},token_fees_owed_1:{}"",
             ctx.accounts.personal_position.liquidity,
             ctx.accounts.personal_position.token_fees_owed_0,
             ctx.accounts.personal_position.token_fees_owed_1     
        );
        
        return err!(ErrorCode::ClosePositionErr);
    }
    
    for i in 0..ctx.accounts.personal_position.reward_infos.len() {
        if ctx.accounts.personal_position.reward_infos[i].reward_amount_owed != 0 {
            msg!(""remaing reward index:{},amount:{}"",
                 i,
                 ctx.accounts.personal_position.reward_infos[i].reward_amount_owed                 
            );
            return err!(ErrorCode::ClosePositionErr);
        }
    }
    
    if ctx.accounts.position_nft_account.amount == 1 {
        burn(&ctx.accounts.nft_owner, 
             &ctx.accounts.position_nft_mint, 
             &ctx.accounts.position_nft_account, 
             &ctx.accounts.token_program, 
             &[], 
             1,
        )?;
    }
    
    close_spl_account(&ctx.accounts.nft_owner, 
                      &ctx.accounts.nft_owner.to_account_info(), 
                      &ctx.accounts.position_nft_account.to_account_info(), 
                      &ctx.accounts.token_program, 
                      &[],
    )?;
    
    Ok(())
}",Medium,"In order for the issue to be remediated, the ClosePosition instruction should verify that the position NFT account, which should hold the NFT, is non-empty. This can be done with is_authorized_for_token or, as shown below, with an Anchor constraint.","https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/8464f93a-f2c8-49b8-afb1-5056f4782dfc/Raydium_AMM_V3_Audit_Report.pdf?table=block&id=88f0ad30-c74b-4311-82bb-e6062bf12169&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743307200000&signature=AsG6ddNcRmbP3N5kADqbWt0rxS4L2XD4jBIhoabbCvM&downloadName=Raydium+AMM+V3+Audit+Report.pdf, https://github.com/raydium-io/raydium-clmm/pull/26/files#diff-739eab546955ff1d3b67e630630d40fe254afb66133b8d63762ca58999eaf7f5",High
Sol-241,"Arbitrary AMM Config Possible Usage. Every PoolState is created using one of existing AMM configs. The AmmConfig structure is used in swap_internal function to determine trade_fee_rate, protocol_fee_rate and fund_fee_rate that is used in the current pool. In Swap instruction, there are implemented anchor checks that validate the given AmmConfig to be the one that PoolState was initialised with. However, the instruction SwapRouterBaseIn doesn’t implement those checks. The lack of checks makes it possible to pass any AMM Config to the UwapRouterBaseIn and as a result to manipulate the fee value.","rust
use super::{exact_internal, SwapAccounts};
use crate::error::ErrorCode;
use crate::states::*;
use anchor_lang::prelude::*;
use anchor_spl::token::{Token, TokenAccount};

#[derive(Accounts)]
pub struct SwapRouterBaseIn<'info> {
    /// The user performing the swap
    pub payer: Signer<'info>,
    /// The token account that pays input tokens for the swap
    #[account(mut)]
    pub input_token_account: Account<'info, TokenAccount>,
    /// SPL program for token transfers
    pub token_program: Program<'info, Token>,
}

pub fn swap_router_base_in<'a, 'b, 'c, 'info>(
    ctx: Context<'a, 'b, 'c, 'info, SwapRouterBaseIn<'info>>,
    amount_in: u64,
    amount_out_minimum: u64,
) -> Result<()> {
    let mut amount_in_internal = amount_in;
    let mut input_token_account = Box::new(ctx.accounts.input_token_account.clone());
    let mut accounts: &[AccountInfo] = ctx.remaining_accounts;

    while !accounts.is_empty() {
        let mut remaining_accounts = accounts.iter();
        let account_info = remaining_accounts.next().unwrap();

        if accounts.len() != ctx.remaining_accounts.len() && account_info.data_len() != AmmConfig::LEN {
            accounts = remaining_accounts.as_slice();
            continue;
        }

        let amm_config = Box::new(Account::<AmmConfig>::try_from(account_info)?);
        let mut pool_state_loader = AccountLoader::<PoolState>::try_from(remaining_accounts.next().unwrap())?;
        let output_token_account = Box::new(Account::<TokenAccount>::try_from(
            &remaining_accounts.next().unwrap(),
        )?);
        
        let input_vault = Box::new(Account::<TokenAccount>::try_from(
            remaining_accounts.next().unwrap(),
        )?);
        
        let output_vault = Box::new(Account::<TokenAccount>::try_from(
            remaining_accounts.next().unwrap(),
        )?);
        
        let mut observation_state = AccountLoader::<ObservationState>::try_from(remaining_accounts.next().unwrap())?;
        
        // check observation account is owned by the pool
        require_keys_eq!(
            pool_state_loader.load()?.observation_key,
            observation_state.key()
        );
        
        let mut tick_array = AccountLoader::<TickArrayState>::try_from(remaining_accounts.next().unwrap())?;

        // solana_program::log::sol_log_compute_units();
        accounts = remaining_accounts.as_slice();
        amount_in_internal = exact_internal(
            &mut SwapAccounts {
                signer: ctx.accounts.payer.clone(),
                amm_config: &amm_config,
                input_token_account: input_token_account.clone(),
                pool_state: &mut pool_state_loader,
                output_token_account: output_token_account.clone(),
                input_vault: input_vault.clone(),
                output_vault: output_vault.clone(),
                tick_array_state: &mut tick_array,
                observation_state: &mut observation_state,
                token_program: ctx.accounts.token_program.clone(),
            },
            accounts,
            amount_in_internal,
            0,
            true,
        )?;
        
        // output token is the new swap input token
        input_token_account = output_token_account;
    }

    require!(
        amount_in_internal >= amount_out_minimum,
        ErrorCode::TooLittleOutputReceived
    );

    Ok(())
}","rust
use super::{exact_internal, SwapAccounts}; 
use crate::error::ErrorCode; 
use crate::states::*; 
use anchor_lang::prelude::*; 
use anchor_spl::token::{Token, TokenAccount}; 

#[derive(Accounts)] 
pub struct SwapRouterBaseIn<'info> {
    /// The user performing the swap
    pub payer: Signer<'info>,

    /// The token account that pays input tokens for the swap
    #[account(mut)] 
    pub input_token_account: Account<'info, TokenAccount>,

    /// SPL program for token transfers
    pub token_program: Program<'info, Token>, 
}

pub fn swap_router_base_in<'a, 'b, 'c, 'info>(
    ctx: Context<'a, 'b, 'c, 'info, SwapRouterBaseIn<'info>>,
    amount_in: u64,
    amount_out_minimum: u64,
) -> Result<()> {
    let mut amount_in_internal = amount_in;
    let mut input_token_account = Box::new(ctx.accounts.input_token_account.clone());
    let mut accounts: &[AccountInfo] = ctx.remaining_accounts;

    while !accounts.is_empty() {
        let mut remaining_accounts = accounts.iter();
        let account_info = remaining_accounts.next().unwrap();

        if accounts.len() != ctx.remaining_accounts.len() && account_info.data_len() != AmmConfig::LEN {
            accounts = remaining_accounts.as_slice();
            continue;
        }

        let amm_config = Box::new(Account::<AmmConfig>::try_from(account_info)?);
        let mut pool_state_loader = AccountLoader::<PoolState>::try_from(remaining_accounts.next().unwrap())?;
        let output_token_account = Box::new(Account::<TokenAccount>::try_from(&remaining_accounts.next().unwrap())?);
        let input_vault = Box::new(Account::<TokenAccount>::try_from(remaining_accounts.next().unwrap())?);
        let output_vault = Box::new(Account::<TokenAccount>::try_from(remaining_accounts.next().unwrap())?);
        let mut observation_state = AccountLoader::<ObservationState>::try_from(remaining_accounts.next().unwrap())?;

        {
            let pool_state = pool_state_loader.load()?;

            // check observation account is owned by the pool
            require_keys_eq!(pool_state.observation_key, observation_state.key());

            // check ammConfig account is associate with the pool
            require_keys_eq!(pool_state.amm_config, amm_config.key());
        }

        let mut tick_array = AccountLoader::<TickArrayState>::try_from(remaining_accounts.next().unwrap())?;

        // solana_program::log::sol_log_compute_units();

        accounts = remaining_accounts.as_slice();
        amount_in_internal = exact_internal(
            &mut SwapAccounts {
                signer: ctx.accounts.payer.clone(),
                amm_config: &amm_config,
                input_token_account: input_token_account.clone(),
                pool_state: &mut pool_state_loader,
                output_token_account: output_token_account.clone(),
                input_vault: input_vault.clone(),
                output_vault: output_vault.clone(),
                tick_array_state: &mut tick_array,
                observation_state: &mut observation_state,
                token_program: ctx.accounts.token_program.clone(),
            },
            accounts,
            amount_in_internal,
            0,
            true,
        )?;

        // output token is the new swap input token
        input_token_account = output_token_account;
    }

    require!(
        amount_in_internal >= amount_out_minimum,
        ErrorCode::TooLittleOutputReceived
    );

    Ok(())
}",Medium,"In order for the issue to be remediated, the SwapRouterBaseIn instruction should verify that the amm_config, which was passed to the instruction, is the one assigned to the PoolState. This can be done by adding the same check that is implemented for Swap instruction.","https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/8464f93a-f2c8-49b8-afb1-5056f4782dfc/Raydium_AMM_V3_Audit_Report.pdf?table=block&id=88f0ad30-c74b-4311-82bb-e6062bf12169&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743307200000&signature=AsG6ddNcRmbP3N5kADqbWt0rxS4L2XD4jBIhoabbCvM&downloadName=Raydium+AMM+V3+Audit+Report.pdf, https://github.com/raydium-io/raydium-clmm/pull/35/files#diff-b9999aee2d2b188835c85952d3b4e00b8cbe801052dffd196bdb0107103631de",High
Sol-242,"Rewards State DOS. Raydium tracks the total amount of rewards which are supposed to be emitted viareward_total_emissioned. This field is then subtracted from when claiming rewards. Unfortunately, because of small differences in rounding, it is possible to create a discrepancy between the expected rewards emissions and the actual total amount. More specifically, because reward_total_emissioned is updated every time rewards information is updated, but individual user reward emission calculations are only tracked in aggregate, more rewards could be lost due to rounding in the former scenario. Proof of Concept 1. Let’s assume following setup: • open_time = 1665982800 (epoch in seconds), • end_time = open_time + (90 * 24 * 60 * 60) (epoch in seconds, 90 days), • emissions_per_second = 80_000 / (90 * 24 * 60 * 60) = 0.102, • pool_state.liquidity = 100 2. If incurr_timestamp = open_time + 60the user runsPoolState::update_reward_infos() the reward_infos will be updated with reward_0_total_emissioned = 0 3. It is possible to update reward infos to the state in which the reward_growth_global_x64 > 0 && reward_x_total_emissioned == 0 4. By running update_reward_infos instruction every 1 minute (60 seconds), with following setup, it is possible to keep PoolState::reward_x_total_emissioned at value of 0 5. If reward_growth_global_x64will become big enough it is possibleforreward_amount_owed of an user to be greater than 0 6. If personal_position.reward_amount_owed > 0 && reward_x_total_emissioned = 0 the check in decrease_liquidity: check_unclaimed_reward will panic and make it impossible to decrease the liquidity 7. That can result in higher probability of more users gaining Impermanent Loss 8. Even if PoolState::reward_x_total_emissioned will be greater than 0 not all users will be able to decrease liquidity and gain a reward","rust
// Calculates the next global reward growth variables based on the given timestamp.
// The provided timestamp must be greater than or equal to the last updated timestamp.
pub fn update_reward_infos(
    &mut self,
    curr_timestamp: u64,
) -> Result<([RewardInfo; REWARD_NUM])> {
    #[cfg(feature = ""enable-log"")]
    msg!(""current block timestamp:{}"", curr_timestamp);

    let mut next_reward_infos = self.reward_infos;

    for i in 0..REWARD_NUM {
        let reward_info = &mut next_reward_infos[i];

        if !reward_info.initialized() {
            continue;
        }

        if curr_timestamp <= reward_info.open_time {
            continue;
        }

        let latest_update_timestamp = curr_timestamp.min(reward_info.end_time);

        if self.liquidity != 0 {
            let time_delta = latest_update_timestamp
                .checked_sub(reward_info.last_update_time)
                .unwrap();

            let reward_growth_delta = U256::from(time_delta)
                .mul_div_floor(
                    U256::from(reward_info.emissions_per_second_x64),
                    U256::from(self.liquidity),
                )
                .unwrap();

            reward_info.reward_growth_global_x64 = reward_info
                .reward_growth_global_x64
                .checked_add(reward_growth_delta.as_u128())
                .unwrap();

            reward_info.reward_total_emissioned = reward_info
                .reward_total_emissioned
                .checked_add(
                    U128::from(time_delta)
                        .mul_div_floor(
                            U128::from(reward_info.emissions_per_second_x64),
                            U128::from(fixed_point_64::Q64),
                        )
                        .unwrap()
                        .as_u64(),
                )
                .unwrap();

            #[cfg(feature = ""enable-log"")]
            msg!(
                ""reward_index:{},latest_update_timestamp:{},reward_info.reward_last_update_time:{},time_delta:{},reward_emission_per_second_x64:{},reward_growth_delta:{},reward_info.reward_growth_global_x64:{}"",
                i,
                latest_update_timestamp,
                identity(reward_info.last_update_time),
                time_delta,
                identity(reward_info.emissions_per_second_x64),
                reward_growth_delta,
                identity(reward_info.reward_growth_global_x64)
            );
        }

        reward_info.last_update_time = latest_update_timestamp;

        // update reward state
        if latest_update_timestamp >= reward_info.open_time && latest_update_timestamp < reward_info.end_time {
            reward_info.reward_state = RewardState::Opening as u8;
        } else if latest_update_timestamp == next_reward_infos[i].end_time {
            next_reward_infos[i].reward_state = RewardState::Ended as u8;
        }
    }

    self.reward_infos = next_reward_infos;

    #[cfg(feature = ""enable-log"")]
    msg!(
        ""update pool reward info, reward_0_total_emissioned:{}, reward_1_total_emissioned:{}, reward_2_total_emissioned:{}, pool.liquidity:{}"",
        identity(self.reward_infos[0].reward_total_emissioned),
        identity(self.reward_infos[1].reward_total_emissioned),
        identity(self.reward_infos[2].reward_total_emissioned),
        identity(self.liquidity)
    );

    Ok(next_reward_infos)
}","rust
// Calculates the next global reward growth variables based on the given timestamp. 
// The provided timestamp must be greater than or equal to the last updated timestamp.
pub fn update_reward_infos(
    &mut self,
    curr_timestamp: u64,
) -> Result<([RewardInfo; REWARD_NUM])> {
    #[cfg(feature = ""enable-log"")]
    msg!(""current block timestamp:{}"", curr_timestamp);
    
    let mut next_reward_infos = self.reward_infos;
    
    for i in 0..REWARD_NUM {
        let reward_info = &mut next_reward_infos[i];
        
        if !reward_info.initialized() {
            continue;
        }
        
        if curr_timestamp <= reward_info.open_time {
            continue;
        } 
        
        let latest_update_timestamp = curr_timestamp.min(reward_info.end_time);
        
        if self.liquidity != 0 {
            let time_delta = latest_update_timestamp
                .checked_sub(reward_info.last_update_time)
                .unwrap();
                
            let reward_growth_delta = U256::from(time_delta)
                .mul_div_floor( 
                    U256::from(reward_info.emissions_per_second_x64), 
                    U256::from(self.liquidity),
                )
                .unwrap();
                
            reward_info.reward_growth_global_x64 = reward_info
                .reward_growth_global_x64
                .checked_add(reward_growth_delta.as_u128())
                .unwrap();
                
            reward_info.reward_total_emissioned = reward_info
                .reward_total_emissioned
                .checked_add( 
                    U128::from(time_delta)
                        .mul_div_ceil( 
                            U128::from(reward_info.emissions_per_second_x64),
                            U128::from(fixed_point_64::Q64),
                        )
                        .unwrap()
                        .as_u64(),
                )
                .unwrap();
                
            #[cfg(feature = ""enable-log"")]
            msg!(""reward_index:{},latest_update_timestamp:{},reward_info.reward_last_update_time:{},time_delta:{},reward_emission_per_second_x64:{},reward_growth_delta:{},reward_info.reward_growth_global_x64:{}"",
                i, 
                latest_update_timestamp, 
                identity(reward_info.last_update_time), 
                time_delta, 
                identity(reward_info.emissions_per_second_x64), 
                reward_growth_delta, 
                identity(reward_info.reward_growth_global_x64)
            );
        } 
        
        reward_info.last_update_time = latest_update_timestamp;
        
        // update reward state 
        if latest_update_timestamp >= reward_info.open_time && latest_update_timestamp < reward_info.end_time {
            reward_info.reward_state = RewardState::Opening as u8;
        } else if latest_update_timestamp == next_reward_infos[i].end_time {
            next_reward_infos[i].reward_state = RewardState::Ended as u8;
        }
    } 

    self.reward_infos = next_reward_infos;
    
    #[cfg(feature = ""enable-log"")]
    msg!(""update pool reward info, reward_0_total_emissioned:{}, reward_1_total_emissioned:{}, reward_2_total_emissioned:{}, pool.liquidity:{}"",
        identity(self.reward_infos[0].reward_total_emissioned),
        identity(self.reward_infos[1].reward_total_emissioned),
        identity(self.reward_infos[2].reward_total_emissioned),
        identity(self.liquidity)
    );

    Ok(next_reward_infos)
}",Low,Consider changing the code of check_unclaimed_reward to get_unclaimed_reward or replacing mul_div_floor() with mul_div_ceil when calculating reward_total_emissioned,"https://file.notion.so/f/f/97ab6450-64d1-4350-a5cf-a0c0c607f5c4/8464f93a-f2c8-49b8-afb1-5056f4782dfc/Raydium_AMM_V3_Audit_Report.pdf?table=block&id=88f0ad30-c74b-4311-82bb-e6062bf12169&spaceId=97ab6450-64d1-4350-a5cf-a0c0c607f5c4&expirationTimestamp=1743307200000&signature=AsG6ddNcRmbP3N5kADqbWt0rxS4L2XD4jBIhoabbCvM&downloadName=Raydium+AMM+V3+Audit+Report.pdf, https://github.com/raydium-io/raydium-clmm/pull/35/files#diff-37af8671e91d3734626c55422d4530a6dc25c885a582ac9008d2c29a0b0e3804",High